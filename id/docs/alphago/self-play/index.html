<!doctype html>
<html lang="id" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/self-play" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Self-Play | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/id/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/id/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/id/docs/alphago/self-play/"><meta data-rh="true" property="og:locale" content="id"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="id"><meta data-rh="true" name="docsearch:language" content="id"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Self-Play | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Memahami mendalam bagaimana AlphaGo menerobos batas kekuatan manusia melalui self-play"><meta data-rh="true" property="og:description" content="Memahami mendalam bagaimana AlphaGo menerobos batas kekuatan manusia melalui self-play"><link data-rh="true" rel="icon" href="/id/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/id/docs/alphago/self-play/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/self-play/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/self-play/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/self-play/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/self-play/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/self-play/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/self-play/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/self-play/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/self-play/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/self-play/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/self-play/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/id/docs/alphago/"},{"@type":"ListItem","position":2,"name":"Self-Play","item":"https://www.weiqi.kids/id/docs/alphago/self-play"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/id/assets/css/styles.f23bf74b.css">
<script src="/id/assets/js/runtime~main.4e8b45de.js" defer="defer"></script>
<script src="/id/assets/js/main.f6e13202.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/id/img/logo.svg"><div role="region" aria-label="Lewati ke konten utama"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Lewati ke konten utama</a></div><nav aria-label="Utama" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alihkan bilah sisi" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/id/"><div class="navbar__logo"><img src="/id/img/logo.svg" alt="Logo Asosiasi Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/id/img/logo.svg" alt="Logo Asosiasi Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/id/docs/learn/">Belajar Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/id/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/id/docs/animations/">Studio Animasi</a><a class="navbar__item navbar__link" href="/id/docs/tech/">Dokumentasi Teknis</a><a class="navbar__item navbar__link" href="/id/docs/about/">Tentang Kami</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Bahasa Indonesia</a><ul class="dropdown__menu"><li><a href="/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Gulir kembali ke atas" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Bilah sisi dokumentasi" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/id/docs/intro/"><span title="Panduan Pengguna" class="linkLabel_REp1">Panduan Pengguna</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/id/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Ciutkan kategori bilah sisi &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/birth-of-alphago/"><span title="Kelahiran AlphaGo" class="linkLabel_REp1">Kelahiran AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/key-matches/"><span title="Tinjauan Pertandingan Kunci" class="linkLabel_REp1">Tinjauan Pertandingan Kunci</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/move-37/"><span title="Analisis Mendalam &quot;Langkah Ilahi&quot;" class="linkLabel_REp1">Analisis Mendalam &quot;Langkah Ilahi&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/why-go-is-hard/"><span title="Mengapa Go Sulit?" class="linkLabel_REp1">Mengapa Go Sulit?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/traditional-limits/"><span title="Batas Metode Tradisional" class="linkLabel_REp1">Batas Metode Tradisional</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/board-representation/"><span title="Representasi Status Papan" class="linkLabel_REp1">Representasi Status Papan</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/policy-network/"><span title="Penjelasan Detail Policy Network" class="linkLabel_REp1">Penjelasan Detail Policy Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/value-network/"><span title="Penjelasan Detail Value Network" class="linkLabel_REp1">Penjelasan Detail Value Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/input-features/"><span title="Desain Fitur Input" class="linkLabel_REp1">Desain Fitur Input</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/cnn-and-go/"><span title="CNN dan Permainan Go" class="linkLabel_REp1">CNN dan Permainan Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/supervised-learning/"><span title="Tahap Supervised Learning" class="linkLabel_REp1">Tahap Supervised Learning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/reinforcement-intro/"><span title="Pengantar Reinforcement Learning" class="linkLabel_REp1">Pengantar Reinforcement Learning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/id/docs/alphago/self-play/"><span title="Self-Play" class="linkLabel_REp1">Self-Play</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/mcts-neural-combo/"><span title="Kombinasi MCTS dan Neural Network" class="linkLabel_REp1">Kombinasi MCTS dan Neural Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/puct-formula/"><span title="Penjelasan Detail Rumus PUCT" class="linkLabel_REp1">Penjelasan Detail Rumus PUCT</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/alphago-zero/"><span title="Ikhtisar AlphaGo Zero" class="linkLabel_REp1">Ikhtisar AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/dual-head-resnet/"><span title="Dual-Head Network dan Residual Network" class="linkLabel_REp1">Dual-Head Network dan Residual Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/training-from-scratch/"><span title="Proses Pelatihan dari Nol" class="linkLabel_REp1">Proses Pelatihan dari Nol</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/distributed-systems/"><span title="Sistem Terdistribusi dan TPU" class="linkLabel_REp1">Sistem Terdistribusi dan TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/id/docs/alphago/legacy-and-impact/"><span title="Warisan AlphaGo" class="linkLabel_REp1">Warisan AlphaGo</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/id/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Perluas kategori bilah sisi &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/id/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/id/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Perluas kategori bilah sisi &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/id/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Perluas kategori bilah sisi &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Runut navigasi"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Halaman utama" class="breadcrumbs__link" href="/id/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/id/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Self-Play</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">Pada halaman ini</button></div><div class="theme-doc-markdown markdown"><header><h1>Self-Play</h1></header>
<p>Di artikel sebelumnya, kita memperkenalkan konsep dasar reinforcement learning. Sekarang, mari kita eksplorasi salah satu kunci keberhasilan AlphaGo—<strong>Self-Play</strong>.</p>
<p>Ini adalah konsep yang tampak paradoks: <strong>Bagaimana AI bisa menjadi lebih kuat dengan bermain melawan dirinya sendiri?</strong></p>
<p>Jawabannya mendalam sekaligus elegan, melibatkan game theory, dinamika evolusi, dan esensi pembelajaran.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="mengapa-self-play-efektif">Mengapa Self-Play Efektif?<a href="#mengapa-self-play-efektif" class="hash-link" aria-label="Taut langsung ke Mengapa Self-Play Efektif?" title="Taut langsung ke Mengapa Self-Play Efektif?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="penjelasan-intuitif">Penjelasan Intuitif<a href="#penjelasan-intuitif" class="hash-link" aria-label="Taut langsung ke Penjelasan Intuitif" title="Taut langsung ke Penjelasan Intuitif" translate="no">​</a></h3>
<p>Bayangkan Anda adalah seorang pemula Go, berlatih sendirian di pulau terpencil:</p>
<ol>
<li class="">Anda bermain satu permainan, memainkan kedua sisi hitam dan putih sekaligus</li>
<li class="">Setelah permainan selesai, Anda menganalisis langkah mana yang bagus, mana yang buruk</li>
<li class="">Di permainan berikutnya, Anda mencoba menghindari kesalahan sebelumnya</li>
<li class="">Anda mengulangi proses ini jutaan kali</li>
</ol>
<p>Secara intuitif, ini tampak bermasalah:</p>
<ul>
<li class="">Jika level Anda sangat rendah, kedua sisi bermain langkah buruk, apa yang bisa dipelajari?</li>
<li class="">Apakah akan terjebak dalam &quot;keseimbangan yang salah&quot;—kedua sisi bermain langkah salah tapi saling membatalkan?</li>
</ul>
<p>Tetapi sebenarnya, self-play dapat menghasilkan kemajuan berkelanjutan. Alasannya sebagai berikut:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="penemuan-kelemahan-secara-bertahap">Penemuan Kelemahan secara Bertahap<a href="#penemuan-kelemahan-secara-bertahap" class="hash-link" aria-label="Taut langsung ke Penemuan Kelemahan secara Bertahap" title="Taut langsung ke Penemuan Kelemahan secara Bertahap" translate="no">​</a></h3>
<p>Wawasan kunci adalah: <strong>Bahkan jika kedua sisi adalah AI yang sama, hasil setiap permainan tetap mengandung informasi</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Posisi A: AI memilih langkah X, akhirnya menang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Posisi A: AI memilih langkah Y, akhirnya kalah</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">→ Kesimpulan: Di posisi A, X lebih baik dari Y</span><br></span></code></pre></div></div>
<p>Melalui statistik sejumlah besar permainan, AI dapat mempelajari pilihan mana yang lebih baik di setiap posisi. Inilah esensi <strong>policy gradient</strong>: pilihan bagus diperkuat, pilihan buruk ditekan.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="adversarial-learning">Adversarial Learning<a href="#adversarial-learning" class="hash-link" aria-label="Taut langsung ke Adversarial Learning" title="Taut langsung ke Adversarial Learning" translate="no">​</a></h3>
<p>Self-play memiliki properti khusus: <strong>Lawan pelatihan secara otomatis menyesuaikan dengan level Anda</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Siklus pelatihan 1: AI menemukan taktik efektif T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Siklus pelatihan 2: AI sebagai lawan belajar cara mempertahankan T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Siklus pelatihan 3: AI asli dipaksa mencari taktik lebih baik T&#x27;</span><br></span></code></pre></div></div>
<p>Ini membentuk <strong>perlombaan senjata (Arms Race)</strong>, kedua sisi terus menemukan dan mengatasi kelemahan masing-masing.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="perbandingan-dengan-catatan-permainan-manusia">Perbandingan dengan Catatan Permainan Manusia<a href="#perbandingan-dengan-catatan-permainan-manusia" class="hash-link" aria-label="Taut langsung ke Perbandingan dengan Catatan Permainan Manusia" title="Taut langsung ke Perbandingan dengan Catatan Permainan Manusia" translate="no">​</a></h3>
<table><thead><tr><th>Metode Pelatihan</th><th>Kelebihan</th><th>Kekurangan</th></tr></thead><tbody><tr><td><strong>Catatan manusia</strong></td><td>Mempelajari kristalisasi kebijaksanaan manusia</td><td>Terbatas pada level manusia</td></tr><tr><td><strong>Self-play</strong></td><td>Potensi peningkatan tanpa batas</td><td>Mungkin terjebak di optimum lokal</td></tr><tr><td><strong>Kombinasi keduanya</strong></td><td>Mulai cepat + peningkatan berkelanjutan</td><td>Strategi terbaik</td></tr></tbody></table>
<p>AlphaGo versi asli pertama menggunakan catatan manusia untuk supervised learning, kemudian menggunakan self-play untuk reinforcement learning. AlphaGo Zero membuktikan bahwa hanya menggunakan self-play juga dapat mencapai level superhuman.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="perspektif-game-theory">Perspektif Game Theory<a href="#perspektif-game-theory" class="hash-link" aria-label="Taut langsung ke Perspektif Game Theory" title="Taut langsung ke Perspektif Game Theory" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="nash-equilibrium">Nash Equilibrium<a href="#nash-equilibrium" class="hash-link" aria-label="Taut langsung ke Nash Equilibrium" title="Taut langsung ke Nash Equilibrium" translate="no">​</a></h3>
<p>Dalam game theory, <strong>Nash Equilibrium</strong> adalah keadaan stabil: dalam keadaan ini, tidak ada pemain yang memiliki motivasi untuk mengubah strategi secara sepihak.</p>
<p>Untuk <strong>zero-sum, perfect information game</strong> seperti Go, Nash equilibrium memiliki makna khusus:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></msub><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^* = \arg\max_\pi \min_{\pi&#x27;} V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>Di mana <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> adalah nilai ekspektasi ketika strategi <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> melawan strategi <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\pi&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
<p>Inilah <strong>Prinsip Minimax</strong> yang terkenal: Strategi terbaik adalah yang berkinerja terbaik dalam situasi terburuk.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="self-play-dan-nash-equilibrium">Self-Play dan Nash Equilibrium<a href="#self-play-dan-nash-equilibrium" class="hash-link" aria-label="Taut langsung ke Self-Play dan Nash Equilibrium" title="Taut langsung ke Self-Play dan Nash Equilibrium" translate="no">​</a></h3>
<p>Secara teoretis, jika self-play dapat konvergen, ia harus konvergen ke Nash equilibrium. Untuk permainan deterministik seperti Go, Nash equilibrium adalah <strong>permainan sempurna</strong>.</p>
<p>Tetapi ruang state Go terlalu besar (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>170</mn></msup></mrow><annotation encoding="application/x-tex">10^{170}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">170</span></span></span></span></span></span></span></span></span></span></span></span>), kita tidak mungkin menemukan Nash equilibrium yang sebenarnya. Self-play sebenarnya <strong>mendekati</strong> equilibrium ini.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="fictitious-play">Fictitious Play<a href="#fictitious-play" class="hash-link" aria-label="Taut langsung ke Fictitious Play" title="Taut langsung ke Fictitious Play" translate="no">​</a></h3>
<p>Self-play terkait dengan konsep <strong>fictitious play</strong> dalam game theory:</p>
<ol>
<li class="">Setiap pemain mengamati strategi historis lawan</li>
<li class="">Menghitung distribusi rata-rata strategi lawan</li>
<li class="">Memilih respons terbaik terhadap distribusi rata-rata ini</li>
</ol>
<p>Dalam kondisi tertentu, fictitious play dapat dibuktikan akan konvergen ke Nash equilibrium.</p>
<p>Self-play AlphaGo dapat dilihat sebagai implementasi neural network dari konsep ini.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="mekanisme-self-play">Mekanisme Self-Play<a href="#mekanisme-self-play" class="hash-link" aria-label="Taut langsung ke Mekanisme Self-Play" title="Taut langsung ke Mekanisme Self-Play" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alur-dasar">Alur Dasar<a href="#alur-dasar" class="hash-link" aria-label="Taut langsung ke Alur Dasar" title="Taut langsung ke Alur Dasar" translate="no">​</a></h3>
<p>Alur self-play AlphaGo:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Algoritma: Self-Play Training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Inisialisasi: Policy Network π_θ (dapat dimulai dari supervised learning atau inisialisasi acak)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Ulangi langkah berikut hingga konvergen:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Generate data permainan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Untuk i = 1 hingga N (paralel):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. Gunakan policy saat ini π_θ untuk satu permainan self-play</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Kumpulkan trajectory: τ_i = (s_0, a_0, r_1, s_1, a_1, ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Catat hasil akhir z_i ∈ {-1, +1}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Update policy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Hitung policy gradient:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ∇J = (1/N) Σ_i Σ_t ∇_θ log π_θ(a_t|s_t) · z_i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Update parameter: θ ← θ + α · ∇J</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Update value network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Latih Value Network dengan pasangan (s, z)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Minimalkan: L = E[(V_φ(s) - z)²]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Opsional: Evaluasi dan simpan checkpoint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Biarkan policy baru melawan versi lama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Jika win rate &gt; 55%, update pool lawan</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="generasi-data-pelatihan">Generasi Data Pelatihan<a href="#generasi-data-pelatihan" class="hash-link" aria-label="Taut langsung ke Generasi Data Pelatihan" title="Taut langsung ke Generasi Data Pelatihan" translate="no">​</a></h3>
<p>Setiap self-play menghasilkan <strong>trajectory</strong>:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, s_1, a_1, \ldots, s_T, z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)</span></span></span></span></p>
<p>Di mana:</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: State papan di langkah waktu <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: Tindakan yang dipilih di langkah waktu <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span>: Hasil akhir (+1 menang, -1 kalah)</li>
</ul>
<p>Satu permainan 200 langkah menghasilkan 200 sampel pelatihan. Ratusan ribu self-play per hari, jumlah data pelatihan sangat besar.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="update-policy">Update Policy<a href="#update-policy" class="hash-link" aria-label="Taut langsung ke Update Policy" title="Taut langsung ke Update Policy" translate="no">​</a></h3>
<p>Menggunakan policy gradient untuk update Policy Network:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>z</mi><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \cdot \nabla_\theta \mathbb{E}\left[\sum_t \log \pi_\theta(a_t|s_t) \cdot z\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1308em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose delimcenter" style="top:0em">]</span></span></span></span></span></p>
<p>Efek update ini:</p>
<ul>
<li class="">Jika akhirnya menang (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = +1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>), tingkatkan probabilitas semua langkah</li>
<li class="">Jika akhirnya kalah (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = -1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>), kurangi probabilitas semua langkah</li>
</ul>
<p>Ini terlihat kasar—permainan yang menang mungkin juga memiliki langkah buruk, permainan yang kalah mungkin juga memiliki langkah bagus. Tetapi melalui statistik sejumlah besar permainan, &quot;noise&quot; ini akan dirata-ratakan, langkah yang benar-benar bagus akan diidentifikasi.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pelatihan-value-network">Pelatihan Value Network<a href="#pelatihan-value-network" class="hash-link" aria-label="Taut langsung ke Pelatihan Value Network" title="Taut langsung ke Pelatihan Value Network" translate="no">​</a></h3>
<p>Value Network menggunakan <strong>regression</strong> untuk pelatihan:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>←</mo><mi>ϕ</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ϕ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>z</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\phi \leftarrow \phi - \beta \cdot \nabla_\phi \mathbb{E}\left[(V_\phi(s) - z)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>Ini membuat Value Network belajar memprediksi: Mulai dari posisi saat ini, berapa probabilitas menang akhirnya?</p>
<p>Peran Value Network adalah:</p>
<ol>
<li class="">Menyediakan evaluasi leaf node di MCTS</li>
<li class="">Sebagai baseline untuk policy gradient</li>
<li class="">Langsung digunakan untuk evaluasi posisi</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="pentingnya-randomisasi">Pentingnya Randomisasi<a href="#pentingnya-randomisasi" class="hash-link" aria-label="Taut langsung ke Pentingnya Randomisasi" title="Taut langsung ke Pentingnya Randomisasi" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="menghindari-siklus-deterministik">Menghindari Siklus Deterministik<a href="#menghindari-siklus-deterministik" class="hash-link" aria-label="Taut langsung ke Menghindari Siklus Deterministik" title="Taut langsung ke Menghindari Siklus Deterministik" translate="no">​</a></h3>
<p>Jika self-play sepenuhnya deterministik, mungkin terjebak dalam siklus:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Strategi A selalu memainkan pembukaan tetap</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Strategi A melawan strategi A selalu menghasilkan permainan yang sama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Hanya satu permainan yang dipelajari berulang kali</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">AI tidak dapat mengeksplorasi kemungkinan lain</span><br></span></code></pre></div></div>
<p>Inilah mengapa <strong>randomisasi</strong> sangat penting dalam self-play.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="sumber-randomisasi">Sumber Randomisasi<a href="#sumber-randomisasi" class="hash-link" aria-label="Taut langsung ke Sumber Randomisasi" title="Taut langsung ke Sumber Randomisasi" translate="no">​</a></h3>
<p>Cara AlphaGo memperkenalkan randomisasi dalam self-play:</p>
<p><strong>1. Policy network itu sendiri stokastik</strong></p>
<p>Policy Network menghasilkan distribusi probabilitas, bukan pilihan deterministik:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a \sim \pi_\theta(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></p>
<p>Posisi yang sama, setiap kali mungkin memilih langkah berbeda.</p>
<p><strong>2. Parameter suhu</strong></p>
<p>Menggunakan suhu (temperature) lebih tinggi saat pelatihan untuk meningkatkan keragaman:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow><mrow><msub><mo>∑</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\pi_\tau(a|s) = \frac{\pi_\theta(a|s)^{1/\tau}}{\sum_{a&#x27;} \pi_\theta(a&#x27;|s)^{1/\tau}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7721em;vertical-align:-0.6104em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1617em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2854em"><span style="top:-2.2854em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.6068em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em"><span style="top:-2.8496em;margin-right:0.1em"><span class="pstrut" style="height:2.5556em"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667em"><span style="top:-2.9667em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6104em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: Lebih acak, lebih banyak exploration</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: Lebih deterministik, lebih banyak exploitation</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: Distribusi asli</li>
</ul>
<p><strong>3. Dirichlet Noise</strong></p>
<p>AlphaGo Zero menambahkan Dirichlet noise ke prior probability di root node saat self-play:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><mo>⋅</mo><msub><mi>η</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">P(s, a) = (1 - \varepsilon) \cdot \pi_\theta(a|s) + \varepsilon \cdot \eta_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>Di mana <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>∼</mo><mtext>Dir</mtext><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\eta \sim \text{Dir}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span> (untuk 361 tindakan Go).</p>
<p>Ini memastikan bahkan langkah dengan probabilitas sangat rendah memiliki kesempatan untuk dieksplorasi.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="metode-pool">Metode Pool<a href="#metode-pool" class="hash-link" aria-label="Taut langsung ke Metode Pool" title="Taut langsung ke Metode Pool" translate="no">​</a></h3>
<p>Cara lain meningkatkan keragaman adalah mempertahankan <strong>pool</strong>:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Pool = [π_1, π_2, π_3, ..., π_k] (versi strategi berbeda)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Setiap permainan:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Pilih lawan secara acak dari pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Bermain melawan lawan tersebut</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Update strategi saat ini dengan hasil</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Secara berkala tambahkan strategi yang diperbaiki ke pool</span><br></span></code></pre></div></div>
<p>Manfaat metode ini:</p>
<ul>
<li class=""><strong>Keragaman</strong>: Lawan dengan gaya berbeda</li>
<li class=""><strong>Stabilitas</strong>: Menghindari overfitting ke lawan tertentu</li>
<li class=""><strong>Robustness</strong>: Belajar menghadapi berbagai strategi</li>
</ul>
<p>AlphaGo versi asli dan AlphaGo Zero keduanya menggunakan teknik serupa.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="kurva-pertumbuhan-kekuatan">Kurva Pertumbuhan Kekuatan<a href="#kurva-pertumbuhan-kekuatan" class="hash-link" aria-label="Taut langsung ke Kurva Pertumbuhan Kekuatan" title="Taut langsung ke Kurva Pertumbuhan Kekuatan" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="sistem-rating-elo">Sistem Rating Elo<a href="#sistem-rating-elo" class="hash-link" aria-label="Taut langsung ke Sistem Rating Elo" title="Taut langsung ke Sistem Rating Elo" translate="no">​</a></h3>
<p>Untuk melacak perubahan kekuatan AI, AlphaGo menggunakan <strong>Sistem Rating Elo</strong>.</p>
<p>Prinsip dasar sistem Elo:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>A menang</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>B</mi></msub><mo>−</mo><msub><mi>R</mi><mi>A</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>400</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{A menang}) = \frac{1}{1 + 10^{(R_B - R_A)/400}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">A menang</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3331em;vertical-align:-0.488em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.5703em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8853em"><span style="top:-2.8853em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight">A</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/400</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.488em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>Di mana <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">R_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> dan <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">R_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> adalah skor Elo kedua pihak.</p>
<ul>
<li class="">Selisih 200: Yang lebih kuat diharapkan menang 75%</li>
<li class="">Selisih 400: Yang lebih kuat diharapkan menang 90%</li>
<li class="">Selisih 800: Yang lebih kuat diharapkan menang 99%</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pertumbuhan-kekuatan-alphago">Pertumbuhan Kekuatan AlphaGo<a href="#pertumbuhan-kekuatan-alphago" class="hash-link" aria-label="Taut langsung ke Pertumbuhan Kekuatan AlphaGo" title="Taut langsung ke Pertumbuhan Kekuatan AlphaGo" translate="no">​</a></h3>
<p>Mari visualisasikan pertumbuhan kekuatan berbagai versi AlphaGo:</p>
<div>載入中...</div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="analisis-kecepatan-pertumbuhan">Analisis Kecepatan Pertumbuhan<a href="#analisis-kecepatan-pertumbuhan" class="hash-link" aria-label="Taut langsung ke Analisis Kecepatan Pertumbuhan" title="Taut langsung ke Analisis Kecepatan Pertumbuhan" translate="no">​</a></h3>
<p>Dari kurva dapat diamati beberapa fenomena menarik:</p>
<p><strong>1. Pertumbuhan cepat di awal</strong></p>
<p>Dalam beberapa jam pertama pelatihan, AI mempelajari aturan dasar dan taktik sederhana. Ini adalah fase <strong>buah yang mudah dipetik</strong>—terlalu banyak kesalahan jelas yang dapat diperbaiki.</p>
<p><strong>2. Pertumbuhan stabil di tengah</strong></p>
<p>Setelah kesalahan dasar dihilangkan, AI mulai mempelajari taktik dan joseki yang lebih halus. Kecepatan pertumbuhan melambat, tetapi tetap stabil.</p>
<p><strong>3. Pertumbuhan melambat di akhir</strong></p>
<p>Ketika AI sudah sangat kuat, peningkatan lebih lanjut menjadi sulit. Mungkin perlu menemukan strategi yang sepenuhnya baru, bukan hanya memperbaiki kesalahan.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="momen-melampaui-manusia">Momen Melampaui Manusia<a href="#momen-melampaui-manusia" class="hash-link" aria-label="Taut langsung ke Momen Melampaui Manusia" title="Taut langsung ke Momen Melampaui Manusia" translate="no">​</a></h3>
<p>Milestone kunci dalam kurva pelatihan AlphaGo:</p>
<table><thead><tr><th>Milestone</th><th>Setara dengan</th><th>Waktu Pencapaian</th></tr></thead><tbody><tr><td>Melampaui amatir kuat</td><td>Elo ~2700</td><td>Sekitar 3 jam</td></tr><tr><td>Melampaui Fan Hui</td><td>Elo ~3500</td><td>Sekitar 36 jam</td></tr><tr><td>Melampaui Lee Sedol</td><td>Elo ~4500</td><td>Sekitar 60 jam</td></tr><tr><td>Melampaui AlphaGo asli</td><td>Elo ~5000</td><td>Sekitar 72 jam</td></tr></tbody></table>
<p>Angka-angka ini (dari AlphaGo Zero) mengejutkan: <strong>AI melampaui kebijaksanaan Go ribuan tahun manusia dalam 3 hari dari nol</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="analisis-konvergensi">Analisis Konvergensi<a href="#analisis-konvergensi" class="hash-link" aria-label="Taut langsung ke Analisis Konvergensi" title="Taut langsung ke Analisis Konvergensi" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="apakah-self-play-konvergen">Apakah Self-Play Konvergen?<a href="#apakah-self-play-konvergen" class="hash-link" aria-label="Taut langsung ke Apakah Self-Play Konvergen?" title="Taut langsung ke Apakah Self-Play Konvergen?" translate="no">​</a></h3>
<p>Ini adalah pertanyaan teoretis penting. Jawaban singkatnya adalah: <strong>Dalam kondisi tertentu ya, tetapi Go terlalu kompleks, kita tidak dapat membuktikannya secara ketat</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="jaminan-teoretis">Jaminan Teoretis<a href="#jaminan-teoretis" class="hash-link" aria-label="Taut langsung ke Jaminan Teoretis" title="Taut langsung ke Jaminan Teoretis" translate="no">​</a></h3>
<p>Untuk permainan yang lebih sederhana (seperti tic-tac-toe), dapat dibuktikan:</p>
<ol>
<li class=""><strong>Eksistensi</strong>: Nash equilibrium ada (Teorema Minimax)</li>
<li class=""><strong>Konvergensi</strong>: Algoritma tertentu (seperti fictitious play) akan konvergen ke Nash equilibrium</li>
</ol>
<p>Untuk Go, kita tidak memiliki jaminan konvergensi yang ketat, tetapi bukti eksperimental menunjukkan:</p>
<ul>
<li class="">Kekuatan terus meningkat</li>
<li class="">Tidak ada osilasi atau degradasi yang jelas</li>
<li class="">Kekuatan akhir melampaui semua manusia yang dikenal</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="mode-kegagalan-yang-mungkin">Mode Kegagalan yang Mungkin<a href="#mode-kegagalan-yang-mungkin" class="hash-link" aria-label="Taut langsung ke Mode Kegagalan yang Mungkin" title="Taut langsung ke Mode Kegagalan yang Mungkin" translate="no">​</a></h3>
<p>Masalah yang mungkin ditemui self-play:</p>
<p><strong>1. Strategy Cycling</strong></p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Strategi A mengalahkan strategi B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Strategi B mengalahkan strategi C</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Strategi C mengalahkan strategi A</span><br></span></code></pre></div></div>
<p>Ini memang terjadi di beberapa permainan (seperti batu gunting kertas). Tetapi Go memiliki kompleksitas yang cukup, siklus murni seperti ini tampaknya tidak terjadi.</p>
<p><strong>2. Overfitting ke Diri Sendiri</strong></p>
<p>AI mungkin mempelajari strategi yang hanya ditargetkan untuk gaya sendiri, dan tidak dapat menghadapi lawan dengan gaya berbeda. Inilah mengapa AlphaGo bermain melawan berbagai versi dirinya sendiri, dan akhirnya diuji dengan pemain manusia.</p>
<p><strong>3. Optimum Lokal</strong></p>
<p>AI mungkin terjebak di optimum lokal—strategi yang &quot;cukup bagus tapi bukan terbaik&quot;. Randomisasi dan banyak permainan membantu menghindari masalah ini.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pengamatan-aktual">Pengamatan Aktual<a href="#pengamatan-aktual" class="hash-link" aria-label="Taut langsung ke Pengamatan Aktual" title="Taut langsung ke Pengamatan Aktual" translate="no">​</a></h3>
<p>Dari proses pelatihan AlphaGo diamati:</p>
<ol>
<li class=""><strong>Kemajuan berkelanjutan</strong>: Skor Elo terus naik seiring pelatihan</li>
<li class=""><strong>Tidak ada degradasi</strong>: Tidak ada situasi kekuatan turun tiba-tiba</li>
<li class=""><strong>Evolusi gaya</strong>: Gaya bermain AI berubah secara bertahap seiring pelatihan</li>
<li class=""><strong>Penemuan joseki baru</strong>: AI menemukan pembukaan dan taktik yang belum pernah digunakan manusia</li>
</ol>
<p>Pengamatan ini menunjukkan bahwa meskipun kita tidak memiliki jaminan teoretis, self-play memang efektif dalam praktik.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="detail-implementasi">Detail Implementasi<a href="#detail-implementasi" class="hash-link" aria-label="Taut langsung ke Detail Implementasi" title="Taut langsung ke Detail Implementasi" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="parallel-self-play">Parallel Self-Play<a href="#parallel-self-play" class="hash-link" aria-label="Taut langsung ke Parallel Self-Play" title="Taut langsung ke Parallel Self-Play" translate="no">​</a></h3>
<p>Untuk mempercepat pelatihan, AlphaGo menggunakan self-play paralel skala besar:</p>
<!-- -->
<p><strong>Keputusan desain kunci</strong>:</p>
<ul>
<li class=""><strong>Synchronous vs Asynchronous</strong>: AlphaGo menggunakan update asynchronous, Worker tidak perlu menunggu satu sama lain</li>
<li class=""><strong>Frekuensi update</strong>: Update parameter setelah menyelesaikan N permainan</li>
<li class=""><strong>Pemilihan lawan</strong>: Pilih secara acak salah satu dari beberapa versi terakhir sebagai lawan</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="strategi-checkpoint">Strategi Checkpoint<a href="#strategi-checkpoint" class="hash-link" aria-label="Taut langsung ke Strategi Checkpoint" title="Taut langsung ke Strategi Checkpoint" translate="no">​</a></h3>
<p>Simpan checkpoint model secara berkala untuk:</p>
<ol>
<li class=""><strong>Pool</strong>: Mempertahankan versi lawan yang berbeda</li>
<li class=""><strong>Evaluasi</strong>: Melacak perubahan kekuatan</li>
<li class=""><strong>Pemulihan kegagalan</strong>: Dapat melanjutkan jika pelatihan terputus</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Pseudocode</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">training_loop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> iteration </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_iterations</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Generate data permainan</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trajectories </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parallel_self_play</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_games</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Update policy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update_policy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">trajectories</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Evaluasi dan simpan secara berkala</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> iteration </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate_against_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            save_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> elo</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> elo </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> best_elo</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                add_to_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                best_elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> elo</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="kebutuhan-sumber-daya-pelatihan">Kebutuhan Sumber Daya Pelatihan<a href="#kebutuhan-sumber-daya-pelatihan" class="hash-link" aria-label="Taut langsung ke Kebutuhan Sumber Daya Pelatihan" title="Taut langsung ke Kebutuhan Sumber Daya Pelatihan" translate="no">​</a></h3>
<p>Skala pelatihan AlphaGo mengesankan:</p>
<table><thead><tr><th>Versi</th><th>Hardware</th><th>Waktu Pelatihan</th><th>Jumlah Self-Play</th></tr></thead><tbody><tr><td>AlphaGo Fan</td><td>176 GPU</td><td>Beberapa bulan</td><td>~30M</td></tr><tr><td>AlphaGo Lee</td><td>48 TPU</td><td>Beberapa minggu</td><td>~30M</td></tr><tr><td>AlphaGo Zero</td><td>4 TPU</td><td>3 hari</td><td>~5M</td></tr><tr><td>AlphaGo Zero (versi 40 hari)</td><td>4 TPU</td><td>40 hari</td><td>~30M</td></tr></tbody></table>
<p>Perhatikan AlphaGo Zero mencapai kekuatan lebih tinggi dengan hardware lebih sedikit dan waktu lebih singkat—ini adalah peningkatan efisiensi algoritma.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pengaturan-hyperparameter">Pengaturan Hyperparameter<a href="#pengaturan-hyperparameter" class="hash-link" aria-label="Taut langsung ke Pengaturan Hyperparameter" title="Taut langsung ke Pengaturan Hyperparameter" translate="no">​</a></h3>
<p>Beberapa hyperparameter kunci:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Pengaturan self-play</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NUM_PARALLEL_GAMES </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Jumlah permainan paralel</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GAMES_PER_ITERATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">25000</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Permainan per iterasi</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MCTS_SIMULATIONS </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1600</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Simulasi MCTS per langkah</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pengaturan pelatihan</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BATCH_SIZE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Ukuran batch pelatihan</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LEARNING_RATE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># Learning rate awal</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">L2_REGULARIZATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># Weight decay</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pengaturan exploration</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TEMPERATURE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Suhu untuk 30 langkah pertama</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DIRICHLET_ALPHA </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.03</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># Parameter Dirichlet noise</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EXPLORATION_FRACTION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Rasio noise</span><br></span></code></pre></div></div>
<p>Hyperparameter ini disetel melalui banyak eksperimen dan memiliki dampak signifikan pada efek pelatihan.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="varian-self-play">Varian Self-Play<a href="#varian-self-play" class="hash-link" aria-label="Taut langsung ke Varian Self-Play" title="Taut langsung ke Varian Self-Play" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-versi-asli">AlphaGo Versi Asli<a href="#alphago-versi-asli" class="hash-link" aria-label="Taut langsung ke AlphaGo Versi Asli" title="Taut langsung ke AlphaGo Versi Asli" translate="no">​</a></h3>
<p>Alur pelatihan AlphaGo versi asli:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Supervised Learning (SL): Belajar dari catatan manusia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Menghasilkan SL Policy Network (π_SL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Reinforcement Learning (RL): Self-play</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Inisialisasi π_RL = π_SL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Pool lawan = [π_SL]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Ulangi:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. π_RL bermain melawan strategi di pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Update π_RL dengan policy gradient</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Jika π_RL menjadi lebih kuat, tambahkan ke pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Menghasilkan RL Policy Network (π_RL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Pelatihan Value Network:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Generate posisi dengan self-play π_RL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Latih V(s) untuk memprediksi win rate</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero">AlphaGo Zero<a href="#alphago-zero" class="hash-link" aria-label="Taut langsung ke AlphaGo Zero" title="Taut langsung ke AlphaGo Zero" translate="no">​</a></h3>
<p>AlphaGo Zero menyederhanakan alur ini:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Pure self-play (tanpa data manusia)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Inisialisasi jaringan acak f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Ulangi:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. Self-play dengan MCTS + f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Latih policy head dan value head secara bersamaan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Update f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Satu jaringan menghasilkan policy dan value sekaligus</span><br></span></code></pre></div></div>
<p>Perbaikan kunci:</p>
<ul>
<li class=""><strong>Tanpa data manusia</strong>: Mulai dari nol</li>
<li class=""><strong>Satu jaringan</strong>: Policy dan value berbagi fitur</li>
<li class=""><strong>Pelatihan lebih ringkas</strong>: End-to-end learning</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphazero">AlphaZero<a href="#alphazero" class="hash-link" aria-label="Taut langsung ke AlphaZero" title="Taut langsung ke AlphaZero" translate="no">​</a></h3>
<p>AlphaZero lebih lanjut menggeneralisasi:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Algoritma yang sama, permainan berbeda:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Go: Mencapai level melampaui AlphaGo Zero</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Catur: Melampaui Stockfish</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Shogi: Melampaui Elmo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Satu-satunya bagian spesifik permainan: Encoding aturan</span><br></span></code></pre></div></div>
<p>Ini membuktikan bahwa self-play adalah <strong>paradigma pembelajaran universal</strong>, tidak terbatas pada Go.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="apa-yang-dipelajari-manusia">Apa yang Dipelajari Manusia?<a href="#apa-yang-dipelajari-manusia" class="hash-link" aria-label="Taut langsung ke Apa yang Dipelajari Manusia?" title="Taut langsung ke Apa yang Dipelajari Manusia?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="joseki-baru-yang-ditemukan-ai">Joseki Baru yang Ditemukan AI<a href="#joseki-baru-yang-ditemukan-ai" class="hash-link" aria-label="Taut langsung ke Joseki Baru yang Ditemukan AI" title="Taut langsung ke Joseki Baru yang Ditemukan AI" translate="no">​</a></h3>
<p>Self-play menghasilkan banyak langkah yang belum pernah digunakan manusia:</p>
<p><strong>1. Inovasi pembukaan</strong></p>
<p>Beberapa pembukaan yang disukai AlphaGo:</p>
<ul>
<li class="">Invasi 3-3: Menginvasi sudut di awal</li>
<li class="">Langkah tinggi: Secara tradisional dianggap &quot;tidak stabil&quot;</li>
<li class="">Variasi avalanche besar: Manusia menganggap kompleks dan sulit dihitung</li>
</ul>
<p><strong>2. Penilaian situasi baru</strong></p>
<p>Evaluasi AI terhadap beberapa posisi sangat berbeda dari manusia:</p>
<ul>
<li class="">Beberapa bentuk yang terlihat &quot;tipis&quot; sebenarnya sangat solid</li>
<li class="">Nilai beberapa &quot;tebal&quot; dilebih-lebihkan</li>
<li class="">Evaluasi ulang terhadap &quot;sente&quot; dan &quot;gote&quot;</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="dampak-pada-go-manusia">Dampak pada Go Manusia<a href="#dampak-pada-go-manusia" class="hash-link" aria-label="Taut langsung ke Dampak pada Go Manusia" title="Taut langsung ke Dampak pada Go Manusia" translate="no">​</a></h3>
<p>Setelah AlphaGo, Go profesional mengalami perubahan signifikan:</p>
<ol>
<li class=""><strong>Diversifikasi pembukaan</strong>: Pemain profesional mulai menggunakan pembukaan baru yang ditemukan AI</li>
<li class=""><strong>Perubahan metode pelatihan</strong>: AI menjadi alat pelatihan utama pemain profesional</li>
<li class=""><strong>Pemikiran ulang teori</strong>: Banyak &quot;teori&quot; tradisional dipertanyakan dan diperbaiki</li>
<li class=""><strong>Estetika baru</strong>: Mulai mengapresiasi gaya Go AI</li>
</ol>
<p>Ke Jie berkata setelah kalah dari AlphaGo:</p>
<blockquote>
<p>&quot;AlphaGo membuat saya mengenal ulang Go. Dulu saya pikir manusia memahami Go, sekarang saya tahu kita hanya menyentuh permukaan.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="refleksi-filosofis">Refleksi Filosofis<a href="#refleksi-filosofis" class="hash-link" aria-label="Taut langsung ke Refleksi Filosofis" title="Taut langsung ke Refleksi Filosofis" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="esensi-pembelajaran">Esensi Pembelajaran<a href="#esensi-pembelajaran" class="hash-link" aria-label="Taut langsung ke Esensi Pembelajaran" title="Taut langsung ke Esensi Pembelajaran" translate="no">​</a></h3>
<p>Self-play mengajukan pertanyaan mendalam tentang pembelajaran:</p>
<p><strong>Dari mana pengetahuan berasal?</strong></p>
<ul>
<li class="">Pembelajaran manusia bergantung pada informasi eksternal (guru, buku, pengalaman)</li>
<li class="">AI self-play hanya memiliki aturan, tanpa pengetahuan eksternal</li>
<li class="">Tetapi tetap dapat &quot;menemukan&quot; pengetahuan—dari mana pengetahuan ini berasal?</li>
</ul>
<p>Jawabannya mungkin: <strong>Pengetahuan tersirat dalam aturan dan struktur permainan</strong>. Aturan Go mendefinisikan apa itu langkah bagus, apa itu langkah buruk, self-play hanya mengungkap struktur tersembunyi ini.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="kreativitas-dan-penemuan">Kreativitas dan Penemuan<a href="#kreativitas-dan-penemuan" class="hash-link" aria-label="Taut langsung ke Kreativitas dan Penemuan" title="Taut langsung ke Kreativitas dan Penemuan" translate="no">​</a></h3>
<p>Ketika AI memainkan &quot;langkah ilahi&quot; (Move 37), apakah itu kreasi atau penemuan?</p>
<p>Satu pandangan: Langkah itu selalu &quot;ada&quot; dalam aturan Go, AI hanya &quot;menemukan&quot;-nya.
Pandangan lain: AI &quot;menciptakan&quot; langkah itu, karena tidak ada yang (termasuk AI itu sendiri) tahu sebelumnya.</p>
<p>Pertanyaan ini tidak memiliki jawaban standar, tetapi menantang pemahaman tradisional kita tentang kreativitas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="posisi-kecerdasan-manusia">Posisi Kecerdasan Manusia<a href="#posisi-kecerdasan-manusia" class="hash-link" aria-label="Taut langsung ke Posisi Kecerdasan Manusia" title="Taut langsung ke Posisi Kecerdasan Manusia" translate="no">​</a></h3>
<p>Jika AI dapat dari nol, melalui self-play melampaui kebijaksanaan ribuan tahun manusia, apa artinya bagi manusia?</p>
<p>Pandangan optimis:</p>
<ul>
<li class="">AI adalah alat yang diciptakan manusia</li>
<li class="">Penemuan AI dapat meningkatkan pemahaman manusia</li>
<li class="">Manusia dapat berkolaborasi dengan AI, mencapai level lebih tinggi</li>
</ul>
<p>Pandangan hati-hati:</p>
<ul>
<li class="">Di beberapa bidang, komputasi murni mungkin melampaui intuisi manusia</li>
<li class="">Perlu memikirkan ulang nilai &quot;keahlian profesional&quot;</li>
<li class="">Metode pendidikan dan pelatihan mungkin perlu berubah</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="korespondensi-animasi">Korespondensi Animasi<a href="#korespondensi-animasi" class="hash-link" aria-label="Taut langsung ke Korespondensi Animasi" title="Taut langsung ke Korespondensi Animasi" translate="no">​</a></h2>
<p>Konsep inti dalam artikel ini dan nomor animasi terkait:</p>
<table><thead><tr><th>Nomor</th><th>Konsep</th><th>Korespondensi Fisika/Matematika</th></tr></thead><tbody><tr><td>E5</td><td>Siklus self-play</td><td>Iterasi titik tetap</td></tr><tr><td>E6</td><td>Evolusi strategi</td><td>Dinamika evolusi</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="ringkasan">Ringkasan<a href="#ringkasan" class="hash-link" aria-label="Taut langsung ke Ringkasan" title="Taut langsung ke Ringkasan" translate="no">​</a></h2>
<p>Self-play adalah salah satu teknologi kunci keberhasilan AlphaGo. Kita telah mempelajari:</p>
<ol>
<li class=""><strong>Mengapa efektif</strong>: Adversarial learning, penemuan kelemahan bertahap</li>
<li class=""><strong>Mekanisme</strong>: Pengumpulan trajectory, policy gradient, pelatihan value network</li>
<li class=""><strong>Randomisasi</strong>: Parameter suhu, Dirichlet noise, pool</li>
<li class=""><strong>Pertumbuhan kekuatan</strong>: Sistem Elo, analisis kurva pertumbuhan</li>
<li class=""><strong>Konvergensi</strong>: Jaminan teoretis dan pengamatan aktual</li>
<li class=""><strong>Detail implementasi</strong>: Pelatihan paralel, strategi checkpoint, hyperparameter</li>
</ol>
<p>Di artikel berikutnya, kita akan mengeksplorasi bagaimana AlphaGo menggabungkan neural network dengan MCTS, memanfaatkan kelebihan keduanya.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="bacaan-lanjutan">Bacaan Lanjutan<a href="#bacaan-lanjutan" class="hash-link" aria-label="Taut langsung ke Bacaan Lanjutan" title="Taut langsung ke Bacaan Lanjutan" translate="no">​</a></h2>
<ul>
<li class=""><strong>Artikel berikutnya</strong>: <a class="" href="/id/docs/alphago/mcts-neural-combo/">Kombinasi MCTS dan Neural Network</a> — Kombinasi sempurna intuisi dan penalaran</li>
<li class=""><strong>Artikel sebelumnya</strong>: <a class="" href="/id/docs/alphago/reinforcement-intro/">Pengantar Reinforcement Learning</a> — Konsep dasar reinforcement learning</li>
<li class=""><strong>Terkait</strong>: <a class="" href="/id/docs/alphago/alphago-zero/">Gambaran AlphaGo Zero</a> — Terobosan dari nol</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referensi">Referensi<a href="#referensi" class="hash-link" aria-label="Taut langsung ke Referensi" title="Taut langsung ke Referensi" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">Heinrich, J., &amp; Silver, D. (2016). &quot;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.&quot; <em>arXiv preprint</em>.</li>
<li class="">Lanctot, M., et al. (2017). &quot;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/13-self-play.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Sunting halaman ini</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Halaman dokumentasi"><a class="pagination-nav__link pagination-nav__link--prev" href="/id/docs/alphago/reinforcement-intro/"><div class="pagination-nav__sublabel">Sebelum</div><div class="pagination-nav__label">Pengantar Reinforcement Learning</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/id/docs/alphago/mcts-neural-combo/"><div class="pagination-nav__sublabel">Berikut</div><div class="pagination-nav__label">Kombinasi MCTS dan Neural Network</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#mengapa-self-play-efektif" class="table-of-contents__link toc-highlight">Mengapa Self-Play Efektif?</a><ul><li><a href="#penjelasan-intuitif" class="table-of-contents__link toc-highlight">Penjelasan Intuitif</a></li><li><a href="#penemuan-kelemahan-secara-bertahap" class="table-of-contents__link toc-highlight">Penemuan Kelemahan secara Bertahap</a></li><li><a href="#adversarial-learning" class="table-of-contents__link toc-highlight">Adversarial Learning</a></li><li><a href="#perbandingan-dengan-catatan-permainan-manusia" class="table-of-contents__link toc-highlight">Perbandingan dengan Catatan Permainan Manusia</a></li></ul></li><li><a href="#perspektif-game-theory" class="table-of-contents__link toc-highlight">Perspektif Game Theory</a><ul><li><a href="#nash-equilibrium" class="table-of-contents__link toc-highlight">Nash Equilibrium</a></li><li><a href="#self-play-dan-nash-equilibrium" class="table-of-contents__link toc-highlight">Self-Play dan Nash Equilibrium</a></li><li><a href="#fictitious-play" class="table-of-contents__link toc-highlight">Fictitious Play</a></li></ul></li><li><a href="#mekanisme-self-play" class="table-of-contents__link toc-highlight">Mekanisme Self-Play</a><ul><li><a href="#alur-dasar" class="table-of-contents__link toc-highlight">Alur Dasar</a></li><li><a href="#generasi-data-pelatihan" class="table-of-contents__link toc-highlight">Generasi Data Pelatihan</a></li><li><a href="#update-policy" class="table-of-contents__link toc-highlight">Update Policy</a></li><li><a href="#pelatihan-value-network" class="table-of-contents__link toc-highlight">Pelatihan Value Network</a></li></ul></li><li><a href="#pentingnya-randomisasi" class="table-of-contents__link toc-highlight">Pentingnya Randomisasi</a><ul><li><a href="#menghindari-siklus-deterministik" class="table-of-contents__link toc-highlight">Menghindari Siklus Deterministik</a></li><li><a href="#sumber-randomisasi" class="table-of-contents__link toc-highlight">Sumber Randomisasi</a></li><li><a href="#metode-pool" class="table-of-contents__link toc-highlight">Metode Pool</a></li></ul></li><li><a href="#kurva-pertumbuhan-kekuatan" class="table-of-contents__link toc-highlight">Kurva Pertumbuhan Kekuatan</a><ul><li><a href="#sistem-rating-elo" class="table-of-contents__link toc-highlight">Sistem Rating Elo</a></li><li><a href="#pertumbuhan-kekuatan-alphago" class="table-of-contents__link toc-highlight">Pertumbuhan Kekuatan AlphaGo</a></li><li><a href="#analisis-kecepatan-pertumbuhan" class="table-of-contents__link toc-highlight">Analisis Kecepatan Pertumbuhan</a></li><li><a href="#momen-melampaui-manusia" class="table-of-contents__link toc-highlight">Momen Melampaui Manusia</a></li></ul></li><li><a href="#analisis-konvergensi" class="table-of-contents__link toc-highlight">Analisis Konvergensi</a><ul><li><a href="#apakah-self-play-konvergen" class="table-of-contents__link toc-highlight">Apakah Self-Play Konvergen?</a></li><li><a href="#jaminan-teoretis" class="table-of-contents__link toc-highlight">Jaminan Teoretis</a></li><li><a href="#mode-kegagalan-yang-mungkin" class="table-of-contents__link toc-highlight">Mode Kegagalan yang Mungkin</a></li><li><a href="#pengamatan-aktual" class="table-of-contents__link toc-highlight">Pengamatan Aktual</a></li></ul></li><li><a href="#detail-implementasi" class="table-of-contents__link toc-highlight">Detail Implementasi</a><ul><li><a href="#parallel-self-play" class="table-of-contents__link toc-highlight">Parallel Self-Play</a></li><li><a href="#strategi-checkpoint" class="table-of-contents__link toc-highlight">Strategi Checkpoint</a></li><li><a href="#kebutuhan-sumber-daya-pelatihan" class="table-of-contents__link toc-highlight">Kebutuhan Sumber Daya Pelatihan</a></li><li><a href="#pengaturan-hyperparameter" class="table-of-contents__link toc-highlight">Pengaturan Hyperparameter</a></li></ul></li><li><a href="#varian-self-play" class="table-of-contents__link toc-highlight">Varian Self-Play</a><ul><li><a href="#alphago-versi-asli" class="table-of-contents__link toc-highlight">AlphaGo Versi Asli</a></li><li><a href="#alphago-zero" class="table-of-contents__link toc-highlight">AlphaGo Zero</a></li><li><a href="#alphazero" class="table-of-contents__link toc-highlight">AlphaZero</a></li></ul></li><li><a href="#apa-yang-dipelajari-manusia" class="table-of-contents__link toc-highlight">Apa yang Dipelajari Manusia?</a><ul><li><a href="#joseki-baru-yang-ditemukan-ai" class="table-of-contents__link toc-highlight">Joseki Baru yang Ditemukan AI</a></li><li><a href="#dampak-pada-go-manusia" class="table-of-contents__link toc-highlight">Dampak pada Go Manusia</a></li></ul></li><li><a href="#refleksi-filosofis" class="table-of-contents__link toc-highlight">Refleksi Filosofis</a><ul><li><a href="#esensi-pembelajaran" class="table-of-contents__link toc-highlight">Esensi Pembelajaran</a></li><li><a href="#kreativitas-dan-penemuan" class="table-of-contents__link toc-highlight">Kreativitas dan Penemuan</a></li><li><a href="#posisi-kecerdasan-manusia" class="table-of-contents__link toc-highlight">Posisi Kecerdasan Manusia</a></li></ul></li><li><a href="#korespondensi-animasi" class="table-of-contents__link toc-highlight">Korespondensi Animasi</a></li><li><a href="#ringkasan" class="table-of-contents__link toc-highlight">Ringkasan</a></li><li><a href="#bacaan-lanjutan" class="table-of-contents__link toc-highlight">Bacaan Lanjutan</a></li><li><a href="#referensi" class="table-of-contents__link toc-highlight">Referensi</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>