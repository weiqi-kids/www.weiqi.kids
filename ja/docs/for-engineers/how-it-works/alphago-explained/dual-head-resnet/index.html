<!doctype html>
<html lang="ja" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/dual-head-resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">デュアルヘッドネットワークと残差ネットワーク | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ja/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ja/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><meta data-rh="true" property="og:locale" content="ja"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ja"><meta data-rh="true" name="docsearch:language" content="ja"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="デュアルヘッドネットワークと残差ネットワーク | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="AlphaGo Zero のニューラルネットワークアーキテクチャの詳細解説 - 共有バックボーン、Policy Head、Value Head、40層 ResNet"><meta data-rh="true" property="og:description" content="AlphaGo Zero のニューラルネットワークアーキテクチャの詳細解説 - 共有バックボーン、Policy Head、Value Head、40層 ResNet"><meta data-rh="true" name="keywords" content="デュアルヘッドネットワーク,残差ネットワーク,ResNet,Policy Head,Value Head,深層学習,ニューラルネットワークアーキテクチャ"><link data-rh="true" rel="icon" href="/ja/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/ja/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"デュアルヘッドネットワークと残差ネットワーク","item":"https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ja/assets/css/styles.f23bf74b.css">
<script src="/ja/assets/js/runtime~main.5a8f2440.js" defer="defer"></script>
<script src="/ja/assets/js/main.0ede01a4.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ja/img/logo.svg"><div role="region" aria-label="メインコンテンツまでスキップ"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">メインコンテンツまでスキップ</a></div><nav aria-label="ナビゲーション" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="ナビゲーションバーを開く" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ja/"><div class="navbar__logo"><img src="/ja/img/logo.svg" alt="好棋宝宝協会ロゴ" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ja/img/logo.svg" alt="好棋宝宝協会ロゴ" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">囲碁キッズ</b></a><a class="navbar__item navbar__link" href="/ja/docs/for-players/">囲碁プレイヤー向け</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ja/docs/for-engineers/">エンジニア向け</a><a class="navbar__item navbar__link" href="/ja/docs/about/">協会について</a><a class="navbar__item navbar__link" href="/ja/docs/activities/">活動実績</a><a class="navbar__item navbar__link" href="/ja/docs/references/">参考資料</a><a class="navbar__item navbar__link" href="/ja/docs/sop/">標準作業手順</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>日本語</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="検索" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="先頭へ戻る" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="ドキュメントのサイドバー" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ja/docs/intro/"><span title="ご利用ガイド" class="linkLabel_REp1">ご利用ガイド</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="&#x27;關於協會&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="&#x27;活動實績&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/for-players/"><span title="囲碁愛好家向け" class="categoryLinkLabel_ezQx">囲碁愛好家向け</span></a><button aria-label="&#x27;囲碁愛好家向け&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="&#x27;參考資料&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="&#x27;標準作業流程&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ja/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="&#x27;給工程師的圍棋 AI 指南&#x27;の目次を隠す" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ja/docs/for-engineers/deep-dive/"><span title="深く研究したい方へ" class="categoryLinkLabel_ezQx">深く研究したい方へ</span></a><button aria-label="&#x27;深く研究したい方へ&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ja/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="&#x27;30 分鐘跑起第一個圍棋 AI&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ja/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="&#x27;一篇文章搞懂圍棋 AI&#x27;の目次を隠す" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="&#x27;AlphaGo 完整解析&#x27;の目次を隠す" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="AlphaGo の誕生" class="linkLabel_REp1">AlphaGo の誕生</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="重要対局の回顧" class="linkLabel_REp1">重要対局の回顧</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="「神の一手」徹底分析" class="linkLabel_REp1">「神の一手」徹底分析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="囲碁はなぜ難しいのか？" class="linkLabel_REp1">囲碁はなぜ難しいのか？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="従来手法の限界" class="linkLabel_REp1">従来手法の限界</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="盤面状態の表現" class="linkLabel_REp1">盤面状態の表現</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="Policy Network 詳解" class="linkLabel_REp1">Policy Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="Value Network 詳解" class="linkLabel_REp1">Value Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="入力特徴量の設計" class="linkLabel_REp1">入力特徴量の設計</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="CNNと囲碁の融合" class="linkLabel_REp1">CNNと囲碁の融合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="教師あり学習フェーズ" class="linkLabel_REp1">教師あり学習フェーズ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="強化学習入門" class="linkLabel_REp1">強化学習入門</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="自己対局" class="linkLabel_REp1">自己対局</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="MCTS とニューラルネットワークの融合" class="linkLabel_REp1">MCTS とニューラルネットワークの融合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="PUCT 公式詳解" class="linkLabel_REp1">PUCT 公式詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="AlphaGo Zero 概要" class="linkLabel_REp1">AlphaGo Zero 概要</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="デュアルヘッドネットワークと残差ネットワーク" class="linkLabel_REp1">デュアルヘッドネットワークと残差ネットワーク</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="ゼロからの学習過程" class="linkLabel_REp1">ゼロからの学習過程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="分散システムと TPU" class="linkLabel_REp1">分散システムと TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="AlphaGo の遺産" class="linkLabel_REp1">AlphaGo の遺産</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ja/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="&#x27;圍棋 AI 產業現況&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ja/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="&#x27;圍棋 AI 能做什麼？&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="パンくずリストのナビゲーション"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="ホームページ" class="breadcrumbs__link" href="/ja/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ja/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ja/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ja/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">デュアルヘッドネットワークと残差ネットワーク</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">このページの見出し</button></div><div class="theme-doc-markdown markdown"><header><h1>デュアルヘッドネットワークと残差ネットワーク</h1></header>
<p>AlphaGo Zero の最も重要なアーキテクチャ革新の1つは、元祖 AlphaGo のデュアルネットワーク設計を<strong>デュアルヘッドネットワーク</strong>（Dual-Head Network）に置き換えたことです。この一見シンプルな変更が、顕著な性能向上とよりエレガントな学習プロセスをもたらしました。</p>
<p>本記事では、このアーキテクチャの設計原理、数学的基礎、そしてなぜこれほど効果的なのかを詳しく解説します。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="デュアルヘッドネットワーク設計">デュアルヘッドネットワーク設計<a href="#デュアルヘッドネットワーク設計" class="hash-link" aria-label="デュアルヘッドネットワーク設計 への直接リンク" title="デュアルヘッドネットワーク設計 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="全体アーキテクチャ">全体アーキテクチャ<a href="#全体アーキテクチャ" class="hash-link" aria-label="全体アーキテクチャ への直接リンク" title="全体アーキテクチャ への直接リンク" translate="no">​</a></h3>
<p>AlphaGo Zero のニューラルネットワークは3つの部分に分けられます：</p>
<!-- -->
<p>各部分を順に解説します。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="共有バックボーンshared-backbone">共有バックボーン（Shared Backbone）<a href="#共有バックボーンshared-backbone" class="hash-link" aria-label="共有バックボーン（Shared Backbone） への直接リンク" title="共有バックボーン（Shared Backbone） への直接リンク" translate="no">​</a></h3>
<p>共有バックボーンは深い**残差ネットワーク（ResNet）**であり、盤面状態から特徴を抽出する役割を担います。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="アーキテクチャ詳細">アーキテクチャ詳細<a href="#アーキテクチャ詳細" class="hash-link" aria-label="アーキテクチャ詳細 への直接リンク" title="アーキテクチャ詳細 への直接リンク" translate="no">​</a></h4>
<table><thead><tr><th>コンポーネント</th><th>仕様</th></tr></thead><tbody><tr><td>入力層</td><td>3×3 畳み込み、256チャネル</td></tr><tr><td>残差ブロック</td><td>40個（または20個の軽量版）</td></tr><tr><td>各残差ブロック</td><td>2層 3×3 畳み込み、256チャネル</td></tr><tr><td>活性化関数</td><td>ReLU</td></tr><tr><td>正規化</td><td>Batch Normalization</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学的表現">数学的表現<a href="#数学的表現" class="hash-link" aria-label="数学的表現 への直接リンク" title="数学的表現 への直接リンク" translate="no">​</a></h4>
<p>入力を x（次元 17 x 19 x 19）とすると、共有バックボーンの出力は：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">f(x) = ResNet_40(Conv_3x3(x))</span><br></span></code></pre></div></div>
<p>ここで f(x)（次元 256 x 19 x 19）は高次元特徴表現です。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head戦略ヘッド">Policy Head（戦略ヘッド）<a href="#policy-head戦略ヘッド" class="hash-link" aria-label="Policy Head（戦略ヘッド） への直接リンク" title="Policy Head（戦略ヘッド） への直接リンク" translate="no">​</a></h3>
<p>Policy Head は各位置の着手確率を予測する役割を担います。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="アーキテクチャ詳細-1">アーキテクチャ詳細<a href="#アーキテクチャ詳細-1" class="hash-link" aria-label="アーキテクチャ詳細 への直接リンク" title="アーキテクチャ詳細 への直接リンク" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">共有バックボーン出力（256 × 19 × 19）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1×1 畳み込み（2チャネル）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">フラット化（2 × 19 × 19 = 722）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">全結合層（362）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">出力：362個の確率（361位置 + Pass）</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学的表現-1">数学的表現<a href="#数学的表現-1" class="hash-link" aria-label="数学的表現 への直接リンク" title="数学的表現 への直接リンク" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">π = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))</span><br></span></code></pre></div></div>
<p>出力 π は362次元ベクトルで、全要素が非負かつ和が1を満たします。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head価値ヘッド">Value Head（価値ヘッド）<a href="#value-head価値ヘッド" class="hash-link" aria-label="Value Head（価値ヘッド） への直接リンク" title="Value Head（価値ヘッド） への直接リンク" translate="no">​</a></h3>
<p>Value Head は現在の局面の勝率を予測する役割を担います。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="アーキテクチャ詳細-2">アーキテクチャ詳細<a href="#アーキテクチャ詳細-2" class="hash-link" aria-label="アーキテクチャ詳細 への直接リンク" title="アーキテクチャ詳細 への直接リンク" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">共有バックボーン出力（256 × 19 × 19）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1×1 畳み込み（1チャネル）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">フラット化（1 × 19 × 19 = 361）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">全結合層（256）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">全結合層（1）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Tanh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">出力：勝率 [-1, 1]</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学的表現-2">数学的表現<a href="#数学的表現-2" class="hash-link" aria-label="数学的表現 への直接リンク" title="数学的表現 への直接リンク" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))</span><br></span></code></pre></div></div>
<p>出力 v は [-1, 1] の範囲内：</p>
<ul>
<li class="">v = 1：現在の手番が必勝</li>
<li class="">v = -1：現在の手番が必敗</li>
<li class="">v = 0：互角</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜバックボーンを共有するのか">なぜバックボーンを共有するのか？<a href="#なぜバックボーンを共有するのか" class="hash-link" aria-label="なぜバックボーンを共有するのか？ への直接リンク" title="なぜバックボーンを共有するのか？ への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="直感的理解">直感的理解<a href="#直感的理解" class="hash-link" aria-label="直感的理解 への直接リンク" title="直感的理解 への直接リンク" translate="no">​</a></h3>
<p>「次にどこに打つべきか」（Policy）と「誰が勝つか」（Value）という2つの問題は、実際には同じ盤面パターンを理解する必要があります：</p>
<ul>
<li class=""><strong>石形</strong>：どの形が良く、どの形が悪いか</li>
<li class=""><strong>勢力</strong>：どちらが大きいか、どこにまだスペースがあるか</li>
<li class=""><strong>死活</strong>：どの石が生きていて、どの石がまだコウ争い中か</li>
<li class=""><strong>戦い</strong>：どこに攻め合いがあるか、局部の勝敗はどうか</li>
</ul>
<p>2つの独立したネットワークを使用すると、これらの特徴を2回学習する必要があります。共有バックボーンにより、これらの基礎特徴は1回だけ学習すれば、両方のタスクで使用できます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="マルチタスク学習の視点">マルチタスク学習の視点<a href="#マルチタスク学習の視点" class="hash-link" aria-label="マルチタスク学習の視点 への直接リンク" title="マルチタスク学習の視点 への直接リンク" translate="no">​</a></h3>
<p>機械学習の観点から、これは**マルチタスク学習（Multi-task Learning）**の一種です：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value</span><br></span></code></pre></div></div>
<p>2つのタスクが基礎表現を共有することで、いくつかの利点が生まれます：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-正則化効果">1. 正則化効果<a href="#1-正則化効果" class="hash-link" aria-label="1. 正則化効果 への直接リンク" title="1. 正則化効果 への直接リンク" translate="no">​</a></h4>
<p>パラメータの共有は暗黙の正則化に相当します。ある特徴が Policy にのみ有用で Value には無用（またはその逆）の場合、過度に増幅されにくくなります。</p>
<p>有効パラメータ量は2つの独立したネットワークのパラメータ量よりも少なくなります。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-データ効率">2. データ効率<a href="#2-データ効率" class="hash-link" aria-label="2. データ効率 への直接リンク" title="2. データ効率 への直接リンク" translate="no">​</a></h4>
<p>各対局は同時に Policy ラベル（MCTS 探索確率）と Value ラベル（最終的な勝敗）を生成します。共有バックボーンにより、両方のラベルが共有特徴の訓練に使用され、データ利用効率が向上します。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-豊富な勾配信号">3. 豊富な勾配信号<a href="#3-豊富な勾配信号" class="hash-link" aria-label="3. 豊富な勾配信号 への直接リンク" title="3. 豊富な勾配信号 への直接リンク" translate="no">​</a></h4>
<p>両方のタスクの勾配が共有バックボーンに流れます：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂θ_shared = ∂L_policy/∂θ_shared + ∂L_value/∂θ_shared</span><br></span></code></pre></div></div>
<p>これにより、より豊富な監督信号が提供され、共有特徴がよりロバストになります。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="実験的証拠">実験的証拠<a href="#実験的証拠" class="hash-link" aria-label="実験的証拠 への直接リンク" title="実験的証拠 への直接リンク" translate="no">​</a></h3>
<p>DeepMind のアブレーション実験は、デュアルヘッドネットワークが分離したデュアルネットワークを大幅に上回ることを示しました：</p>
<table><thead><tr><th>構成</th><th>ELO レーティング</th><th>相対差</th></tr></thead><tbody><tr><td>分離した Policy + Value ネットワーク</td><td>基準</td><td>-</td></tr><tr><td>デュアルヘッドネットワーク（共有バックボーン）</td><td>+300 ELO</td><td>約65%の勝率差</td></tr></tbody></table>
<p>300 ELO の差は、デュアルヘッドネットワークが分離ネットワークに対して約65%の勝率を持つことを意味します。これは顕著な向上です。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="残差ネットワークの原理">残差ネットワークの原理<a href="#残差ネットワークの原理" class="hash-link" aria-label="残差ネットワークの原理 への直接リンク" title="残差ネットワークの原理 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="深層ネットワークのジレンマ">深層ネットワークのジレンマ<a href="#深層ネットワークのジレンマ" class="hash-link" aria-label="深層ネットワークのジレンマ への直接リンク" title="深層ネットワークのジレンマ への直接リンク" translate="no">​</a></h3>
<p>ResNet が発明される前、深層ニューラルネットワークはパラドックスに直面していました：</p>
<blockquote>
<p>理論的には、より深いネットワークは少なくとも浅いネットワークと同等以上であるべき（最悪の場合、追加の層は恒等写像を学習できる）。しかし実際には、より深いネットワークはしばしばより悪い性能を示す。</p>
</blockquote>
<p>これが**劣化問題（Degradation Problem）**です：</p>
<ul>
<li class="">訓練誤差が深さとともに増加する（過学習ではなく、最適化の困難）</li>
<li class="">勾配が逆伝播時に徐々に消失する（Vanishing Gradient）</li>
<li class="">深い層のパラメータはほとんど効果的に更新されない</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="残差ブロックの設計">残差ブロックの設計<a href="#残差ブロックの設計" class="hash-link" aria-label="残差ブロックの設計 への直接リンク" title="残差ブロックの設計 への直接リンク" translate="no">​</a></h3>
<p>何愷明らは2015年に、シンプルでエレガントな解決策を提案しました：<strong>残差接続（Skip Connection）</strong>。</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学的表現-3">数学的表現<a href="#数学的表現-3" class="hash-link" aria-label="数学的表現 への直接リンク" title="数学的表現 への直接リンク" translate="no">​</a></h4>
<p>従来のネットワーク：目標写像 H(x) を学習</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = H(x)</span><br></span></code></pre></div></div>
<p>残差ネットワーク：<strong>残差写像</strong> F(x) = H(x) - x を学習</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = F(x) + x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ残差接続は効果的なのか">なぜ残差接続は効果的なのか？<a href="#なぜ残差接続は効果的なのか" class="hash-link" aria-label="なぜ残差接続は効果的なのか？ への直接リンク" title="なぜ残差接続は効果的なのか？ への直接リンク" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-勾配ハイウェイ">1. 勾配ハイウェイ<a href="#1-勾配ハイウェイ" class="hash-link" aria-label="1. 勾配ハイウェイ への直接リンク" title="1. 勾配ハイウェイ への直接リンク" translate="no">​</a></h4>
<p>逆伝播の勾配を考えます：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂x = ∂L/∂y × ∂y/∂x = ∂L/∂y × (1 + ∂F(x)/∂x)</span><br></span></code></pre></div></div>
<p>鍵となるのは <strong>+1</strong> です。∂F(x)/∂x が非常に小さいかゼロであっても、勾配は +1 を通じて直接伝播できます。</p>
<p>これは「勾配ハイウェイ」を建設したようなもので、勾配が出力層から入力層へ障害なく伝播できます。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-恒等写像の学習が容易">2. 恒等写像の学習が容易<a href="#2-恒等写像の学習が容易" class="hash-link" aria-label="2. 恒等写像の学習が容易 への直接リンク" title="2. 恒等写像の学習が容易 への直接リンク" translate="no">​</a></h4>
<p>最適解が恒等写像に近い（H(x) が約 x）場合：</p>
<ul>
<li class="">従来のネットワーク：H(x) = x を学習する必要があり、難しい可能性がある</li>
<li class="">残差ネットワーク：F(x) が約 0 を学習するだけでよく、比較的容易</li>
</ul>
<p>重みをゼロまたはゼロに近い値に初期化すると、残差ブロックは自然に恒等写像に向かいます。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-アンサンブル効果">3. アンサンブル効果<a href="#3-アンサンブル効果" class="hash-link" aria-label="3. アンサンブル効果 への直接リンク" title="3. アンサンブル効果 への直接リンク" translate="no">​</a></h4>
<p>深い ResNet は多くの浅いネットワークの<strong>暗黙的なアンサンブル</strong>と見なせます。n 個の残差ブロックがある場合、情報は 2^n 種類の異なるパスを通じて流れることができます。</p>
<p>このアンサンブル効果はモデルのロバスト性を高めます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="imagenet-での-resnet-の突破">ImageNet での ResNet の突破<a href="#imagenet-での-resnet-の突破" class="hash-link" aria-label="ImageNet での ResNet の突破 への直接リンク" title="ImageNet での ResNet の突破 への直接リンク" translate="no">​</a></h3>
<p>ResNet は2015年の ImageNet コンペティションで驚くべき成績を収めました：</p>
<table><thead><tr><th>深さ</th><th>Top-5 エラー率</th></tr></thead><tbody><tr><td>VGG-19（残差なし）</td><td>7.3%</td></tr><tr><td>ResNet-34</td><td>5.7%</td></tr><tr><td>ResNet-152</td><td>4.5%</td></tr><tr><td>人間レベル</td><td>約5.1%</td></tr></tbody></table>
<p><strong>152層</strong>の ResNet は訓練可能であるだけでなく、19層の VGG よりもはるかに優れていました。これは残差接続が深層ネットワークの訓練問題を確かに解決したことを証明しています。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero-の40層-resnet">AlphaGo Zero の40層 ResNet<a href="#alphago-zero-の40層-resnet" class="hash-link" aria-label="AlphaGo Zero の40層 ResNet への直接リンク" title="AlphaGo Zero の40層 ResNet への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ40層を選択したのか">なぜ40層を選択したのか？<a href="#なぜ40層を選択したのか" class="hash-link" aria-label="なぜ40層を選択したのか？ への直接リンク" title="なぜ40層を選択したのか？ への直接リンク" translate="no">​</a></h3>
<p>DeepMind は異なる深さの ResNet をテストしました：</p>
<table><thead><tr><th>残差ブロック数</th><th>総層数</th><th>ELO レーティング</th></tr></thead><tbody><tr><td>5</td><td>11</td><td>基準</td></tr><tr><td>10</td><td>21</td><td>+200</td></tr><tr><td>20</td><td>41</td><td>+400</td></tr><tr><td>40</td><td>81</td><td>+500</td></tr></tbody></table>
<p>より深いネットワークは確かにより強いですが、限界効用は逓減します。AlphaGo Zero は20または40個の残差ブロックを使用します：</p>
<ul>
<li class=""><strong>AlphaGo Zero（論文版）</strong>：40個の残差ブロック、256チャネル</li>
<li class=""><strong>軽量版</strong>：20個の残差ブロック、256チャネル</li>
</ul>
<p>40層の構成は棋力と訓練コストの間で良いバランスを取っています。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="具体的な構成">具体的な構成<a href="#具体的な構成" class="hash-link" aria-label="具体的な構成 への直接リンク" title="具体的な構成 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo Zero の ResNet 構成は以下の通りです：</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="パラメータ数の推定">パラメータ数の推定<a href="#パラメータ数の推定" class="hash-link" aria-label="パラメータ数の推定 への直接リンク" title="パラメータ数の推定 への直接リンク" translate="no">​</a></h4>
<table><thead><tr><th>コンポーネント</th><th>パラメータ数（約）</th></tr></thead><tbody><tr><td>入力畳み込み</td><td>17 × 3 × 3 × 256 ≈ 39K</td></tr><tr><td>各残差ブロック</td><td>2 × 256 × 3 × 3 × 256 ≈ 1.2M</td></tr><tr><td>40個の残差ブロック</td><td>40 × 1.2M ≈ 47M</td></tr><tr><td>Policy Head</td><td>約1M</td></tr><tr><td>Value Head</td><td>約0.2M</td></tr><tr><td><strong>合計</strong></td><td><strong>約48M</strong></td></tr></tbody></table>
<p>約4800万パラメータで、現代の基準では中規模のニューラルネットワークです。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="batch-normalization-の役割">Batch Normalization の役割<a href="#batch-normalization-の役割" class="hash-link" aria-label="Batch Normalization の役割 への直接リンク" title="Batch Normalization の役割 への直接リンク" translate="no">​</a></h3>
<p>各畳み込み層の後には <strong>Batch Normalization（BN）</strong> があり、これは訓練の安定性に不可欠です：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-活性値の正規化">1. 活性値の正規化<a href="#1-活性値の正規化" class="hash-link" aria-label="1. 活性値の正規化 への直接リンク" title="1. 活性値の正規化 への直接リンク" translate="no">​</a></h4>
<p>BN は各層の活性値を平均0、分散1に正規化します：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_B) / sqrt(σ_B² + ε)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y = γ × x_hat + β</span><br></span></code></pre></div></div>
<p>ここで γ と β は学習可能なパラメータです。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-内部共変量シフトの緩和">2. 内部共変量シフトの緩和<a href="#2-内部共変量シフトの緩和" class="hash-link" aria-label="2. 内部共変量シフトの緩和 への直接リンク" title="2. 内部共変量シフトの緩和 への直接リンク" translate="no">​</a></h4>
<p>深層ネットワークでは、各層の入力分布が前の層のパラメータ更新とともに変化します。BN により各層の入力分布が安定し、訓練の収束が加速されます。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-正則化効果">3. 正則化効果<a href="#3-正則化効果" class="hash-link" aria-label="3. 正則化効果 への直接リンク" title="3. 正則化効果 への直接リンク" translate="no">​</a></h4>
<p>BN は訓練時に mini-batch の統計量を使用するため、ランダム性が導入され、軽度の正則化効果があります。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="他のアーキテクチャとの比較">他のアーキテクチャとの比較<a href="#他のアーキテクチャとの比較" class="hash-link" aria-label="他のアーキテクチャとの比較 への直接リンク" title="他のアーキテクチャとの比較 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-元祖-alphago-の-cnn">vs. 元祖 AlphaGo の CNN<a href="#vs-元祖-alphago-の-cnn" class="hash-link" aria-label="vs. 元祖 AlphaGo の CNN への直接リンク" title="vs. 元祖 AlphaGo の CNN への直接リンク" translate="no">​</a></h3>
<table><thead><tr><th>特性</th><th>AlphaGo 元祖</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>アーキテクチャタイプ</td><td>標準 CNN</td><td>ResNet</td></tr><tr><td>深さ</td><td>13層</td><td>41-81層</td></tr><tr><td>残差接続</td><td>なし</td><td>あり</td></tr><tr><td>ネットワーク数</td><td>2（分離）</td><td>1（共有）</td></tr><tr><td>BN</td><td>なし</td><td>あり</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-vgg-スタイルネットワーク">vs. VGG スタイルネットワーク<a href="#vs-vgg-スタイルネットワーク" class="hash-link" aria-label="vs. VGG スタイルネットワーク への直接リンク" title="vs. VGG スタイルネットワーク への直接リンク" translate="no">​</a></h3>
<p>VGG は2014年 ImageNet 準優勝のアーキテクチャで、積み重ねた 3×3 畳み込みを使用：</p>
<table><thead><tr><th>特性</th><th>VGG</th><th>ResNet</th></tr></thead><tbody><tr><td>訓練可能な最大深さ</td><td>約19層</td><td>152層以上</td></tr><tr><td>勾配の流れ</td><td>層ごとに減衰</td><td>ハイウェイあり</td></tr><tr><td>訓練の難易度</td><td>深層は困難</td><td>深層も訓練可能</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-inception--googlenet">vs. Inception / GoogLeNet<a href="#vs-inception--googlenet" class="hash-link" aria-label="vs. Inception / GoogLeNet への直接リンク" title="vs. Inception / GoogLeNet への直接リンク" translate="no">​</a></h3>
<p>Inception はマルチスケール畳み込みを並列に使用：</p>
<table><thead><tr><th>特性</th><th>Inception</th><th>ResNet</th></tr></thead><tbody><tr><td>特徴</td><td>マルチスケール特徴</td><td>深さの積み重ね</td></tr><tr><td>複雑さ</td><td>比較的高い</td><td>シンプル</td></tr><tr><td>囲碁への適用性</td><td>一般的</td><td>優秀</td></tr></tbody></table>
<p>ResNet のシンプルな設計は、深い推論が必要な囲碁のようなタスクにより適しています。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-transformer">vs. Transformer<a href="#vs-transformer" class="hash-link" aria-label="vs. Transformer への直接リンク" title="vs. Transformer への直接リンク" translate="no">​</a></h3>
<p>2017年に提案された Transformer アーキテクチャは NLP 分野で大きな成功を収めました。Transformer を囲碁に適用する試みもあります：</p>
<table><thead><tr><th>特性</th><th>ResNet</th><th>Transformer</th></tr></thead><tbody><tr><td>帰納バイアス</td><td>局所性（畳み込み）</td><td>グローバルアテンション</td></tr><tr><td>位置エンコーディング</td><td>暗黙的（畳み込み）</td><td>明示的</td></tr><tr><td>囲碁での性能</td><td>優秀</td><td>可能だが ResNet を上回らない</td></tr><tr><td>計算効率</td><td>比較的高い</td><td>比較的低い（O(n²)）</td></tr></tbody></table>
<p>明確な空間構造を持つ囲碁のような問題には、CNN/ResNet の帰納バイアスがより適切です。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="設計選択の詳細分析">設計選択の詳細分析<a href="#設計選択の詳細分析" class="hash-link" aria-label="設計選択の詳細分析 への直接リンク" title="設計選択の詳細分析 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ-33-畳み込みを使うのか">なぜ 3×3 畳み込みを使うのか？<a href="#なぜ-33-畳み込みを使うのか" class="hash-link" aria-label="なぜ 3×3 畳み込みを使うのか？ への直接リンク" title="なぜ 3×3 畳み込みを使うのか？ への直接リンク" translate="no">​</a></h3>
<p>AlphaGo Zero は全体を通じて 3×3 畳み込みを使用し、より大きな畳み込みカーネルは使用しません：</p>
<ol>
<li class=""><strong>パラメータ効率</strong>：2つの 3×3 畳み込みの受容野は1つの 5×5 と同等ですが、パラメータ数は少ない（18 vs 25）</li>
<li class=""><strong>より深いネットワーク</strong>：同じパラメータ量でより多くの層を積み重ねられる</li>
<li class=""><strong>より多くの非線形性</strong>：層間に ReLU があり、表現力が増加</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ256チャネルなのか">なぜ256チャネルなのか？<a href="#なぜ256チャネルなのか" class="hash-link" aria-label="なぜ256チャネルなのか？ への直接リンク" title="なぜ256チャネルなのか？ への直接リンク" translate="no">​</a></h3>
<p>256チャネルは経験的な選択です：</p>
<ul>
<li class=""><strong>少なすぎる</strong>（例：64）：表現力が不足し、複雑なパターンを捉えられない</li>
<li class=""><strong>多すぎる</strong>（例：512）：パラメータ量が倍増し、訓練コストが大幅に増加するが、棋力向上は限定的</li>
</ul>
<p>後の KataGo の実験では、チャネル数は訓練リソースに応じて調整できることが示されました：</p>
<ul>
<li class="">低リソース：128チャネル、20ブロック</li>
<li class="">高リソース：256チャネル、40ブロック</li>
<li class="">より高リソース：384チャネル、60ブロック</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ-policy-head-は-softmaxvalue-head-は-tanh-なのか">なぜ Policy Head は Softmax、Value Head は Tanh なのか？<a href="#なぜ-policy-head-は-softmaxvalue-head-は-tanh-なのか" class="hash-link" aria-label="なぜ Policy Head は Softmax、Value Head は Tanh なのか？ への直接リンク" title="なぜ Policy Head は Softmax、Value Head は Tanh なのか？ への直接リンク" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-headsoftmax">Policy Head：Softmax<a href="#policy-headsoftmax" class="hash-link" aria-label="Policy Head：Softmax への直接リンク" title="Policy Head：Softmax への直接リンク" translate="no">​</a></h4>
<p>着手は<strong>分類問題</strong>です——361位置（+ Pass）から1つを選択します。Softmax 出力は以下を満たします：</p>
<ul>
<li class="">全確率が非負：π_i &gt;= 0</li>
<li class="">確率の和が1：Σπ_i = 1</li>
</ul>
<p>これは確率分布の定義と一致します。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-headtanh">Value Head：Tanh<a href="#value-headtanh" class="hash-link" aria-label="Value Head：Tanh への直接リンク" title="Value Head：Tanh への直接リンク" translate="no">​</a></h4>
<p>勝率は<strong>回帰問題</strong>です——連続値を予測します。Tanh の出力範囲は [-1, 1]：</p>
<ul>
<li class="">有界：極端な値を生成しない</li>
<li class="">対称：勝ちと負けを対称に処理</li>
<li class="">微分可能：勾配計算に便利</li>
</ul>
<p>Tanh を使用し、非有界出力（線形層など）を使用しないことで、訓練の不安定性を防ぎます。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="訓練の詳細">訓練の詳細<a href="#訓練の詳細" class="hash-link" aria-label="訓練の詳細 への直接リンク" title="訓練の詳細 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="損失関数">損失関数<a href="#損失関数" class="hash-link" aria-label="損失関数 への直接リンク" title="損失関数 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo Zero の総損失は3項の和です：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value + L_reg</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-loss">Policy Loss<a href="#policy-loss" class="hash-link" aria-label="Policy Loss への直接リンク" title="Policy Loss への直接リンク" translate="no">​</a></h4>
<p><strong>交差エントロピー損失</strong>を使用し、ネットワーク出力を MCTS 探索確率に近づけます：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_policy = -Σ π_MCTS(a) × log(π_net(a))</span><br></span></code></pre></div></div>
<p>ここで：</p>
<ul>
<li class="">π_MCTS(a) は行動 a に対する MCTS の探索確率</li>
<li class="">π_net(a) はネットワーク出力の確率</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-loss">Value Loss<a href="#value-loss" class="hash-link" aria-label="Value Loss への直接リンク" title="Value Loss への直接リンク" translate="no">​</a></h4>
<p><strong>平均二乗誤差（MSE）</strong> を使用し、ネットワーク出力を実際の勝敗に近づけます：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_value = (v_net - z)²</span><br></span></code></pre></div></div>
<p>ここで：</p>
<ul>
<li class="">v_net はネットワークが予測する勝率</li>
<li class="">z は実際の対局結果（+1 または -1）</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="regularization-loss">Regularization Loss<a href="#regularization-loss" class="hash-link" aria-label="Regularization Loss への直接リンク" title="Regularization Loss への直接リンク" translate="no">​</a></h4>
<p>過学習を防ぐために <strong>L2 正則化</strong>を使用：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_reg = c × ||θ||²</span><br></span></code></pre></div></div>
<p>ここで c は正則化係数、θ はネットワークパラメータです。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="最適化器の設定">最適化器の設定<a href="#最適化器の設定" class="hash-link" aria-label="最適化器の設定 への直接リンク" title="最適化器の設定 への直接リンク" translate="no">​</a></h3>
<table><thead><tr><th>パラメータ</th><th>値</th></tr></thead><tbody><tr><td>最適化器</td><td>SGD + Momentum</td></tr><tr><td>モメンタム</td><td>0.9</td></tr><tr><td>初期学習率</td><td>0.01</td></tr><tr><td>学習率減衰</td><td>X ステップごとに半減</td></tr><tr><td>Batch Size</td><td>32 × 2048 = 64K（分散）</td></tr><tr><td>L2 正則化係数</td><td>1e-4</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="データ拡張">データ拡張<a href="#データ拡張" class="hash-link" aria-label="データ拡張 への直接リンク" title="データ拡張 への直接リンク" translate="no">​</a></h3>
<p>囲碁盤には8つの対称性があります（4回の回転 × 2回の反転）。訓練時、各局面から8つの等価な訓練サンプルを生成できます。</p>
<p>これにより有効訓練データが8倍に増加し、追加の自己対戦は不要です。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="実装上の考慮事項">実装上の考慮事項<a href="#実装上の考慮事項" class="hash-link" aria-label="実装上の考慮事項 への直接リンク" title="実装上の考慮事項 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="メモリ最適化">メモリ最適化<a href="#メモリ最適化" class="hash-link" aria-label="メモリ最適化 への直接リンク" title="メモリ最適化 への直接リンク" translate="no">​</a></h3>
<p>40層 ResNet の訓練には大量のメモリが必要です：</p>
<ul>
<li class=""><strong>順伝播</strong>：各層の活性値を保存する必要がある（逆伝播用）</li>
<li class=""><strong>逆伝播</strong>：勾配を保存する必要がある</li>
</ul>
<p>最適化戦略：</p>
<ol>
<li class=""><strong>勾配チェックポイント（Gradient Checkpointing）</strong>：一部の活性値のみを保存し、必要時に再計算</li>
<li class=""><strong>混合精度訓練</strong>：FP16 を使用してメモリ使用量を削減</li>
<li class=""><strong>分散訓練</strong>：batch を複数の GPU/TPU に分散</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="推論の最適化">推論の最適化<a href="#推論の最適化" class="hash-link" aria-label="推論の最適化 への直接リンク" title="推論の最適化 への直接リンク" translate="no">​</a></h3>
<p>推論時には BN の mini-batch 統計量は不要で、訓練時に蓄積した移動平均を使用できます：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_moving) / sqrt(σ_moving² + ε)</span><br></span></code></pre></div></div>
<p>これにより推論速度が向上し、結果が決定論的になります。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="量子化と圧縮">量子化と圧縮<a href="#量子化と圧縮" class="hash-link" aria-label="量子化と圧縮 への直接リンク" title="量子化と圧縮 への直接リンク" translate="no">​</a></h3>
<p>デプロイ時にはネットワークをさらに圧縮できます：</p>
<ul>
<li class=""><strong>重み量子化</strong>：FP32 → INT8、メモリが4分の1に削減</li>
<li class=""><strong>プルーニング</strong>：小さな重みの接続を除去</li>
<li class=""><strong>知識蒸留</strong>：大きなネットワークで小さなネットワークを訓練</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="アニメーション対応">アニメーション対応<a href="#アニメーション対応" class="hash-link" aria-label="アニメーション対応 への直接リンク" title="アニメーション対応 への直接リンク" translate="no">​</a></h2>
<p>本記事に関連するコア概念とアニメーション番号：</p>
<table><thead><tr><th>番号</th><th>概念</th><th>物理/数学対応</th></tr></thead><tbody><tr><td>🎬 E3</td><td>デュアルヘッドネットワーク</td><td>マルチタスク学習</td></tr><tr><td>🎬 D12</td><td>残差接続</td><td>勾配ハイウェイ</td></tr><tr><td>🎬 D8</td><td>畳み込みニューラルネットワーク</td><td>局所受容野</td></tr><tr><td>🎬 D10</td><td>Batch Normalization</td><td>分布正規化</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="関連記事">関連記事<a href="#関連記事" class="hash-link" aria-label="関連記事 への直接リンク" title="関連記事 への直接リンク" translate="no">​</a></h2>
<ul>
<li class=""><strong>前の記事</strong>：<a class="" href="/ja/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/">AlphaGo Zero 概要</a> — なぜ人間の棋譜は不要なのか</li>
<li class=""><strong>次の記事</strong>：<a class="" href="/ja/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/">ゼロからの訓練プロセス</a> — Day 0-3 の詳細な進化</li>
<li class=""><strong>技術深掘り</strong>：<a class="" href="/ja/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/">CNN と囲碁の融合</a> — なぜ CNN は盤面に適しているのか</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="参考文献">参考文献<a href="#参考文献" class="hash-link" aria-label="参考文献 への直接リンク" title="参考文献 への直接リンク" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">He, K., et al. (2016). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR 2016</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&quot; <em>ICML 2015</em>.</li>
<li class="">Caruana, R. (1997). &quot;Multitask Learning.&quot; <em>Machine Learning</em>, 28(1), 41-75.</li>
<li class="">Veit, A., et al. (2016). &quot;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&quot; <em>NeurIPS 2016</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/17-dual-head-resnet.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>このページを編集</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="ドキュメントページ"><a class="pagination-nav__link pagination-nav__link--prev" href="/ja/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><div class="pagination-nav__sublabel">前へ</div><div class="pagination-nav__label">AlphaGo Zero 概要</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ja/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><div class="pagination-nav__sublabel">次へ</div><div class="pagination-nav__label">ゼロからの学習過程</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#デュアルヘッドネットワーク設計" class="table-of-contents__link toc-highlight">デュアルヘッドネットワーク設計</a><ul><li><a href="#全体アーキテクチャ" class="table-of-contents__link toc-highlight">全体アーキテクチャ</a></li><li><a href="#共有バックボーンshared-backbone" class="table-of-contents__link toc-highlight">共有バックボーン（Shared Backbone）</a></li><li><a href="#policy-head戦略ヘッド" class="table-of-contents__link toc-highlight">Policy Head（戦略ヘッド）</a></li><li><a href="#value-head価値ヘッド" class="table-of-contents__link toc-highlight">Value Head（価値ヘッド）</a></li></ul></li><li><a href="#なぜバックボーンを共有するのか" class="table-of-contents__link toc-highlight">なぜバックボーンを共有するのか？</a><ul><li><a href="#直感的理解" class="table-of-contents__link toc-highlight">直感的理解</a></li><li><a href="#マルチタスク学習の視点" class="table-of-contents__link toc-highlight">マルチタスク学習の視点</a></li><li><a href="#実験的証拠" class="table-of-contents__link toc-highlight">実験的証拠</a></li></ul></li><li><a href="#残差ネットワークの原理" class="table-of-contents__link toc-highlight">残差ネットワークの原理</a><ul><li><a href="#深層ネットワークのジレンマ" class="table-of-contents__link toc-highlight">深層ネットワークのジレンマ</a></li><li><a href="#残差ブロックの設計" class="table-of-contents__link toc-highlight">残差ブロックの設計</a></li><li><a href="#なぜ残差接続は効果的なのか" class="table-of-contents__link toc-highlight">なぜ残差接続は効果的なのか？</a></li><li><a href="#imagenet-での-resnet-の突破" class="table-of-contents__link toc-highlight">ImageNet での ResNet の突破</a></li></ul></li><li><a href="#alphago-zero-の40層-resnet" class="table-of-contents__link toc-highlight">AlphaGo Zero の40層 ResNet</a><ul><li><a href="#なぜ40層を選択したのか" class="table-of-contents__link toc-highlight">なぜ40層を選択したのか？</a></li><li><a href="#具体的な構成" class="table-of-contents__link toc-highlight">具体的な構成</a></li><li><a href="#batch-normalization-の役割" class="table-of-contents__link toc-highlight">Batch Normalization の役割</a></li></ul></li><li><a href="#他のアーキテクチャとの比較" class="table-of-contents__link toc-highlight">他のアーキテクチャとの比較</a><ul><li><a href="#vs-元祖-alphago-の-cnn" class="table-of-contents__link toc-highlight">vs. 元祖 AlphaGo の CNN</a></li><li><a href="#vs-vgg-スタイルネットワーク" class="table-of-contents__link toc-highlight">vs. VGG スタイルネットワーク</a></li><li><a href="#vs-inception--googlenet" class="table-of-contents__link toc-highlight">vs. Inception / GoogLeNet</a></li><li><a href="#vs-transformer" class="table-of-contents__link toc-highlight">vs. Transformer</a></li></ul></li><li><a href="#設計選択の詳細分析" class="table-of-contents__link toc-highlight">設計選択の詳細分析</a><ul><li><a href="#なぜ-33-畳み込みを使うのか" class="table-of-contents__link toc-highlight">なぜ 3×3 畳み込みを使うのか？</a></li><li><a href="#なぜ256チャネルなのか" class="table-of-contents__link toc-highlight">なぜ256チャネルなのか？</a></li><li><a href="#なぜ-policy-head-は-softmaxvalue-head-は-tanh-なのか" class="table-of-contents__link toc-highlight">なぜ Policy Head は Softmax、Value Head は Tanh なのか？</a></li></ul></li><li><a href="#訓練の詳細" class="table-of-contents__link toc-highlight">訓練の詳細</a><ul><li><a href="#損失関数" class="table-of-contents__link toc-highlight">損失関数</a></li><li><a href="#最適化器の設定" class="table-of-contents__link toc-highlight">最適化器の設定</a></li><li><a href="#データ拡張" class="table-of-contents__link toc-highlight">データ拡張</a></li></ul></li><li><a href="#実装上の考慮事項" class="table-of-contents__link toc-highlight">実装上の考慮事項</a><ul><li><a href="#メモリ最適化" class="table-of-contents__link toc-highlight">メモリ最適化</a></li><li><a href="#推論の最適化" class="table-of-contents__link toc-highlight">推論の最適化</a></li><li><a href="#量子化と圧縮" class="table-of-contents__link toc-highlight">量子化と圧縮</a></li></ul></li><li><a href="#アニメーション対応" class="table-of-contents__link toc-highlight">アニメーション対応</a></li><li><a href="#関連記事" class="table-of-contents__link toc-highlight">関連記事</a></li><li><a href="#参考文献" class="table-of-contents__link toc-highlight">参考文献</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>