<!doctype html>
<html lang="ja" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/self-play" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">自己対局 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ja/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ja/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ja/docs/alphago/self-play/"><meta data-rh="true" property="og:locale" content="ja"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ja"><meta data-rh="true" name="docsearch:language" content="ja"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="自己対局 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="AlphaGo がどのように自己対局を通じて人間の棋力の限界を突破したかを深く理解する"><meta data-rh="true" property="og:description" content="AlphaGo がどのように自己対局を通じて人間の棋力の限界を突破したかを深く理解する"><link data-rh="true" rel="icon" href="/ja/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ja/docs/alphago/self-play/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/self-play/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/self-play/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/self-play/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/self-play/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/self-play/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/self-play/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/self-play/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/self-play/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/self-play/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/self-play/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/ja/docs/alphago/"},{"@type":"ListItem","position":2,"name":"自己対局","item":"https://www.weiqi.kids/ja/docs/alphago/self-play"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ja/assets/css/styles.f23bf74b.css">
<script src="/ja/assets/js/runtime~main.cfcf5f9b.js" defer="defer"></script>
<script src="/ja/assets/js/main.a02c4c61.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ja/img/logo.svg"><div role="region" aria-label="メインコンテンツまでスキップ"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">メインコンテンツまでスキップ</a></div><nav aria-label="ナビゲーション" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="ナビゲーションバーを開く" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ja/"><div class="navbar__logo"><img src="/ja/img/logo.svg" alt="好棋宝宝協会ロゴ" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ja/img/logo.svg" alt="好棋宝宝協会ロゴ" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">囲碁キッズ</b></a><a class="navbar__item navbar__link" href="/ja/docs/learn/">囲碁を学ぶ</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ja/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/ja/docs/animations/">アニメ教室</a><a class="navbar__item navbar__link" href="/ja/docs/tech/">技術ドキュメント</a><a class="navbar__item navbar__link" href="/ja/docs/about/">私たちについて</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>日本語</a><ul class="dropdown__menu"><li><a href="/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="検索" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="先頭へ戻る" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="ドキュメントのサイドバー" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ja/docs/intro/"><span title="ご利用ガイド" class="linkLabel_REp1">ご利用ガイド</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ja/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="&#x27;AlphaGo&#x27;の目次を隠す" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/birth-of-alphago/"><span title="AlphaGo の誕生" class="linkLabel_REp1">AlphaGo の誕生</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/key-matches/"><span title="重要対局の回顧" class="linkLabel_REp1">重要対局の回顧</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/move-37/"><span title="「神の一手」徹底分析" class="linkLabel_REp1">「神の一手」徹底分析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/why-go-is-hard/"><span title="囲碁はなぜ難しいのか？" class="linkLabel_REp1">囲碁はなぜ難しいのか？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/traditional-limits/"><span title="従来手法の限界" class="linkLabel_REp1">従来手法の限界</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/board-representation/"><span title="盤面状態の表現" class="linkLabel_REp1">盤面状態の表現</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/policy-network/"><span title="Policy Network 詳解" class="linkLabel_REp1">Policy Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/value-network/"><span title="Value Network 詳解" class="linkLabel_REp1">Value Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/input-features/"><span title="入力特徴量の設計" class="linkLabel_REp1">入力特徴量の設計</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/cnn-and-go/"><span title="CNNと囲碁の融合" class="linkLabel_REp1">CNNと囲碁の融合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/supervised-learning/"><span title="教師あり学習フェーズ" class="linkLabel_REp1">教師あり学習フェーズ</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/reinforcement-intro/"><span title="強化学習入門" class="linkLabel_REp1">強化学習入門</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ja/docs/alphago/self-play/"><span title="自己対局" class="linkLabel_REp1">自己対局</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/mcts-neural-combo/"><span title="MCTS とニューラルネットワークの融合" class="linkLabel_REp1">MCTS とニューラルネットワークの融合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/puct-formula/"><span title="PUCT 公式詳解" class="linkLabel_REp1">PUCT 公式詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/alphago-zero/"><span title="AlphaGo Zero 概要" class="linkLabel_REp1">AlphaGo Zero 概要</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/dual-head-resnet/"><span title="デュアルヘッドネットワークと残差ネットワーク" class="linkLabel_REp1">デュアルヘッドネットワークと残差ネットワーク</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/training-from-scratch/"><span title="ゼロからの学習過程" class="linkLabel_REp1">ゼロからの学習過程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/distributed-systems/"><span title="分散システムと TPU" class="linkLabel_REp1">分散システムと TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ja/docs/alphago/legacy-and-impact/"><span title="AlphaGo の遺産" class="linkLabel_REp1">AlphaGo の遺産</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="&#x27;學圍棋&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ja/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="&#x27;技術文件&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ja/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="&#x27;關於我們&#x27;の目次を開く" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="パンくずリストのナビゲーション"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="ホームページ" class="breadcrumbs__link" href="/ja/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ja/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">自己対局</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">このページの見出し</button></div><div class="theme-doc-markdown markdown"><header><h1>自己対局</h1></header>
<p>前の記事では、強化学習の基本概念を紹介しました。ここでは、AlphaGo 成功の鍵の一つである<strong>自己対局（Self-Play）</strong> を探求しましょう。</p>
<p>これは一見矛盾した概念です：<strong>AI はどうやって自分と対局することで強くなれるのでしょうか？</strong></p>
<p>その答えは深遠かつエレガントで、ゲーム理論、進化動力学、そして学習の本質に関わっています。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="なぜ自己対局は有効なのか">なぜ自己対局は有効なのか？<a href="#なぜ自己対局は有効なのか" class="hash-link" aria-label="なぜ自己対局は有効なのか？ への直接リンク" title="なぜ自己対局は有効なのか？ への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="直感的な説明">直感的な説明<a href="#直感的な説明" class="hash-link" aria-label="直感的な説明 への直接リンク" title="直感的な説明 への直接リンク" translate="no">​</a></h3>
<p>あなたが囲碁初心者で、無人島で一人で練習していると想像してください：</p>
<ol>
<li class="">一局の碁を打ち、自分で黒と白の両方を担当する</li>
<li class="">対局後、どの手が良くてどの手が悪かったかを分析する</li>
<li class="">次の対局では、前回の間違いを避けようとする</li>
<li class="">このプロセスを数百万回繰り返す</li>
</ol>
<p>直感的に、これには問題があるように思えます：</p>
<ul>
<li class="">レベルが低ければ、黒も白も悪い手を打つが、何を学べるのか？</li>
<li class="">「間違った均衡」に陥らないか——双方が悪い手を打つが互いに相殺する？</li>
</ul>
<p>しかし実際には、自己対局は継続的な進歩を生み出すことができます。理由は以下の通りです：</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="段階的な弱点の発見">段階的な弱点の発見<a href="#段階的な弱点の発見" class="hash-link" aria-label="段階的な弱点の発見 への直接リンク" title="段階的な弱点の発見 への直接リンク" translate="no">​</a></h3>
<p>重要な洞察：<strong>たとえ両方が同じ AI でも、各対局の結果には情報が含まれている</strong>。</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">局面 A：AI は着手 X を選び、最終的に勝利</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">局面 A：AI は着手 Y を選び、最終的に敗北</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">→ 結論：局面 A では、X は Y より良い</span><br></span></code></pre></div></div>
<p>大量の対局を統計することで、AI は各局面でどの選択がより優れているかを学習できます。これが<strong>Policy Gradient</strong> の本質です：良い選択は強化され、悪い選択は抑制されます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="対抗的学習">対抗的学習<a href="#対抗的学習" class="hash-link" aria-label="対抗的学習 への直接リンク" title="対抗的学習 への直接リンク" translate="no">​</a></h3>
<p>自己対局には特別な性質があります：<strong>訓練相手が自動的にあなたのレベルに適応する</strong>。</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">訓練サイクル 1：AI は効果的な戦術 T を発見</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">訓練サイクル 2：相手としての AI は T を防ぐ方法を学ぶ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">訓練サイクル 3：元の AI はより良い戦術 T&#x27; を探さざるを得ない</span><br></span></code></pre></div></div>
<p>これは<strong>軍拡競争（Arms Race）</strong> を形成し、双方が互いの弱点を継続的に発見し克服します。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="人間の棋譜との比較">人間の棋譜との比較<a href="#人間の棋譜との比較" class="hash-link" aria-label="人間の棋譜との比較 への直接リンク" title="人間の棋譜との比較 への直接リンク" translate="no">​</a></h3>
<table><thead><tr><th>訓練方法</th><th>利点</th><th>欠点</th></tr></thead><tbody><tr><td><strong>人間の棋譜</strong></td><td>人間の知恵の結晶を学ぶ</td><td>人間のレベルに制限される</td></tr><tr><td><strong>自己対局</strong></td><td>向上に上限がない</td><td>局所最適に陥る可能性</td></tr><tr><td><strong>両者の組み合わせ</strong></td><td>素早いスタート + 継続的向上</td><td>最良の戦略</td></tr></tbody></table>
<p>AlphaGo オリジナル版は、まず人間の棋譜で教師あり学習を行い、次に自己対局で強化学習を行いました。AlphaGo Zero は、自己対局のみでも超人的なレベルに達することを証明しました。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="ゲーム理論の視点">ゲーム理論の視点<a href="#ゲーム理論の視点" class="hash-link" aria-label="ゲーム理論の視点 への直接リンク" title="ゲーム理論の視点 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ナッシュ均衡">ナッシュ均衡<a href="#ナッシュ均衡" class="hash-link" aria-label="ナッシュ均衡 への直接リンク" title="ナッシュ均衡 への直接リンク" translate="no">​</a></h3>
<p>ゲーム理論において、<strong>ナッシュ均衡（Nash Equilibrium）</strong> は安定状態です：この状態では、どのプレイヤーも一方的に戦略を変更する動機がありません。</p>
<p>囲碁のような<strong>ゼロサム、完全情報ゲーム</strong>では、ナッシュ均衡には特別な意味があります：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></msub><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^* = \arg\max_\pi \min_{\pi&#x27;} V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>ここで <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> は戦略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> が戦略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\pi&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> と対戦したときの期待値です。</p>
<p>これが有名な <strong>Minimax 原理</strong>です：最良の戦略は、最悪の場合でも最も良く機能する戦略です。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="自己対局とナッシュ均衡">自己対局とナッシュ均衡<a href="#自己対局とナッシュ均衡" class="hash-link" aria-label="自己対局とナッシュ均衡 への直接リンク" title="自己対局とナッシュ均衡 への直接リンク" translate="no">​</a></h3>
<p>理論的には、自己対局が収束すれば、ナッシュ均衡に収束するはずです。囲碁のような決定論的ゲームでは、ナッシュ均衡は<strong>完璧な着手</strong>です。</p>
<p>しかし、囲碁の状態空間は大きすぎます（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>170</mn></msup></mrow><annotation encoding="application/x-tex">10^{170}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">170</span></span></span></span></span></span></span></span></span></span></span></span>）、真のナッシュ均衡を見つけることは不可能です。自己対局は実際にはこの均衡を<strong>近似</strong>しています。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="仮想対局fictitious-play">仮想対局（Fictitious Play）<a href="#仮想対局fictitious-play" class="hash-link" aria-label="仮想対局（Fictitious Play） への直接リンク" title="仮想対局（Fictitious Play） への直接リンク" translate="no">​</a></h3>
<p>自己対局はゲーム理論の<strong>仮想対局</strong>概念に関連しています：</p>
<ol>
<li class="">各プレイヤーは相手の過去の戦略を観察</li>
<li class="">相手の戦略の平均分布を計算</li>
<li class="">この平均分布に対する最良の応答を選択</li>
</ol>
<p>ある条件下では、仮想対局がナッシュ均衡に収束することが証明できます。</p>
<p>AlphaGo の自己対局は、この概念のニューラルネットワーク実装と見なすことができます。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="自己対局のメカニズム">自己対局のメカニズム<a href="#自己対局のメカニズム" class="hash-link" aria-label="自己対局のメカニズム への直接リンク" title="自己対局のメカニズム への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="基本的な流れ">基本的な流れ<a href="#基本的な流れ" class="hash-link" aria-label="基本的な流れ への直接リンク" title="基本的な流れ への直接リンク" translate="no">​</a></h3>
<p>AlphaGo の自己対局の流れ：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">アルゴリズム：Self-Play Training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">初期化：Policy Network π_θ（教師あり学習またはランダム初期化から開始可能）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">収束するまで以下のステップを繰り返す：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. 対局データの生成</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   i = 1 から N まで（並列実行）：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. 現在の方策 π_θ で一局の自己対局を行う</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 軌跡を収集：τ_i = (s_0, a_0, r_1, s_1, a_1, ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. 最終結果を記録 z_i ∈ {-1, +1}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 方策の更新</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 方策勾配を計算：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ∇J = (1/N) Σ_i Σ_t ∇_θ log π_θ(a_t|s_t) · z_i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. パラメータを更新：θ ← θ + α · ∇J</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 価値ネットワークの更新</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. (s, z) ペアで Value Network を訓練</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 最小化：L = E[(V_φ(s) - z)²]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. オプション：評価とチェックポイント保存</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 新しい方策を旧バージョンと対戦させる</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 勝率 &gt; 55% なら、対戦相手プールを更新</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="訓練データの生成">訓練データの生成<a href="#訓練データの生成" class="hash-link" aria-label="訓練データの生成 への直接リンク" title="訓練データの生成 への直接リンク" translate="no">​</a></h3>
<p>各自己対局は<strong>軌跡（trajectory）</strong> を生成します：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, s_1, a_1, \ldots, s_T, z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)</span></span></span></span></p>
<p>ここで：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>：タイムステップ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> の盤面状態</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>：タイムステップ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> で選択した行動</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span>：最終結果（+1 勝利、-1 敗北）</li>
</ul>
<p>200手の対局は200の訓練サンプルを生成します。毎日数十万局の自己対局を行うと、訓練データ量は驚異的です。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="方策の更新">方策の更新<a href="#方策の更新" class="hash-link" aria-label="方策の更新 への直接リンク" title="方策の更新 への直接リンク" translate="no">​</a></h3>
<p>Policy Gradient を使って Policy Network を更新：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>z</mi><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \cdot \nabla_\theta \mathbb{E}\left[\sum_t \log \pi_\theta(a_t|s_t) \cdot z\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1308em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose delimcenter" style="top:0em">]</span></span></span></span></span></p>
<p>この更新の効果：</p>
<ul>
<li class="">最終的に勝利（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = +1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>）すれば、すべての着手の確率を増やす</li>
<li class="">最終的に敗北（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = -1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>）すれば、すべての着手の確率を減らす</li>
</ul>
<p>これは粗く見えます——勝った碁にも悪い手があるかもしれないし、負けた碁にも良い手があるかもしれません。しかし、大量の対局の統計を通じて、これらの「ノイズ」は平均化され、本当に良い手が識別されます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="価値ネットワークの訓練">価値ネットワークの訓練<a href="#価値ネットワークの訓練" class="hash-link" aria-label="価値ネットワークの訓練 への直接リンク" title="価値ネットワークの訓練 への直接リンク" translate="no">​</a></h3>
<p>Value Network は<strong>回帰（regression）</strong> で訓練されます：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>←</mo><mi>ϕ</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ϕ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>z</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\phi \leftarrow \phi - \beta \cdot \nabla_\phi \mathbb{E}\left[(V_\phi(s) - z)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>これにより Value Network は予測を学習します：現在の局面から始めて、最終的に勝つ確率は？</p>
<p>Value Network の役割：</p>
<ol>
<li class="">MCTS でリーフノード評価を提供</li>
<li class="">Policy Gradient のベースラインとして機能</li>
<li class="">直接の局面評価に使用</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="ランダム性の重要性">ランダム性の重要性<a href="#ランダム性の重要性" class="hash-link" aria-label="ランダム性の重要性 への直接リンク" title="ランダム性の重要性 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="決定論的ループの回避">決定論的ループの回避<a href="#決定論的ループの回避" class="hash-link" aria-label="決定論的ループの回避 への直接リンク" title="決定論的ループの回避 への直接リンク" translate="no">​</a></h3>
<p>自己対局が完全に決定論的だと、ループに陥る可能性があります：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">方策 A は常に固定の序盤を打つ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">方策 A 対 方策 A は常に同じ棋局を生成</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">一局だけが繰り返し学習される</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">AI は他の可能性を探索できない</span><br></span></code></pre></div></div>
<p>これが<strong>ランダム性</strong>が自己対局で極めて重要な理由です。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ランダム性の源">ランダム性の源<a href="#ランダム性の源" class="hash-link" aria-label="ランダム性の源 への直接リンク" title="ランダム性の源 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo が自己対局でランダム性を導入する方法：</p>
<p><strong>1. 方策ネットワーク自体が確率的</strong></p>
<p>Policy Network は決定論的選択ではなく確率分布を出力：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a \sim \pi_\theta(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></p>
<p>同じ局面でも、毎回異なる着手を選ぶ可能性があります。</p>
<p><strong>2. 温度パラメータ</strong></p>
<p>訓練時に高い温度（temperature）を使用して多様性を増やす：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow><mrow><msub><mo>∑</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\pi_\tau(a|s) = \frac{\pi_\theta(a|s)^{1/\tau}}{\sum_{a&#x27;} \pi_\theta(a&#x27;|s)^{1/\tau}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7721em;vertical-align:-0.6104em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1617em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2854em"><span style="top:-2.2854em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.6068em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em"><span style="top:-2.8496em;margin-right:0.1em"><span class="pstrut" style="height:2.5556em"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667em"><span style="top:-2.9667em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6104em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：よりランダム、より探索</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：より決定論的、より活用</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：元の分布</li>
</ul>
<p><strong>3. Dirichlet Noise</strong></p>
<p>AlphaGo Zero は自己対局時に、ルートノードの事前確率に Dirichlet ノイズを追加：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><mo>⋅</mo><msub><mi>η</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">P(s, a) = (1 - \varepsilon) \cdot \pi_\theta(a|s) + \varepsilon \cdot \eta_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>ここで <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>∼</mo><mtext>Dir</mtext><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\eta \sim \text{Dir}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span>（囲碁の361の行動用）。</p>
<p>これにより、非常に低確率の着手でも探索される機会が確保されます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="対戦相手プールpopulationアプローチ">対戦相手プール（Population）アプローチ<a href="#対戦相手プールpopulationアプローチ" class="hash-link" aria-label="対戦相手プール（Population）アプローチ への直接リンク" title="対戦相手プール（Population）アプローチ への直接リンク" translate="no">​</a></h3>
<p>多様性を増やす別の方法は<strong>対戦相手プール</strong>を維持することです：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">対戦相手プール = [π_1, π_2, π_3, ..., π_k]（異なるバージョンの方策）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">各対局：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. プールからランダムに対戦相手を選択</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. その対戦相手と対局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 結果で現在の方策を更新</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 定期的に改善された方策をプールに追加</span><br></span></code></pre></div></div>
<p>このアプローチの利点：</p>
<ul>
<li class=""><strong>多様性</strong>：異なるスタイルの対戦相手</li>
<li class=""><strong>安定性</strong>：特定の対戦相手への過学習を回避</li>
<li class=""><strong>頑健性</strong>：さまざまな戦略への対応を学習</li>
</ul>
<p>AlphaGo オリジナル版と AlphaGo Zero の両方が類似の技術を使用しました。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="棋力成長曲線">棋力成長曲線<a href="#棋力成長曲線" class="hash-link" aria-label="棋力成長曲線 への直接リンク" title="棋力成長曲線 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="elo-レーティングシステム">Elo レーティングシステム<a href="#elo-レーティングシステム" class="hash-link" aria-label="Elo レーティングシステム への直接リンク" title="Elo レーティングシステム への直接リンク" translate="no">​</a></h3>
<p>AI の棋力変化を追跡するために、AlphaGo は <strong>Elo レーティングシステム</strong>を使用しました。</p>
<p>Elo システムの基本原理：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>A wins</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>B</mi></msub><mo>−</mo><msub><mi>R</mi><mi>A</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>400</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{A wins}) = \frac{1}{1 + 10^{(R_B - R_A)/400}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">A wins</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3331em;vertical-align:-0.488em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.5703em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8853em"><span style="top:-2.8853em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight">A</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/400</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.488em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>ここで <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">R_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> と <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">R_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> は双方の Elo スコアです。</p>
<ul>
<li class="">200点差：強者は75%勝つと予想</li>
<li class="">400点差：強者は90%勝つと予想</li>
<li class="">800点差：強者は99%勝つと予想</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-の棋力成長">AlphaGo の棋力成長<a href="#alphago-の棋力成長" class="hash-link" aria-label="AlphaGo の棋力成長 への直接リンク" title="AlphaGo の棋力成長 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo 各バージョンの棋力成長を視覚化してみましょう：</p>
<div>載入中...</div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="成長速度の分析">成長速度の分析<a href="#成長速度の分析" class="hash-link" aria-label="成長速度の分析 への直接リンク" title="成長速度の分析 への直接リンク" translate="no">​</a></h3>
<p>曲線からいくつかの興味深い現象が観察できます：</p>
<p><strong>1. 初期の急速な成長</strong></p>
<p>訓練の最初の数時間で、AI は基本ルールと単純な戦術を学びました。これは<strong>低い位置の果実</strong>段階——修正すべき明らかな間違いが多すぎます。</p>
<p><strong>2. 中期の安定した成長</strong></p>
<p>基本的な間違いが解消されると、AI はより精妙な戦術と定石を学び始めます。成長速度は遅くなりますが、安定しています。</p>
<p><strong>3. 後期の成長鈍化</strong></p>
<p>AI がすでに非常に強くなると、さらなる向上は困難になります。間違いを修正するだけでなく、まったく新しい戦略を発見する必要があるかもしれません。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="人間を超える瞬間">人間を超える瞬間<a href="#人間を超える瞬間" class="hash-link" aria-label="人間を超える瞬間 への直接リンク" title="人間を超える瞬間 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo 訓練曲線の主要なマイルストーン：</p>
<table><thead><tr><th>マイルストーン</th><th>相当するレベル</th><th>達成時間</th></tr></thead><tbody><tr><td>アマチュア強豪を超える</td><td>Elo ~2700</td><td>約3時間</td></tr><tr><td>Fan Hui を超える</td><td>Elo ~3500</td><td>約36時間</td></tr><tr><td>Lee Sedol を超える</td><td>Elo ~4500</td><td>約60時間</td></tr><tr><td>オリジナル AlphaGo を超える</td><td>Elo ~5000</td><td>約72時間</td></tr></tbody></table>
<p>これらの数字（AlphaGo Zero より）は驚くべきものです：<strong>AI は3日でゼロから始めて、人間の数千年の囲碁の知恵を超えました</strong>。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="収束性分析">収束性分析<a href="#収束性分析" class="hash-link" aria-label="収束性分析 への直接リンク" title="収束性分析 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="自己対局は収束するか">自己対局は収束するか？<a href="#自己対局は収束するか" class="hash-link" aria-label="自己対局は収束するか？ への直接リンク" title="自己対局は収束するか？ への直接リンク" translate="no">​</a></h3>
<p>これは重要な理論的問題です。簡潔な答え：<strong>ある条件下では収束するが、囲碁は複雑すぎて厳密に証明できない</strong>。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="理論的保証">理論的保証<a href="#理論的保証" class="hash-link" aria-label="理論的保証 への直接リンク" title="理論的保証 への直接リンク" translate="no">​</a></h3>
<p>より単純なゲーム（三目並べなど）では、以下を証明できます：</p>
<ol>
<li class=""><strong>存在性</strong>：ナッシュ均衡は存在する（Minimax 定理）</li>
<li class=""><strong>収束性</strong>：一部のアルゴリズム（仮想対局など）はナッシュ均衡に収束する</li>
</ol>
<p>囲碁では、厳密な収束保証はありませんが、実験的証拠は以下を示しています：</p>
<ul>
<li class="">棋力は継続的に向上</li>
<li class="">明らかな振動や退化は発生しない</li>
<li class="">最終的な棋力はすべての既知の人間を超える</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="起こりうる失敗モード">起こりうる失敗モード<a href="#起こりうる失敗モード" class="hash-link" aria-label="起こりうる失敗モード への直接リンク" title="起こりうる失敗モード への直接リンク" translate="no">​</a></h3>
<p>自己対局で遭遇しうる問題：</p>
<p><strong>1. 戦略循環（Strategy Cycling）</strong></p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">戦略 A が戦略 B に勝つ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">戦略 B が戦略 C に勝つ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">戦略 C が戦略 A に勝つ</span><br></span></code></pre></div></div>
<p>これは一部のゲームでは確かに起こります（じゃんけんなど）。しかし囲碁には十分な複雑さがあり、このような純粋な循環は起こらないようです。</p>
<p><strong>2. 自分自身への過学習</strong></p>
<p>AI は自分のスタイルだけを対象とした戦略を学習し、他のスタイルの対戦相手に対応できなくなる可能性があります。これが AlphaGo が異なるバージョンの自分自身と対局し、最終的に人間棋士とテストする理由です。</p>
<p><strong>3. 局所最適</strong></p>
<p>AI は局所最適に陥る可能性があります——「まあまあだが最良ではない」戦略。ランダム化と大量の対局がこの問題を回避するのに役立ちます。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="実際の観察">実際の観察<a href="#実際の観察" class="hash-link" aria-label="実際の観察 への直接リンク" title="実際の観察 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo の訓練プロセスからの観察：</p>
<ol>
<li class=""><strong>継続的進歩</strong>：Elo スコアは訓練とともに継続的に上昇</li>
<li class=""><strong>退化なし</strong>：棋力が突然低下することはない</li>
<li class=""><strong>スタイルの進化</strong>：AI の着手スタイルは訓練に伴い徐々に変化</li>
<li class=""><strong>新定石の発見</strong>：AI は人間が使用したことのない序盤や戦術を発見</li>
</ol>
<p>これらの観察は、理論的保証はないものの、自己対局が実践では確かに有効であることを示しています。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="実装の詳細">実装の詳細<a href="#実装の詳細" class="hash-link" aria-label="実装の詳細 への直接リンク" title="実装の詳細 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="並列自己対局">並列自己対局<a href="#並列自己対局" class="hash-link" aria-label="並列自己対局 への直接リンク" title="並列自己対局 への直接リンク" translate="no">​</a></h3>
<p>訓練を加速するため、AlphaGo は大規模な並列自己対局を使用：</p>
<!-- -->
<p><strong>主要な設計決定</strong>：</p>
<ul>
<li class=""><strong>同期 vs 非同期</strong>：AlphaGo は非同期更新を使用、Worker は互いを待つ必要がない</li>
<li class=""><strong>更新頻度</strong>：N 局の対局完了ごとにパラメータを更新</li>
<li class=""><strong>対戦相手選択</strong>：最近の数バージョンからランダムに一つを対戦相手として選択</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="チェックポイント戦略">チェックポイント戦略<a href="#チェックポイント戦略" class="hash-link" aria-label="チェックポイント戦略 への直接リンク" title="チェックポイント戦略 への直接リンク" translate="no">​</a></h3>
<p>定期的にモデルチェックポイントを保存、用途：</p>
<ol>
<li class=""><strong>対戦相手プール</strong>：異なるバージョンの対戦相手を維持</li>
<li class=""><strong>評価</strong>：棋力変化を追跡</li>
<li class=""><strong>障害復旧</strong>：訓練中断時に復旧可能</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 擬似コード</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">training_loop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> iteration </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_iterations</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 対局データを生成</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trajectories </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parallel_self_play</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_games</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 方策を更新</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update_policy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">trajectories</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 定期的に評価と保存</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> iteration </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate_against_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            save_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> elo</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> elo </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> best_elo</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                add_to_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                best_elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> elo</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="訓練リソース要件">訓練リソース要件<a href="#訓練リソース要件" class="hash-link" aria-label="訓練リソース要件 への直接リンク" title="訓練リソース要件 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo の訓練規模は印象的です：</p>
<table><thead><tr><th>バージョン</th><th>ハードウェア</th><th>訓練時間</th><th>自己対局局数</th></tr></thead><tbody><tr><td>AlphaGo Fan</td><td>176 GPU</td><td>数ヶ月</td><td>~30M</td></tr><tr><td>AlphaGo Lee</td><td>48 TPU</td><td>数週間</td><td>~30M</td></tr><tr><td>AlphaGo Zero</td><td>4 TPU</td><td>3日</td><td>~5M</td></tr><tr><td>AlphaGo Zero (40日版)</td><td>4 TPU</td><td>40日</td><td>~30M</td></tr></tbody></table>
<p>AlphaGo Zero はより少ないハードウェアとより短い時間でより強い棋力に達したことに注目——これはアルゴリズム効率の向上です。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ハイパーパラメータ設定">ハイパーパラメータ設定<a href="#ハイパーパラメータ設定" class="hash-link" aria-label="ハイパーパラメータ設定 への直接リンク" title="ハイパーパラメータ設定 への直接リンク" translate="no">​</a></h3>
<p>いくつかの重要なハイパーパラメータ：</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 自己対局設定</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NUM_PARALLEL_GAMES </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># 同時に進行する対局数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GAMES_PER_ITERATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">25000</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 各イテレーションの対局数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MCTS_SIMULATIONS </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1600</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 各手の MCTS シミュレーション回数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 訓練設定</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BATCH_SIZE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 訓練バッチサイズ</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LEARNING_RATE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># 初期学習率</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">L2_REGULARIZATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># 重み減衰</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 探索設定</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TEMPERATURE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 序盤30手の温度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DIRICHLET_ALPHA </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.03</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># Dirichlet ノイズパラメータ</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EXPLORATION_FRACTION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># ノイズ比率</span><br></span></code></pre></div></div>
<p>これらのハイパーパラメータは大量の実験で調整されており、訓練効果に大きな影響を与えます。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="自己対局の変形">自己対局の変形<a href="#自己対局の変形" class="hash-link" aria-label="自己対局の変形 への直接リンク" title="自己対局の変形 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-オリジナル版">AlphaGo オリジナル版<a href="#alphago-オリジナル版" class="hash-link" aria-label="AlphaGo オリジナル版 への直接リンク" title="AlphaGo オリジナル版 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo オリジナル版の訓練フロー：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 教師あり学習 (SL)：人間の棋譜から学習</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → SL Policy Network を生成 (π_SL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 強化学習 (RL)：自己対局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   初期化 π_RL = π_SL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   対戦相手プール = [π_SL]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   繰り返し：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. π_RL がプール内の方策と対局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Policy Gradient で π_RL を更新</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. π_RL が強くなったらプールに追加</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → RL Policy Network を生成 (π_RL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 価値ネットワーク訓練：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   π_RL 自己対局で局面を生成</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   V(s) を訓練して勝率を予測</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero">AlphaGo Zero<a href="#alphago-zero" class="hash-link" aria-label="AlphaGo Zero への直接リンク" title="AlphaGo Zero への直接リンク" translate="no">​</a></h3>
<p>AlphaGo Zero はこのフローを簡略化しました：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 純粋な自己対局（人間データなし）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ランダムネットワーク f_θ を初期化</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   繰り返し：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. MCTS + f_θ で自己対局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 方策ヘッドと価値ヘッドを同時に訓練</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. f_θ を更新</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → 単一ネットワークが同時に方策と価値を出力</span><br></span></code></pre></div></div>
<p>主要な改良：</p>
<ul>
<li class=""><strong>人間データ不要</strong>：ゼロから開始</li>
<li class=""><strong>単一ネットワーク</strong>：方策と価値が特徴を共有</li>
<li class=""><strong>より簡潔な訓練</strong>：End-to-End 学習</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphazero">AlphaZero<a href="#alphazero" class="hash-link" aria-label="AlphaZero への直接リンク" title="AlphaZero への直接リンク" translate="no">​</a></h3>
<p>AlphaZero はさらに汎化しました：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">同じアルゴリズム、異なるゲーム：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 囲碁：AlphaGo Zero を超えるレベルに到達</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- チェス：Stockfish を超える</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 将棋：Elmo を超える</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">唯一のゲーム固有部分：ルールのエンコード</span><br></span></code></pre></div></div>
<p>これは自己対局が<strong>汎用的な学習パラダイム</strong>であり、囲碁に限定されないことを証明しました。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="人間は何を学んだか">人間は何を学んだか？<a href="#人間は何を学んだか" class="hash-link" aria-label="人間は何を学んだか？ への直接リンク" title="人間は何を学んだか？ への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ai-が発見した新定石">AI が発見した新定石<a href="#ai-が発見した新定石" class="hash-link" aria-label="AI が発見した新定石 への直接リンク" title="AI が発見した新定石 への直接リンク" translate="no">​</a></h3>
<p>自己対局は人間が使用したことのない多くの着手を生み出しました：</p>
<p><strong>1. 序盤のイノベーション</strong></p>
<p>AlphaGo が好む序盤のいくつか：</p>
<ul>
<li class="">三々への侵入：早期に隅に侵入</li>
<li class="">高い位置の着手：伝統的に「不安定」と考えられていた</li>
<li class="">大ナダレ変化：人間は複雑で計算困難と考えていた</li>
</ul>
<p><strong>2. 新しい形勢判断</strong></p>
<p>AI の一部の局面評価は人間と大きく異なりました：</p>
<ul>
<li class="">一見「薄い」形が実は堅実</li>
<li class="">一部の「厚み」の価値が過大評価されていた</li>
<li class="">「先手」と「後手」の再評価</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="人間の囲碁への影響">人間の囲碁への影響<a href="#人間の囲碁への影響" class="hash-link" aria-label="人間の囲碁への影響 への直接リンク" title="人間の囲碁への影響 への直接リンク" translate="no">​</a></h3>
<p>AlphaGo 後、プロ囲碁は大きく変化しました：</p>
<ol>
<li class=""><strong>序盤の多様化</strong>：プロ棋士は AI が発見した新しい序盤を使い始めた</li>
<li class=""><strong>訓練方法の変化</strong>：AI がプロ棋士の主要な訓練ツールになった</li>
<li class=""><strong>棋理の再考</strong>：多くの伝統的「棋理」が疑問視され修正された</li>
<li class=""><strong>新しい美学</strong>：AI スタイルの碁を鑑賞し始めた</li>
</ol>
<p>柯潔は AlphaGo に負けた後、こう言いました：</p>
<blockquote>
<p>「AlphaGo は私に囲碁を再認識させました。以前は人間が囲碁を理解していると思っていましたが、今では私たちは表面をなぞっているだけだとわかりました。」</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="哲学的考察">哲学的考察<a href="#哲学的考察" class="hash-link" aria-label="哲学的考察 への直接リンク" title="哲学的考察 への直接リンク" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="学習の本質">学習の本質<a href="#学習の本質" class="hash-link" aria-label="学習の本質 への直接リンク" title="学習の本質 への直接リンク" translate="no">​</a></h3>
<p>自己対局は学習に関する深い問題を提起します：</p>
<p><strong>知識はどこから来るのか？</strong></p>
<ul>
<li class="">人間の学習は外部情報（教師、本、経験）に依存</li>
<li class="">自己対局の AI はルールだけで、外部知識がない</li>
<li class="">それでも知識を「発見」できる——これらの知識はどこから来るのか？</li>
</ul>
<p>答えはおそらく：<strong>知識はゲームのルールと構造に暗黙的に含まれている</strong>。囲碁のルールが良い手と悪い手を定義し、自己対局はこれらの暗黙的な構造を明らかにするだけです。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="創造性と発見">創造性と発見<a href="#創造性と発見" class="hash-link" aria-label="創造性と発見 への直接リンク" title="創造性と発見 への直接リンク" translate="no">​</a></h3>
<p>AI が「神の一手」（Move 37）を打ったとき、これは創造なのか発見なのか？</p>
<p>一つの見方：その手は囲碁のルールにずっと「存在」しており、AI はそれを「発見」しただけ。
別の見方：AI はその手を「創造」した、なぜなら誰も（AI 自身を含め）事前にそれを知らなかったから。</p>
<p>この問題に標準的な答えはありませんが、創造性に関する私たちの伝統的理解に挑戦しています。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="人間の知性の位置">人間の知性の位置<a href="#人間の知性の位置" class="hash-link" aria-label="人間の知性の位置 への直接リンク" title="人間の知性の位置 への直接リンク" translate="no">​</a></h3>
<p>AI がゼロから始めて、自己対局で人間の数千年の知恵を超えられるなら、これは人間にとって何を意味するか？</p>
<p>楽観的な見方：</p>
<ul>
<li class="">AI は人間が創造したツール</li>
<li class="">AI の発見は人間の理解を増強できる</li>
<li class="">人間は AI と協力して、より高いレベルに到達できる</li>
</ul>
<p>慎重な見方：</p>
<ul>
<li class="">一部の領域では、純粋な計算が人間の直感を超えるかもしれない</li>
<li class="">「専門スキル」の価値を再考する必要がある</li>
<li class="">教育と訓練の方法を変える必要があるかもしれない</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="アニメーション対応">アニメーション対応<a href="#アニメーション対応" class="hash-link" aria-label="アニメーション対応 への直接リンク" title="アニメーション対応 への直接リンク" translate="no">​</a></h2>
<p>本記事で扱う核心概念とアニメーション番号：</p>
<table><thead><tr><th>番号</th><th>概念</th><th>物理/数学対応</th></tr></thead><tbody><tr><td>🎬 E5</td><td>自己対局ループ</td><td>不動点反復</td></tr><tr><td>🎬 E6</td><td>戦略の進化</td><td>進化動力学</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="まとめ">まとめ<a href="#まとめ" class="hash-link" aria-label="まとめ への直接リンク" title="まとめ への直接リンク" translate="no">​</a></h2>
<p>自己対局は AlphaGo 成功の鍵となる技術の一つです。以下を学びました：</p>
<ol>
<li class=""><strong>なぜ有効か</strong>：対抗的学習、段階的な弱点の発見</li>
<li class=""><strong>メカニズム</strong>：軌跡収集、Policy Gradient、Value Network 訓練</li>
<li class=""><strong>ランダム化</strong>：温度パラメータ、Dirichlet ノイズ、対戦相手プール</li>
<li class=""><strong>棋力成長</strong>：Elo システム、成長曲線分析</li>
<li class=""><strong>収束性</strong>：理論的保証と実際の観察</li>
<li class=""><strong>実装の詳細</strong>：並列訓練、チェックポイント戦略、ハイパーパラメータ</li>
</ol>
<p>次の記事では、AlphaGo がニューラルネットワークと MCTS をどのように組み合わせて両者の長所を発揮するかを探ります。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="さらに読む">さらに読む<a href="#さらに読む" class="hash-link" aria-label="さらに読む への直接リンク" title="さらに読む への直接リンク" translate="no">​</a></h2>
<ul>
<li class=""><strong>次の記事</strong>：<a class="" href="/ja/docs/alphago/mcts-neural-combo/">MCTS とニューラルネットワークの融合</a> — 直感と推論の完璧な組み合わせ</li>
<li class=""><strong>前の記事</strong>：<a class="" href="/ja/docs/alphago/reinforcement-intro/">強化学習入門</a> — 強化学習の基本概念</li>
<li class=""><strong>関連</strong>：<a class="" href="/ja/docs/alphago/alphago-zero/">AlphaGo Zero 概要</a> — ゼロからの突破</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="参考文献">参考文献<a href="#参考文献" class="hash-link" aria-label="参考文献 への直接リンク" title="参考文献 への直接リンク" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">Heinrich, J., &amp; Silver, D. (2016). &quot;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.&quot; <em>arXiv preprint</em>.</li>
<li class="">Lanctot, M., et al. (2017). &quot;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/13-self-play.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>このページを編集</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="ドキュメントページ"><a class="pagination-nav__link pagination-nav__link--prev" href="/ja/docs/alphago/reinforcement-intro/"><div class="pagination-nav__sublabel">前へ</div><div class="pagination-nav__label">強化学習入門</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ja/docs/alphago/mcts-neural-combo/"><div class="pagination-nav__sublabel">次へ</div><div class="pagination-nav__label">MCTS とニューラルネットワークの融合</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#なぜ自己対局は有効なのか" class="table-of-contents__link toc-highlight">なぜ自己対局は有効なのか？</a><ul><li><a href="#直感的な説明" class="table-of-contents__link toc-highlight">直感的な説明</a></li><li><a href="#段階的な弱点の発見" class="table-of-contents__link toc-highlight">段階的な弱点の発見</a></li><li><a href="#対抗的学習" class="table-of-contents__link toc-highlight">対抗的学習</a></li><li><a href="#人間の棋譜との比較" class="table-of-contents__link toc-highlight">人間の棋譜との比較</a></li></ul></li><li><a href="#ゲーム理論の視点" class="table-of-contents__link toc-highlight">ゲーム理論の視点</a><ul><li><a href="#ナッシュ均衡" class="table-of-contents__link toc-highlight">ナッシュ均衡</a></li><li><a href="#自己対局とナッシュ均衡" class="table-of-contents__link toc-highlight">自己対局とナッシュ均衡</a></li><li><a href="#仮想対局fictitious-play" class="table-of-contents__link toc-highlight">仮想対局（Fictitious Play）</a></li></ul></li><li><a href="#自己対局のメカニズム" class="table-of-contents__link toc-highlight">自己対局のメカニズム</a><ul><li><a href="#基本的な流れ" class="table-of-contents__link toc-highlight">基本的な流れ</a></li><li><a href="#訓練データの生成" class="table-of-contents__link toc-highlight">訓練データの生成</a></li><li><a href="#方策の更新" class="table-of-contents__link toc-highlight">方策の更新</a></li><li><a href="#価値ネットワークの訓練" class="table-of-contents__link toc-highlight">価値ネットワークの訓練</a></li></ul></li><li><a href="#ランダム性の重要性" class="table-of-contents__link toc-highlight">ランダム性の重要性</a><ul><li><a href="#決定論的ループの回避" class="table-of-contents__link toc-highlight">決定論的ループの回避</a></li><li><a href="#ランダム性の源" class="table-of-contents__link toc-highlight">ランダム性の源</a></li><li><a href="#対戦相手プールpopulationアプローチ" class="table-of-contents__link toc-highlight">対戦相手プール（Population）アプローチ</a></li></ul></li><li><a href="#棋力成長曲線" class="table-of-contents__link toc-highlight">棋力成長曲線</a><ul><li><a href="#elo-レーティングシステム" class="table-of-contents__link toc-highlight">Elo レーティングシステム</a></li><li><a href="#alphago-の棋力成長" class="table-of-contents__link toc-highlight">AlphaGo の棋力成長</a></li><li><a href="#成長速度の分析" class="table-of-contents__link toc-highlight">成長速度の分析</a></li><li><a href="#人間を超える瞬間" class="table-of-contents__link toc-highlight">人間を超える瞬間</a></li></ul></li><li><a href="#収束性分析" class="table-of-contents__link toc-highlight">収束性分析</a><ul><li><a href="#自己対局は収束するか" class="table-of-contents__link toc-highlight">自己対局は収束するか？</a></li><li><a href="#理論的保証" class="table-of-contents__link toc-highlight">理論的保証</a></li><li><a href="#起こりうる失敗モード" class="table-of-contents__link toc-highlight">起こりうる失敗モード</a></li><li><a href="#実際の観察" class="table-of-contents__link toc-highlight">実際の観察</a></li></ul></li><li><a href="#実装の詳細" class="table-of-contents__link toc-highlight">実装の詳細</a><ul><li><a href="#並列自己対局" class="table-of-contents__link toc-highlight">並列自己対局</a></li><li><a href="#チェックポイント戦略" class="table-of-contents__link toc-highlight">チェックポイント戦略</a></li><li><a href="#訓練リソース要件" class="table-of-contents__link toc-highlight">訓練リソース要件</a></li><li><a href="#ハイパーパラメータ設定" class="table-of-contents__link toc-highlight">ハイパーパラメータ設定</a></li></ul></li><li><a href="#自己対局の変形" class="table-of-contents__link toc-highlight">自己対局の変形</a><ul><li><a href="#alphago-オリジナル版" class="table-of-contents__link toc-highlight">AlphaGo オリジナル版</a></li><li><a href="#alphago-zero" class="table-of-contents__link toc-highlight">AlphaGo Zero</a></li><li><a href="#alphazero" class="table-of-contents__link toc-highlight">AlphaZero</a></li></ul></li><li><a href="#人間は何を学んだか" class="table-of-contents__link toc-highlight">人間は何を学んだか？</a><ul><li><a href="#ai-が発見した新定石" class="table-of-contents__link toc-highlight">AI が発見した新定石</a></li><li><a href="#人間の囲碁への影響" class="table-of-contents__link toc-highlight">人間の囲碁への影響</a></li></ul></li><li><a href="#哲学的考察" class="table-of-contents__link toc-highlight">哲学的考察</a><ul><li><a href="#学習の本質" class="table-of-contents__link toc-highlight">学習の本質</a></li><li><a href="#創造性と発見" class="table-of-contents__link toc-highlight">創造性と発見</a></li><li><a href="#人間の知性の位置" class="table-of-contents__link toc-highlight">人間の知性の位置</a></li></ul></li><li><a href="#アニメーション対応" class="table-of-contents__link toc-highlight">アニメーション対応</a></li><li><a href="#まとめ" class="table-of-contents__link toc-highlight">まとめ</a></li><li><a href="#さらに読む" class="table-of-contents__link toc-highlight">さらに読む</a></li><li><a href="#参考文献" class="table-of-contents__link toc-highlight">参考文献</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>