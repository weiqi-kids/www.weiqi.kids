"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[4436],{58905(e,a,n){n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"alphago/traditional-limits","title":"Limites dos Metodos Tradicionais","description":"Do Minimax ao MCTS, compreendendo por que os metodos tradicionais de IA falharam no Go","source":"@site/i18n/pt/docusaurus-plugin-content-docs/current/alphago/05-traditional-limits.mdx","sourceDirName":"alphago","slug":"/alphago/traditional-limits","permalink":"/pt/docs/alphago/traditional-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/05-traditional-limits.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Limites dos Metodos Tradicionais","description":"Do Minimax ao MCTS, compreendendo por que os metodos tradicionais de IA falharam no Go","keywords":["Minimax","Poda Alpha-Beta","MCTS","Busca em Arvore Monte Carlo","Historia do Go Computacional"]},"sidebar":"tutorialSidebar","previous":{"title":"Por Que o Go \xc9 Dif\xedcil?","permalink":"/pt/docs/alphago/why-go-is-hard"},"next":{"title":"Representacao do Estado do Tabuleiro","permalink":"/pt/docs/alphago/board-representation"}}');var r=n(62615),s=n(30416),t=n(45695);const i={sidebar_position:6,title:"Limites dos Metodos Tradicionais",description:"Do Minimax ao MCTS, compreendendo por que os metodos tradicionais de IA falharam no Go",keywords:["Minimax","Poda Alpha-Beta","MCTS","Busca em Arvore Monte Carlo","Historia do Go Computacional"]},l="Limites dos Metodos Tradicionais",d={},c=[{value:"Algoritmo Minimax: A Base da Teoria dos Jogos",id:"algoritmo-minimax-a-base-da-teoria-dos-jogos",level:2},{value:"Principio Basico",id:"principio-basico",level:3},{value:"Formalizacao Matematica",id:"formalizacao-matematica",level:3},{value:"Diagrama da Arvore de Busca",id:"diagrama-da-arvore-de-busca",level:3},{value:"Implementacao em Codigo",id:"implementacao-em-codigo",level:3},{value:"Problemas do Minimax no Go",id:"problemas-do-minimax-no-go",level:3},{value:"1. Explosao do Espaco de Busca",id:"1-explosao-do-espaco-de-busca",level:4},{value:"2. Dificuldade da Funcao de Avaliacao",id:"2-dificuldade-da-funcao-de-avaliacao",level:4},{value:"Poda Alpha-Beta: Reduzindo Buscas Inuteis",id:"poda-alpha-beta-reduzindo-buscas-inuteis",level:2},{value:"Insight Central",id:"insight-central",level:3},{value:"Principio da Poda",id:"principio-da-poda",level:3},{value:"Formalizacao Matematica",id:"formalizacao-matematica-1",level:3},{value:"Implementacao em Codigo",id:"implementacao-em-codigo-1",level:3},{value:"Eficiencia da Poda",id:"eficiencia-da-poda",level:3},{value:"Por que ainda nao e suficiente",id:"por-que-ainda-nao-e-suficiente",level:3},{value:"1. Poda ideal requer ordenacao perfeita",id:"1-poda-ideal-requer-ordenacao-perfeita",level:4},{value:"2. Profundidade ainda insuficiente",id:"2-profundidade-ainda-insuficiente",level:4},{value:"3. Gargalo da funcao de avaliacao",id:"3-gargalo-da-funcao-de-avaliacao",level:4},{value:"Metodo Monte Carlo Puro: O Poder da Aleatoriedade",id:"metodo-monte-carlo-puro-o-poder-da-aleatoriedade",level:2},{value:"Abandonando a Funcao de Avaliacao",id:"abandonando-a-funcao-de-avaliacao",level:3},{value:"Principio de Estimativa Estatistica",id:"principio-de-estimativa-estatistica",level:3},{value:"Implementacao em Codigo",id:"implementacao-em-codigo-2",level:3},{value:"Vantagens e Limitacoes",id:"vantagens-e-limitacoes",level:3},{value:"Vantagens",id:"vantagens",level:4},{value:"Limitacoes",id:"limitacoes",level:4},{value:"Desempenho do Monte Carlo Puro no Go",id:"desempenho-do-monte-carlo-puro-no-go",level:3},{value:"O Avanco do MCTS (2006)",id:"o-avanco-do-mcts-2006",level:2},{value:"O Nascimento do Algoritmo UCT",id:"o-nascimento-do-algoritmo-uct",level:3},{value:"Formula UCB1",id:"formula-ucb1",level:3},{value:"As Quatro Fases do MCTS",id:"as-quatro-fases-do-mcts",level:3},{value:"1. Selection (Selecao)",id:"1-selection-selecao",level:4},{value:"2. Expansion (Expansao)",id:"2-expansion-expansao",level:4},{value:"3. Simulation (Simulacao)",id:"3-simulation-simulacao",level:4},{value:"4. Backpropagation (Retropropagacao)",id:"4-backpropagation-retropropagacao",level:4},{value:"Implementacao Completa do MCTS",id:"implementacao-completa-do-mcts",level:3},{value:"Por que o MCTS Funciona?",id:"por-que-o-mcts-funciona",level:3},{value:"1. Foco Progressivo",id:"1-foco-progressivo",level:4},{value:"2. Algoritmo de Tempo Arbitrario",id:"2-algoritmo-de-tempo-arbitrario",level:4},{value:"3. Nao Precisa de Funcao de Avaliacao",id:"3-nao-precisa-de-funcao-de-avaliacao",level:4},{value:"2006-2015: A Era do MCTS",id:"2006-2015-a-era-do-mcts",level:3},{value:"O Gargalo da Funcao de Avaliacao",id:"o-gargalo-da-funcao-de-avaliacao",level:2},{value:"Limitacoes das Caracteristicas Manuais",id:"limitacoes-das-caracteristicas-manuais",level:3},{value:"Caracteristicas Comuns",id:"caracteristicas-comuns",level:4},{value:"Problemas",id:"problemas",level:4},{value:"Problema de Simulacao no MCTS",id:"problema-de-simulacao-no-mcts",level:3},{value:"Problemas da Simulacao Aleatoria",id:"problemas-da-simulacao-aleatoria",level:4},{value:"Tentativas de Melhoria",id:"tentativas-de-melhoria",level:4},{value:"Por que Precisamos de Redes Neurais",id:"por-que-precisamos-de-redes-neurais",level:3},{value:"Resumo dos Limites dos Metodos Tradicionais",id:"resumo-dos-limites-dos-metodos-tradicionais",level:2},{value:"Gargalos Centrais",id:"gargalos-centrais",level:3},{value:"1. Problema de Avaliacao",id:"1-problema-de-avaliacao",level:4},{value:"2. Problema de Busca",id:"2-problema-de-busca",level:4},{value:"A Solucao do AlphaGo",id:"a-solucao-do-alphago",level:3},{value:"Correspondencia com Animacoes",id:"correspondencia-com-animacoes",level:2},{value:"Leitura Adicional",id:"leitura-adicional",level:2},{value:"Referencias",id:"referencias",level:2}];function m(e){const a={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.header,{children:(0,r.jsx)(a.h1,{id:"limites-dos-metodos-tradicionais",children:"Limites dos Metodos Tradicionais"})}),"\n",(0,r.jsx)(a.p,{children:'Antes do surgimento do aprendizado profundo, os pesquisadores passaram decadas tentando resolver o problema do Go usando metodos "tradicionais". Do algoritmo Minimax a Busca em Arvore Monte Carlo (MCTS), cada avanco tornou o Go computacional um pouco mais forte, mas nunca conseguiu alcancar o nivel profissional humano.'}),"\n",(0,r.jsx)(a.p,{children:"Este artigo explorara os principios, vantagens e desvantagens desses metodos, e por que eles encontraram um gargalo no Go."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"algoritmo-minimax-a-base-da-teoria-dos-jogos",children:"Algoritmo Minimax: A Base da Teoria dos Jogos"}),"\n",(0,r.jsx)(a.h3,{id:"principio-basico",children:"Principio Basico"}),"\n",(0,r.jsxs)(a.p,{children:["O ",(0,r.jsx)(a.strong,{children:"algoritmo Minimax"})," e um conceito central na teoria dos jogos, proposto por John von Neumann em 1928. Sua ideia basica e:"]}),"\n",(0,r.jsxs)(a.blockquote,{children:["\n",(0,r.jsx)(a.p,{children:'Em um jogo de soma zero, devo escolher a opcao que me deixa na melhor posicao mesmo apos a "melhor resposta" do oponente.'}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Em outras palavras:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Eu (Max)"})," quero maximizar a pontuacao"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Oponente (Min)"})," quer minimizar minha pontuacao"]}),"\n",(0,r.jsx)(a.li,{children:"Devo assumir que o oponente sempre fara a melhor jogada"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"formalizacao-matematica",children:"Formalizacao Matematica"}),"\n",(0,r.jsx)(a.p,{children:"Seja V(s) o valor da posicao s, definido recursivamente como:"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{children:"V(s) = eval(s)                        // se s e posicao final\nV(s) = max{ V(result(s, a)) | a \u2208 A(s) }  // se e a vez do Max\nV(s) = min{ V(result(s, a)) | a \u2208 A(s) }  // se e a vez do Min\n"})}),"\n",(0,r.jsx)(a.p,{children:"Onde:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"A(s)"}),": todas as acoes legais na posicao s"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"result(s, a)"}),": resultado de executar a acao a na posicao s"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"eval(s)"}),": avaliacao da posicao final"]}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"diagrama-da-arvore-de-busca",children:"Diagrama da Arvore de Busca"}),"\n",(0,r.jsx)(a.mermaid,{value:'flowchart TB\n    subgraph Max["Camada Max (eu)"]\n        A["-3"]\n        B["+5"]\n        C["+2"]\n    end\n\n    subgraph MinA["Camada Min"]\n        A1["-3"]\n        A2["+7"]\n        A3["+5"]\n    end\n\n    subgraph MinB["Camada Min"]\n        B1["+5"]\n        B2["-2"]\n        B3["+9"]\n    end\n\n    subgraph MinC["Camada Min"]\n        C1["+2"]\n        C2["+1"]\n        C3["+4"]\n    end\n\n    A --\x3e A1\n    A --\x3e A2\n    A --\x3e A3\n    B --\x3e B1\n    B --\x3e B2\n    B --\x3e B3\n    C --\x3e C1\n    C --\x3e C2\n    C --\x3e C3'}),"\n",(0,r.jsx)(a.p,{children:"Neste exemplo:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"A camada Min escolhera o valor menos favoravel para mim (minimo)"}),"\n",(0,r.jsx)(a.li,{children:"A camada Max escolhera o valor mais favoravel para mim (maximo)"}),"\n",(0,r.jsx)(a.li,{children:"No final, Max deve escolher o ramo do meio (+5)"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"implementacao-em-codigo",children:"Implementacao em Codigo"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def minimax(state, depth, is_max_turn):\n    """\n    Implementacao basica do algoritmo Minimax\n\n    Args:\n        state: posicao atual\n        depth: profundidade de busca\n        is_max_turn: se e a vez do Max\n\n    Returns:\n        (melhor valor, melhor acao)\n    """\n    # Condicao de termino: limite de profundidade ou fim do jogo\n    if depth == 0 or is_terminal(state):\n        return evaluate(state), None\n\n    legal_moves = get_legal_moves(state)\n    best_move = None\n\n    if is_max_turn:\n        best_value = float(\'-inf\')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            value, _ = minimax(next_state, depth - 1, False)\n            if value > best_value:\n                best_value = value\n                best_move = move\n    else:\n        best_value = float(\'inf\')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            value, _ = minimax(next_state, depth - 1, True)\n            if value < best_value:\n                best_value = value\n                best_move = move\n\n    return best_value, best_move\n'})}),"\n",(0,r.jsx)(a.h3,{id:"problemas-do-minimax-no-go",children:"Problemas do Minimax no Go"}),"\n",(0,r.jsx)(a.h4,{id:"1-explosao-do-espaco-de-busca",children:"1. Explosao do Espaco de Busca"}),"\n",(0,r.jsxs)(a.p,{children:["Como mencionado no ",(0,r.jsx)(a.a,{href:"../why-go-is-hard",children:"artigo anterior"}),", o fator de ramificacao do Go e aproximadamente 250. Para ver N jogadas:"]}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Numero de nos \u2248 250^N"})}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Profundidade"}),(0,r.jsx)(a.th,{children:"Numero de Nos"}),(0,r.jsx)(a.th,{children:"Calculando a 1 milhao de nos/segundo"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"2"}),(0,r.jsx)(a.td,{children:"62.500"}),(0,r.jsx)(a.td,{children:"0,06 segundos"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"4"}),(0,r.jsx)(a.td,{children:"3,9 bilhoes"}),(0,r.jsx)(a.td,{children:"65 minutos"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"6"}),(0,r.jsx)(a.td,{children:"2,4\xd710^14"}),(0,r.jsx)(a.td,{children:"7.600 anos"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"8"}),(0,r.jsx)(a.td,{children:"1,5\xd710^19"}),(0,r.jsx)(a.td,{children:"480 milhoes de anos"})]})]})]}),"\n",(0,r.jsx)(a.p,{children:"Ver 6 jogadas ja levaria 7.600 anos, quanto mais jogar uma partida completa."}),"\n",(0,r.jsx)(a.h4,{id:"2-dificuldade-da-funcao-de-avaliacao",children:"2. Dificuldade da Funcao de Avaliacao"}),"\n",(0,r.jsxs)(a.p,{children:["Mesmo que olhemos apenas 4 jogadas, ainda precisamos de uma ",(0,r.jsx)(a.strong,{children:"funcao de avaliacao"})," precisa para julgar o valor de posicoes nao-terminais. Mas como mencionado no artigo anterior, a avaliacao de posicoes no Go e extremamente dificil."]}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Conclusao: Minimax puro e completamente inviavel no Go."})}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"poda-alpha-beta-reduzindo-buscas-inuteis",children:"Poda Alpha-Beta: Reduzindo Buscas Inuteis"}),"\n",(0,r.jsx)(a.h3,{id:"insight-central",children:"Insight Central"}),"\n",(0,r.jsxs)(a.p,{children:["O insight central da poda Alpha-Beta e: ",(0,r.jsx)(a.strong,{children:"nao precisamos buscar todos os ramos"}),"."]}),"\n",(0,r.jsx)(a.p,{children:'Se ja sabemos que um ramo "certamente e ruim", podemos pula-lo diretamente.'}),"\n",(0,r.jsx)(a.h3,{id:"principio-da-poda",children:"Principio da Poda"}),"\n",(0,r.jsx)(a.mermaid,{value:'flowchart TB\n    A["No Max A<br/>(melhor atual \u03b1 = +5)"]\n    B1["Ramo 1<br/>ja avaliado, valor = +5"]\n    B["Ramo 2: No Min B"]\n    C1["Sub-ramo B1: valor = +3"]\n    C2["Sub-ramo B2: ???<br/>(pode pular!)"]\n\n    A --\x3e B1\n    A --\x3e B\n    B --\x3e C1\n    B --\x3e C2'}),"\n",(0,r.jsx)(a.p,{children:"Neste exemplo:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"A ja tem uma opcao com valor +5"}),"\n",(0,r.jsx)(a.li,{children:"O primeiro sub-ramo de B e +3, entao o valor final de B \u2264 +3"}),"\n",(0,r.jsx)(a.li,{children:"Como B \u2264 +3 < +5, A nao escolhera B"}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.strong,{children:"B2 nao precisa ser avaliado"})}),"\n"]}),"\n",(0,r.jsxs)(a.p,{children:["Isso e a ",(0,r.jsx)(a.strong,{children:"poda Beta"}),". Similarmente, existe a ",(0,r.jsx)(a.strong,{children:"poda Alpha"}),"."]}),"\n",(0,r.jsx)(a.h3,{id:"formalizacao-matematica-1",children:"Formalizacao Matematica"}),"\n",(0,r.jsx)(a.p,{children:"Introduzimos dois parametros:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"\u03b1 (alpha)"}),": valor minimo que Max pode garantir (limite inferior)"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"\u03b2 (beta)"}),": valor maximo que Min pode garantir (limite superior)"]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Condicoes de poda:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Em um no Max, se valor \u2265 \u03b2, podar (poda Beta)"}),"\n",(0,r.jsx)(a.li,{children:"Em um no Min, se valor \u2264 \u03b1, podar (poda Alpha)"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"implementacao-em-codigo-1",children:"Implementacao em Codigo"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"def alpha_beta(state, depth, alpha, beta, is_max_turn):\n    \"\"\"\n    Algoritmo de Poda Alpha-Beta\n\n    Args:\n        state: posicao atual\n        depth: profundidade de busca\n        alpha: limite inferior do Max\n        beta: limite superior do Min\n        is_max_turn: se e a vez do Max\n\n    Returns:\n        (valor, melhor acao)\n    \"\"\"\n    if depth == 0 or is_terminal(state):\n        return evaluate(state), None\n\n    legal_moves = get_legal_moves(state)\n    best_move = None\n\n    if is_max_turn:\n        value = float('-inf')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            child_value, _ = alpha_beta(next_state, depth - 1,\n                                        alpha, beta, False)\n            if child_value > value:\n                value = child_value\n                best_move = move\n            alpha = max(alpha, value)\n            if value >= beta:\n                break  # Poda Beta\n        return value, best_move\n    else:\n        value = float('inf')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            child_value, _ = alpha_beta(next_state, depth - 1,\n                                        alpha, beta, True)\n            if child_value < value:\n                value = child_value\n                best_move = move\n            beta = min(beta, value)\n            if value <= alpha:\n                break  # Poda Alpha\n        return value, best_move\n\n# Como chamar\nvalue, best_move = alpha_beta(state, depth=4,\n                               alpha=float('-inf'),\n                               beta=float('inf'),\n                               is_max_turn=True)\n"})}),"\n",(0,r.jsx)(a.h3,{id:"eficiencia-da-poda",children:"Eficiencia da Poda"}),"\n",(0,r.jsx)(a.p,{children:"No caso ideal (ordenacao perfeita de jogadas), Alpha-Beta pode reduzir o fator de ramificacao efetivo de b para \u221ab:"}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Fator de ramificacao efetivo = b^0.5"})}),"\n",(0,r.jsx)(a.p,{children:"Isso significa:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Xadrez: de 35 para ~6"}),"\n",(0,r.jsx)(a.li,{children:"Go: de 250 para ~16"}),"\n"]}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Profundidade"}),(0,r.jsx)(a.th,{children:"Nos Originais"}),(0,r.jsx)(a.th,{children:"Alpha-Beta (ideal)"}),(0,r.jsx)(a.th,{children:"Aceleracao"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"4"}),(0,r.jsx)(a.td,{children:"3,9 bilhoes"}),(0,r.jsx)(a.td,{children:"65.000"}),(0,r.jsx)(a.td,{children:"60.000\xd7"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"6"}),(0,r.jsx)(a.td,{children:"2,4\xd710^14"}),(0,r.jsx)(a.td,{children:"16 milhoes"}),(0,r.jsx)(a.td,{children:"1,5\xd710^7 \xd7"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"8"}),(0,r.jsx)(a.td,{children:"1,5\xd710^19"}),(0,r.jsx)(a.td,{children:"4,2 bilhoes"}),(0,r.jsx)(a.td,{children:"3,6\xd710^9 \xd7"})]})]})]}),"\n",(0,r.jsx)(a.h3,{id:"por-que-ainda-nao-e-suficiente",children:"Por que ainda nao e suficiente"}),"\n",(0,r.jsx)(a.p,{children:"Mesmo com poda Alpha-Beta, o Go ainda e dificil de tratar:"}),"\n",(0,r.jsx)(a.h4,{id:"1-poda-ideal-requer-ordenacao-perfeita",children:"1. Poda ideal requer ordenacao perfeita"}),"\n",(0,r.jsx)(a.p,{children:'Para alcancar eficiencia de poda ideal, precisamos buscar primeiro os "melhores" ramos. Mas para saber qual ramo e melhor, precisamos buscar... e um problema do ovo e da galinha.'}),"\n",(0,r.jsx)(a.p,{children:"Na pratica, a eficiencia de poda no Go e muito menor que o ideal, e o fator de ramificacao efetivo pode ainda ser 50-100."}),"\n",(0,r.jsx)(a.h4,{id:"2-profundidade-ainda-insuficiente",children:"2. Profundidade ainda insuficiente"}),"\n",(0,r.jsx)(a.p,{children:"Mesmo com fator de ramificacao efetivo de 50, ver 10 jogadas ainda requer 50^10 \u2248 10^17 nos. Isso ainda e demais para computadores."}),"\n",(0,r.jsx)(a.h4,{id:"3-gargalo-da-funcao-de-avaliacao",children:"3. Gargalo da funcao de avaliacao"}),"\n",(0,r.jsx)(a.p,{children:'Alpha-Beta resolve apenas o problema de "eficiencia de busca", nao o problema de "precisao de avaliacao". Uma funcao de avaliacao ruim, mesmo com busca mais rapida, ainda produz resultados ruins.'}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Conclusao: Alpha-Beta melhorou muito a IA de xadrez, mas ajudou pouco no Go."})}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"metodo-monte-carlo-puro-o-poder-da-aleatoriedade",children:"Metodo Monte Carlo Puro: O Poder da Aleatoriedade"}),"\n",(0,r.jsx)(a.h3,{id:"abandonando-a-funcao-de-avaliacao",children:"Abandonando a Funcao de Avaliacao"}),"\n",(0,r.jsxs)(a.p,{children:["Na decada de 1990, pesquisadores comecaram a tentar uma ideia radical: ",(0,r.jsx)(a.strong,{children:"nao usar funcao de avaliacao"}),"."]}),"\n",(0,r.jsxs)(a.p,{children:["Em seu lugar, usaram ",(0,r.jsx)(a.strong,{children:"simulacao aleatoria"})," (Random Playout):"]}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsx)(a.li,{children:"Comecar da posicao atual"}),"\n",(0,r.jsx)(a.li,{children:"Ambos os lados jogam aleatoriamente ate o fim do jogo"}),"\n",(0,r.jsx)(a.li,{children:"Registrar o resultado (vitoria/derrota)"}),"\n",(0,r.jsx)(a.li,{children:"Repetir N vezes, calcular taxa de vitoria"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"principio-de-estimativa-estatistica",children:"Principio de Estimativa Estatistica"}),"\n",(0,r.jsx)(a.p,{children:"Pela lei dos grandes numeros, quando o numero de simulacoes N e grande o suficiente:"}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"V\u0302(s) = Numero de vitorias / N \u2248 V(s)"})}),"\n",(0,r.jsx)(a.p,{children:"O erro padrao dessa estimativa e:"}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"SE = \u221a(V(s)(1-V(s))/N) \u2248 1/(2\u221aN)"})}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Numero de Simulacoes"}),(0,r.jsx)(a.th,{children:"Erro Padrao"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"100"}),(0,r.jsx)(a.td,{children:"5%"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"1.000"}),(0,r.jsx)(a.td,{children:"1,6%"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"10.000"}),(0,r.jsx)(a.td,{children:"0,5%"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"100.000"}),(0,r.jsx)(a.td,{children:"0,16%"})]})]})]}),"\n",(0,r.jsx)(a.h3,{id:"implementacao-em-codigo-2",children:"Implementacao em Codigo"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'import random\n\ndef random_playout(state, player):\n    """\n    A partir da posicao atual, ambos os lados jogam aleatoriamente ate o fim\n\n    Returns:\n        1 se player vencer, 0 se perder\n    """\n    current = state.copy()\n    current_player = player\n\n    while not is_terminal(current):\n        legal_moves = get_legal_moves(current)\n        if not legal_moves:\n            current_player = opponent(current_player)\n            continue\n\n        # Escolher uma jogada aleatoriamente\n        move = random.choice(legal_moves)\n        current = apply_move(current, move)\n        current_player = opponent(current_player)\n\n    return 1 if get_winner(current) == player else 0\n\n\ndef monte_carlo_move_selection(state, player, num_simulations=10000):\n    """\n    Usar metodo Monte Carlo para selecionar a melhor jogada\n    """\n    legal_moves = get_legal_moves(state)\n\n    if len(legal_moves) == 0:\n        return None\n\n    # Alocar simulacoes para cada jogada legal\n    sims_per_move = num_simulations // len(legal_moves)\n\n    best_move = None\n    best_win_rate = -1\n\n    for move in legal_moves:\n        next_state = apply_move(state, move)\n\n        wins = 0\n        for _ in range(sims_per_move):\n            wins += random_playout(next_state, opponent(player))\n\n        # Taxa de vitoria do oponente baixa = minha taxa de vitoria alta\n        my_win_rate = 1 - (wins / sims_per_move)\n\n        if my_win_rate > best_win_rate:\n            best_win_rate = my_win_rate\n            best_move = move\n\n    return best_move, best_win_rate\n'})}),"\n",(0,r.jsx)(a.h3,{id:"vantagens-e-limitacoes",children:"Vantagens e Limitacoes"}),"\n",(0,r.jsx)(a.h4,{id:"vantagens",children:"Vantagens"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Nao precisa de funcao de avaliacao"}),": depende inteiramente de simulacoes"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Aplicavel a qualquer jogo"}),": basta conhecer as regras"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Fornece estimativa de probabilidade"}),': sabemos "quao certos" estamos']}),"\n"]}),"\n",(0,r.jsx)(a.h4,{id:"limitacoes",children:"Limitacoes"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Aleatoriedade excessiva"}),": jogar aleatoriamente e muito diferente de jogar profissionalmente"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Requer muitas simulacoes"}),": cada jogada precisa de dezenas de milhares de simulacoes"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Pontos cegos taticos"}),": taticas cruciais podem ser perdidas aleatoriamente"]}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"desempenho-do-monte-carlo-puro-no-go",children:"Desempenho do Monte Carlo Puro no Go"}),"\n",(0,r.jsx)(a.p,{children:"Programas de Go usando metodo Monte Carlo puro podem alcancar aproximadamente:"}),"\n",(0,r.jsxs)(a.blockquote,{children:["\n",(0,r.jsxs)(a.p,{children:["Nivel de ",(0,r.jsx)(a.strong,{children:"amador 5-10 kyu"})]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Isso e melhor que programas anteriores usando Minimax + funcao de avaliacao, mas ainda esta muito longe do nivel profissional."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"o-avanco-do-mcts-2006",children:"O Avanco do MCTS (2006)"}),"\n",(0,r.jsx)(a.h3,{id:"o-nascimento-do-algoritmo-uct",children:"O Nascimento do Algoritmo UCT"}),"\n",(0,r.jsxs)(a.p,{children:["Em 2006, Remi Coulom propos o algoritmo ",(0,r.jsx)(a.strong,{children:"MCTS (Monte Carlo Tree Search)"}),", combinando as vantagens da busca em arvore e simulacao Monte Carlo. No mesmo ano, Levente Kocsis e Csaba Szepesvari propuseram o algoritmo ",(0,r.jsx)(a.strong,{children:"UCT (Upper Confidence Bounds for Trees)"}),", fornecendo base teorica para o MCTS."]}),"\n",(0,r.jsxs)(a.p,{children:["Este foi um ",(0,r.jsx)(a.strong,{children:"avanco historico"})," no Go computacional."]}),"\n",(0,r.jsx)(a.h3,{id:"formula-ucb1",children:"Formula UCB1"}),"\n",(0,r.jsxs)(a.p,{children:["O nucleo do MCTS e a formula ",(0,r.jsx)(a.strong,{children:"UCB1 (Upper Confidence Bound)"}),":"]}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{children:"UCB1(s, a) = X\u0304(s,a) + C \xd7 \u221a(ln(Ns) / n(s,a))\n"})}),"\n",(0,r.jsx)(a.p,{children:"Onde:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"X\u0304(s,a)"}),": valor medio (taxa de vitoria) de tomar a acao a no estado s"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Ns"}),": numero total de visitas ao estado s"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"n(s,a)"}),": numero de vezes que a acao a foi tomada no estado s"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"C"}),": constante de exploracao (geralmente C = \u221a2)"]}),"\n"]}),"\n",(0,r.jsxs)(a.p,{children:["Esta formula equilibra habilmente ",(0,r.jsx)(a.strong,{children:"exploracao"})," (escolher o que e sabidamente bom) e ",(0,r.jsx)(a.strong,{children:"exploitacao"})," (tentar o desconhecido)."]}),"\n",(0,r.jsx)(a.h3,{id:"as-quatro-fases-do-mcts",children:"As Quatro Fases do MCTS"}),"\n",(0,r.jsx)(t.u8,{showPUCT:!0,width:700,height:450}),"\n",(0,r.jsx)(a.p,{children:"Cada iteracao do MCTS inclui quatro fases:"}),"\n",(0,r.jsx)(a.h4,{id:"1-selection-selecao",children:"1. Selection (Selecao)"}),"\n",(0,r.jsx)(a.p,{children:"A partir do no raiz, usar a formula UCB1 para selecionar nos filhos ate chegar a um no folha."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def select(node):\n    """Usar UCB1 para selecionar o melhor no filho"""\n    while node.is_fully_expanded():\n        node = max(node.children,\n                   key=lambda c: ucb1(c, node.visits))\n    return node\n\ndef ucb1(child, parent_visits, C=1.414):\n    """Formula UCB1"""\n    if child.visits == 0:\n        return float(\'inf\')  # Nos nao visitados tem prioridade\n\n    exploitation = child.wins / child.visits\n    exploration = C * math.sqrt(math.log(parent_visits) / child.visits)\n\n    return exploitation + exploration\n'})}),"\n",(0,r.jsx)(a.h4,{id:"2-expansion-expansao",children:"2. Expansion (Expansao)"}),"\n",(0,r.jsx)(a.p,{children:"Adicionar um ou mais nos filhos ao no folha."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def expand(node, state):\n    """Expandir no"""\n    legal_moves = get_legal_moves(state)\n    untried = [m for m in legal_moves if m not in node.tried_moves]\n\n    if untried:\n        move = random.choice(untried)\n        new_state = apply_move(state, move)\n        child = Node(move=move, parent=node)\n        node.children.append(child)\n        node.tried_moves.add(move)\n        return child, new_state\n\n    return node, state\n'})}),"\n",(0,r.jsx)(a.h4,{id:"3-simulation-simulacao",children:"3. Simulation (Simulacao)"}),"\n",(0,r.jsx)(a.p,{children:"A partir do novo no, realizar simulacao aleatoria ate o fim do jogo."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def simulate(state, player):\n    """Simulacao aleatoria ate o fim do jogo"""\n    return random_playout(state, player)\n'})}),"\n",(0,r.jsx)(a.h4,{id:"4-backpropagation-retropropagacao",children:"4. Backpropagation (Retropropagacao)"}),"\n",(0,r.jsx)(a.p,{children:"Propagar o resultado da simulacao para todos os nos ancestrais."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def backpropagate(node, result):\n    """Propagar resultado para todos os ancestrais"""\n    while node is not None:\n        node.visits += 1\n        node.wins += result\n        result = 1 - result  # Trocar perspectiva\n        node = node.parent\n'})}),"\n",(0,r.jsx)(a.h3,{id:"implementacao-completa-do-mcts",children:"Implementacao Completa do MCTS"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'class MCTSNode:\n    def __init__(self, move=None, parent=None):\n        self.move = move\n        self.parent = parent\n        self.children = []\n        self.wins = 0\n        self.visits = 0\n        self.tried_moves = set()\n\n    def is_fully_expanded(self, legal_moves):\n        return len(self.tried_moves) == len(legal_moves)\n\n\ndef mcts(root_state, player, num_iterations=10000):\n    """\n    Funcao principal do MCTS\n\n    Args:\n        root_state: posicao inicial\n        player: jogador atual\n        num_iterations: numero de iteracoes\n\n    Returns:\n        melhor acao\n    """\n    root = MCTSNode()\n\n    for _ in range(num_iterations):\n        node = root\n        state = root_state.copy()\n        current_player = player\n\n        # 1. Selection\n        while node.children and node.is_fully_expanded(get_legal_moves(state)):\n            node = max(node.children,\n                      key=lambda c: ucb1(c, node.visits))\n            state = apply_move(state, node.move)\n            current_player = opponent(current_player)\n\n        # 2. Expansion\n        legal_moves = get_legal_moves(state)\n        if not node.is_fully_expanded(legal_moves) and not is_terminal(state):\n            move = random.choice([m for m in legal_moves\n                                  if m not in node.tried_moves])\n            state = apply_move(state, move)\n            child = MCTSNode(move=move, parent=node)\n            node.children.append(child)\n            node.tried_moves.add(move)\n            node = child\n            current_player = opponent(current_player)\n\n        # 3. Simulation\n        result = simulate(state, current_player)\n\n        # 4. Backpropagation\n        backpropagate(node, result)\n\n    # Escolher o no filho com mais visitas\n    return max(root.children, key=lambda c: c.visits).move\n'})}),"\n",(0,r.jsx)(a.h3,{id:"por-que-o-mcts-funciona",children:"Por que o MCTS Funciona?"}),"\n",(0,r.jsx)(a.p,{children:"O sucesso do MCTS tem varios fatores-chave:"}),"\n",(0,r.jsx)(a.h4,{id:"1-foco-progressivo",children:"1. Foco Progressivo"}),"\n",(0,r.jsx)(a.p,{children:'O MCTS nao busca todos os ramos uniformemente, mas investe mais recursos em ramos que parecem mais promissores. Isso permite "ignorar" jogadas obviamente ruins.'}),"\n",(0,r.jsx)(a.h4,{id:"2-algoritmo-de-tempo-arbitrario",children:"2. Algoritmo de Tempo Arbitrario"}),"\n",(0,r.jsx)(a.p,{children:"O MCTS pode parar a qualquer momento e dar a melhor resposta atual. Mais tempo, melhor resposta."}),"\n",(0,r.jsx)(a.h4,{id:"3-nao-precisa-de-funcao-de-avaliacao",children:"3. Nao Precisa de Funcao de Avaliacao"}),"\n",(0,r.jsx)(a.p,{children:"O MCTS estima valores atraves de simulacoes, sem necessidade de projetar funcao de avaliacao manualmente."}),"\n",(0,r.jsx)(a.h3,{id:"2006-2015-a-era-do-mcts",children:"2006-2015: A Era do MCTS"}),"\n",(0,r.jsx)(a.p,{children:"O surgimento do MCTS levou o Go computacional a uma nova era:"}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Programa"}),(0,r.jsx)(a.th,{children:"Ano"}),(0,r.jsx)(a.th,{children:"Caracteristicas"}),(0,r.jsx)(a.th,{children:"Forca"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Crazy Stone"})}),(0,r.jsx)(a.td,{children:"2006"}),(0,r.jsx)(a.td,{children:"Primeiro programa de Go com MCTS"}),(0,r.jsx)(a.td,{children:"Amador alto dan"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"MoGo"})}),(0,r.jsx)(a.td,{children:"2007"}),(0,r.jsx)(a.td,{children:"MCTS otimizado"}),(0,r.jsx)(a.td,{children:"Amador 5 dan"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Zen"})}),(0,r.jsx)(a.td,{children:"2009"}),(0,r.jsx)(a.td,{children:"Adicao de reconhecimento de padroes"}),(0,r.jsx)(a.td,{children:"Amador 6 dan"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Crazy Stone"})}),(0,r.jsx)(a.td,{children:"2013"}),(0,r.jsx)(a.td,{children:"Venceu profissional 9 dan com 4 pedras de handicap"}),(0,r.jsx)(a.td,{children:"Profissional 1 dan (com handicap)"})]})]})]}),"\n",(0,r.jsx)(a.p,{children:"Este foi um progresso historico, mas ainda havia uma grande lacuna:"}),"\n",(0,r.jsxs)(a.blockquote,{children:["\n",(0,r.jsxs)(a.p,{children:["O programa MCTS mais forte, ",(0,r.jsx)(a.strong,{children:"sem handicap"}),", ainda nao conseguia vencer jogadores profissionais."]}),"\n"]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"o-gargalo-da-funcao-de-avaliacao",children:"O Gargalo da Funcao de Avaliacao"}),"\n",(0,r.jsx)(a.h3,{id:"limitacoes-das-caracteristicas-manuais",children:"Limitacoes das Caracteristicas Manuais"}),"\n",(0,r.jsxs)(a.p,{children:["Antes do MCTS, pesquisadores tentaram projetar varias ",(0,r.jsx)(a.strong,{children:"caracteristicas manuais"})," para avaliar posicoes:"]}),"\n",(0,r.jsx)(a.h4,{id:"caracteristicas-comuns",children:"Caracteristicas Comuns"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def evaluate_position(state):\n    """Funcao de avaliacao projetada manualmente"""\n    score = 0\n\n    # 1. Estimativa de territorio\n    score += count_territory(state, BLACK) - count_territory(state, WHITE)\n\n    # 2. Liberdades das pedras\n    score += sum(liberties(group) for group in groups(state, BLACK))\n    score -= sum(liberties(group) for group in groups(state, WHITE))\n\n    # 3. Numero de olhos\n    score += count_eyes(state, BLACK) * 10\n    score -= count_eyes(state, WHITE) * 10\n\n    # 4. Forca de conexao\n    score += connectivity_score(state, BLACK)\n    score -= connectivity_score(state, WHITE)\n\n    # ... mais caracteristicas\n\n    return score\n'})}),"\n",(0,r.jsx)(a.h4,{id:"problemas",children:"Problemas"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Caracteristicas incompletas"}),": muitos fatores da intuicao humana sao dificeis de descrever em codigo"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Pesos dificeis de ajustar"}),": como determinar a importancia relativa de cada caracteristica?"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Local vs Global"}),": calculo local e facil, julgamento global e dificil"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Interacoes"}),": interacoes entre caracteristicas sao dificeis de modelar"]}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"problema-de-simulacao-no-mcts",children:"Problema de Simulacao no MCTS"}),"\n",(0,r.jsxs)(a.p,{children:["Mesmo no MCTS, onde nao usamos diretamente funcao de avaliacao, a ",(0,r.jsx)(a.strong,{children:"qualidade da simulacao"})," ainda e um gargalo crucial."]}),"\n",(0,r.jsx)(a.h4,{id:"problemas-da-simulacao-aleatoria",children:"Problemas da Simulacao Aleatoria"}),"\n",(0,r.jsx)(a.p,{children:'Jogar aleatoriamente produz muitas posicoes "irracionais", levando a estimativas imprecisas:'}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Grandes grupos morrem sem motivo"}),"\n",(0,r.jsx)(a.li,{children:"Capturas obvias nao sao feitas"}),"\n",(0,r.jsx)(a.li,{children:"Mortes simples sao ignoradas"}),"\n"]}),"\n",(0,r.jsx)(a.h4,{id:"tentativas-de-melhoria",children:"Tentativas de Melhoria"}),"\n",(0,r.jsxs)(a.p,{children:["Pesquisadores tentaram adicionar ",(0,r.jsx)(a.strong,{children:"conhecimento previo"})," nas simulacoes:"]}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'def simulation_policy(state, legal_moves):\n    """\n    Politica de simulacao com conhecimento previo\n    """\n    # Considerar com prioridade:\n    # 1. Capturas\n    # 2. Fugas\n    # 3. Conexoes\n    # 4. Ocupar grandes pontos\n    # ...\n\n    for move in legal_moves:\n        if is_capture(state, move):\n            return move\n        if saves_group(state, move):\n            return move\n\n    # Resto aleatorio\n    return random.choice(legal_moves)\n'})}),"\n",(0,r.jsx)(a.p,{children:"Mas essas regras heuristicas:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Aumentam o custo computacional"}),"\n",(0,r.jsx)(a.li,{children:"Podem introduzir vieses"}),"\n",(0,r.jsx)(a.li,{children:"Ainda nao sao precisas o suficiente"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"por-que-precisamos-de-redes-neurais",children:"Por que Precisamos de Redes Neurais"}),"\n",(0,r.jsxs)(a.p,{children:["O gargalo dos metodos tradicionais e essencialmente um problema de ",(0,r.jsx)(a.strong,{children:"aprendizado de representacao"}),":"]}),"\n",(0,r.jsxs)(a.blockquote,{children:["\n",(0,r.jsx)(a.p,{children:'Como aprender caracteristicas de "boas jogadas" a partir dos pixels do tabuleiro (estados de 361 pontos)?'}),"\n"]}),"\n",(0,r.jsxs)(a.p,{children:["Isso e exatamente onde o ",(0,r.jsx)(a.strong,{children:"aprendizado profundo"})," se destaca:"]}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Aprendizado automatico de caracteristicas"}),": sem necessidade de projeto manual"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Mapeamento nao-linear"}),": pode capturar relacoes complexas"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Treinamento fim-a-fim"}),": diretamente da entrada para a saida"]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"O avanco do aprendizado profundo no ImageNet em 2012 fez os pesquisadores pensarem:"}),"\n",(0,r.jsxs)(a.blockquote,{children:["\n",(0,r.jsx)(a.p,{children:'Se redes neurais podem "entender" fotos, sera que tambem podem "entender" tabuleiros?'}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"A resposta a essa pergunta e o AlphaGo."}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"resumo-dos-limites-dos-metodos-tradicionais",children:"Resumo dos Limites dos Metodos Tradicionais"}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Metodo"}),(0,r.jsx)(a.th,{children:"Vantagens"}),(0,r.jsx)(a.th,{children:"Problemas no Go"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Minimax"})}),(0,r.jsx)(a.td,{children:"Teoricamente completo, solucao otima"}),(0,r.jsx)(a.td,{children:"Fator de ramificacao muito grande, impossivel buscar fundo"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Alpha-Beta"})}),(0,r.jsx)(a.td,{children:"Reduz muito a busca"}),(0,r.jsx)(a.td,{children:"Fator de ramificacao efetivo ainda muito alto"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"Monte Carlo Puro"})}),(0,r.jsx)(a.td,{children:"Nao precisa de funcao de avaliacao"}),(0,r.jsx)(a.td,{children:"Qualidade da simulacao aleatoria muito ruim"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:(0,r.jsx)(a.strong,{children:"MCTS"})}),(0,r.jsx)(a.td,{children:"Busca focada inteligente"}),(0,r.jsx)(a.td,{children:"Simulacao ainda nao boa o suficiente, alcanca nivel amador alto"})]})]})]}),"\n",(0,r.jsx)(a.h3,{id:"gargalos-centrais",children:"Gargalos Centrais"}),"\n",(0,r.jsx)(a.p,{children:"No fundo, os metodos tradicionais enfrentam dois grandes gargalos:"}),"\n",(0,r.jsx)(a.h4,{id:"1-problema-de-avaliacao",children:"1. Problema de Avaliacao"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Nenhuma boa funcao de avaliacao"}),"\n",(0,r.jsx)(a.li,{children:'Impossivel quantificar conceitos abstratos como "espessura" e "influencia"'}),"\n",(0,r.jsx)(a.li,{children:"Caracteristicas manuais nao sao expressivas o suficiente"}),"\n"]}),"\n",(0,r.jsx)(a.h4,{id:"2-problema-de-busca",children:"2. Problema de Busca"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Mesmo com poda, o espaco de busca ainda e muito grande"}),"\n",(0,r.jsx)(a.li,{children:"Impossivel ver variacoes profundas o suficiente"}),"\n",(0,r.jsx)(a.li,{children:"Qualidade da simulacao afeta precisao da estimativa"}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"a-solucao-do-alphago",children:"A Solucao do AlphaGo"}),"\n",(0,r.jsx)(a.p,{children:"O AlphaGo usou aprendizado profundo para resolver esses dois problemas:"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Policy Network"}),': aprender "onde provavelmente e uma boa jogada", reduzindo o fator de ramificacao efetivo']}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Value Network"}),': aprender "quem provavelmente vai ganhar", substituindo funcao de avaliacao manual']}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Integracao com MCTS"}),": usar redes neurais para guiar a busca, usar busca para melhorar decisoes"]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:'Isso nao e simplesmente "substituir funcao de avaliacao por rede neural", mas uma arquitetura completamente nova.'}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"correspondencia-com-animacoes",children:"Correspondencia com Animacoes"}),"\n",(0,r.jsx)(a.p,{children:"Conceitos centrais abordados neste artigo e numeros das animacoes:"}),"\n",(0,r.jsxs)(a.table,{children:[(0,r.jsx)(a.thead,{children:(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.th,{children:"Numero"}),(0,r.jsx)(a.th,{children:"Conceito"}),(0,r.jsx)(a.th,{children:"Correspondencia Fisica/Matematica"})]})}),(0,r.jsxs)(a.tbody,{children:[(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"A3"}),(0,r.jsx)(a.td,{children:"Busca Minimax"}),(0,r.jsx)(a.td,{children:"Teoria dos jogos, jogo de soma zero"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"C5"}),(0,r.jsx)(a.td,{children:"Quatro fases do MCTS"}),(0,r.jsx)(a.td,{children:"Metodo Monte Carlo, UCB"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"C2"}),(0,r.jsx)(a.td,{children:"Formula UCB1"}),(0,r.jsx)(a.td,{children:"Problema do bandido multi-braco, equilibrio exploracao-exploitacao"})]}),(0,r.jsxs)(a.tr,{children:[(0,r.jsx)(a.td,{children:"C4"}),(0,r.jsx)(a.td,{children:"Crescimento da arvore de busca"}),(0,r.jsx)(a.td,{children:"Expansao progressiva"})]})]})]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"leitura-adicional",children:"Leitura Adicional"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Artigo anterior"}),": ",(0,r.jsx)(a.a,{href:"../why-go-is-hard",children:"Por que o Go e dificil?"})," - Espaco de estados e dificuldade de avaliacao"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Proximo artigo"}),": ",(0,r.jsx)(a.a,{href:"../board-representation",children:"Representacao do Estado do Tabuleiro"})," - Zobrist Hashing, codificacao de caracteristicas"]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Aprofundamento tecnico"}),": ",(0,r.jsx)(a.a,{href:"../mcts-neural-combo",children:"Combinacao de MCTS e Redes Neurais"})," - A arquitetura central do AlphaGo"]}),"\n"]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"referencias",children:"Referencias"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:['Coulom, R. (2006). "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search." ',(0,r.jsx)(a.em,{children:"Computers and Games"}),", 72-83. - Artigo original do MCTS"]}),"\n",(0,r.jsxs)(a.li,{children:['Kocsis, L., & Szepesvari, C. (2006). "Bandit based Monte-Carlo Planning." ',(0,r.jsx)(a.em,{children:"ECML"}),", 282-293. - Algoritmo UCT"]}),"\n",(0,r.jsxs)(a.li,{children:['Browne, C., et al. (2012). "A Survey of Monte Carlo Tree Search Methods." ',(0,r.jsx)(a.em,{children:"IEEE TCIAIG"}),", 4(1), 1-43. - Revisao do MCTS"]}),"\n",(0,r.jsxs)(a.li,{children:['Gelly, S., & Silver, D. (2011). "Monte-Carlo tree search and rapid action value estimation in computer Go." ',(0,r.jsx)(a.em,{children:"Artificial Intelligence"}),", 175(11), 1856-1875. - Aplicacao do MCTS no Go"]}),"\n"]})]})}function h(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},42948(e,a,n){n.d(a,{A:()=>s});n(59471);var o=n(61785),r=n(62615);function s({children:e,fallback:a}){return(0,o.A)()?(0,r.jsx)(r.Fragment,{children:e?.()}):a??null}},45695(e,a,n){n.d(a,{$W:()=>C,tO:()=>l,u8:()=>v,dW:()=>u});var o=n(59471),r=n(90989),s=n(62615);const t=19,i=[[3,3],[3,9],[3,15],[9,3],[9,9],[9,15],[15,3],[15,9],[15,15]];function l({size:e=400,stones:a=[],highlights:n=[],labels:l=[],onCellClick:d=null,showCoordinates:c=!0}){const m=(0,o.useRef)(null),h=c?30:15,p=e-2*h,u=p/18;return(0,o.useEffect)(()=>{if(!m.current)return;const e=r.Ltv(m.current);e.selectAll("*").remove();const o=e.append("g").attr("transform",`translate(${h}, ${h})`);o.append("rect").attr("x",-u/2).attr("y",-u/2).attr("width",p+u).attr("height",p+u).attr("fill","#dcb35c").attr("rx",4);const s=o.append("g").attr("class","grid");for(let a=0;a<t;a++)s.append("line").attr("class","grid-line").attr("x1",0).attr("y1",a*u).attr("x2",18*u).attr("y2",a*u);for(let a=0;a<t;a++)s.append("line").attr("class","grid-line").attr("x1",a*u).attr("y1",0).attr("x2",a*u).attr("y2",18*u);const x=o.append("g").attr("class","star-points");if(i.forEach(([e,a])=>{x.append("circle").attr("class","star-point").attr("cx",e*u).attr("cy",a*u).attr("r",u/8)}),n.length>0){const e=o.append("g").attr("class","highlights");n.forEach(({x:a,y:n,intensity:o})=>{e.append("rect").attr("class","heatmap-cell").attr("x",a*u-u/2).attr("y",n*u-u/2).attr("width",u).attr("height",u).attr("fill",r.Q3(o)).attr("opacity",.7*o)})}const j=o.append("g").attr("class","stones");if(a.forEach(({x:e,y:a,color:n})=>{const o="black"===n?"stone-black":"stone-white";j.append("circle").attr("cx",e*u+2).attr("cy",a*u+2).attr("r",.45*u).attr("fill","rgba(0,0,0,0.2)"),j.append("circle").attr("class",o).attr("cx",e*u).attr("cy",a*u).attr("r",.45*u)}),l.length>0){const e=o.append("g").attr("class","labels");l.forEach(({x:n,y:o,text:r})=>{const s=a.find(e=>e.x===n&&e.y===o),t="black"===s?.color?"#fff":"#000";e.append("text").attr("x",n*u).attr("y",o*u).attr("dy","0.35em").attr("text-anchor","middle").attr("fill",t).attr("font-size",.5*u).attr("font-weight","bold").text(r)})}if(c){const a=e.append("g").attr("class","coordinates"),n="ABCDEFGHJKLMNOPQRST";for(let e=0;e<t;e++)a.append("text").attr("x",h+e*u).attr("y",h/2).attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(n[e]);for(let e=0;e<t;e++)a.append("text").attr("x",h/2).attr("y",h+e*u).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(t-e)}d&&o.append("g").attr("class","click-targets").selectAll("rect").data(r.y17(361)).enter().append("rect").attr("x",e=>e%t*u-u/2).attr("y",e=>Math.floor(e/t)*u-u/2).attr("width",u).attr("height",u).attr("fill","transparent").attr("cursor","pointer").on("click",(e,a)=>{const n=a%t,o=Math.floor(a/t);d({x:n,y:o})})},[e,a,n,l,c,d,u,h,p]),(0,s.jsx)("div",{className:"go-board-container",children:(0,s.jsx)("svg",{ref:m,width:e,height:e,className:"go-board"})})}var d=n(42948);const c=19,m={empty:function(){const e=[];for(let a=0;a<c;a++)for(let n=0;n<c;n++)e.push({x:n,y:a,prob:1/361});return e}(),corner:function(){const e=[],a=[[3,3],[3,15],[15,3],[15,15]],n=[[2,4],[4,2],[2,14],[4,16],[14,2],[16,4],[14,16],[16,14]];for(let o=0;o<c;o++)for(let r=0;r<c;r++){let s=.001;a.some(([e,a])=>e===r&&a===o)?s=.15:n.some(([e,a])=>e===r&&a===o)?s=.05:0!==r&&18!==r&&0!==o&&18!==o||(s=5e-4),e.push({x:r,y:o,prob:s})}return h(e)}(),move37:function(){const e=[],a={x:9,y:4},n=[[3,2],[15,2],[10,10],[8,6]];for(let o=0;o<c;o++)for(let r=0;r<c;r++){let s=.001;r===a.x&&o===a.y?s=.08:n.some(([e,a])=>e===r&&a===o)?s=.12:r>=5&&r<=13&&o>=5&&o<=13&&(s=.005+.01*Math.random()),e.push({x:r,y:o,prob:s})}return h(e)}()};function h(e){const a=e.reduce((e,a)=>e+a.prob,0);return e.map(e=>({...e,prob:e.prob/a}))}function p({initialPosition:e="corner",stones:a=[],highlightMoves:n=[],size:t=450,showTopN:i=5,interactive:l=!0}){const d=(0,o.useRef)(null),h=(0,o.useRef)(null),[p,u]=(0,o.useState)(m[e]||m.corner),[x,j]=(0,o.useState)(null),v=35,g=t-70,f=g/18;(0,o.useEffect)(()=>{if(!d.current)return;const e=r.Ltv(d.current);e.selectAll("*").remove();const n=e.append("g").attr("transform","translate(35, 35)");n.append("rect").attr("x",-f/2).attr("y",-f/2).attr("width",g+f).attr("height",g+f).attr("fill","#dcb35c").attr("rx",4);const o=Math.max(...p.map(e=>e.prob)),s=r.exT(r.oKI).domain([0,o]);n.append("g").attr("class","heatmap").selectAll("rect").data(p).enter().append("rect").attr("class","heatmap-cell").attr("x",e=>e.x*f-f/2).attr("y",e=>e.y*f-f/2).attr("width",f).attr("height",f).attr("fill",e=>s(e.prob)).attr("opacity",e=>.3+e.prob/o*.6).attr("cursor",l?"pointer":"default").on("mouseover",function(e,a){if(!l)return;r.Ltv(this).attr("stroke","#333").attr("stroke-width",2);r.Ltv(h.current).style("display","block").style("left",`${e.pageX+10}px`).style("top",e.pageY-10+"px").html(`\u4f4d\u7f6e: ${String.fromCharCode(65+a.x)}${19-a.y}<br>\u6a5f\u7387: ${(100*a.prob).toFixed(2)}%`)}).on("mouseout",function(){r.Ltv(this).attr("stroke","none"),r.Ltv(h.current).style("display","none")}).on("click",function(e,a){l&&j(a)});const t=n.append("g").attr("class","grid");for(let a=0;a<c;a++)t.append("line").attr("class","grid-line").attr("x1",0).attr("y1",a*f).attr("x2",18*f).attr("y2",a*f).attr("stroke","#333").attr("stroke-width",.5).attr("opacity",.5),t.append("line").attr("class","grid-line").attr("x1",a*f).attr("y1",0).attr("x2",a*f).attr("y2",18*f).attr("stroke","#333").attr("stroke-width",.5).attr("opacity",.5);const m=n.append("g").attr("class","stones");a.forEach(({x:e,y:a,color:n})=>{m.append("circle").attr("cx",e*f).attr("cy",a*f).attr("r",.45*f).attr("fill","black"===n?"#1a1a1a":"#f5f5f5").attr("stroke","black"===n?"#000":"#333").attr("stroke-width",1)});const u=[...p].sort((e,a)=>a.prob-e.prob).slice(0,i),x=n.append("g").attr("class","top-labels");u.forEach((e,n)=>{a.some(a=>a.x===e.x&&a.y===e.y)||(x.append("circle").attr("cx",e.x*f).attr("cy",e.y*f).attr("r",.3*f).attr("fill","rgba(255,255,255,0.8)").attr("stroke","#e74c3c").attr("stroke-width",2),x.append("text").attr("x",e.x*f).attr("y",e.y*f).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#e74c3c").attr("font-size",.4*f).attr("font-weight","bold").text(n+1))});const b=e.append("g").attr("class","coordinates");for(let a=0;a<c;a++)b.append("text").attr("x",v+a*f).attr("y",17.5).attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text("ABCDEFGHJKLMNOPQRST"[a]),b.append("text").attr("x",17.5).attr("y",v+a*f).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(c-a)},[p,a,i,l,f,v,g]);const b=e=>{u(m[e]||m.corner)};return(0,s.jsxs)("div",{children:[l&&(0,s.jsxs)("div",{className:"d3-controls",children:[(0,s.jsx)("button",{className:"empty"===e?"active":"",onClick:()=>b("empty"),children:"\u5747\u52fb\u5206\u5e03"}),(0,s.jsx)("button",{className:"corner"===e?"active":"",onClick:()=>b("corner"),children:"\u958b\u5c40\u661f\u4f4d"}),(0,s.jsx)("button",{className:"move37"===e?"active":"",onClick:()=>b("move37"),children:"\u7b2c 37 \u624b"})]}),(0,s.jsx)("div",{className:"go-board-container",children:(0,s.jsx)("svg",{ref:d,width:t,height:t,className:"go-board"})}),(0,s.jsx)("div",{ref:h,className:"d3-tooltip",style:{display:"none",position:"fixed"}}),x&&(0,s.jsx)("div",{className:"d3-legend",children:(0,s.jsxs)("div",{className:"d3-legend-item",children:["\u5df2\u9078\u64c7: ",String.fromCharCode(65+x.x),19-x.y,"\u2014 \u6a5f\u7387: ",(100*x.prob).toFixed(2),"%"]})}),(0,s.jsxs)("div",{className:"d3-legend",children:[(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#ffffb2"}}),"\u4f4e\u6a5f\u7387"]}),(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#fd8d3c"}}),"\u4e2d\u6a5f\u7387"]}),(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#bd0026"}}),"\u9ad8\u6a5f\u7387"]})]})]})}function u(e){return(0,s.jsx)(d.A,{fallback:(0,s.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,s.jsx)(p,{...e})})}const x={name:"Root",visits:1600,value:.55,prior:1,children:[{name:"D4",visits:800,value:.62,prior:.35,selected:!0,children:[{name:"Q16",visits:400,value:.58,prior:.3},{name:"R4",visits:300,value:.65,prior:.25,selected:!0},{name:"C16",visits:100,value:.55,prior:.2}]},{name:"Q4",visits:500,value:.52,prior:.3,children:[{name:"D16",visits:300,value:.5,prior:.28},{name:"Q16",visits:200,value:.54,prior:.22}]},{name:"D16",visits:200,value:.48,prior:.2},{name:"Q16",visits:100,value:.45,prior:.15}]};function j({data:e=x,width:a=700,height:n=450,showPUCT:t=!0,cPuct:i=1.5,interactive:l=!0}){const d=(0,o.useRef)(null),c=(0,o.useRef)(null),[m,h]=(0,o.useState)(null),[p,u]=(0,o.useState)(i),j=40,v=40,g=a-v-40,f=n-j-40;return(0,o.useEffect)(()=>{if(!d.current)return;const o=r.Ltv(d.current);o.selectAll("*").remove();const s=r.B22().size([g,f-50]),i=r.Sk5(e);s(i);const m=o.append("g").attr("transform",`translate(${v}, ${j})`);m.append("g").attr("class","links").selectAll("path").data(i.links()).enter().append("path").attr("class",e=>"link "+(e.target.data.selected?"selected":"")).attr("fill","none").attr("stroke",e=>e.target.data.selected?"#4a90d9":"#999").attr("stroke-width",e=>e.target.data.selected?3:1.5).attr("d",r.vu().x(e=>e.x).y(e=>e.y));const u=m.append("g").attr("class","nodes").selectAll("g").data(i.descendants()).enter().append("g").attr("class","node").attr("transform",e=>`translate(${e.x}, ${e.y})`).attr("cursor",l?"pointer":"default").on("mouseover",function(e,a){if(!l)return;r.Ltv(this).select("circle").transition().duration(200).attr("r",30);const n=a.parent?a.parent.data.visits:a.data.visits,o=((e,a)=>{if(!a)return 0;const n=e.value,o=e.prior,r=e.visits;return n+p*o*Math.sqrt(a)/(1+r)})(a.data,n);r.Ltv(c.current).style("display","block").style("left",`${e.pageX+15}px`).style("top",e.pageY-10+"px").html(`\n            <strong>${a.data.name}</strong><br>\n            \u8a2a\u554f\u6b21\u6578 (N): ${a.data.visits}<br>\n            \u5e73\u5747\u50f9\u503c (Q): ${a.data.value.toFixed(3)}<br>\n            \u5148\u9a57\u6a5f\u7387 (P): ${(100*a.data.prior).toFixed(1)}%<br>\n            ${t?`PUCT \u5206\u6578: ${o.toFixed(3)}`:""}\n          `)}).on("mouseout",function(){r.Ltv(this).select("circle").transition().duration(200).attr("r",25),r.Ltv(c.current).style("display","none")}).on("click",function(e,a){l&&h(a.data)});u.append("circle").attr("r",25).attr("fill",e=>e.data.selected?"#4a90d9":"#fff").attr("stroke",a=>{if(a.data.selected)return"#2c5282";const n=a.data.visits/e.visits;return r.dM(.3+.5*n)}).attr("stroke-width",e=>e.data.selected?3:2),u.append("text").attr("dy",-5).attr("text-anchor","middle").attr("fill",e=>e.data.selected?"#fff":"#333").attr("font-size",11).attr("font-weight","bold").text(e=>e.data.name),u.append("text").attr("dy",10).attr("text-anchor","middle").attr("fill",e=>e.data.selected?"#fff":"#666").attr("font-size",9).text(e=>`N=${e.data.visits}`),o.append("text").attr("x",a/2).attr("y",20).attr("text-anchor","middle").attr("font-size",14).attr("font-weight","bold").attr("fill","#333").text("MCTS \u641c\u7d22\u6a39"),t&&o.append("text").attr("x",a/2).attr("y",n-10).attr("text-anchor","middle").attr("font-size",11).attr("fill","#666").text("\u85cd\u8272\u8def\u5f91\uff1aPUCT \u9078\u64c7\u7684\u6700\u4f73\u8def\u5f91")},[e,a,n,t,p,l,g,f]),(0,s.jsxs)("div",{children:[t&&l&&(0,s.jsx)("div",{className:"d3-controls",children:(0,s.jsxs)("div",{className:"d3-slider",children:[(0,s.jsxs)("label",{children:["c_puct: ",p.toFixed(1)]}),(0,s.jsx)("input",{type:"range",min:"0.5",max:"3",step:"0.1",value:p,onChange:e=>u(parseFloat(e.target.value))})]})}),(0,s.jsx)("div",{className:"mcts-tree-container",children:(0,s.jsx)("svg",{ref:d,width:a,height:n,className:"mcts-tree"})}),(0,s.jsx)("div",{ref:c,className:"d3-tooltip",style:{display:"none",position:"fixed"}}),m&&(0,s.jsxs)("div",{className:"d3-legend",style:{background:"#f5f5f5",padding:"1rem",borderRadius:"4px"},children:[(0,s.jsxs)("strong",{children:["\u5df2\u9078\u64c7\u7bc0\u9ede: ",m.name]}),(0,s.jsxs)("div",{children:["\u8a2a\u554f\u6b21\u6578: ",m.visits]}),(0,s.jsxs)("div",{children:["\u5e73\u5747\u50f9\u503c: ",m.value.toFixed(3)]}),(0,s.jsxs)("div",{children:["\u5148\u9a57\u6a5f\u7387: ",(100*m.prior).toFixed(1),"%"]})]}),(0,s.jsxs)("div",{className:"d3-legend",children:[(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#4a90d9"}}),"\u9078\u4e2d\u8def\u5f91"]}),(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#fff",border:"2px solid #999"}}),"\u5176\u4ed6\u7bc0\u9ede"]}),(0,s.jsx)("div",{className:"d3-legend-item",children:(0,s.jsx)("span",{style:{fontSize:"12px"},children:"\u7bc0\u9ede\u5927\u5c0f \u221d \u8a2a\u554f\u6b21\u6578"})})]})]})}function v(e){return(0,s.jsx)(d.A,{fallback:(0,s.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,s.jsx)(j,{...e})})}const g=[{hours:0,elo:0,label:"\u96a8\u6a5f"},{hours:3,elo:1e3,label:"\u767c\u73fe\u898f\u5247"},{hours:6,elo:2e3},{hours:12,elo:3e3,label:"\u767c\u73fe\u5b9a\u5f0f"},{hours:24,elo:4e3},{hours:36,elo:4500,label:"\u8d85\u8d8a Fan Hui"},{hours:48,elo:5e3},{hours:60,elo:5200,label:"\u8d85\u8d8a Lee Sedol"},{hours:72,elo:5400,label:"\u8d85\u8d8a\u539f\u7248 AlphaGo"}],f=[{elo:2700,label:"\u696d\u9918\u5f37\u8c6a"},{elo:3500,label:"Fan Hui (\u8077\u696d\u4e8c\u6bb5)"},{elo:4500,label:"Lee Sedol (\u4e16\u754c\u51a0\u8ecd)"},{elo:5e3,label:"\u539f\u7248 AlphaGo"}],b=[{epochs:0,elo:0},{epochs:10,elo:1500},{epochs:20,elo:2500},{epochs:30,elo:3e3},{epochs:40,elo:3200},{epochs:50,elo:3300}],y=[{games:0,elo:3300},{games:1e3,elo:3800},{games:5e3,elo:4200},{games:1e4,elo:4500},{games:5e4,elo:4800},{games:1e5,elo:5e3}];function _({mode:e="zero",width:a=600,height:n=400,animated:t=!0,showMilestones:i=!0}){const l=(0,o.useRef)(null),[d,c]=(0,o.useState)(e),m=40,h=70,p=a-h-100,u=n-m-60;return(0,o.useEffect)(()=>{if(!l.current)return;const e=r.Ltv(l.current);let n,o,s;e.selectAll("*").remove(),"zero"===d?(n=g,o="\u8a13\u7df4\u6642\u9593\uff08\u5c0f\u6642\uff09",s=[0,80]):"sl"===d?(n=b,o="\u8a13\u7df4\u8f2a\u6578\uff08Epochs\uff09",s=[0,60]):(n=y,o="\u81ea\u6211\u5c0d\u5f08\u5c40\u6578",s=[0,12e4]);const c="selfplay"===d?r.ZEH().domain([1,s[1]]).range([0,p]):r.m4Y().domain(s).range([0,p]),x=r.m4Y().domain([0,6e3]).range([u,0]),j=e.append("g").attr("transform",`translate(${h}, ${m})`);if(j.append("g").attr("class","grid").selectAll(".grid-line-y").data(x.ticks(6)).enter().append("line").attr("class","grid-line-y").attr("x1",0).attr("x2",p).attr("y1",e=>x(e)).attr("y2",e=>x(e)).attr("stroke","#ddd").attr("stroke-dasharray","3,3"),i&&"zero"===d){const e=j.append("g").attr("class","human-levels");f.forEach(a=>{e.append("line").attr("x1",0).attr("x2",p).attr("y1",x(a.elo)).attr("y2",x(a.elo)).attr("stroke","#e74c3c").attr("stroke-dasharray","5,5").attr("opacity",.6),e.append("text").attr("x",p+5).attr("y",x(a.elo)).attr("dy","0.35em").attr("fill","#e74c3c").attr("font-size",10).text(a.label)})}const v=r.n8j().x(e=>c("zero"===d?e.hours:"sl"===d?e.epochs:Math.max(1,e.games))).y(e=>x(e.elo)).curve(r.nVG),_=r.Wcw().x(e=>c("zero"===d?e.hours:"sl"===d?e.epochs:Math.max(1,e.games))).y0(u).y1(e=>x(e.elo)).curve(r.nVG);j.append("path").datum(n).attr("class","area").attr("fill","#4a90d9").attr("opacity",.1).attr("d",_);const C=j.append("path").datum(n).attr("class","line").attr("fill","none").attr("stroke","#4a90d9").attr("stroke-width",3).attr("d",v);if(t){const e=C.node().getTotalLength();C.attr("stroke-dasharray",`${e} ${e}`).attr("stroke-dashoffset",e).transition().duration(2e3).ease(r.yfw).attr("stroke-dashoffset",0)}if(i&&"zero"===d){const e=n.filter(e=>e.label),a=j.append("g").attr("class","milestones");a.selectAll("circle").data(e).enter().append("circle").attr("cx",e=>c(e.hours)).attr("cy",e=>x(e.elo)).attr("r",6).attr("fill","#e74c3c").attr("stroke","#fff").attr("stroke-width",2),a.selectAll("text").data(e).enter().append("text").attr("x",e=>c(e.hours)).attr("y",e=>x(e.elo)-15).attr("text-anchor","middle").attr("fill","#333").attr("font-size",10).text(e=>e.label)}const M="selfplay"===d?r.l78(c).ticks(5,"~s"):r.l78(c);j.append("g").attr("class","x-axis").attr("transform",`translate(0, ${u})`).call(M),j.append("text").attr("class","axis-label").attr("x",p/2).attr("y",u+45).attr("text-anchor","middle").attr("fill","#666").text(o),j.append("g").attr("class","y-axis").call(r.V4s(x).ticks(6)),j.append("text").attr("class","axis-label").attr("transform","rotate(-90)").attr("x",-u/2).attr("y",-50).attr("text-anchor","middle").attr("fill","#666").text("ELO \u8a55\u5206"),e.append("text").attr("x",a/2).attr("y",20).attr("text-anchor","middle").attr("font-size",14).attr("font-weight","bold").attr("fill","#333").text("zero"===d?"AlphaGo Zero \u8a13\u7df4\u66f2\u7dda":"sl"===d?"\u76e3\u7763\u5b78\u7fd2\u68cb\u529b\u6210\u9577":"\u81ea\u6211\u5c0d\u5f08\u68cb\u529b\u6210\u9577")},[d,a,n,t,i,p,u]),(0,s.jsxs)("div",{children:[(0,s.jsxs)("div",{className:"d3-controls",children:[(0,s.jsx)("button",{className:"zero"===d?"active":"",onClick:()=>c("zero"),children:"AlphaGo Zero"}),(0,s.jsx)("button",{className:"sl"===d?"active":"",onClick:()=>c("sl"),children:"\u76e3\u7763\u5b78\u7fd2"}),(0,s.jsx)("button",{className:"selfplay"===d?"active":"",onClick:()=>c("selfplay"),children:"\u81ea\u6211\u5c0d\u5f08"})]}),(0,s.jsx)("div",{className:"elo-chart-container",children:(0,s.jsx)("svg",{ref:l,width:a,height:n,className:"elo-chart"})}),(0,s.jsxs)("div",{className:"d3-legend",children:[(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#4a90d9"}}),"ELO \u8a55\u5206"]}),i&&"zero"===d&&(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#e74c3c"}}),"\u91cc\u7a0b\u7891"]}),(0,s.jsxs)("div",{className:"d3-legend-item",children:[(0,s.jsx)("div",{className:"d3-legend-color",style:{background:"#e74c3c",opacity:.3}}),"\u4eba\u985e\u6c34\u5e73\u53c3\u8003\u7dda"]})]})]})]})}function C(e){return(0,s.jsx)(d.A,{fallback:(0,s.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,s.jsx)(_,{...e})})}},30416(e,a,n){n.d(a,{R:()=>t,x:()=>i});var o=n(59471);const r={},s=o.createContext(r);function t(e){const a=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),o.createElement(s.Provider,{value:a},e.children)}}}]);