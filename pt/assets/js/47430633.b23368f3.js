"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[8495],{11178(e,a,n){n.r(a),n.d(a,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"tech/deep-dive/mcts-implementation","title":"Detalhes de Implementa\xe7\xe3o do MCTS","description":"An\xe1lise aprofundada da implementa\xe7\xe3o da Busca em \xc1rvore de Monte Carlo, sele\xe7\xe3o PUCT e t\xe9cnicas de paraleliza\xe7\xe3o","source":"@site/i18n/pt/docusaurus-plugin-content-docs/current/tech/deep-dive/mcts-implementation.md","sourceDirName":"tech/deep-dive","slug":"/tech/deep-dive/mcts-implementation","permalink":"/pt/docs/tech/deep-dive/mcts-implementation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tech/deep-dive/mcts-implementation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Detalhes de Implementa\xe7\xe3o do MCTS","description":"An\xe1lise aprofundada da implementa\xe7\xe3o da Busca em \xc1rvore de Monte Carlo, sele\xe7\xe3o PUCT e t\xe9cnicas de paraleliza\xe7\xe3o"},"sidebar":"tutorialSidebar","previous":{"title":"Arquitetura de Rede Neural Detalhada","permalink":"/pt/docs/tech/deep-dive/neural-network"},"next":{"title":"Backend GPU e Otimiza\xe7\xe3o","permalink":"/pt/docs/tech/deep-dive/gpu-optimization"}}');var o=n(62615),r=n(30416);const t={sidebar_position:5,title:"Detalhes de Implementa\xe7\xe3o do MCTS",description:"An\xe1lise aprofundada da implementa\xe7\xe3o da Busca em \xc1rvore de Monte Carlo, sele\xe7\xe3o PUCT e t\xe9cnicas de paraleliza\xe7\xe3o"},l="Detalhes de Implementa\xe7\xe3o do MCTS",s={},d=[{value:"Revis\xe3o das Quatro Etapas do MCTS",id:"revis\xe3o-das-quatro-etapas-do-mcts",level:2},{value:"Estrutura de Dados do N\xf3",id:"estrutura-de-dados-do-n\xf3",level:2},{value:"Dados Principais",id:"dados-principais",level:3},{value:"Otimiza\xe7\xe3o de Mem\xf3ria",id:"otimiza\xe7\xe3o-de-mem\xf3ria",level:3},{value:"Selection: Sele\xe7\xe3o PUCT",id:"selection-sele\xe7\xe3o-puct",level:2},{value:"F\xf3rmula PUCT",id:"f\xf3rmula-puct",level:3},{value:"Descri\xe7\xe3o dos Par\xe2metros",id:"descri\xe7\xe3o-dos-par\xe2metros",level:3},{value:"Implementa\xe7\xe3o",id:"implementa\xe7\xe3o",level:3},{value:"Equil\xedbrio entre Explora\xe7\xe3o e Aproveitamento",id:"equil\xedbrio-entre-explora\xe7\xe3o-e-aproveitamento",level:3},{value:"Expansion: Expans\xe3o de N\xf3s",id:"expansion-expans\xe3o-de-n\xf3s",level:2},{value:"Condi\xe7\xf5es de Expans\xe3o",id:"condi\xe7\xf5es-de-expans\xe3o",level:3},{value:"Filtragem de Jogadas Legais",id:"filtragem-de-jogadas-legais",level:3},{value:"Evaluation: Avalia\xe7\xe3o pela Rede Neural",id:"evaluation-avalia\xe7\xe3o-pela-rede-neural",level:2},{value:"Avalia\xe7\xe3o \xdanica",id:"avalia\xe7\xe3o-\xfanica",level:3},{value:"Avalia\xe7\xe3o em Lote (Otimiza\xe7\xe3o Crucial)",id:"avalia\xe7\xe3o-em-lote-otimiza\xe7\xe3o-crucial",level:3},{value:"Backpropagation: Atualiza\xe7\xe3o por Retropropaga\xe7\xe3o",id:"backpropagation-atualiza\xe7\xe3o-por-retropropaga\xe7\xe3o",level:2},{value:"Retropropaga\xe7\xe3o B\xe1sica",id:"retropropaga\xe7\xe3o-b\xe1sica",level:3},{value:"Import\xe2ncia da Altern\xe2ncia de Perspectiva",id:"import\xe2ncia-da-altern\xe2ncia-de-perspectiva",level:3},{value:"Paraleliza\xe7\xe3o: Perda Virtual",id:"paraleliza\xe7\xe3o-perda-virtual",level:2},{value:"O Problema",id:"o-problema",level:3},{value:"Solu\xe7\xe3o: Perda Virtual",id:"solu\xe7\xe3o-perda-virtual",level:3},{value:"Efeito",id:"efeito",level:3},{value:"Implementa\xe7\xe3o Completa da Busca",id:"implementa\xe7\xe3o-completa-da-busca",level:2},{value:"T\xe9cnicas Avan\xe7adas",id:"t\xe9cnicas-avan\xe7adas",level:2},{value:"Ru\xeddo de Dirichlet",id:"ru\xeddo-de-dirichlet",level:3},{value:"Par\xe2metro de Temperatura",id:"par\xe2metro-de-temperatura",level:3},{value:"Reutiliza\xe7\xe3o de \xc1rvore",id:"reutiliza\xe7\xe3o-de-\xe1rvore",level:3},{value:"Resumo de Otimiza\xe7\xf5es de Desempenho",id:"resumo-de-otimiza\xe7\xf5es-de-desempenho",level:2},{value:"Leitura Adicional",id:"leitura-adicional",level:2}];function c(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.header,{children:(0,o.jsx)(a.h1,{id:"detalhes-de-implementa\xe7\xe3o-do-mcts",children:"Detalhes de Implementa\xe7\xe3o do MCTS"})}),"\n",(0,o.jsx)(a.p,{children:"Este artigo analisa em profundidade os detalhes de implementa\xe7\xe3o da Busca em \xc1rvore de Monte Carlo (MCTS) no KataGo, incluindo estruturas de dados, estrat\xe9gias de sele\xe7\xe3o e t\xe9cnicas de paraleliza\xe7\xe3o."}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"revis\xe3o-das-quatro-etapas-do-mcts",children:"Revis\xe3o das Quatro Etapas do MCTS"}),"\n",(0,o.jsx)(a.mermaid,{value:'flowchart TB\n    subgraph MCTS["Ciclo de Busca MCTS"]\n        S["1. Selection<br/>Selecao: Desce pela arvore usando PUCT"]\n        S --\x3e E["2. Expansion<br/>Expansao: Ao chegar em no folha, cria nos filhos"]\n        E --\x3e V["3. Evaluation<br/>Avaliacao: Avalia o no folha usando rede neural"]\n        V --\x3e B["4. Backprop<br/>Retropropagacao: Atualiza estatisticas de todos os nos"]\n        B -.->|"Repete milhares de vezes"| S\n    end\n    MCTS --\x3e Result["Seleciona a jogada com mais visitas"]'}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"estrutura-de-dados-do-n\xf3",children:"Estrutura de Dados do N\xf3"}),"\n",(0,o.jsx)(a.h3,{id:"dados-principais",children:"Dados Principais"}),"\n",(0,o.jsx)(a.p,{children:"Cada n\xf3 do MCTS precisa armazenar:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'class MCTSNode:\n    def __init__(self, state, parent=None, prior=0.0):\n        # Informa\xe7\xf5es b\xe1sicas\n        self.state = state              # Estado do tabuleiro\n        self.parent = parent            # N\xf3 pai\n        self.children = {}              # Dicion\xe1rio de filhos {a\xe7\xe3o: n\xf3}\n        self.action = None              # A\xe7\xe3o que levou a este n\xf3\n\n        # Informa\xe7\xf5es estat\xedsticas\n        self.visit_count = 0            # N(s): Contagem de visitas\n        self.value_sum = 0.0            # W(s): Soma dos valores\n        self.prior = prior              # P(s,a): Probabilidade a priori\n\n        # Para busca paralela\n        self.virtual_loss = 0           # Perda virtual\n        self.is_expanded = False        # Se j\xe1 foi expandido\n\n    @property\n    def value(self):\n        """Q(s) = W(s) / N(s)"""\n        if self.visit_count == 0:\n            return 0.0\n        return self.value_sum / self.visit_count\n'})}),"\n",(0,o.jsx)(a.h3,{id:"otimiza\xe7\xe3o-de-mem\xf3ria",children:"Otimiza\xe7\xe3o de Mem\xf3ria"}),"\n",(0,o.jsx)(a.p,{children:"O KataGo usa v\xe1rias t\xe9cnicas para reduzir o uso de mem\xf3ria:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:"# Usando arrays numpy em vez de dict Python\nclass OptimizedNode:\n    __slots__ = ['visit_count', 'value_sum', 'prior', 'children_indices']\n\n    def __init__(self):\n        self.visit_count = np.int32(0)\n        self.value_sum = np.float32(0.0)\n        self.prior = np.float32(0.0)\n        self.children_indices = None  # Aloca\xe7\xe3o adiada\n"})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"selection-sele\xe7\xe3o-puct",children:"Selection: Sele\xe7\xe3o PUCT"}),"\n",(0,o.jsx)(a.h3,{id:"f\xf3rmula-puct",children:"F\xf3rmula PUCT"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"Pontua\xe7\xe3o de sele\xe7\xe3o = Q(s,a) + U(s,a)\n\nOnde:\nQ(s,a) = W(s,a) / N(s,a)              # Valor m\xe9dio\nU(s,a) = c_puct \xd7 P(s,a) \xd7 \u221a(N(s)) / (1 + N(s,a))  # Termo de explora\xe7\xe3o\n"})}),"\n",(0,o.jsx)(a.h3,{id:"descri\xe7\xe3o-dos-par\xe2metros",children:"Descri\xe7\xe3o dos Par\xe2metros"}),"\n",(0,o.jsxs)(a.table,{children:[(0,o.jsx)(a.thead,{children:(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.th,{children:"S\xedmbolo"}),(0,o.jsx)(a.th,{children:"Significado"}),(0,o.jsx)(a.th,{children:"Valor t\xedpico"})]})}),(0,o.jsxs)(a.tbody,{children:[(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:"Q(s,a)"}),(0,o.jsx)(a.td,{children:"Valor m\xe9dio da a\xe7\xe3o a"}),(0,o.jsx)(a.td,{children:"[-1, +1]"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:"P(s,a)"}),(0,o.jsx)(a.td,{children:"Probabilidade a priori da rede neural"}),(0,o.jsx)(a.td,{children:"[0, 1]"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:"N(s)"}),(0,o.jsx)(a.td,{children:"Contagem de visitas do n\xf3 pai"}),(0,o.jsx)(a.td,{children:"Inteiro"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:"N(s,a)"}),(0,o.jsx)(a.td,{children:"Contagem de visitas da a\xe7\xe3o a"}),(0,o.jsx)(a.td,{children:"Inteiro"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:"c_puct"}),(0,o.jsx)(a.td,{children:"Constante de explora\xe7\xe3o"}),(0,o.jsx)(a.td,{children:"1.0 ~ 2.5"})]})]})]}),"\n",(0,o.jsx)(a.h3,{id:"implementa\xe7\xe3o",children:"Implementa\xe7\xe3o"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def select_child(self, c_puct=1.5):\n    """Seleciona o n\xf3 filho com maior pontua\xe7\xe3o PUCT"""\n    best_score = -float(\'inf\')\n    best_action = None\n    best_child = None\n\n    # Raiz quadrada das visitas do n\xf3 pai\n    sqrt_parent_visits = math.sqrt(self.visit_count)\n\n    for action, child in self.children.items():\n        # Valor Q (valor m\xe9dio)\n        if child.visit_count > 0:\n            q_value = child.value_sum / child.visit_count\n        else:\n            q_value = 0.0\n\n        # Valor U (termo de explora\xe7\xe3o)\n        u_value = c_puct * child.prior * sqrt_parent_visits / (1 + child.visit_count)\n\n        # Pontua\xe7\xe3o total\n        score = q_value + u_value\n\n        if score > best_score:\n            best_score = score\n            best_action = action\n            best_child = child\n\n    return best_action, best_child\n'})}),"\n",(0,o.jsx)(a.h3,{id:"equil\xedbrio-entre-explora\xe7\xe3o-e-aproveitamento",children:"Equil\xedbrio entre Explora\xe7\xe3o e Aproveitamento"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"Fase inicial: N(s,a) pequeno\n\u251c\u2500\u2500 U(s,a) grande \u2192 Foco na explora\xe7\xe3o\n\u2514\u2500\u2500 A\xe7\xf5es com alta probabilidade a priori s\xe3o exploradas primeiro\n\nFase posterior: N(s,a) grande\n\u251c\u2500\u2500 U(s,a) pequeno \u2192 Foco no aproveitamento\n\u2514\u2500\u2500 Q(s,a) domina, seleciona a\xe7\xf5es conhecidamente boas\n"})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"expansion-expans\xe3o-de-n\xf3s",children:"Expansion: Expans\xe3o de N\xf3s"}),"\n",(0,o.jsx)(a.h3,{id:"condi\xe7\xf5es-de-expans\xe3o",children:"Condi\xe7\xf5es de Expans\xe3o"}),"\n",(0,o.jsx)(a.p,{children:"Ao chegar em um n\xf3 folha, usa a rede neural para expandir:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def expand(self, policy_probs, legal_moves):\n    """Expande o n\xf3, criando n\xf3s filhos para todas as jogadas legais"""\n    for action in legal_moves:\n        if action not in self.children:\n            prior = policy_probs[action]  # Probabilidade prevista pela rede neural\n            child_state = self.state.play(action)\n            self.children[action] = MCTSNode(\n                state=child_state,\n                parent=self,\n                prior=prior\n            )\n\n    self.is_expanded = True\n'})}),"\n",(0,o.jsx)(a.h3,{id:"filtragem-de-jogadas-legais",children:"Filtragem de Jogadas Legais"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def get_legal_moves(state):\n    """Obt\xe9m todas as jogadas legais"""\n    legal = []\n    for i in range(361):\n        x, y = i // 19, i % 19\n        if state.is_legal(x, y):\n            legal.append(i)\n\n    # Adiciona pass\n    legal.append(361)\n\n    return legal\n'})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"evaluation-avalia\xe7\xe3o-pela-rede-neural",children:"Evaluation: Avalia\xe7\xe3o pela Rede Neural"}),"\n",(0,o.jsx)(a.h3,{id:"avalia\xe7\xe3o-\xfanica",children:"Avalia\xe7\xe3o \xdanica"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def evaluate(self, state):\n    """Avalia a posi\xe7\xe3o usando a rede neural"""\n    # Codifica recursos de entrada\n    features = encode_state(state)  # (22, 19, 19)\n    features = torch.tensor(features).unsqueeze(0)  # (1, 22, 19, 19)\n\n    # Infer\xeancia da rede neural\n    with torch.no_grad():\n        output = self.network(features)\n\n    policy = output[\'policy\'][0].numpy()  # (362,)\n    value = output[\'value\'][0].item()     # escalar\n\n    return policy, value\n'})}),"\n",(0,o.jsx)(a.h3,{id:"avalia\xe7\xe3o-em-lote-otimiza\xe7\xe3o-crucial",children:"Avalia\xe7\xe3o em Lote (Otimiza\xe7\xe3o Crucial)"}),"\n",(0,o.jsx)(a.p,{children:"A GPU \xe9 mais eficiente com infer\xeancia em lote:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'class BatchedEvaluator:\n    def __init__(self, network, batch_size=8):\n        self.network = network\n        self.batch_size = batch_size\n        self.pending = []  # Lista de (estado, callback) aguardando avalia\xe7\xe3o\n\n    def request_evaluation(self, state, callback):\n        """Solicita avalia\xe7\xe3o, executa automaticamente quando o lote est\xe1 cheio"""\n        self.pending.append((state, callback))\n\n        if len(self.pending) >= self.batch_size:\n            self.flush()\n\n    def flush(self):\n        """Executa avalia\xe7\xe3o em lote"""\n        if not self.pending:\n            return\n\n        # Prepara entrada em lote\n        states = [s for s, _ in self.pending]\n        features = torch.stack([encode_state(s) for s in states])\n\n        # Infer\xeancia em lote\n        with torch.no_grad():\n            outputs = self.network(features)\n\n        # Retorna resultados via callback\n        for i, (_, callback) in enumerate(self.pending):\n            policy = outputs[\'policy\'][i].numpy()\n            value = outputs[\'value\'][i].item()\n            callback(policy, value)\n\n        self.pending.clear()\n'})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"backpropagation-atualiza\xe7\xe3o-por-retropropaga\xe7\xe3o",children:"Backpropagation: Atualiza\xe7\xe3o por Retropropaga\xe7\xe3o"}),"\n",(0,o.jsx)(a.h3,{id:"retropropaga\xe7\xe3o-b\xe1sica",children:"Retropropaga\xe7\xe3o B\xe1sica"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def backpropagate(self, value):\n    """Retropropaga do n\xf3 folha at\xe9 a raiz, atualizando estat\xedsticas"""\n    node = self\n\n    while node is not None:\n        node.visit_count += 1\n        node.value_sum += value\n\n        # Altern\xe2ncia de perspectiva: o valor para o oponente \xe9 oposto\n        value = -value\n\n        node = node.parent\n'})}),"\n",(0,o.jsx)(a.h3,{id:"import\xe2ncia-da-altern\xe2ncia-de-perspectiva",children:"Import\xe2ncia da Altern\xe2ncia de Perspectiva"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"Perspectiva do Preto: value = +0.6 (Preto em vantagem)\n\nCaminho de retropropaga\xe7\xe3o:\nN\xf3 folha (Preto joga): value_sum += +0.6\n    \u2191\nN\xf3 pai (Branco joga): value_sum += -0.6  \u2190 Desfavor\xe1vel para Branco\n    \u2191\nN\xf3 av\xf4 (Preto joga): value_sum += +0.6\n    \u2191\n...\n"})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"paraleliza\xe7\xe3o-perda-virtual",children:"Paraleliza\xe7\xe3o: Perda Virtual"}),"\n",(0,o.jsx)(a.h3,{id:"o-problema",children:"O Problema"}),"\n",(0,o.jsx)(a.p,{children:"Quando m\xfaltiplas threads buscam simultaneamente, podem todas selecionar o mesmo n\xf3:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"Thread 1: Seleciona n\xf3 A (Q=0.6, N=100)\nThread 2: Seleciona n\xf3 A (Q=0.6, N=100) \u2190 Repetido!\nThread 3: Seleciona n\xf3 A (Q=0.6, N=100) \u2190 Repetido!\n"})}),"\n",(0,o.jsx)(a.h3,{id:"solu\xe7\xe3o-perda-virtual",children:"Solu\xe7\xe3o: Perda Virtual"}),"\n",(0,o.jsx)(a.p,{children:'Ao selecionar um n\xf3, primeiro adiciona "perda virtual" para que outras threads n\xe3o queiram selecion\xe1-lo:'}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'VIRTUAL_LOSS = 3  # Valor da perda virtual\n\ndef select_with_virtual_loss(self):\n    """Sele\xe7\xe3o com perda virtual"""\n    action, child = self.select_child()\n\n    # Adiciona perda virtual\n    child.visit_count += VIRTUAL_LOSS\n    child.value_sum -= VIRTUAL_LOSS  # Finge que perdeu\n\n    return action, child\n\ndef backpropagate_with_virtual_loss(self, value):\n    """Retropropaga\xe7\xe3o removendo perda virtual"""\n    node = self\n\n    while node is not None:\n        # Remove perda virtual\n        node.visit_count -= VIRTUAL_LOSS\n        node.value_sum += VIRTUAL_LOSS\n\n        # Atualiza\xe7\xe3o normal\n        node.visit_count += 1\n        node.value_sum += value\n\n        value = -value\n        node = node.parent\n'})}),"\n",(0,o.jsx)(a.h3,{id:"efeito",children:"Efeito"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"Thread 1: Seleciona n\xf3 A, adiciona perda virtual\n         Valor Q de A cai temporariamente\n\nThread 2: Seleciona n\xf3 B (porque A parece pior agora)\n\nThread 3: Seleciona n\xf3 C\n\n\u2192 Diferentes threads exploram diferentes ramos, aumentando efici\xeancia\n"})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"implementa\xe7\xe3o-completa-da-busca",children:"Implementa\xe7\xe3o Completa da Busca"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'class MCTS:\n    def __init__(self, network, c_puct=1.5, num_simulations=800):\n        self.network = network\n        self.c_puct = c_puct\n        self.num_simulations = num_simulations\n        self.evaluator = BatchedEvaluator(network)\n\n    def search(self, root_state):\n        """Executa busca MCTS"""\n        root = MCTSNode(root_state)\n\n        # Expande n\xf3 raiz\n        policy, value = self.evaluate(root_state)\n        legal_moves = get_legal_moves(root_state)\n        root.expand(policy, legal_moves)\n\n        # Executa simula\xe7\xf5es\n        for _ in range(self.num_simulations):\n            node = root\n            path = [node]\n\n            # Selection: Desce pela \xe1rvore\n            while node.is_expanded and node.children:\n                action, node = node.select_child(self.c_puct)\n                path.append(node)\n\n            # Expansion + Evaluation\n            if not node.is_expanded:\n                policy, value = self.evaluate(node.state)\n                legal_moves = get_legal_moves(node.state)\n\n                if legal_moves:\n                    node.expand(policy, legal_moves)\n\n            # Backpropagation\n            for n in reversed(path):\n                n.visit_count += 1\n                n.value_sum += value\n                value = -value\n\n        # Seleciona a a\xe7\xe3o com mais visitas\n        best_action = max(root.children.items(),\n                         key=lambda x: x[1].visit_count)[0]\n\n        return best_action\n\n    def evaluate(self, state):\n        features = encode_state(state)\n        features = torch.tensor(features).unsqueeze(0)\n\n        with torch.no_grad():\n            output = self.network(features)\n\n        return output[\'policy\'][0].numpy(), output[\'value\'][0].item()\n'})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"t\xe9cnicas-avan\xe7adas",children:"T\xe9cnicas Avan\xe7adas"}),"\n",(0,o.jsx)(a.h3,{id:"ru\xeddo-de-dirichlet",children:"Ru\xeddo de Dirichlet"}),"\n",(0,o.jsx)(a.p,{children:"Adiciona ru\xeddo no n\xf3 raiz durante o treinamento para aumentar a explora\xe7\xe3o:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def add_dirichlet_noise(root, alpha=0.03, epsilon=0.25):\n    """Adiciona ru\xeddo de Dirichlet ao n\xf3 raiz"""\n    noise = np.random.dirichlet([alpha] * len(root.children))\n\n    for i, child in enumerate(root.children.values()):\n        child.prior = (1 - epsilon) * child.prior + epsilon * noise[i]\n'})}),"\n",(0,o.jsx)(a.h3,{id:"par\xe2metro-de-temperatura",children:"Par\xe2metro de Temperatura"}),"\n",(0,o.jsx)(a.p,{children:"Controla a aleatoriedade na sele\xe7\xe3o de a\xe7\xf5es:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def select_action_with_temperature(root, temperature=1.0):\n    """Seleciona a\xe7\xe3o baseado na contagem de visitas e temperatura"""\n    visits = np.array([c.visit_count for c in root.children.values()])\n    actions = list(root.children.keys())\n\n    if temperature == 0:\n        # Sele\xe7\xe3o gulosa\n        return actions[np.argmax(visits)]\n    else:\n        # Seleciona de acordo com distribui\xe7\xe3o de probabilidade das visitas\n        probs = visits ** (1 / temperature)\n        probs = probs / probs.sum()\n        return np.random.choice(actions, p=probs)\n'})}),"\n",(0,o.jsx)(a.h3,{id:"reutiliza\xe7\xe3o-de-\xe1rvore",children:"Reutiliza\xe7\xe3o de \xc1rvore"}),"\n",(0,o.jsx)(a.p,{children:"A nova jogada pode reutilizar a \xe1rvore de busca anterior:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-python",children:'def reuse_tree(root, action):\n    """Reutiliza sub\xe1rvore"""\n    if action in root.children:\n        new_root = root.children[action]\n        new_root.parent = None\n        return new_root\n    else:\n        return None  # Precisa criar nova \xe1rvore\n'})}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"resumo-de-otimiza\xe7\xf5es-de-desempenho",children:"Resumo de Otimiza\xe7\xf5es de Desempenho"}),"\n",(0,o.jsxs)(a.table,{children:[(0,o.jsx)(a.thead,{children:(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.th,{children:"T\xe9cnica"}),(0,o.jsx)(a.th,{children:"Efeito"})]})}),(0,o.jsxs)(a.tbody,{children:[(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:(0,o.jsx)(a.strong,{children:"Avalia\xe7\xe3o em lote"})}),(0,o.jsx)(a.td,{children:"Utiliza\xe7\xe3o da GPU de 10% \u2192 80%+"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:(0,o.jsx)(a.strong,{children:"Perda virtual"})}),(0,o.jsx)(a.td,{children:"Efici\xeancia multi-thread aumenta 3-5x"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:(0,o.jsx)(a.strong,{children:"Reutiliza\xe7\xe3o de \xe1rvore"})}),(0,o.jsx)(a.td,{children:"Reduz cold start, economiza 30%+ de computa\xe7\xe3o"})]}),(0,o.jsxs)(a.tr,{children:[(0,o.jsx)(a.td,{children:(0,o.jsx)(a.strong,{children:"Pool de mem\xf3ria"})}),(0,o.jsx)(a.td,{children:"Reduz overhead de aloca\xe7\xe3o de mem\xf3ria"})]})]})]}),"\n",(0,o.jsx)(a.hr,{}),"\n",(0,o.jsx)(a.h2,{id:"leitura-adicional",children:"Leitura Adicional"}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.a,{href:"../neural-network",children:"Arquitetura de Rede Neural Detalhada"})," \u2014 Origem da fun\xe7\xe3o de avalia\xe7\xe3o"]}),"\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.a,{href:"../gpu-optimization",children:"Backend GPU e Otimiza\xe7\xe3o"})," \u2014 Otimiza\xe7\xe3o de hardware para infer\xeancia em lote"]}),"\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.a,{href:"../papers",children:"Guia de Artigos Importantes"})," \u2014 Base te\xf3rica da f\xf3rmula PUCT"]}),"\n"]})]})}function u(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},30416(e,a,n){n.d(a,{R:()=>t,x:()=>l});var i=n(59471);const o={},r=i.createContext(o);function t(e){const a=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),i.createElement(r.Provider,{value:a},e.children)}}}]);