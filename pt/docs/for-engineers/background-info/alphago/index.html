<!doctype html>
<html lang="pt" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/background-info/alphago" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Analise do Artigo AlphaGo | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/pt/docs/for-engineers/background-info/alphago/"><meta data-rh="true" property="og:locale" content="pt"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Analise do Artigo AlphaGo | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Este artigo analisa profundamente o artigo classico publicado na Nature pela DeepMind: &quot;Mastering the game of Go with deep neural networks and tree search&quot;, bem como os artigos subsequentes do AlphaGo Zero e AlphaZero."><meta data-rh="true" property="og:description" content="Este artigo analisa profundamente o artigo classico publicado na Nature pela DeepMind: &quot;Mastering the game of Go with deep neural networks and tree search&quot;, bem como os artigos subsequentes do AlphaGo Zero e AlphaZero."><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/pt/docs/for-engineers/background-info/alphago/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/background-info/alphago/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/background-info/alphago/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/background-info/alphago/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/background-info/alphago/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/background-info/alphago/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/background-info/alphago/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/background-info/alphago/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/background-info/alphago/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/background-info/alphago/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/background-info/alphago/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/background-info/alphago/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/background-info/alphago/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Guia de IA de Go para Engenheiros","item":"https://www.weiqi.kids/pt/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"Conhecimento de Fundo","item":"https://www.weiqi.kids/pt/docs/for-engineers/background-info/"},{"@type":"ListItem","position":3,"name":"Analise do Artigo AlphaGo","item":"https://www.weiqi.kids/pt/docs/for-engineers/background-info/alphago"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會"><link rel="stylesheet" href="/pt/assets/css/styles.e359e741.css">
<script src="/pt/assets/js/runtime~main.af8471b1.js" defer="defer"></script>
<script src="/pt/assets/js/main.583ae065.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.svg"><div role="region" aria-label="Pular para o conteúdo principal"><a class="skipToContent_bFSG" href="#__docusaurus_skipToContent_fallback">Pular para o conteúdo principal</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navegação" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_Wuuq themedComponent--light_w2On"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_Wuuq themedComponent--dark_zC0W"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/pt/docs/for-players/">Para Jogadores</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/docs/for-engineers/">Para Engenheiros</a><a class="navbar__item navbar__link" href="/pt/docs/about/">Sobre Nós</a><a class="navbar__item navbar__link" href="/pt/docs/activities/">Atividades</a><a class="navbar__item navbar__link" href="/pt/docs/references/">Referências</a><a class="navbar__item navbar__link" href="/pt/docs/sop/">Procedimentos</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_Zh_g"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Português</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/background-info/alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_pmRL"><div class="navbar__search searchBarContainer_nNQu" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_jmZR" value=""><div class="loadingRing_zZTX searchBarLoadingRing_JhV3"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_WlJ3"><div class="docsWrapper_ramL"><button aria-label="Volte para o topo" class="clean-btn theme-back-to-top-button backToTopButton_MqxJ" type="button"></button><div class="docRoot_UZ1h"><aside class="theme-doc-sidebar-container docSidebarContainer_y0QC"><div class="sidebarViewport_jAkm"><div class="sidebar_HjkB"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_jqYH"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/intro/">Guia de Uso</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/pt/docs/about/">關於協會</a><button aria-label="Expandir a categoria lateral &#x27;關於協會&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/pt/docs/activities/">活動實績</a><button aria-label="Expandir a categoria lateral &#x27;活動實績&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/pt/docs/for-players/">Para Jogadores de Go</a><button aria-label="Expandir a categoria lateral &#x27;Para Jogadores de Go&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/pt/docs/references/">參考資料</a><button aria-label="Expandir a categoria lateral &#x27;參考資料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/pt/docs/sop/">標準作業流程</a><button aria-label="Expandir a categoria lateral &#x27;標準作業流程&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/pt/docs/for-engineers/">Guia de IA de Go para Engenheiros</a><button aria-label="Fechar a categoria lateral &#x27;Guia de IA de Go para Engenheiros&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/pt/docs/for-engineers/background-info/">Conhecimento de Fundo</a><button aria-label="Fechar a categoria lateral &#x27;Conhecimento de Fundo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pt/docs/for-engineers/background-info/alphago/">Analise do Artigo AlphaGo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/for-engineers/background-info/katago-paper/">Analise do Artigo KataGo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/for-engineers/background-info/zen/">Introducao a Outras IAs de Go</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/pt/docs/for-engineers/katago-source/">Introducao Pratica ao KataGo</a><button aria-label="Expandir a categoria lateral &#x27;Introducao Pratica ao KataGo&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_qMQS"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Wlt9"><div class="docItemContainer_oLHG"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_M4ek" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página Inicial" class="breadcrumbs__link" href="/pt/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_pL7f"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/for-engineers/"><span>Guia de IA de Go para Engenheiros</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/for-engineers/background-info/"><span>Conhecimento de Fundo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Analise do Artigo AlphaGo</span></li></ul></nav><div class="tocCollapsible_K0FP theme-doc-toc-mobile tocMobile_PzQu"><button type="button" class="clean-btn tocCollapsibleButton_E0oR">Nessa página</button></div><div class="theme-doc-markdown markdown"><header><h1>Analise do Artigo AlphaGo</h1></header>
<p>Este artigo analisa profundamente o artigo classico publicado na Nature pela DeepMind: &quot;Mastering the game of Go with deep neural networks and tree search&quot;, bem como os artigos subsequentes do AlphaGo Zero e AlphaZero.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="significado-historico-do-alphago">Significado Historico do AlphaGo<a href="#significado-historico-do-alphago" class="hash-link" aria-label="Link direto para Significado Historico do AlphaGo" title="Link direto para Significado Historico do AlphaGo">​</a></h2>
<p>O Go foi por muito tempo visto como o desafio &quot;Santo Graal&quot; da inteligencia artificial. Diferente do xadrez, o espaco de busca do Go e extremamente vasto:</p>
<table><thead><tr><th>Jogo</th><th>Fator de Ramificacao Medio</th><th>Comprimento Medio do Jogo</th><th>Espaco de Estados</th></tr></thead><tbody><tr><td>Xadrez</td><td>~35</td><td>~80</td><td>~10^47</td></tr><tr><td>Go</td><td>~250</td><td>~150</td><td>~10^170</td></tr></tbody></table>
<p>Metodos tradicionais de busca por forca bruta sao completamente inviaveis no Go. A vitoria do AlphaGo sobre Lee Sedol em 2016 demonstrou o tremendo poder da combinacao de aprendizado profundo com aprendizado por reforco.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="eventos-marcantes">Eventos Marcantes<a href="#eventos-marcantes" class="hash-link" aria-label="Link direto para Eventos Marcantes" title="Link direto para Eventos Marcantes">​</a></h3>
<ul>
<li><strong>Outubro 2015</strong>: AlphaGo Fan derrota o campeao europeu Fan Hui (profissional 2-dan) por 5:0</li>
<li><strong>Marco 2016</strong>: AlphaGo Lee derrota o campeao mundial Lee Sedol (profissional 9-dan) por 4:1</li>
<li><strong>Maio 2017</strong>: AlphaGo Master derrota Ke Jie, numero 1 do mundo, por 3:0</li>
<li><strong>Outubro 2017</strong>: AlphaGo Zero publicado, treinamento puro por self-play, superando todas as versoes anteriores</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="arquitetura-tecnica-central">Arquitetura Tecnica Central<a href="#arquitetura-tecnica-central" class="hash-link" aria-label="Link direto para Arquitetura Tecnica Central" title="Link direto para Arquitetura Tecnica Central">​</a></h2>
<p>A inovacao central do AlphaGo esta em combinar tres tecnologias-chave:</p>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="policy-network-rede-de-estrategia">Policy Network (Rede de Estrategia)<a href="#policy-network-rede-de-estrategia" class="hash-link" aria-label="Link direto para Policy Network (Rede de Estrategia)" title="Link direto para Policy Network (Rede de Estrategia)">​</a></h3>
<p>A Policy Network e responsavel por prever a probabilidade de jogada para cada posicao, usada para guiar a direcao da busca.</p>
<h4 class="anchor anchorWithStickyNavbar_BVHq" id="arquitetura-da-rede">Arquitetura da Rede<a href="#arquitetura-da-rede" class="hash-link" aria-label="Link direto para Arquitetura da Rede" title="Link direto para Arquitetura da Rede">​</a></h4>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_BVHq" id="caracteristicas-de-entrada">Caracteristicas de Entrada<a href="#caracteristicas-de-entrada" class="hash-link" aria-label="Link direto para Caracteristicas de Entrada" title="Link direto para Caracteristicas de Entrada">​</a></h4>
<p>AlphaGo usa 48 planos de caracteristicas como entrada:</p>
<table><thead><tr><th>Caracteristica</th><th>Num Planos</th><th>Descricao</th></tr></thead><tbody><tr><td>Cor da pedra</td><td>3</td><td>Preta, branca, vazia</td></tr><tr><td>Liberdades</td><td>8</td><td>1, 2, ..., 8+ liberdades</td></tr><tr><td>Liberdades apos captura</td><td>8</td><td>Quantas liberdades apos capturar</td></tr><tr><td>Num de capturas</td><td>8</td><td>Quantas pedras podem ser capturadas nessa posicao</td></tr><tr><td>Ko</td><td>1</td><td>Se e posicao de ko</td></tr><tr><td>Jogada legal</td><td>1</td><td>Se a posicao e jogavel</td></tr><tr><td>Posicoes das ultimas 1-8 jogadas</td><td>8</td><td>Posicoes das jogadas anteriores</td></tr><tr><td>De quem e a vez</td><td>1</td><td>Atualmente vez de preto ou branco</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_BVHq" id="metodo-de-treinamento">Metodo de Treinamento<a href="#metodo-de-treinamento" class="hash-link" aria-label="Link direto para Metodo de Treinamento" title="Link direto para Metodo de Treinamento">​</a></h4>
<p>O treinamento da Policy Network e dividido em duas fases:</p>
<p><strong>Fase 1: Aprendizado Supervisionado (SL Policy Network)</strong></p>
<ul>
<li>Usa 30 milhoes de registros de jogos do servidor KGS</li>
<li>Objetivo: Prever a proxima jogada de jogadores humanos</li>
<li>Atinge 57% de precisao de predicao</li>
</ul>
<p><strong>Fase 2: Aprendizado por Reforco (RL Policy Network)</strong></p>
<ul>
<li>Comeca da SL Policy Network</li>
<li>Joga contra versoes anteriores de si mesmo</li>
<li>Usa algoritmo REINFORCE para otimizar</li>
</ul>
<div class="language-python codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-python codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Policy Gradient update simplificado</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># reward: +1 vitoria, -1 derrota</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">policy</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">action</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> reward</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="value-network-rede-de-valor">Value Network (Rede de Valor)<a href="#value-network-rede-de-valor" class="hash-link" aria-label="Link direto para Value Network (Rede de Valor)" title="Link direto para Value Network (Rede de Valor)">​</a></h3>
<p>A Value Network avalia a taxa de vitoria da posicao atual, usada para reduzir a profundidade de busca.</p>
<h4 class="anchor anchorWithStickyNavbar_BVHq" id="arquitetura-da-rede-1">Arquitetura da Rede<a href="#arquitetura-da-rede-1" class="hash-link" aria-label="Link direto para Arquitetura da Rede" title="Link direto para Arquitetura da Rede">​</a></h4>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_BVHq" id="metodo-de-treinamento-1">Metodo de Treinamento<a href="#metodo-de-treinamento-1" class="hash-link" aria-label="Link direto para Metodo de Treinamento" title="Link direto para Metodo de Treinamento">​</a></h4>
<p>A Value Network e treinada usando 30 milhoes de posicoes geradas por self-play da RL Policy Network:</p>
<ul>
<li>Amostra aleatoriamente uma posicao de cada jogo</li>
<li>Usa resultado final do jogo como label</li>
<li>Usa funcao de perda MSE</li>
</ul>
<div class="language-python codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-python codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Treinamento da Value Network</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">value_prediction </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> value_network</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">position</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">value_prediction </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> game_outcome</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">**</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><br></span></code></pre></div></div>
<p><strong>Por que amostrar apenas uma posicao por jogo?</strong></p>
<p>Se amostrar multiplas posicoes, posicoes adjacentes do mesmo jogo serao altamente correlacionadas, levando a overfitting. Amostragem aleatoria garante diversidade nos dados de treinamento.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="busca-por-arvore-de-monte-carlo-mcts">Busca por Arvore de Monte Carlo (MCTS)<a href="#busca-por-arvore-de-monte-carlo-mcts" class="hash-link" aria-label="Link direto para Busca por Arvore de Monte Carlo (MCTS)" title="Link direto para Busca por Arvore de Monte Carlo (MCTS)">​</a></h2>
<p>MCTS e o nucleo de decisao do AlphaGo, combinando redes neurais para buscar eficientemente a melhor jogada.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="quatro-passos-do-mcts">Quatro Passos do MCTS<a href="#quatro-passos-do-mcts" class="hash-link" aria-label="Link direto para Quatro Passos do MCTS" title="Link direto para Quatro Passos do MCTS">​</a></h3>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="formula-de-selecao-puct">Formula de Selecao (PUCT)<a href="#formula-de-selecao-puct" class="hash-link" aria-label="Link direto para Formula de Selecao (PUCT)" title="Link direto para Formula de Selecao (PUCT)">​</a></h3>
<p>AlphaGo usa a formula PUCT (Predictor + UCT) para selecionar qual ramo explorar:</p>
<div class="language-text codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-text codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token plain">a = argmax[Q(s,a) + u(s,a)]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">u(s,a) = c_puct * P(s,a) * sqrt(N(s)) / (1 + N(s,a))</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li><strong>Q(s,a)</strong>: Valor medio da acao a (exploitation)</li>
<li><strong>P(s,a)</strong>: Probabilidade prior prevista pela Policy Network</li>
<li><strong>N(s)</strong>: Numero de visitas do no pai</li>
<li><strong>N(s,a)</strong>: Numero de visitas desta acao</li>
<li><strong>c_puct</strong>: Constante de exploracao, equilibrando exploration e exploitation</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="detalhes-do-processo-de-busca">Detalhes do Processo de Busca<a href="#detalhes-do-processo-de-busca" class="hash-link" aria-label="Link direto para Detalhes do Processo de Busca" title="Link direto para Detalhes do Processo de Busca">​</a></h3>
<ol>
<li><strong>Selection</strong>: Do no raiz, use a formula PUCT para selecionar acoes ate chegar ao no folha</li>
<li><strong>Expansion</strong>: Expanda novos nos filhos no no folha, inicialize probabilidades prior com Policy Network</li>
<li><strong>Evaluation</strong>: Combine avaliacao da Value Network com simulacao de rollout rapido para avaliar valor</li>
<li><strong>Backpropagation</strong>: Propague valor de avaliacao pelo caminho, atualize valores Q e N</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="rollout-simulacao-rapida">Rollout (Simulacao Rapida)<a href="#rollout-simulacao-rapida" class="hash-link" aria-label="Link direto para Rollout (Simulacao Rapida)" title="Link direto para Rollout (Simulacao Rapida)">​</a></h3>
<p>AlphaGo (versao nao-Zero) tambem usa uma pequena rede de estrategia rapida para simulacao:</p>
<div class="language-text codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-text codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token plain">No folha → Jogadas rapidas aleatorias ate fim do jogo → Calcular resultado</span><br></span></code></pre></div></div>
<p>O valor final de avaliacao combina Value Network e Rollout:</p>
<div class="language-text codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-text codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token plain">V = λ * v_network + (1-λ) * v_rollout</span><br></span></code></pre></div></div>
<p>AlphaGo usa λ = 0.5, dando peso igual a ambos.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="metodo-de-treinamento-self-play">Metodo de Treinamento Self-play<a href="#metodo-de-treinamento-self-play" class="hash-link" aria-label="Link direto para Metodo de Treinamento Self-play" title="Link direto para Metodo de Treinamento Self-play">​</a></h2>
<p>Self-play e a estrategia central de treinamento do AlphaGo, permitindo que a IA melhore continuamente jogando contra si mesma.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="ciclo-de-treinamento">Ciclo de Treinamento<a href="#ciclo-de-treinamento" class="hash-link" aria-label="Link direto para Ciclo de Treinamento" title="Link direto para Ciclo de Treinamento">​</a></h3>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="por-que-self-play-e-efetivo">Por que Self-play e Efetivo?<a href="#por-que-self-play-e-efetivo" class="hash-link" aria-label="Link direto para Por que Self-play e Efetivo?" title="Link direto para Por que Self-play e Efetivo?">​</a></h3>
<ol>
<li><strong>Dados infinitos</strong>: Nao limitado pela quantidade de registros humanos</li>
<li><strong>Dificuldade adaptativa</strong>: Forca do oponente melhora junto com voce</li>
<li><strong>Exploracao e inovacao</strong>: Nao restrito por padroes de pensamento humano</li>
<li><strong>Objetivo claro</strong>: Otimiza diretamente taxa de vitoria, nao imitacao de humanos</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="melhorias-do-alphago-zero">Melhorias do AlphaGo Zero<a href="#melhorias-do-alphago-zero" class="hash-link" aria-label="Link direto para Melhorias do AlphaGo Zero" title="Link direto para Melhorias do AlphaGo Zero">​</a></h2>
<p>O AlphaGo Zero publicado em 2017 trouxe melhorias revolucionarias:</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="principais-diferencas">Principais Diferencas<a href="#principais-diferencas" class="hash-link" aria-label="Link direto para Principais Diferencas" title="Link direto para Principais Diferencas">​</a></h3>
<table><thead><tr><th>Caracteristica</th><th>AlphaGo</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>Treinamento inicial</td><td>Aprendizado supervisionado de registros humanos</td><td>Comeca completamente do zero</td></tr><tr><td>Arquitetura de rede</td><td>Policy/Value separadas</td><td>Rede unica de duas cabecas</td></tr><tr><td>Estrutura de rede</td><td>CNN comum</td><td>ResNet</td></tr><tr><td>Engenharia de features</td><td>48 features manuais</td><td>17 features simples</td></tr><tr><td>Rollout</td><td>Necessario</td><td>Nao necessario</td></tr><tr><td>Tempo de treinamento</td><td>Meses</td><td>3 dias para superar humanos</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="simplificacao-da-arquitetura">Simplificacao da Arquitetura<a href="#simplificacao-da-arquitetura" class="hash-link" aria-label="Link direto para Simplificacao da Arquitetura" title="Link direto para Simplificacao da Arquitetura">​</a></h3>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="features-de-entrada-simplificadas">Features de Entrada Simplificadas<a href="#features-de-entrada-simplificadas" class="hash-link" aria-label="Link direto para Features de Entrada Simplificadas" title="Link direto para Features de Entrada Simplificadas">​</a></h3>
<p>AlphaGo Zero usa apenas 17 planos de caracteristicas:</p>
<ul>
<li>8 planos: Posicoes das suas ultimas 8 jogadas</li>
<li>8 planos: Posicoes das ultimas 8 jogadas do oponente</li>
<li>1 plano: De quem e a vez (todo 0 ou todo 1)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="melhorias-no-treinamento">Melhorias no Treinamento<a href="#melhorias-no-treinamento" class="hash-link" aria-label="Link direto para Melhorias no Treinamento" title="Link direto para Melhorias no Treinamento">​</a></h3>
<ol>
<li><strong>Self-play puro</strong>: Nao usa nenhum dado humano</li>
<li><strong>Usa probabilidades MCTS diretamente como alvo de treinamento</strong>: Em vez de vitoria/derrota binaria</li>
<li><strong>Sem Rollout</strong>: Depende completamente da Value Network</li>
<li><strong>Treinamento de rede unica</strong>: Policy e Value compartilham parametros, reforcando-se mutuamente</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="generalizacao-do-alphazero">Generalizacao do AlphaZero<a href="#generalizacao-do-alphazero" class="hash-link" aria-label="Link direto para Generalizacao do AlphaZero" title="Link direto para Generalizacao do AlphaZero">​</a></h2>
<p>O AlphaZero publicado no final de 2017 aplicou a mesma arquitetura a Go, xadrez e shogi:</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="caracteristicas-chave">Caracteristicas-chave<a href="#caracteristicas-chave" class="hash-link" aria-label="Link direto para Caracteristicas-chave" title="Link direto para Caracteristicas-chave">​</a></h3>
<ul>
<li><strong>Zero conhecimento de dominio</strong>: Nao usa nenhum conhecimento especifico do dominio alem das regras do jogo</li>
<li><strong>Arquitetura unificada</strong>: Mesmo algoritmo aplicavel a diferentes jogos de tabuleiro</li>
<li><strong>Treinamento mais rapido</strong>:<!-- -->
<ul>
<li>Go: 8 horas para superar AlphaGo Lee</li>
<li>Xadrez: 4 horas para superar Stockfish</li>
<li>Shogi: 2 horas para superar Elmo</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="diferencas-do-alphago-zero">Diferencas do AlphaGo Zero<a href="#diferencas-do-alphago-zero" class="hash-link" aria-label="Link direto para Diferencas do AlphaGo Zero" title="Link direto para Diferencas do AlphaGo Zero">​</a></h3>
<table><thead><tr><th>Caracteristica</th><th>AlphaGo Zero</th><th>AlphaZero</th></tr></thead><tbody><tr><td>Jogo alvo</td><td>Apenas Go</td><td>Go, xadrez, shogi</td></tr><tr><td>Uso de simetria</td><td>Usa 8 simetrias do Go</td><td>Nao assume simetria</td></tr><tr><td>Ajuste de hiperparametros</td><td>Otimizado para Go</td><td>Configuracoes universais</td></tr><tr><td>Metodo de treinamento</td><td>Self-play do melhor modelo</td><td>Self-play do modelo mais recente</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="pontos-chave-de-implementacao">Pontos-chave de Implementacao<a href="#pontos-chave-de-implementacao" class="hash-link" aria-label="Link direto para Pontos-chave de Implementacao" title="Link direto para Pontos-chave de Implementacao">​</a></h2>
<p>Se voce quiser implementar um sistema similar, aqui estao as principais consideracoes:</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="recursos-computacionais">Recursos Computacionais<a href="#recursos-computacionais" class="hash-link" aria-label="Link direto para Recursos Computacionais" title="Link direto para Recursos Computacionais">​</a></h3>
<p>O treinamento do AlphaGo requer recursos computacionais enormes:</p>
<ul>
<li><strong>AlphaGo Lee</strong>: 176 GPUs + 48 TPUs</li>
<li><strong>AlphaGo Zero</strong>: 4 TPUs (treinamento) + 1 TPU (self-play)</li>
<li><strong>AlphaZero</strong>: 5000 TPUs (treinamento)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="hiperparametros-chave">Hiperparametros-chave<a href="#hiperparametros-chave" class="hash-link" aria-label="Link direto para Hiperparametros-chave" title="Link direto para Hiperparametros-chave">​</a></h3>
<div class="language-python codeBlockContainer_WV0T theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_GRu9"><pre tabindex="0" class="prism-code language-python codeBlock_md1K thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_L4YE"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Relacionados a MCTS</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">num_simulations </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">800</span><span class="token plain">     </span><span class="token comment" style="color:#999988;font-style:italic"># Simulacoes de busca por jogada</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">c_puct </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.5</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Constante de exploracao</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">temperature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># Parametro de temperatura para selecao de acao</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Relacionados a treinamento</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">batch_size </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">learning_rate </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Com decay</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">l2_regularization </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="problemas-comuns">Problemas Comuns<a href="#problemas-comuns" class="hash-link" aria-label="Link direto para Problemas Comuns" title="Link direto para Problemas Comuns">​</a></h3>
<ol>
<li><strong>Treinamento instavel</strong>: Use learning rate menor, aumente batch size</li>
<li><strong>Overfitting</strong>: Garanta diversidade nos dados de treinamento, use regularizacao</li>
<li><strong>Eficiencia de busca</strong>: Otimize inferencia em batch na GPU, paralelizacao do MCTS</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="leitura-adicional">Leitura Adicional<a href="#leitura-adicional" class="hash-link" aria-label="Link direto para Leitura Adicional" title="Link direto para Leitura Adicional">​</a></h2>
<ul>
<li><a href="https://www.nature.com/articles/nature16961" target="_blank" rel="noopener noreferrer">Artigo original: Mastering the game of Go with deep neural networks and tree search</a></li>
<li><a href="https://www.nature.com/articles/nature24270" target="_blank" rel="noopener noreferrer">Artigo AlphaGo Zero: Mastering the game of Go without human knowledge</a></li>
<li><a href="https://www.science.org/doi/10.1126/science.aar6404" target="_blank" rel="noopener noreferrer">Artigo AlphaZero: A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play</a></li>
</ul>
<p>Apos entender a tecnologia do AlphaGo, vamos ver como o <a href="/pt/docs/for-engineers/background-info/katago-paper/">KataGo fez melhorias com base nisso</a>.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/background-info/alphago.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_O1mQ" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa página</a></div><div class="col lastUpdated_hyfO"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Páginas de documentação"><a class="pagination-nav__link pagination-nav__link--prev" href="/pt/docs/for-engineers/background-info/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Conhecimento de Fundo</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/pt/docs/for-engineers/background-info/katago-paper/"><div class="pagination-nav__sublabel">Próxima</div><div class="pagination-nav__label">Analise do Artigo KataGo</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_tqik thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#significado-historico-do-alphago" class="table-of-contents__link toc-highlight">Significado Historico do AlphaGo</a><ul><li><a href="#eventos-marcantes" class="table-of-contents__link toc-highlight">Eventos Marcantes</a></li></ul></li><li><a href="#arquitetura-tecnica-central" class="table-of-contents__link toc-highlight">Arquitetura Tecnica Central</a><ul><li><a href="#policy-network-rede-de-estrategia" class="table-of-contents__link toc-highlight">Policy Network (Rede de Estrategia)</a></li><li><a href="#value-network-rede-de-valor" class="table-of-contents__link toc-highlight">Value Network (Rede de Valor)</a></li></ul></li><li><a href="#busca-por-arvore-de-monte-carlo-mcts" class="table-of-contents__link toc-highlight">Busca por Arvore de Monte Carlo (MCTS)</a><ul><li><a href="#quatro-passos-do-mcts" class="table-of-contents__link toc-highlight">Quatro Passos do MCTS</a></li><li><a href="#formula-de-selecao-puct" class="table-of-contents__link toc-highlight">Formula de Selecao (PUCT)</a></li><li><a href="#detalhes-do-processo-de-busca" class="table-of-contents__link toc-highlight">Detalhes do Processo de Busca</a></li><li><a href="#rollout-simulacao-rapida" class="table-of-contents__link toc-highlight">Rollout (Simulacao Rapida)</a></li></ul></li><li><a href="#metodo-de-treinamento-self-play" class="table-of-contents__link toc-highlight">Metodo de Treinamento Self-play</a><ul><li><a href="#ciclo-de-treinamento" class="table-of-contents__link toc-highlight">Ciclo de Treinamento</a></li><li><a href="#por-que-self-play-e-efetivo" class="table-of-contents__link toc-highlight">Por que Self-play e Efetivo?</a></li></ul></li><li><a href="#melhorias-do-alphago-zero" class="table-of-contents__link toc-highlight">Melhorias do AlphaGo Zero</a><ul><li><a href="#principais-diferencas" class="table-of-contents__link toc-highlight">Principais Diferencas</a></li><li><a href="#simplificacao-da-arquitetura" class="table-of-contents__link toc-highlight">Simplificacao da Arquitetura</a></li><li><a href="#features-de-entrada-simplificadas" class="table-of-contents__link toc-highlight">Features de Entrada Simplificadas</a></li><li><a href="#melhorias-no-treinamento" class="table-of-contents__link toc-highlight">Melhorias no Treinamento</a></li></ul></li><li><a href="#generalizacao-do-alphazero" class="table-of-contents__link toc-highlight">Generalizacao do AlphaZero</a><ul><li><a href="#caracteristicas-chave" class="table-of-contents__link toc-highlight">Caracteristicas-chave</a></li><li><a href="#diferencas-do-alphago-zero" class="table-of-contents__link toc-highlight">Diferencas do AlphaGo Zero</a></li></ul></li><li><a href="#pontos-chave-de-implementacao" class="table-of-contents__link toc-highlight">Pontos-chave de Implementacao</a><ul><li><a href="#recursos-computacionais" class="table-of-contents__link toc-highlight">Recursos Computacionais</a></li><li><a href="#hiperparametros-chave" class="table-of-contents__link toc-highlight">Hiperparametros-chave</a></li><li><a href="#problemas-comuns" class="table-of-contents__link toc-highlight">Problemas Comuns</a></li></ul></li><li><a href="#leitura-adicional" class="table-of-contents__link toc-highlight">Leitura Adicional</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>