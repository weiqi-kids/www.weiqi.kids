<!doctype html>
<html lang="pt" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/explained/policy-network" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Detalhes da Policy Network | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/pt/docs/alphago/explained/policy-network/"><meta data-rh="true" property="og:locale" content="pt"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Detalhes da Policy Network | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Compreensão aprofundada da arquitetura, métodos de treinamento e aplicações práticas da rede de políticas do AlphaGo, desde 13 camadas convolucionais até a saída Softmax"><meta data-rh="true" property="og:description" content="Compreensão aprofundada da arquitetura, métodos de treinamento e aplicações práticas da rede de políticas do AlphaGo, desde 13 camadas convolucionais até a saída Softmax"><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/pt/docs/alphago/explained/policy-network/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/policy-network/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/policy-network/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/explained/policy-network/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/explained/policy-network/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/explained/policy-network/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/explained/policy-network/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/explained/policy-network/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/explained/policy-network/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/explained/policy-network/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/explained/policy-network/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/explained/policy-network/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/policy-network/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/pt/docs/alphago/"},{"@type":"ListItem","position":2,"name":"完整解析","item":"https://www.weiqi.kids/pt/docs/alphago/explained/"},{"@type":"ListItem","position":3,"name":"Detalhes da Policy Network","item":"https://www.weiqi.kids/pt/docs/alphago/explained/policy-network"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/pt/assets/css/styles.f23bf74b.css">
<script src="/pt/assets/js/runtime~main.9908e616.js" defer="defer"></script>
<script src="/pt/assets/js/main.c4a2f5c5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.svg"><div role="region" aria-label="Pular para o conteúdo principal"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Pular para o conteúdo principal</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navegação" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/pt/docs/learn/">Aprender Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/pt/docs/animations/">Estúdio de Animação</a><a class="navbar__item navbar__link" href="/pt/docs/tech/">Documentação Técnica</a><a class="navbar__item navbar__link" href="/pt/docs/about/">Sobre Nós</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Português</a><ul class="dropdown__menu"><li><a href="/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Volte para o topo" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/intro/"><span title="Guia de Uso" class="linkLabel_REp1">Guia de Uso</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Expandir a categoria lateral &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/pt/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Fechar a categoria lateral &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/pt/docs/alphago/explained/"><span title="完整解析" class="categoryLinkLabel_ezQx">完整解析</span></a><button aria-label="Fechar a categoria lateral &#x27;完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/birth-of-alphago/"><span title="O Nascimento do AlphaGo" class="linkLabel_REp1">O Nascimento do AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/key-matches/"><span title="Retrospectiva das Partidas-Chave" class="linkLabel_REp1">Retrospectiva das Partidas-Chave</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/move-37/"><span title="Análise Profunda da &quot;Jogada Divina&quot;" class="linkLabel_REp1">Análise Profunda da &quot;Jogada Divina&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/why-go-is-hard/"><span title="Por Que o Go É Difícil?" class="linkLabel_REp1">Por Que o Go É Difícil?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/traditional-limits/"><span title="Limites dos Metodos Tradicionais" class="linkLabel_REp1">Limites dos Metodos Tradicionais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/board-representation/"><span title="Representacao do Estado do Tabuleiro" class="linkLabel_REp1">Representacao do Estado do Tabuleiro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pt/docs/alphago/explained/policy-network/"><span title="Detalhes da Policy Network" class="linkLabel_REp1">Detalhes da Policy Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/value-network/"><span title="Detalhes da Value Network" class="linkLabel_REp1">Detalhes da Value Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/input-features/"><span title="Design de Caracteristicas de Entrada" class="linkLabel_REp1">Design de Caracteristicas de Entrada</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/cnn-and-go/"><span title="CNN e Go" class="linkLabel_REp1">CNN e Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/supervised-learning/"><span title="Fase de Aprendizado Supervisionado" class="linkLabel_REp1">Fase de Aprendizado Supervisionado</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/reinforcement-intro/"><span title="Introdução ao Aprendizado por Reforço" class="linkLabel_REp1">Introdução ao Aprendizado por Reforço</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/self-play/"><span title="Autopartida" class="linkLabel_REp1">Autopartida</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/mcts-neural-combo/"><span title="A Combinação de MCTS e Redes Neurais" class="linkLabel_REp1">A Combinação de MCTS e Redes Neurais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/puct-formula/"><span title="Fórmula PUCT em Detalhes" class="linkLabel_REp1">Fórmula PUCT em Detalhes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/alphago-zero/"><span title="Visão Geral do AlphaGo Zero" class="linkLabel_REp1">Visão Geral do AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/dual-head-resnet/"><span title="Rede de Cabeça Dupla e Rede Residual" class="linkLabel_REp1">Rede de Cabeça Dupla e Rede Residual</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/training-from-scratch/"><span title="O Processo de Treinamento do Zero" class="linkLabel_REp1">O Processo de Treinamento do Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/distributed-systems/"><span title="Sistemas Distribuídos e TPU" class="linkLabel_REp1">Sistemas Distribuídos e TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/legacy-and-impact/"><span title="O Legado do AlphaGo" class="linkLabel_REp1">O Legado do AlphaGo</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Expandir a categoria lateral &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Expandir a categoria lateral &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página Inicial" class="breadcrumbs__link" href="/pt/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/explained/"><span>完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Detalhes da Policy Network</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">Nessa página</button></div><div class="theme-doc-markdown markdown"><header><h1>Detalhes da Policy Network</h1></header>
<p>Em qualquer posição de Go, existem em média 250 jogadas legais. Se deixarmos o computador escolher aleatoriamente, ele nunca conseguirá jogar bem.</p>
<p>A inovação do AlphaGo está em: ele aprendeu a &quot;olhar para o tabuleiro e saber quais posições vale a pena considerar&quot;.</p>
<p>Esta capacidade vem da <strong>Policy Network (Rede de Políticas)</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="o-que-é-a-policy-network">O que é a Policy Network?<a href="#o-que-é-a-policy-network" class="hash-link" aria-label="Link direto para O que é a Policy Network?" title="Link direto para O que é a Policy Network?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="função-principal">Função Principal<a href="#função-principal" class="hash-link" aria-label="Link direto para Função Principal" title="Link direto para Função Principal" translate="no">​</a></h3>
<p>A Policy Network é uma rede neural convolucional profunda, cuja tarefa é:</p>
<blockquote>
<p><strong>Dado o estado atual do tabuleiro, produzir a probabilidade de jogar em cada posição</strong></p>
</blockquote>
<p>Em termos matemáticos:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">p = f_θ(s)</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li class=""><code>s</code>: Estado atual do tabuleiro (tabuleiro 19×19 + outras características)</li>
<li class=""><code>f_θ</code>: Policy Network (θ são os parâmetros da rede)</li>
<li class=""><code>p</code>: Distribuição de probabilidade para 361 posições (incluindo passar)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="compreensão-intuitiva">Compreensão Intuitiva<a href="#compreensão-intuitiva" class="hash-link" aria-label="Link direto para Compreensão Intuitiva" title="Link direto para Compreensão Intuitiva" translate="no">​</a></h3>
<p>Imagine que você é um jogador profissional. Quando você vê uma posição, seu cérebro automaticamente &quot;ilumina&quot; algumas posições importantes — estas são as que sua intuição considera dignas de consideração.</p>
<p>A Policy Network está simulando este processo.</p>
<div>載入中...</div>
<p>O mapa de calor acima mostra a saída da Policy Network. Quanto mais brilhante a cor, mais o modelo considera que vale a pena jogar ali.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-precisamos-da-policy-network">Por que precisamos da Policy Network?<a href="#por-que-precisamos-da-policy-network" class="hash-link" aria-label="Link direto para Por que precisamos da Policy Network?" title="Link direto para Por que precisamos da Policy Network?" translate="no">​</a></h3>
<p>O espaço de busca do Go é imenso. Se buscarmos todas as jogadas possíveis sem filtragem:</p>
<table><thead><tr><th>Estratégia</th><th>Jogadas consideradas por lance</th><th>Nós para buscar 10 lances</th></tr></thead><tbody><tr><td>Considerar tudo</td><td>361</td><td>361^10 ≈ 10^25</td></tr><tr><td>Filtrado pela Policy Network</td><td>~20</td><td>20^10 ≈ 10^13</td></tr></tbody></table>
<p>A Policy Network reduz o espaço de busca em <strong>10^12 vezes</strong> (um trilhão de vezes).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="arquitetura-da-rede">Arquitetura da Rede<a href="#arquitetura-da-rede" class="hash-link" aria-label="Link direto para Arquitetura da Rede" title="Link direto para Arquitetura da Rede" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="estrutura-geral">Estrutura Geral<a href="#estrutura-geral" class="hash-link" aria-label="Link direto para Estrutura Geral" title="Link direto para Estrutura Geral" translate="no">​</a></h3>
<p>A Policy Network do AlphaGo usa uma arquitetura de rede neural convolucional profunda (CNN):</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Camada de Entrada → Camadas Conv ×12 → Camada Conv de Saída → Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ↓                ↓                    ↓                  ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    19×19×48         19×19×192            19×19×1           362 probabilidades</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="camada-de-entrada">Camada de Entrada<a href="#camada-de-entrada" class="hash-link" aria-label="Link direto para Camada de Entrada" title="Link direto para Camada de Entrada" translate="no">​</a></h3>
<p>A entrada é um tensor de características <strong>19×19×48</strong>:</p>
<ul>
<li class=""><strong>19×19</strong>: Tamanho do tabuleiro</li>
<li class=""><strong>48</strong>: 48 planos de características (veja <a class="" href="/pt/docs/alphago/explained/input-features/">Design de Características de Entrada</a>)</li>
</ul>
<p>Esses 48 planos incluem:</p>
<ul>
<li class="">Posições das pedras pretas, posições das pedras brancas</li>
<li class="">Histórico das últimas 8 jogadas</li>
<li class="">Liberdades, atari, escadas, etc.</li>
<li class="">Legalidade (quais posições podem ser jogadas)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="camadas-convolucionais">Camadas Convolucionais<a href="#camadas-convolucionais" class="hash-link" aria-label="Link direto para Camadas Convolucionais" title="Link direto para Camadas Convolucionais" translate="no">​</a></h3>
<p>A rede contém <strong>12 camadas convolucionais</strong>, cada uma configurada como:</p>
<table><thead><tr><th>Parâmetro</th><th>Valor</th><th>Descrição</th></tr></thead><tbody><tr><td>Número de filtros</td><td>192</td><td>Cada camada produz 192 mapas de características</td></tr><tr><td>Tamanho do kernel</td><td>3×3 (5×5 na primeira camada)</td><td>Cada vez observa uma região 3×3</td></tr><tr><td>Modo de padding</td><td>same</td><td>Mantém o tamanho 19×19</td></tr><tr><td>Função de ativação</td><td>ReLU</td><td>max(0, x)</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-192-filtros">Por que 192 filtros?<a href="#por-que-192-filtros" class="hash-link" aria-label="Link direto para Por que 192 filtros?" title="Link direto para Por que 192 filtros?" translate="no">​</a></h4>
<p>Este é um valor empírico. Muito poucos limitariam a capacidade do modelo, muitos aumentariam o custo computacional e o risco de overfitting. A equipe do DeepMind determinou através de experimentos que 192 é um bom ponto de equilíbrio.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-kernels-33">Por que kernels 3×3?<a href="#por-que-kernels-33" class="hash-link" aria-label="Link direto para Por que kernels 3×3?" title="Link direto para Por que kernels 3×3?" translate="no">​</a></h4>
<p>3×3 é o tamanho mais comum em redes neurais convolucionais, pelas seguintes razões:</p>
<ol>
<li class=""><strong>Captura suficiente de padrões locais</strong>: Olhos, conexões e cortes no Go estão dentro de uma região 3×3</li>
<li class=""><strong>Alta eficiência computacional</strong>: Comparado a kernels maiores, 3×3 tem menos parâmetros</li>
<li class=""><strong>Empilhável</strong>: Múltiplas camadas de convolução 3×3 podem alcançar um campo receptivo maior</li>
</ol>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-a-primeira-camada-usa-55">Por que a primeira camada usa 5×5?<a href="#por-que-a-primeira-camada-usa-55" class="hash-link" aria-label="Link direto para Por que a primeira camada usa 5×5?" title="Link direto para Por que a primeira camada usa 5×5?" translate="no">​</a></h4>
<p>A primeira camada usa um kernel 5×5 maior para capturar padrões de alcance ligeiramente maior na camada de entrada (como saltos pequenos e grandes). Esta é uma escolha de design, e o posterior AlphaGo Zero unificou para usar 3×3.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="função-de-ativação-relu">Função de Ativação ReLU<a href="#função-de-ativação-relu" class="hash-link" aria-label="Link direto para Função de Ativação ReLU" title="Link direto para Função de Ativação ReLU" translate="no">​</a></h3>
<p>Cada camada convolucional é seguida pela função de ativação ReLU (Rectified Linear Unit):</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">ReLU(x) = max(0, x)</span><br></span></code></pre></div></div>
<p>Por que usar ReLU?</p>
<ol>
<li class=""><strong>Computação simples</strong>: Apenas toma o máximo, muito mais rápido que sigmoid</li>
<li class=""><strong>Alivia o desaparecimento do gradiente</strong>: O gradiente na região positiva é constantemente 1</li>
<li class=""><strong>Ativação esparsa</strong>: Valores negativos são zerados, produzindo representação esparsa</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="camada-de-saída">Camada de Saída<a href="#camada-de-saída" class="hash-link" aria-label="Link direto para Camada de Saída" title="Link direto para Camada de Saída" translate="no">​</a></h3>
<p>A última camada é uma camada convolucional especial:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">19×19×192 → Convolução(1×1, 1 filtro) → 19×19×1 → Achatado → Vetor 362-dim → Softmax</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="convolução-11">Convolução 1×1<a href="#convolução-11" class="hash-link" aria-label="Link direto para Convolução 1×1" title="Link direto para Convolução 1×1" translate="no">​</a></h4>
<p>A camada de saída usa convolução 1×1, comprimindo 192 canais em 1. Isso equivale a fazer uma combinação linear das 192 características dimensionais em cada posição.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="saída-softmax">Saída Softmax<a href="#saída-softmax" class="hash-link" aria-label="Link direto para Saída Softmax" title="Link direto para Saída Softmax" translate="no">​</a></h4>
<p>O vetor 362-dimensional (361 posições do tabuleiro + 1 para passar) passa pela função Softmax:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Softmax(z_i) = exp(z_i) / Σ_j exp(z_j)</span><br></span></code></pre></div></div>
<p>O Softmax garante que a saída seja uma distribuição de probabilidade válida:</p>
<ul>
<li class="">Todos os valores estão entre 0 e 1</li>
<li class="">A soma de todos os valores é 1</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="contagem-de-parâmetros">Contagem de Parâmetros<a href="#contagem-de-parâmetros" class="hash-link" aria-label="Link direto para Contagem de Parâmetros" title="Link direto para Contagem de Parâmetros" translate="no">​</a></h3>
<p>Vamos calcular o número total de parâmetros da rede:</p>
<table><thead><tr><th>Camada</th><th>Cálculo</th><th>Número de Parâmetros</th></tr></thead><tbody><tr><td>Primeira camada conv</td><td>5×5×48×192 + 192</td><td>230.592</td></tr><tr><td>Camadas conv intermediárias ×11</td><td>(3×3×192×192 + 192) × 11</td><td>3.633.792</td></tr><tr><td>Camada conv de saída</td><td>1×1×192×1 + 1</td><td>193</td></tr><tr><td><strong>Total</strong></td><td></td><td><strong>~3,9M</strong></td></tr></tbody></table>
<p>Aproximadamente <strong>3,9 milhões de parâmetros</strong>, considerada uma rede pequena pelos padrões atuais.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="objetivo-e-métodos-de-treinamento">Objetivo e Métodos de Treinamento<a href="#objetivo-e-métodos-de-treinamento" class="hash-link" aria-label="Link direto para Objetivo e Métodos de Treinamento" title="Link direto para Objetivo e Métodos de Treinamento" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="dados-de-treinamento">Dados de Treinamento<a href="#dados-de-treinamento" class="hash-link" aria-label="Link direto para Dados de Treinamento" title="Link direto para Dados de Treinamento" translate="no">​</a></h3>
<p>A Policy Network usa <strong>aprendizado supervisionado</strong>, aprendendo a partir de registros de jogos humanos.</p>
<p>Fontes de dados:</p>
<ul>
<li class=""><strong>KGS Go Server</strong>: Jogos de jogadores amadores e profissionais</li>
<li class=""><strong>Aproximadamente 30 milhões de posições</strong>: Amostradas de 160 mil jogos</li>
<li class=""><strong>Rótulos</strong>: A próxima jogada humana correspondente a cada posição</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="função-de-perda-de-entropia-cruzada">Função de Perda de Entropia Cruzada<a href="#função-de-perda-de-entropia-cruzada" class="hash-link" aria-label="Link direto para Função de Perda de Entropia Cruzada" title="Link direto para Função de Perda de Entropia Cruzada" translate="no">​</a></h3>
<p>O objetivo do treinamento é maximizar a probabilidade de prever as jogadas humanas. Usando a função de perda de entropia cruzada:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L(θ) = -Σ log p_θ(a | s)</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li class=""><code>s</code>: Estado do tabuleiro</li>
<li class=""><code>a</code>: Posição onde o humano realmente jogou</li>
<li class=""><code>p_θ(a | s)</code>: Probabilidade do modelo para aquela posição</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="compreensão-intuitiva-1">Compreensão Intuitiva<a href="#compreensão-intuitiva-1" class="hash-link" aria-label="Link direto para Compreensão Intuitiva" title="Link direto para Compreensão Intuitiva" translate="no">​</a></h4>
<p>A perda de entropia cruzada tem um significado simples:</p>
<blockquote>
<p><strong>Quanto maior a probabilidade do modelo para a posição correta, menor a perda</strong></p>
</blockquote>
<p>Se o humano jogou em K10, e a probabilidade do modelo para K10 é:</p>
<ul>
<li class="">0,9 → Perda = -log(0,9) ≈ 0,1 (muito baixa, bom)</li>
<li class="">0,1 → Perda = -log(0,1) ≈ 2,3 (alta, ruim)</li>
<li class="">0,01 → Perda = -log(0,01) ≈ 4,6 (muito alta, muito ruim)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="processo-de-treinamento">Processo de Treinamento<a href="#processo-de-treinamento" class="hash-link" aria-label="Link direto para Processo de Treinamento" title="Link direto para Processo de Treinamento" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Pseudocódigo</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> epoch </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_epochs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> batch </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> dataloader</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        states</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Propagação direta</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> network</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">states</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Vetor de probabilidade 361-dim</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Calcular perda (entropia cruzada)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cross_entropy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Retropropagação</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Detalhes do treinamento:</p>
<ul>
<li class=""><strong>Otimizador</strong>: SGD com momentum</li>
<li class=""><strong>Taxa de aprendizado</strong>: Inicial 0,003, decaindo gradualmente</li>
<li class=""><strong>Tamanho do lote</strong>: 16</li>
<li class=""><strong>Tempo de treinamento</strong>: Aproximadamente 3 semanas (50 GPUs)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="aumento-de-dados">Aumento de Dados<a href="#aumento-de-dados" class="hash-link" aria-label="Link direto para Aumento de Dados" title="Link direto para Aumento de Dados" translate="no">​</a></h3>
<p>O tabuleiro de Go tem simetria de 8 dobras (4 rotações × 2 espelhamentos). Cada amostra de treinamento pode ser transformada em 8 amostras equivalentes:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Original → Rotação 90° → Rotação 180° → Rotação 270°</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ↓          ↓              ↓              ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Espelhamento horizontal → ...</span><br></span></code></pre></div></div>
<p>Isso aumenta os dados de treinamento efetivos em 8 vezes e garante que os padrões aprendidos pelo modelo não dependam da orientação.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="resultados-do-treinamento">Resultados do Treinamento<a href="#resultados-do-treinamento" class="hash-link" aria-label="Link direto para Resultados do Treinamento" title="Link direto para Resultados do Treinamento" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="57-de-precisão">57% de Precisão<a href="#57-de-precisão" class="hash-link" aria-label="Link direto para 57% de Precisão" title="Link direto para 57% de Precisão" translate="no">​</a></h3>
<p>Após o treinamento, a Policy Network alcançou <strong>57% de precisão top-1</strong>.</p>
<p>Isso significa: dada qualquer posição, o modelo tem 57% de chance de prever a jogada exata que o especialista humano fez.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="esta-precisão-é-alta">Esta precisão é alta?<a href="#esta-precisão-é-alta" class="hash-link" aria-label="Link direto para Esta precisão é alta?" title="Link direto para Esta precisão é alta?" translate="no">​</a></h4>
<p>Considerando que cada posição tem em média 250 jogadas legais, a precisão de adivinhação aleatória é de apenas 0,4%.</p>
<table><thead><tr><th>Método</th><th>Precisão Top-1</th></tr></thead><tbody><tr><td>Adivinhação aleatória</td><td>0,4%</td></tr><tr><td>Melhor programa de Go anterior</td><td>~44%</td></tr><tr><td>Policy Network do AlphaGo</td><td><strong>57%</strong></td></tr></tbody></table>
<p>Um aumento de 13 pontos percentuais pode parecer pequeno, mas é muito significativo.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="melhoria-na-força-de-jogo">Melhoria na Força de Jogo<a href="#melhoria-na-força-de-jogo" class="hash-link" aria-label="Link direto para Melhoria na Força de Jogo" title="Link direto para Melhoria na Força de Jogo" translate="no">​</a></h3>
<p>Qual força de jogo pode ser alcançada usando puramente a Policy Network (sem busca)?</p>
<table><thead><tr><th>Configuração</th><th>Classificação Elo</th><th>Nível Aproximado</th></tr></thead><tbody><tr><td>Melhor programa anterior (Pachi)</td><td>2.500</td><td>Amador 4-5 dan</td></tr><tr><td>Apenas Policy Network</td><td>2.800</td><td>Amador 6-7 dan</td></tr><tr><td>+ MCTS 1600 simulações</td><td>3.200+</td><td>Nível profissional</td></tr></tbody></table>
<p>A Policy Network sozinha já é de nível amador alto, e com MCTS salta para nível profissional.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-apenas-57">Por que apenas 57%?<a href="#por-que-apenas-57" class="hash-link" aria-label="Link direto para Por que apenas 57%?" title="Link direto para Por que apenas 57%?" translate="no">​</a></h3>
<p>Os registros de jogos humanos têm as seguintes características que limitam a precisão:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-múltiplas-boas-jogadas">1. Múltiplas Boas Jogadas<a href="#1-múltiplas-boas-jogadas" class="hash-link" aria-label="Link direto para 1. Múltiplas Boas Jogadas" title="Link direto para 1. Múltiplas Boas Jogadas" translate="no">​</a></h4>
<p>Muitas posições têm múltiplas boas jogadas. Por exemplo, &quot;aproximação do canto&quot; e &quot;defesa do canto&quot; podem ambas ser escolhas corretas. Se o modelo escolhe outra boa jogada, é contado como &quot;errado&quot;.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-diferenças-de-estilo">2. Diferenças de Estilo<a href="#2-diferenças-de-estilo" class="hash-link" aria-label="Link direto para 2. Diferenças de Estilo" title="Link direto para 2. Diferenças de Estilo" translate="no">​</a></h4>
<p>Diferentes jogadores têm estilos diferentes. Jogadores agressivos e jogadores sólidos podem fazer jogadas diferentes na mesma posição. O modelo aprende um estilo &quot;médio&quot;.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-humanos-também-erram">3. Humanos Também Erram<a href="#3-humanos-também-erram" class="hash-link" aria-label="Link direto para 3. Humanos Também Erram" title="Link direto para 3. Humanos Também Erram" translate="no">​</a></h4>
<p>Os dados do KGS incluem jogos de jogadores amadores, cujas escolhas nem sempre são ótimas. É normal o modelo aprender alguns &quot;erros&quot;.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="papel-no-mcts">Papel no MCTS<a href="#papel-no-mcts" class="hash-link" aria-label="Link direto para Papel no MCTS" title="Link direto para Papel no MCTS" translate="no">​</a></h2>
<p>A Policy Network desempenha dois papéis-chave no MCTS do AlphaGo:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="1-guiar-a-direção-da-busca">1. Guiar a Direção da Busca<a href="#1-guiar-a-direção-da-busca" class="hash-link" aria-label="Link direto para 1. Guiar a Direção da Busca" title="Link direto para 1. Guiar a Direção da Busca" translate="no">​</a></h3>
<p>Na fase de <strong>Seleção</strong> do MCTS, a saída da Policy Network é usada para calcular o UCB (Upper Confidence Bound):</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">UCB(s, a) = Q(s, a) + c_puct × P(s, a) × √(N(s)) / (1 + N(s, a))</span><br></span></code></pre></div></div>
<p>Onde <code>P(s, a)</code> é a probabilidade dada pela Policy Network.</p>
<p>Isso significa:</p>
<ul>
<li class=""><strong>Jogadas de alta probabilidade são exploradas primeiro</strong></li>
<li class=""><strong>Jogadas de baixa probabilidade também têm chance de serem exploradas</strong> (por causa do termo de exploração)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="2-prior-para-expansão-de-nós">2. Prior para Expansão de Nós<a href="#2-prior-para-expansão-de-nós" class="hash-link" aria-label="Link direto para 2. Prior para Expansão de Nós" title="Link direto para 2. Prior para Expansão de Nós" translate="no">​</a></h3>
<p>Quando o MCTS expande um novo nó, a Policy Network fornece as <strong>probabilidades a priori</strong> para todos os nós filhos.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Expandir nó s:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  for each action a:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child = Node()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.prior = policy_network(s)[a]  # Probabilidade a priori</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.value = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.visits = 0</span><br></span></code></pre></div></div>
<p>Essas probabilidades a priori permitem que o MCTS &quot;saiba&quot; quais nós filhos vale mais a pena explorar, mesmo que ainda não tenham sido visitados.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="versão-leve-vs-versão-completa">Versão Leve vs. Versão Completa<a href="#versão-leve-vs-versão-completa" class="hash-link" aria-label="Link direto para Versão Leve vs. Versão Completa" title="Link direto para Versão Leve vs. Versão Completa" translate="no">​</a></h2>
<p>O AlphaGo na verdade tem duas Policy Networks:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="versão-completa-sl-policy-network">Versão Completa (SL Policy Network)<a href="#versão-completa-sl-policy-network" class="hash-link" aria-label="Link direto para Versão Completa (SL Policy Network)" title="Link direto para Versão Completa (SL Policy Network)" translate="no">​</a></h3>
<ul>
<li class=""><strong>Arquitetura</strong>: CNN de 13 camadas, 192 filtros</li>
<li class=""><strong>Precisão</strong>: 57%</li>
<li class=""><strong>Tempo de inferência</strong>: ~3 milissegundos/posição</li>
<li class=""><strong>Uso</strong>: Seleção e Expansão no MCTS</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="versão-leve-rollout-policy-network">Versão Leve (Rollout Policy Network)<a href="#versão-leve-rollout-policy-network" class="hash-link" aria-label="Link direto para Versão Leve (Rollout Policy Network)" title="Link direto para Versão Leve (Rollout Policy Network)" translate="no">​</a></h3>
<ul>
<li class=""><strong>Arquitetura</strong>: Modelo linear + características manuais</li>
<li class=""><strong>Precisão</strong>: 24%</li>
<li class=""><strong>Tempo de inferência</strong>: ~2 microssegundos/posição (1500× mais rápido)</li>
<li class=""><strong>Uso</strong>: Simulação rápida (rollout)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-precisamos-da-versão-leve">Por que precisamos da versão leve?<a href="#por-que-precisamos-da-versão-leve" class="hash-link" aria-label="Link direto para Por que precisamos da versão leve?" title="Link direto para Por que precisamos da versão leve?" translate="no">​</a></h3>
<p>Na fase de <strong>Simulação</strong> do MCTS, é necessário jogar desde o nó atual até o fim do jogo, potencialmente 100+ jogadas. Se cada jogada usar a Policy Network completa, é muito lento.</p>
<p>A versão leve tem apenas 24% de precisão, mas é 1500× mais rápida. No rollout, velocidade é mais importante que precisão.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="características-da-versão-leve">Características da Versão Leve<a href="#características-da-versão-leve" class="hash-link" aria-label="Link direto para Características da Versão Leve" title="Link direto para Características da Versão Leve" translate="no">​</a></h3>
<p>A versão leve usa características projetadas manualmente, incluindo:</p>
<table><thead><tr><th>Tipo de Característica</th><th>Exemplos</th></tr></thead><tbody><tr><td>Padrões locais</td><td>Configuração de pedras em região 3×3</td></tr><tr><td>Características globais</td><td>Se está no canto/borda, pontos grandes</td></tr><tr><td>Características táticas</td><td>Atari, escadas, conexões</td></tr></tbody></table>
<p>Essas características são alimentadas em um modelo linear (sem camadas ocultas), calculando extremamente rápido.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="melhorias-no-alphago-zero">Melhorias no AlphaGo Zero<a href="#melhorias-no-alphago-zero" class="hash-link" aria-label="Link direto para Melhorias no AlphaGo Zero" title="Link direto para Melhorias no AlphaGo Zero" translate="no">​</a></h3>
<p>O posterior AlphaGo Zero abandonou completamente a versão leve e os rollouts. Ele avalia os nós folha diretamente com a Value Network, não precisando de simulação rápida. Esta foi uma simplificação importante.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="refinamento-com-aprendizado-por-reforço-rl-policy-network">Refinamento com Aprendizado por Reforço (RL Policy Network)<a href="#refinamento-com-aprendizado-por-reforço-rl-policy-network" class="hash-link" aria-label="Link direto para Refinamento com Aprendizado por Reforço (RL Policy Network)" title="Link direto para Refinamento com Aprendizado por Reforço (RL Policy Network)" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="limitações-do-aprendizado-supervisionado">Limitações do Aprendizado Supervisionado<a href="#limitações-do-aprendizado-supervisionado" class="hash-link" aria-label="Link direto para Limitações do Aprendizado Supervisionado" title="Link direto para Limitações do Aprendizado Supervisionado" translate="no">​</a></h3>
<p>A Policy Network treinada com aprendizado supervisionado tem um problema fundamental:</p>
<blockquote>
<p><strong>Ela aprende a &quot;imitar humanos&quot;, não a &quot;vencer&quot;</strong></p>
</blockquote>
<p>Isso significa que ela aprenderá os maus hábitos dos humanos e também terá desempenho ruim em posições que os humanos nunca encontraram.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="auto-jogo-com-reforço">Auto-jogo com Reforço<a href="#auto-jogo-com-reforço" class="hash-link" aria-label="Link direto para Auto-jogo com Reforço" title="Link direto para Auto-jogo com Reforço" translate="no">​</a></h3>
<p>A solução do DeepMind é usar o método de <strong>Policy Gradient</strong> para aprendizado por reforço:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Deixar a Policy Network jogar contra si mesma</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Registrar todas as jogadas de cada partida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Ajustar parâmetros baseado no resultado:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Venceu → Aumentar probabilidade dessas jogadas</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Perdeu → Diminuir probabilidade dessas jogadas</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="algoritmo-reinforce">Algoritmo REINFORCE<a href="#algoritmo-reinforce" class="hash-link" aria-label="Link direto para Algoritmo REINFORCE" title="Link direto para Algoritmo REINFORCE" translate="no">​</a></h3>
<p>Especificamente usando o algoritmo REINFORCE:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∇J(θ) = E[Σ_t ∇log π_θ(a_t | s_t) × z]</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li class=""><code>z</code>: Resultado do jogo (+1 vitória, -1 derrota)</li>
<li class=""><code>π_θ(a_t | s_t)</code>: Probabilidade de escolher ação <code>a_t</code> no estado <code>s_t</code></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="resultados">Resultados<a href="#resultados" class="hash-link" aria-label="Link direto para Resultados" title="Link direto para Resultados" translate="no">​</a></h3>
<p>Após aproximadamente 1 dia de treinamento com auto-jogo (1,28 milhão de jogos), a RL Policy Network:</p>
<table><thead><tr><th>Métrica</th><th>SL Policy</th><th>RL Policy</th></tr></thead><tbody><tr><td>Taxa de vitória contra SL Policy</td><td>50%</td><td><strong>80%</strong></td></tr><tr><td>Aumento de Elo</td><td>-</td><td>+100</td></tr></tbody></table>
<p>A precisão pode diminuir ligeiramente (porque não imita mais completamente os humanos), mas a taxa de vitória real melhora significativamente.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="de-imitar-para-inovar">De &quot;Imitar&quot; para &quot;Inovar&quot;<a href="#de-imitar-para-inovar" class="hash-link" aria-label="Link direto para De &quot;Imitar&quot; para &quot;Inovar&quot;" title="Link direto para De &quot;Imitar&quot; para &quot;Inovar&quot;" translate="no">​</a></h3>
<p>O aprendizado por reforço permitiu que a Policy Network aprendesse algumas jogadas que os humanos nunca pensaram. Essas jogadas nunca apareceram nos dados de treinamento, mas são eficazes.</p>
<p>É por isso que o AlphaGo pode fazer &quot;a jogada divina&quot; — não é limitado pela experiência humana.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="análise-visual">Análise Visual<a href="#análise-visual" class="hash-link" aria-label="Link direto para Análise Visual" title="Link direto para Análise Visual" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="distribuições-de-probabilidade-em-diferentes-posições">Distribuições de Probabilidade em Diferentes Posições<a href="#distribuições-de-probabilidade-em-diferentes-posições" class="hash-link" aria-label="Link direto para Distribuições de Probabilidade em Diferentes Posições" title="Link direto para Distribuições de Probabilidade em Diferentes Posições" translate="no">​</a></h3>
<p>Vamos ver a saída da Policy Network em diferentes posições:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="abertura-fase-de-fuseki">Abertura (Fase de Fuseki)<a href="#abertura-fase-de-fuseki" class="hash-link" aria-label="Link direto para Abertura (Fase de Fuseki)" title="Link direto para Abertura (Fase de Fuseki)" translate="no">​</a></h4>
<div>載入中...</div>
<p>Na abertura, a probabilidade está principalmente concentrada em:</p>
<ul>
<li class="">Cantos (ocupar cantos)</li>
<li class="">Bordas (aproximação do canto, defesa do canto)</li>
<li class="">Posições de &quot;grande escala&quot;</li>
</ul>
<p>Isso está de acordo com o princípio básico do Go: cantos de ouro, bordas de prata, centro de grama.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="posição-de-combate">Posição de Combate<a href="#posição-de-combate" class="hash-link" aria-label="Link direto para Posição de Combate" title="Link direto para Posição de Combate" translate="no">​</a></h4>
<div>載入中...</div>
<p>Durante o combate, a probabilidade está concentrada em:</p>
<ul>
<li class="">Pontos de corte críticos</li>
<li class="">Atari, conexões</li>
<li class="">Fazer olhos, destruir olhos</li>
</ul>
<p>Isso mostra que o modelo aprendeu táticas locais.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="fase-de-yose">Fase de Yose<a href="#fase-de-yose" class="hash-link" aria-label="Link direto para Fase de Yose" title="Link direto para Fase de Yose" translate="no">​</a></h4>
<div>載入中...</div>
<p>No yose, a probabilidade está dispersa em vários pontos de fechamento, requerendo cálculo preciso de pontos.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-que-as-camadas-ocultas-aprenderam">O que as Camadas Ocultas Aprenderam?<a href="#o-que-as-camadas-ocultas-aprenderam" class="hash-link" aria-label="Link direto para O que as Camadas Ocultas Aprenderam?" title="Link direto para O que as Camadas Ocultas Aprenderam?" translate="no">​</a></h3>
<p>Visualizando a saída das camadas convolucionais, podemos ver as &quot;características&quot; aprendidas pelo modelo:</p>
<ul>
<li class=""><strong>Camadas baixas</strong>: Formas básicas (olhos, pontos de corte)</li>
<li class=""><strong>Camadas médias</strong>: Padrões táticos (atari, escadas)</li>
<li class=""><strong>Camadas altas</strong>: Conceitos globais (influência, espessura)</li>
</ul>
<p>Isso é muito similar à estrutura hierárquica de como os humanos compreendem o Go.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="pontos-de-implementação">Pontos de Implementação<a href="#pontos-de-implementação" class="hash-link" aria-label="Link direto para Pontos de Implementação" title="Link direto para Pontos de Implementação" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="implementação-em-pytorch">Implementação em PyTorch<a href="#implementação-em-pytorch" class="hash-link" aria-label="Link direto para Implementação em PyTorch" title="Link direto para Implementação em PyTorch" translate="no">​</a></h3>
<p>Aqui está uma implementação simplificada da Policy Network:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">functional </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> F</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">PolicyNetwork</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> input_channels</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">48</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">192</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_layers</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">12</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Primeira camada convolucional (5×5)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_channels</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                               kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Camadas convolucionais intermediárias (3×3)×11</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ModuleList</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                     kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_layers </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Camada convolucional de saída (1×1)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_out </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">forward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># x: (batch, 48, 19, 19)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Primeira camada</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Camadas intermediárias</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> conv </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">conv</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Camada de saída</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_out</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 1, 19, 19)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Achatar + Softmax</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">view</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 361)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">softmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="loop-de-treinamento">Loop de Treinamento<a href="#loop-de-treinamento" class="hash-link" aria-label="Link direto para Loop de Treinamento" title="Link direto para Loop de Treinamento" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">train_step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> optimizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> states</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    states: (batch, 48, 19, 19) - Características do tabuleiro</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    actions: (batch,) - Posição jogada pelo humano (0-360)</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Propagação direta</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">states</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 361)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Perda de entropia cruzada</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cross_entropy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">policy </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-8</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Prevenir log(0)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        actions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Retropropagação</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Calcular precisão</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    predictions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    accuracy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">predictions </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">float</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mean</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">item</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> accuracy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">item</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="considerações-para-inferência">Considerações para Inferência<a href="#considerações-para-inferência" class="hash-link" aria-label="Link direto para Considerações para Inferência" title="Link direto para Considerações para Inferência" translate="no">​</a></h3>
<p>Durante o jogo real, note:</p>
<ol>
<li class=""><strong>Filtrar jogadas ilegais</strong>: Definir probabilidade de posições ilegais como 0, depois renormalizar</li>
<li class=""><strong>Ajuste de temperatura</strong>: Pode usar parâmetro de temperatura para controlar a &quot;nitidez&quot; da distribuição de probabilidade</li>
<li class=""><strong>Inferência em lote</strong>: No MCTS pode processar múltiplas posições em lote</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">get_move_probabilities</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> state</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> legal_moves</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;Obter distribuição de probabilidade para jogadas legais&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">state</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (361,)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Manter apenas jogadas legais</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mask </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">361</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mask</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">legal_moves</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> mask</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Ajuste de temperatura</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> temperature </span><span class="token operator" style="color:#393A34">!=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">**</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> temperature</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Renormalizar</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> policy</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="correspondência-com-animações">Correspondência com Animações<a href="#correspondência-com-animações" class="hash-link" aria-label="Link direto para Correspondência com Animações" title="Link direto para Correspondência com Animações" translate="no">​</a></h2>
<p>Os conceitos principais abordados neste artigo e seus números de animação:</p>
<table><thead><tr><th>Número</th><th>Conceito</th><th>Correspondência Física/Matemática</th></tr></thead><tbody><tr><td>E1</td><td>Policy Network</td><td>Campo de probabilidade</td></tr><tr><td>D9</td><td>Extração de características CNN</td><td>Resposta de filtros</td></tr><tr><td>D3</td><td>Aprendizado supervisionado</td><td>Estimativa de máxima verossimilhança</td></tr><tr><td>H4</td><td>Policy gradient</td><td>Otimização estocástica</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="leitura-adicional">Leitura Adicional<a href="#leitura-adicional" class="hash-link" aria-label="Link direto para Leitura Adicional" title="Link direto para Leitura Adicional" translate="no">​</a></h2>
<ul>
<li class=""><strong>Próximo artigo</strong>: <a class="" href="/pt/docs/alphago/explained/value-network/">Detalhes da Value Network</a> — Como o AlphaGo avalia posições</li>
<li class=""><strong>Tópico relacionado</strong>: <a class="" href="/pt/docs/alphago/explained/input-features/">Design de Características de Entrada</a> — Detalhes dos 48 planos de características</li>
<li class=""><strong>Princípios profundos</strong>: <a class="" href="/pt/docs/alphago/explained/cnn-and-go/">CNN e Go</a> — Por que redes neurais convolucionais são adequadas para tabuleiros</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="pontos-chave">Pontos-Chave<a href="#pontos-chave" class="hash-link" aria-label="Link direto para Pontos-Chave" title="Link direto para Pontos-Chave" translate="no">​</a></h2>
<ol>
<li class=""><strong>Policy Network é um gerador de distribuição de probabilidade</strong>: Entrada do tabuleiro, saída de probabilidades para 361 posições</li>
<li class=""><strong>13 camadas CNN + Softmax</strong>: Convolução profunda para extração de características, Softmax para saída de probabilidades</li>
<li class=""><strong>57% de precisão</strong>: Muito superior aos programas de Go anteriores</li>
<li class=""><strong>Duas versões</strong>: Versão completa para decisões no MCTS, versão leve para simulação rápida</li>
<li class=""><strong>Refinamento com aprendizado por reforço</strong>: De &quot;imitar humanos&quot; para &quot;buscar vitória&quot;</li>
</ol>
<p>A Policy Network é a &quot;intuição&quot; do AlphaGo — ela permite que a IA, como os humanos, identifique rapidamente jogadas que valem a pena considerar.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referências">Referências<a href="#referências" class="hash-link" aria-label="Link direto para Referências" title="Link direto para Referências" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Maddison, C. J., et al. (2014). &quot;Move Evaluation in Go Using Deep Convolutional Neural Networks.&quot; <em>arXiv:1412.6564</em>.</li>
<li class="">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em>. MIT Press.</li>
<li class="">LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). &quot;Deep learning.&quot; <em>Nature</em>, 521, 436-444.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/explained/07-policy-network.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa página</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Páginas de documentação"><a class="pagination-nav__link pagination-nav__link--prev" href="/pt/docs/alphago/explained/board-representation/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Representacao do Estado do Tabuleiro</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/pt/docs/alphago/explained/value-network/"><div class="pagination-nav__sublabel">Próxima</div><div class="pagination-nav__label">Detalhes da Value Network</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#o-que-é-a-policy-network" class="table-of-contents__link toc-highlight">O que é a Policy Network?</a><ul><li><a href="#função-principal" class="table-of-contents__link toc-highlight">Função Principal</a></li><li><a href="#compreensão-intuitiva" class="table-of-contents__link toc-highlight">Compreensão Intuitiva</a></li><li><a href="#por-que-precisamos-da-policy-network" class="table-of-contents__link toc-highlight">Por que precisamos da Policy Network?</a></li></ul></li><li><a href="#arquitetura-da-rede" class="table-of-contents__link toc-highlight">Arquitetura da Rede</a><ul><li><a href="#estrutura-geral" class="table-of-contents__link toc-highlight">Estrutura Geral</a></li><li><a href="#camada-de-entrada" class="table-of-contents__link toc-highlight">Camada de Entrada</a></li><li><a href="#camadas-convolucionais" class="table-of-contents__link toc-highlight">Camadas Convolucionais</a></li><li><a href="#função-de-ativação-relu" class="table-of-contents__link toc-highlight">Função de Ativação ReLU</a></li><li><a href="#camada-de-saída" class="table-of-contents__link toc-highlight">Camada de Saída</a></li><li><a href="#contagem-de-parâmetros" class="table-of-contents__link toc-highlight">Contagem de Parâmetros</a></li></ul></li><li><a href="#objetivo-e-métodos-de-treinamento" class="table-of-contents__link toc-highlight">Objetivo e Métodos de Treinamento</a><ul><li><a href="#dados-de-treinamento" class="table-of-contents__link toc-highlight">Dados de Treinamento</a></li><li><a href="#função-de-perda-de-entropia-cruzada" class="table-of-contents__link toc-highlight">Função de Perda de Entropia Cruzada</a></li><li><a href="#processo-de-treinamento" class="table-of-contents__link toc-highlight">Processo de Treinamento</a></li><li><a href="#aumento-de-dados" class="table-of-contents__link toc-highlight">Aumento de Dados</a></li></ul></li><li><a href="#resultados-do-treinamento" class="table-of-contents__link toc-highlight">Resultados do Treinamento</a><ul><li><a href="#57-de-precisão" class="table-of-contents__link toc-highlight">57% de Precisão</a></li><li><a href="#melhoria-na-força-de-jogo" class="table-of-contents__link toc-highlight">Melhoria na Força de Jogo</a></li><li><a href="#por-que-apenas-57" class="table-of-contents__link toc-highlight">Por que apenas 57%?</a></li></ul></li><li><a href="#papel-no-mcts" class="table-of-contents__link toc-highlight">Papel no MCTS</a><ul><li><a href="#1-guiar-a-direção-da-busca" class="table-of-contents__link toc-highlight">1. Guiar a Direção da Busca</a></li><li><a href="#2-prior-para-expansão-de-nós" class="table-of-contents__link toc-highlight">2. Prior para Expansão de Nós</a></li></ul></li><li><a href="#versão-leve-vs-versão-completa" class="table-of-contents__link toc-highlight">Versão Leve vs. Versão Completa</a><ul><li><a href="#versão-completa-sl-policy-network" class="table-of-contents__link toc-highlight">Versão Completa (SL Policy Network)</a></li><li><a href="#versão-leve-rollout-policy-network" class="table-of-contents__link toc-highlight">Versão Leve (Rollout Policy Network)</a></li><li><a href="#por-que-precisamos-da-versão-leve" class="table-of-contents__link toc-highlight">Por que precisamos da versão leve?</a></li><li><a href="#características-da-versão-leve" class="table-of-contents__link toc-highlight">Características da Versão Leve</a></li><li><a href="#melhorias-no-alphago-zero" class="table-of-contents__link toc-highlight">Melhorias no AlphaGo Zero</a></li></ul></li><li><a href="#refinamento-com-aprendizado-por-reforço-rl-policy-network" class="table-of-contents__link toc-highlight">Refinamento com Aprendizado por Reforço (RL Policy Network)</a><ul><li><a href="#limitações-do-aprendizado-supervisionado" class="table-of-contents__link toc-highlight">Limitações do Aprendizado Supervisionado</a></li><li><a href="#auto-jogo-com-reforço" class="table-of-contents__link toc-highlight">Auto-jogo com Reforço</a></li><li><a href="#algoritmo-reinforce" class="table-of-contents__link toc-highlight">Algoritmo REINFORCE</a></li><li><a href="#resultados" class="table-of-contents__link toc-highlight">Resultados</a></li><li><a href="#de-imitar-para-inovar" class="table-of-contents__link toc-highlight">De &quot;Imitar&quot; para &quot;Inovar&quot;</a></li></ul></li><li><a href="#análise-visual" class="table-of-contents__link toc-highlight">Análise Visual</a><ul><li><a href="#distribuições-de-probabilidade-em-diferentes-posições" class="table-of-contents__link toc-highlight">Distribuições de Probabilidade em Diferentes Posições</a></li><li><a href="#o-que-as-camadas-ocultas-aprenderam" class="table-of-contents__link toc-highlight">O que as Camadas Ocultas Aprenderam?</a></li></ul></li><li><a href="#pontos-de-implementação" class="table-of-contents__link toc-highlight">Pontos de Implementação</a><ul><li><a href="#implementação-em-pytorch" class="table-of-contents__link toc-highlight">Implementação em PyTorch</a></li><li><a href="#loop-de-treinamento" class="table-of-contents__link toc-highlight">Loop de Treinamento</a></li><li><a href="#considerações-para-inferência" class="table-of-contents__link toc-highlight">Considerações para Inferência</a></li></ul></li><li><a href="#correspondência-com-animações" class="table-of-contents__link toc-highlight">Correspondência com Animações</a></li><li><a href="#leitura-adicional" class="table-of-contents__link toc-highlight">Leitura Adicional</a></li><li><a href="#pontos-chave" class="table-of-contents__link toc-highlight">Pontos-Chave</a></li><li><a href="#referências" class="table-of-contents__link toc-highlight">Referências</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>