<!doctype html>
<html lang="pt" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/explained/birth-of-alphago" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">O Nascimento do AlphaGo | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/pt/docs/alphago/explained/birth-of-alphago/"><meta data-rh="true" property="og:locale" content="pt"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="O Nascimento do AlphaGo | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Da fundação da DeepMind à aquisição pelo Google, como o AlphaGo passou de uma ideia louca a uma IA que mudou o mundo"><meta data-rh="true" property="og:description" content="Da fundação da DeepMind à aquisição pelo Google, como o AlphaGo passou de uma ideia louca a uma IA que mudou o mundo"><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/pt/docs/alphago/explained/birth-of-alphago/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/birth-of-alphago/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/birth-of-alphago/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/explained/birth-of-alphago/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/explained/birth-of-alphago/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/explained/birth-of-alphago/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/explained/birth-of-alphago/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/explained/birth-of-alphago/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/explained/birth-of-alphago/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/explained/birth-of-alphago/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/explained/birth-of-alphago/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/explained/birth-of-alphago/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/birth-of-alphago/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/pt/docs/alphago/"},{"@type":"ListItem","position":2,"name":"完整解析","item":"https://www.weiqi.kids/pt/docs/alphago/explained/"},{"@type":"ListItem","position":3,"name":"O Nascimento do AlphaGo","item":"https://www.weiqi.kids/pt/docs/alphago/explained/birth-of-alphago"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/pt/assets/css/styles.f23bf74b.css">
<script src="/pt/assets/js/runtime~main.9908e616.js" defer="defer"></script>
<script src="/pt/assets/js/main.c4a2f5c5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.svg"><div role="region" aria-label="Pular para o conteúdo principal"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Pular para o conteúdo principal</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navegação" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/pt/docs/learn/">Aprender Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/pt/docs/animations/">Estúdio de Animação</a><a class="navbar__item navbar__link" href="/pt/docs/tech/">Documentação Técnica</a><a class="navbar__item navbar__link" href="/pt/docs/about/">Sobre Nós</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Português</a><ul class="dropdown__menu"><li><a href="/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Volte para o topo" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/intro/"><span title="Guia de Uso" class="linkLabel_REp1">Guia de Uso</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Expandir a categoria lateral &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/pt/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Fechar a categoria lateral &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/pt/docs/alphago/explained/"><span title="完整解析" class="categoryLinkLabel_ezQx">完整解析</span></a><button aria-label="Fechar a categoria lateral &#x27;完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pt/docs/alphago/explained/birth-of-alphago/"><span title="O Nascimento do AlphaGo" class="linkLabel_REp1">O Nascimento do AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/key-matches/"><span title="Retrospectiva das Partidas-Chave" class="linkLabel_REp1">Retrospectiva das Partidas-Chave</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/move-37/"><span title="Análise Profunda da &quot;Jogada Divina&quot;" class="linkLabel_REp1">Análise Profunda da &quot;Jogada Divina&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/why-go-is-hard/"><span title="Por Que o Go É Difícil?" class="linkLabel_REp1">Por Que o Go É Difícil?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/traditional-limits/"><span title="Limites dos Metodos Tradicionais" class="linkLabel_REp1">Limites dos Metodos Tradicionais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/board-representation/"><span title="Representacao do Estado do Tabuleiro" class="linkLabel_REp1">Representacao do Estado do Tabuleiro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/policy-network/"><span title="Detalhes da Policy Network" class="linkLabel_REp1">Detalhes da Policy Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/value-network/"><span title="Detalhes da Value Network" class="linkLabel_REp1">Detalhes da Value Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/input-features/"><span title="Design de Caracteristicas de Entrada" class="linkLabel_REp1">Design de Caracteristicas de Entrada</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/cnn-and-go/"><span title="CNN e Go" class="linkLabel_REp1">CNN e Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/supervised-learning/"><span title="Fase de Aprendizado Supervisionado" class="linkLabel_REp1">Fase de Aprendizado Supervisionado</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/reinforcement-intro/"><span title="Introdução ao Aprendizado por Reforço" class="linkLabel_REp1">Introdução ao Aprendizado por Reforço</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/self-play/"><span title="Autopartida" class="linkLabel_REp1">Autopartida</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/mcts-neural-combo/"><span title="A Combinação de MCTS e Redes Neurais" class="linkLabel_REp1">A Combinação de MCTS e Redes Neurais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/puct-formula/"><span title="Fórmula PUCT em Detalhes" class="linkLabel_REp1">Fórmula PUCT em Detalhes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/alphago-zero/"><span title="Visão Geral do AlphaGo Zero" class="linkLabel_REp1">Visão Geral do AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/dual-head-resnet/"><span title="Rede de Cabeça Dupla e Rede Residual" class="linkLabel_REp1">Rede de Cabeça Dupla e Rede Residual</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/training-from-scratch/"><span title="O Processo de Treinamento do Zero" class="linkLabel_REp1">O Processo de Treinamento do Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/distributed-systems/"><span title="Sistemas Distribuídos e TPU" class="linkLabel_REp1">Sistemas Distribuídos e TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/explained/legacy-and-impact/"><span title="O Legado do AlphaGo" class="linkLabel_REp1">O Legado do AlphaGo</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Expandir a categoria lateral &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Expandir a categoria lateral &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página Inicial" class="breadcrumbs__link" href="/pt/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/explained/"><span>完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">O Nascimento do AlphaGo</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">Nessa página</button></div><div class="theme-doc-markdown markdown"><header><h1>O Nascimento do AlphaGo</h1></header>
<p>Em março de 2016, quando o AlphaGo derrotou Lee Sedol por 4:1, o mundo inteiro perguntou: como nasceu este programa que mudou a história da inteligência artificial?</p>
<p>A resposta começa com o sonho de um prodígio do xadrez.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="a-fundação-da-deepmind">A Fundação da DeepMind<a href="#a-fundação-da-deepmind" class="hash-link" aria-label="Link direto para A Fundação da DeepMind" title="Link direto para A Fundação da DeepMind" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="demis-hassabis-de-prodígio-a-pioneiro-da-ia">Demis Hassabis: De Prodígio a Pioneiro da IA<a href="#demis-hassabis-de-prodígio-a-pioneiro-da-ia" class="hash-link" aria-label="Link direto para Demis Hassabis: De Prodígio a Pioneiro da IA" title="Link direto para Demis Hassabis: De Prodígio a Pioneiro da IA" translate="no">​</a></h3>
<p><strong>Demis Hassabis</strong> é o cofundador e CEO da DeepMind. Sua trajetória de vida parece ter sido preparada para criar o AlphaGo.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="prodígio-do-xadrez">Prodígio do Xadrez<a href="#prodígio-do-xadrez" class="hash-link" aria-label="Link direto para Prodígio do Xadrez" title="Link direto para Prodígio do Xadrez" translate="no">​</a></h4>
<p>Nascido em Londres em 1975, Hassabis aprendeu a jogar xadrez aos 4 anos e alcançou o nível de mestre de xadrez (Elo 2300+) aos 13 anos, sendo o segundo mais jovem a alcançar esse nível na história britânica.</p>
<p>Essa experiência lhe deu uma compreensão profunda de:</p>
<ul>
<li class=""><strong>Jogos de tabuleiro são um teste para a inteligência</strong>: Jogar xadrez requer planejamento, intuição e reconhecimento de padrões</li>
<li class=""><strong>A natureza da inteligência humana</strong>: Como os jogadores encontram boas jogadas em meio a enormes possibilidades?</li>
<li class=""><strong>As limitações dos computadores</strong>: A vitória do Deep Blue sobre Kasparov em 1997 foi baseada em busca por força bruta, não em verdadeira &quot;compreensão&quot;</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="designer-de-jogos">Designer de Jogos<a href="#designer-de-jogos" class="hash-link" aria-label="Link direto para Designer de Jogos" title="Link direto para Designer de Jogos" translate="no">​</a></h4>
<p>Aos 17 anos, Hassabis juntou-se à Bullfrog Productions (empresa de jogos fundada por Peter Molyneux, criador de &quot;Populous&quot;), participando do desenvolvimento do jogo clássico &quot;Theme Park&quot;. Essa experiência ensinou-lhe:</p>
<ul>
<li class=""><strong>Como projetar sistemas complexos</strong>: Jogos são modelos simplificados que simulam o mundo real</li>
<li class=""><strong>Previsão de comportamento dos jogadores</strong>: A IA precisa entender o processo de tomada de decisão humana</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="neurocientista-cognitivo">Neurocientista Cognitivo<a href="#neurocientista-cognitivo" class="hash-link" aria-label="Link direto para Neurocientista Cognitivo" title="Link direto para Neurocientista Cognitivo" translate="no">​</a></h4>
<p>Após obter seu diploma em Ciência da Computação em Cambridge, Hassabis obteve seu doutorado em Neurociência Cognitiva na University College London (UCL). Seu tema de pesquisa foi: <strong>como o hipocampo permite que os humanos imaginem e planejem</strong>.</p>
<p>Esta pesquisa descobriu:</p>
<ul>
<li class="">A memória humana e a imaginação usam a mesma região cerebral</li>
<li class="">Planejamos o futuro através de &quot;viagens mentais no tempo&quot;</li>
<li class="">Essa capacidade pode ser o núcleo da inteligência</li>
</ul>
<p>Esses insights influenciaram diretamente o design posterior do AlphaGo — permitindo que a IA &quot;imagine&quot; jogadas futuras e aprenda com elas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="cofundadores">Cofundadores<a href="#cofundadores" class="hash-link" aria-label="Link direto para Cofundadores" title="Link direto para Cofundadores" translate="no">​</a></h3>
<p>Em 2010, Hassabis cofundou a DeepMind com dois parceiros:</p>
<table><thead><tr><th>Fundador</th><th>Background</th><th>Contribuição</th></tr></thead><tbody><tr><td><strong>Demis Hassabis</strong></td><td>Neurociência, Design de Jogos</td><td>Visão e Estratégia</td></tr><tr><td><strong>Shane Legg</strong></td><td>PhD em Machine Learning</td><td>Base Teórica da AGI</td></tr><tr><td><strong>Mustafa Suleyman</strong></td><td>Empreendedor Social</td><td>Negócios e Aplicações</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="resolver-a-inteligência-usar-a-inteligência-para-resolver-tudo">&quot;Resolver a Inteligência, Usar a Inteligência para Resolver Tudo&quot;<a href="#resolver-a-inteligência-usar-a-inteligência-para-resolver-tudo" class="hash-link" aria-label="Link direto para &quot;Resolver a Inteligência, Usar a Inteligência para Resolver Tudo&quot;" title="Link direto para &quot;Resolver a Inteligência, Usar a Inteligência para Resolver Tudo&quot;" translate="no">​</a></h3>
<p>A declaração de missão da DeepMind é:</p>
<blockquote>
<p><strong>&quot;Solve intelligence, and then use that to solve everything else.&quot;</strong></p>
<p>&quot;Resolver a inteligência e então usá-la para resolver todo o resto.&quot;</p>
</blockquote>
<p>Esta não é uma empresa de IA comum. Seu objetivo não é criar produtos, mas criar <strong>Inteligência Artificial Geral (AGI)</strong> — uma IA capaz de pensar, aprender e resolver qualquer problema como os humanos.</p>
<p>Por que &quot;resolver a inteligência&quot; primeiro? Porque uma vez que tenhamos AGI, ela pode nos ajudar a resolver os maiores desafios da humanidade: mudanças climáticas, doenças, energia.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="avanços-iniciais-jogos-de-atari">Avanços Iniciais: Jogos de Atari<a href="#avanços-iniciais-jogos-de-atari" class="hash-link" aria-label="Link direto para Avanços Iniciais: Jogos de Atari" title="Link direto para Avanços Iniciais: Jogos de Atari" translate="no">​</a></h2>
<p>Antes de desafiar o Go, a DeepMind primeiro provou suas capacidades — usando IA para jogar jogos de Atari.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="dqn-a-ia-que-aprendeu-a-jogar">DQN: A IA que Aprendeu a Jogar<a href="#dqn-a-ia-que-aprendeu-a-jogar" class="hash-link" aria-label="Link direto para DQN: A IA que Aprendeu a Jogar" title="Link direto para DQN: A IA que Aprendeu a Jogar" translate="no">​</a></h3>
<p>Em 2013, a DeepMind publicou o algoritmo <strong>DQN (Deep Q-Network)</strong>. Esta IA era capaz de:</p>
<ol>
<li class=""><strong>Ver apenas pixels da tela</strong> — sem receber nenhuma regra do jogo</li>
<li class=""><strong>Aprender a jogar sozinha</strong> — através de tentativa e erro</li>
<li class=""><strong>Alcançar nível humano</strong> — e até superar humanos em alguns jogos</li>
</ol>
<p>No Breakout, a DQN aprendeu uma estratégia que os humanos levam horas para descobrir: <strong>cavar um túnel para deixar a bola passar atrás dos tijolos, eliminando muitos de uma vez</strong>.</p>
<p>Isso provou que a combinação de deep learning + aprendizado por reforço pode descobrir estratégias que os humanos nunca imaginaram.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-começar-com-jogos">Por Que Começar com Jogos?<a href="#por-que-começar-com-jogos" class="hash-link" aria-label="Link direto para Por Que Começar com Jogos?" title="Link direto para Por Que Começar com Jogos?" translate="no">​</a></h3>
<p>Hassabis escolheu jogos como plataforma de pesquisa por várias razões:</p>
<ol>
<li class=""><strong>Ambiente controlável</strong>: Jogos têm regras e objetivos claros</li>
<li class=""><strong>Progresso mensurável</strong>: Há pontuações objetivas para avaliar a capacidade da IA</li>
<li class=""><strong>Referência humana</strong>: Pode-se comparar com jogadores humanos</li>
<li class=""><strong>Diversidade</strong>: Diferentes jogos testam diferentes habilidades</li>
</ol>
<p>Essa metodologia foi posteriormente aplicada ao Go.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="aquisição-pelo-google">Aquisição pelo Google<a href="#aquisição-pelo-google" class="hash-link" aria-label="Link direto para Aquisição pelo Google" title="Link direto para Aquisição pelo Google" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-aposta-de-500-milhões-de-dólares">A Aposta de 500 Milhões de Dólares<a href="#a-aposta-de-500-milhões-de-dólares" class="hash-link" aria-label="Link direto para A Aposta de 500 Milhões de Dólares" title="Link direto para A Aposta de 500 Milhões de Dólares" translate="no">​</a></h3>
<p>Em janeiro de 2014, o Google adquiriu a DeepMind por aproximadamente <strong>500 milhões de dólares</strong>. Esta foi uma das maiores aquisições no campo da IA na época.</p>
<p>Por que o Google estava disposto a pagar tanto por uma empresa com apenas 75 pessoas e sem produtos?</p>
<p>A resposta está na <strong>teoria dos jogos</strong>:</p>
<ul>
<li class=""><strong>Facebook também estava competindo</strong>: Rumores dizem que o Facebook ofereceu 400 milhões de dólares</li>
<li class=""><strong>IA é a tecnologia chave do futuro</strong>: Quem dominar a IA primeiro, dominará o futuro</li>
<li class=""><strong>DeepMind é a melhor equipe</strong>: Eles provaram a viabilidade do deep reinforcement learning</li>
</ul>
<p>O CEO do Google, Larry Page, interveio pessoalmente para convencer Hassabis a escolher o Google em vez do Facebook.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="condições-da-aquisição">Condições da Aquisição<a href="#condições-da-aquisição" class="hash-link" aria-label="Link direto para Condições da Aquisição" title="Link direto para Condições da Aquisição" translate="no">​</a></h3>
<p>Hassabis negociou várias condições importantes:</p>
<ol>
<li class=""><strong>Operação independente</strong>: A DeepMind manteve sua sede em Londres, P&amp;D independente</li>
<li class=""><strong>Liberdade acadêmica</strong>: Pode publicar artigos, em vez de manter tudo confidencial</li>
<li class=""><strong>Comitê de ética</strong>: Estabelecimento de um mecanismo de revisão ética de IA</li>
<li class=""><strong>Pesquisa de longo prazo</strong>: Sem pressão de comercialização a curto prazo</li>
</ol>
<p>Essas condições permitiram que a DeepMind perseguisse pesquisas de longo prazo e alto risco — como conquistar o Go com IA.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="estratégia-de-ia-do-google">Estratégia de IA do Google<a href="#estratégia-de-ia-do-google" class="hash-link" aria-label="Link direto para Estratégia de IA do Google" title="Link direto para Estratégia de IA do Google" translate="no">​</a></h3>
<p>A aquisição da DeepMind fez parte da estratégia &quot;IA primeiro&quot; do Google:</p>
<table><thead><tr><th>Ano</th><th>Evento</th></tr></thead><tbody><tr><td>2011</td><td>Fundação do Google Brain</td></tr><tr><td>2013</td><td>Aquisição da DNNresearch (equipe de Hinton)</td></tr><tr><td>2014</td><td>Aquisição da DeepMind</td></tr><tr><td>2015</td><td>TensorFlow de código aberto</td></tr><tr><td>2016</td><td>Lançamento do TPU</td></tr></tbody></table>
<p>O Google percebeu que busca, publicidade, tradução, voz — todos os negócios principais seriam remodelados pela IA. Quem tiver a melhor IA será o vencedor.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="escolhendo-o-go-como-objetivo">Escolhendo o Go como Objetivo<a href="#escolhendo-o-go-como-objetivo" class="hash-link" aria-label="Link direto para Escolhendo o Go como Objetivo" title="Link direto para Escolhendo o Go como Objetivo" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-o-go">Por Que o Go?<a href="#por-que-o-go" class="hash-link" aria-label="Link direto para Por Que o Go?" title="Link direto para Por Que o Go?" translate="no">​</a></h3>
<p>Após ser adquirida pelo Google, a DeepMind tinha mais recursos. Hassabis decidiu enfrentar um objetivo aparentemente impossível: <strong>usar IA para derrotar o campeão mundial de Go humano</strong>.</p>
<p>Por que escolher o Go, e não outros problemas?</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-go-é-o-santo-graal-da-ia">1. Go é o &quot;Santo Graal da IA&quot;<a href="#1-go-é-o-santo-graal-da-ia" class="hash-link" aria-label="Link direto para 1. Go é o &quot;Santo Graal da IA&quot;" title="Link direto para 1. Go é o &quot;Santo Graal da IA&quot;" translate="no">​</a></h4>
<p>Antes de 2016, especialistas geralmente acreditavam que a IA precisaria de pelo menos 10-20 anos para derrotar humanos no Go. O Go era chamado de &quot;a última fortaleza da IA&quot;.</p>
<p>Razões:</p>
<ul>
<li class=""><strong>Espaço de busca enorme</strong>: 10^170 posições possíveis (o número de átomos no universo é apenas 10^80)</li>
<li class=""><strong>Avaliação difícil</strong>: Ao contrário do xadrez, não há valores claros de peças</li>
<li class=""><strong>Dependência da intuição</strong>: Jogadores de alto nível frequentemente dizem &quot;esta jogada parece certa&quot;, mas não conseguem explicar por quê</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-a-lição-do-deep-blue">2. A Lição do Deep Blue<a href="#2-a-lição-do-deep-blue" class="hash-link" aria-label="Link direto para 2. A Lição do Deep Blue" title="Link direto para 2. A Lição do Deep Blue" translate="no">​</a></h4>
<p>Em 1997, o Deep Blue da IBM derrotou o campeão mundial de xadrez Kasparov. Mas essa vitória foi controversa:</p>
<ul>
<li class="">O Deep Blue dependia de <strong>busca por força bruta</strong> (avaliando 200 milhões de posições por segundo)</li>
<li class="">Usava <strong>funções de avaliação projetadas por especialistas humanos</strong></li>
<li class="">Isso não era verdadeira &quot;inteligência&quot;, mas &quot;poder computacional&quot;</li>
</ul>
<p>Hassabis queria provar: a IA pode resolver problemas através de <strong>aprendizado</strong>, não força bruta.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-objetivo-mensurável">3. Objetivo Mensurável<a href="#3-objetivo-mensurável" class="hash-link" aria-label="Link direto para 3. Objetivo Mensurável" title="Link direto para 3. Objetivo Mensurável" translate="no">​</a></h4>
<p>O Go tem um sistema de classificação internacional (Elo rating) e jogadores profissionais, fornecendo padrões objetivos de medição. Se a IA pudesse derrotar o campeão mundial, seria um sucesso indiscutível.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="4-conexão-com-a-neurociência">4. Conexão com a Neurociência<a href="#4-conexão-com-a-neurociência" class="hash-link" aria-label="Link direto para 4. Conexão com a Neurociência" title="Link direto para 4. Conexão com a Neurociência" translate="no">​</a></h4>
<p>A intuição dos jogadores humanos — olhar para o tabuleiro e instantaneamente saber quais posições são importantes — é exatamente a capacidade que Hassabis queria replicar com IA. O Go é o cenário perfeito para testar a &quot;intuição da máquina&quot;.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="equipe-alphago">Equipe AlphaGo<a href="#equipe-alphago" class="hash-link" aria-label="Link direto para Equipe AlphaGo" title="Link direto para Equipe AlphaGo" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="figuras-principais">Figuras Principais<a href="#figuras-principais" class="hash-link" aria-label="Link direto para Figuras Principais" title="Link direto para Figuras Principais" translate="no">​</a></h3>
<p>O sucesso do AlphaGo veio de uma equipe com backgrounds multidisciplinares:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="david-silver-pesquisador-principal">David Silver: Pesquisador Principal<a href="#david-silver-pesquisador-principal" class="hash-link" aria-label="Link direto para David Silver: Pesquisador Principal" title="Link direto para David Silver: Pesquisador Principal" translate="no">​</a></h4>
<p><strong>David Silver</strong> é o primeiro autor do artigo do AlphaGo e um especialista de ponta em aprendizado por reforço.</p>
<ul>
<li class=""><strong>Background</strong>: Graduado em Matemática em Cambridge, PhD em RL pela Universidade de Alberta</li>
<li class=""><strong>Orientador</strong>: Richard Sutton (pai do aprendizado por reforço)</li>
<li class=""><strong>Especialidade</strong>: Monte Carlo Tree Search, aprendizado por diferença temporal</li>
</ul>
<p>Silver pesquisou Go computacional em sua tese de doutorado, mas a tecnologia na época estava longe de ser madura. Após entrar na DeepMind, ele finalmente teve a chance de realizar esse sonho.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="aja-huang-especialista-em-go">Aja Huang: Especialista em Go<a href="#aja-huang-especialista-em-go" class="hash-link" aria-label="Link direto para Aja Huang: Especialista em Go" title="Link direto para Aja Huang: Especialista em Go" translate="no">​</a></h4>
<p><strong>Aja Huang</strong> (Huang Shih-Chieh) é taiwanês, jogador amador de 6 dan, e também um pioneiro no campo do Go computacional.</p>
<ul>
<li class=""><strong>Background</strong>: PhD em Ciência da Computação pela National Taiwan Normal University</li>
<li class=""><strong>Especialidade</strong>: Programação de Go computacional</li>
<li class=""><strong>Trabalho famoso</strong>: Erica (programa de Go computacional antigo)</li>
</ul>
<p>Huang desempenhou um papel fundamental na equipe do AlphaGo: ele não só entendia Go, mas também IA. Durante as partidas contra Lee Sedol, ele foi quem operou o AlphaGo.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="outros-membros-importantes">Outros Membros Importantes<a href="#outros-membros-importantes" class="hash-link" aria-label="Link direto para Outros Membros Importantes" title="Link direto para Outros Membros Importantes" translate="no">​</a></h4>
<table><thead><tr><th>Membro</th><th>Função</th></tr></thead><tbody><tr><td>Chris J. Maddison</td><td>Especialista em Monte Carlo Tree Search</td></tr><tr><td>Arthur Guez</td><td>Pesquisador de Aprendizado por Reforço</td></tr><tr><td>Laurent Sifre</td><td>Engenheiro de Deep Learning</td></tr><tr><td>George van den Driessche</td><td>Engenheiro de Sistemas Distribuídos</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="colaboração-interdisciplinar">Colaboração Interdisciplinar<a href="#colaboração-interdisciplinar" class="hash-link" aria-label="Link direto para Colaboração Interdisciplinar" title="Link direto para Colaboração Interdisciplinar" translate="no">​</a></h3>
<p>O sucesso do AlphaGo provou o poder da <strong>colaboração interdisciplinar</strong>:</p>
<ul>
<li class=""><strong>Especialistas em Go</strong> forneceram conhecimento de domínio</li>
<li class=""><strong>Pesquisadores de machine learning</strong> projetaram algoritmos</li>
<li class=""><strong>Engenheiros</strong> implementaram sistemas de treinamento em larga escala</li>
<li class=""><strong>Neurocientistas</strong> forneceram inspiração teórica</li>
</ul>
<p>Essa composição de equipe mais tarde se tornou o padrão da DeepMind.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="publicação-no-nature">Publicação no Nature<a href="#publicação-no-nature" class="hash-link" aria-label="Link direto para Publicação no Nature" title="Link direto para Publicação no Nature" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-surpresa-secreta">A Surpresa Secreta<a href="#a-surpresa-secreta" class="hash-link" aria-label="Link direto para A Surpresa Secreta" title="Link direto para A Surpresa Secreta" translate="no">​</a></h3>
<p>Em 27 de janeiro de 2016, a DeepMind publicou um artigo na prestigiosa revista acadêmica <em>Nature</em>:</p>
<blockquote>
<p><strong>&quot;Mastering the game of Go with deep neural networks and tree search&quot;</strong></p>
</blockquote>
<p>O artigo anunciou que o AlphaGo tinha:</p>
<ol>
<li class="">Derrotado todos os outros programas de Go</li>
<li class="">Derrotado o campeão europeu <strong>Fan Hui</strong> (profissional 2 dan) por <strong>5:0</strong></li>
</ol>
<p>Esta notícia chocou o mundo. Antes da publicação do artigo, ninguém sabia que a DeepMind estava pesquisando Go.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="contribuições-principais-do-artigo">Contribuições Principais do Artigo<a href="#contribuições-principais-do-artigo" class="hash-link" aria-label="Link direto para Contribuições Principais do Artigo" title="Link direto para Contribuições Principais do Artigo" translate="no">​</a></h3>
<p>O artigo da <em>Nature</em> descreveu três grandes inovações do AlphaGo:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-policy-network-rede-de-políticas">1. Policy Network (Rede de Políticas)<a href="#1-policy-network-rede-de-políticas" class="hash-link" aria-label="Link direto para 1. Policy Network (Rede de Políticas)" title="Link direto para 1. Policy Network (Rede de Políticas)" translate="no">​</a></h4>
<p>Usar redes neurais convolucionais profundas para prever o próximo movimento de jogadores humanos. Os dados de treinamento vieram de <strong>30 milhões de partidas</strong> humanas.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Precisão: 57% (prever o próximo movimento de especialistas humanos)</span><br></span></code></pre></div></div>
<p>Isso foi mais de 10 pontos percentuais maior que os melhores programas de Go computacional anteriores.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-value-network-rede-de-valor">2. Value Network (Rede de Valor)<a href="#2-value-network-rede-de-valor" class="hash-link" aria-label="Link direto para 2. Value Network (Rede de Valor)" title="Link direto para 2. Value Network (Rede de Valor)" translate="no">​</a></h4>
<p>Usar outra rede neural para avaliar a taxa de vitória da posição atual. Isso substituiu as simulações aleatórias tradicionais (Monte Carlo rollout).</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Precisão: Equivalente a 15.000 simulações aleatórias, mas 15.000 vezes mais rápido</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-integração-com-monte-carlo-tree-search">3. Integração com Monte Carlo Tree Search<a href="#3-integração-com-monte-carlo-tree-search" class="hash-link" aria-label="Link direto para 3. Integração com Monte Carlo Tree Search" title="Link direto para 3. Integração com Monte Carlo Tree Search" translate="no">​</a></h4>
<p>Integrar as duas redes neurais no framework MCTS:</p>
<ul>
<li class="">Policy Network guia a direção da busca</li>
<li class="">Value Network avalia os nós folha</li>
</ul>
<p>Isso deu ao AlphaGo tanto &quot;intuição&quot; (redes neurais) quanto &quot;raciocínio&quot; (busca em árvore).</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="reação-da-comunidade-acadêmica">Reação da Comunidade Acadêmica<a href="#reação-da-comunidade-acadêmica" class="hash-link" aria-label="Link direto para Reação da Comunidade Acadêmica" title="Link direto para Reação da Comunidade Acadêmica" translate="no">​</a></h3>
<p>Após a publicação do artigo, a comunidade acadêmica reagiu entusiasticamente:</p>
<blockquote>
<p>&quot;Este é o momento de pouso na lua da inteligência artificial.&quot;
— <strong>Stuart Russell</strong>, Professor da UC Berkeley, autor de livro-texto de IA</p>
</blockquote>
<blockquote>
<p>&quot;Eu originalmente pensei que levaria mais 10 anos, não esperava que fosse tão rápido.&quot;
— <strong>Martin Müller</strong>, especialista em Go computacional</p>
</blockquote>
<p>Mas alguns também eram céticos:</p>
<blockquote>
<p>&quot;Fan Hui é apenas um profissional 2 dan, não um jogador de alto nível real. Deixe o AlphaGo jogar contra Lee Sedol primeiro.&quot;</p>
</blockquote>
<p>A DeepMind aceitou esse desafio.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="desafiando-lee-sedol">Desafiando Lee Sedol<a href="#desafiando-lee-sedol" class="hash-link" aria-label="Link direto para Desafiando Lee Sedol" title="Link direto para Desafiando Lee Sedol" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-lee-sedol">Por Que Lee Sedol?<a href="#por-que-lee-sedol" class="hash-link" aria-label="Link direto para Por Que Lee Sedol?" title="Link direto para Por Que Lee Sedol?" translate="no">​</a></h3>
<p><strong>Lee Sedol</strong> é um jogador coreano, considerado um dos jogadores mais fortes da última década:</p>
<table><thead><tr><th>Métrica</th><th>Dados</th></tr></thead><tbody><tr><td>Títulos de Campeão Mundial</td><td>18</td></tr><tr><td>Campeonatos Internacionais</td><td>32</td></tr><tr><td>Maior Ranking Mundial</td><td>#1</td></tr><tr><td>Estilo</td><td>&quot;Gênio&quot; &quot;Calculista Divino&quot;</td></tr></tbody></table>
<p>Ao escolher Lee Sedol, a DeepMind estava desafiando o oponente humano mais forte.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="prêmio-de-1-milhão-de-dólares">Prêmio de 1 Milhão de Dólares<a href="#prêmio-de-1-milhão-de-dólares" class="hash-link" aria-label="Link direto para Prêmio de 1 Milhão de Dólares" title="Link direto para Prêmio de 1 Milhão de Dólares" translate="no">​</a></h3>
<p>O Google ofereceu um prêmio de <strong>1 milhão de dólares</strong> para esta partida:</p>
<ul>
<li class="">Se Lee Sedol vencesse: O prêmio iria para Lee Sedol</li>
<li class="">Se o AlphaGo vencesse: O prêmio seria doado para UNICEF, educação STEM e outras instituições de caridade</li>
</ul>
<p>Isso não foi apenas uma demonstração técnica, mas também um evento esportivo de atenção global.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="previsões-antes-da-partida">Previsões Antes da Partida<a href="#previsões-antes-da-partida" class="hash-link" aria-label="Link direto para Previsões Antes da Partida" title="Link direto para Previsões Antes da Partida" translate="no">​</a></h3>
<p>Antes da partida, a maioria dos jogadores profissionais previa que Lee Sedol venceria facilmente:</p>
<blockquote>
<p>&quot;O AlphaGo pode ganhar um jogo, mas em 5 jogos eu vencerei 5:0.&quot;
— <strong>Lee Sedol</strong>, entrevista pré-partida</p>
</blockquote>
<blockquote>
<p>&quot;Computadores jogam de forma rígida, jogadores de alto nível podem facilmente encontrar fraquezas.&quot;
— Um profissional 9 dan</p>
</blockquote>
<p>Mas a equipe da DeepMind tinha uma visão diferente. David Silver revelou depois:</p>
<blockquote>
<p>&quot;Em nossos testes internos, já havíamos feito o AlphaGo jogar 500 partidas contra a versão que enfrentou Fan Hui. A nova versão ganhou 499.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="março-de-2016-cinco-jogos-que-mudaram-o-mundo">Março de 2016: Cinco Jogos que Mudaram o Mundo<a href="#março-de-2016-cinco-jogos-que-mudaram-o-mundo" class="hash-link" aria-label="Link direto para Março de 2016: Cinco Jogos que Mudaram o Mundo" title="Link direto para Março de 2016: Cinco Jogos que Mudaram o Mundo" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="primeiro-jogo-o-choque-começa">Primeiro Jogo: O Choque Começa<a href="#primeiro-jogo-o-choque-começa" class="hash-link" aria-label="Link direto para Primeiro Jogo: O Choque Começa" title="Link direto para Primeiro Jogo: O Choque Começa" translate="no">​</a></h3>
<p>9 de março de 2016, Hotel Four Seasons, Seul.</p>
<p>Lee Sedol jogou de preto primeiro, AlphaGo de branco. Após 3 horas e 28 minutos de jogo, o AlphaGo venceu por resignação no meio do jogo.</p>
<p>Esta foi a primeira vez que um jogador humano de elite perdeu oficialmente para uma IA.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="segundo-jogo-a-jogada-divina">Segundo Jogo: A Jogada Divina<a href="#segundo-jogo-a-jogada-divina" class="hash-link" aria-label="Link direto para Segundo Jogo: A Jogada Divina" title="Link direto para Segundo Jogo: A Jogada Divina" translate="no">​</a></h3>
<p>O segundo jogo produziu o que ficou conhecido como a &quot;<strong>Jogada Divina</strong>&quot; na jogada 37 — AlphaGo fez um shoulder hit na quinta linha que todos os jogadores profissionais pensaram ser um erro, mas que se provou ser a chave para a vitória.</p>
<p>(Veja detalhes no próximo artigo: <a class="" href="/pt/docs/alphago/explained/move-37/">Análise Aprofundada da &quot;Jogada Divina&quot;</a>)</p>
<p>O AlphaGo venceu novamente.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="terceiro-jogo-30">Terceiro Jogo: 3:0<a href="#terceiro-jogo-30" class="hash-link" aria-label="Link direto para Terceiro Jogo: 3:0" title="Link direto para Terceiro Jogo: 3:0" translate="no">​</a></h3>
<p>No terceiro jogo, Lee Sedol tentou uma abertura não tradicional, mas o AlphaGo respondeu com facilidade. 3:0.</p>
<p>O mundo começou a perceber: isso não foi acidente, a IA realmente superou os humanos.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="quarto-jogo-o-contra-ataque-humano">Quarto Jogo: O Contra-Ataque Humano<a href="#quarto-jogo-o-contra-ataque-humano" class="hash-link" aria-label="Link direto para Quarto Jogo: O Contra-Ataque Humano" title="Link direto para Quarto Jogo: O Contra-Ataque Humano" translate="no">​</a></h3>
<p>No quarto jogo, Lee Sedol fez o que ficou conhecido como a &quot;<strong>Jogada Divina</strong>&quot; na jogada 78 — um wedge brilhante que causou confusão no AlphaGo.</p>
<p>O AlphaGo fez jogadas claramente ruins nos movimentos seguintes e finalmente resignou.</p>
<p>Esta vitória provou: a IA também tem fraquezas. Lee Sedol a encontrou.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="quinto-jogo-placar-final">Quinto Jogo: Placar Final<a href="#quinto-jogo-placar-final" class="hash-link" aria-label="Link direto para Quinto Jogo: Placar Final" title="Link direto para Quinto Jogo: Placar Final" translate="no">​</a></h3>
<p>No quinto jogo, o AlphaGo voltou ao normal e terminou a partida com uma vitória por resignação no meio do jogo.</p>
<p><strong>Placar final: AlphaGo 4:1 Lee Sedol</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="impacto-e-consequências">Impacto e Consequências<a href="#impacto-e-consequências" class="hash-link" aria-label="Link direto para Impacto e Consequências" title="Link direto para Impacto e Consequências" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="atenção-global">Atenção Global<a href="#atenção-global" class="hash-link" aria-label="Link direto para Atenção Global" title="Link direto para Atenção Global" translate="no">​</a></h3>
<p>O impacto desta partida foi muito além do mundo do Go:</p>
<ul>
<li class=""><strong>200 milhões de pessoas</strong> ao redor do mundo assistiram à transmissão ao vivo</li>
<li class=""><em>The New York Times</em>, <em>The Economist</em> e outros meios de comunicação mainstream cobriram extensivamente</li>
<li class="">O preço das ações do Google subiu durante a partida</li>
<li class="">&quot;Inteligência Artificial&quot; tornou-se o tópico de tecnologia mais quente daquele ano</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="impacto-no-mundo-do-go">Impacto no Mundo do Go<a href="#impacto-no-mundo-do-go" class="hash-link" aria-label="Link direto para Impacto no Mundo do Go" title="Link direto para Impacto no Mundo do Go" translate="no">​</a></h3>
<p>Após a partida, a atitude dos jogadores profissionais mudou de &quot;desdém&quot; para &quot;respeito&quot;:</p>
<blockquote>
<p>&quot;Nós pensávamos que humanos entendiam Go, agora descobrimos que só sabemos um pouco.&quot;
— <strong>Ke Jie</strong>, jogador chinês, #1 mundial na época</p>
</blockquote>
<p>Muitos jogadores profissionais começaram a usar IA para treinar, e a forma de jogar Go também mudou como resultado.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="impacto-no-campo-da-ia">Impacto no Campo da IA<a href="#impacto-no-campo-da-ia" class="hash-link" aria-label="Link direto para Impacto no Campo da IA" title="Link direto para Impacto no Campo da IA" translate="no">​</a></h3>
<p>O AlphaGo provou várias coisas:</p>
<ol>
<li class=""><strong>Deep learning pode resolver problemas de nível especialista</strong>: Não apenas reconhecer gatos e cachorros, mas também jogar Go</li>
<li class=""><strong>Aprendizado por reforço pode superar humanos</strong>: Através de auto-jogo, a IA pode descobrir estratégias desconhecidas pelos humanos</li>
<li class=""><strong>Redes neurais + busca é uma combinação poderosa</strong>: Intuição + raciocínio = inteligência mais forte</li>
</ol>
<p>Esses insights foram posteriormente aplicados a:</p>
<ul>
<li class=""><strong>AlphaFold</strong>: Previsão de estrutura de proteínas (conquista de nível Prêmio Nobel em 2020)</li>
<li class=""><strong>AlphaZero</strong>: IA de jogos gerais</li>
<li class=""><strong>MuZero</strong>: Aprendizado sem regras</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="correspondência-de-animações">Correspondência de Animações<a href="#correspondência-de-animações" class="hash-link" aria-label="Link direto para Correspondência de Animações" title="Link direto para Correspondência de Animações" translate="no">​</a></h2>
<p>Conceitos principais abordados neste artigo e números de animação:</p>
<table><thead><tr><th>Número</th><th>Conceito</th><th>Correspondência Física/Matemática</th></tr></thead><tbody><tr><td>E7</td><td>Do Zero</td><td>Auto-organização</td></tr><tr><td>E5</td><td>Auto-Jogo</td><td>Convergência de ponto fixo</td></tr><tr><td>F8</td><td>Capacidades Emergentes</td><td>Transição de fase</td></tr><tr><td>H4</td><td>Gradiente de Política</td><td>Otimização estocástica</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="leitura-adicional">Leitura Adicional<a href="#leitura-adicional" class="hash-link" aria-label="Link direto para Leitura Adicional" title="Link direto para Leitura Adicional" translate="no">​</a></h2>
<ul>
<li class=""><strong>Próximo artigo</strong>: <a class="" href="/pt/docs/alphago/explained/key-matches/">Revisão das Partidas Principais</a> — Análise completa das partidas de Fan Hui, Lee Sedol, Ke Jie</li>
<li class=""><strong>Detalhes técnicos</strong>: <a class="" href="/pt/docs/alphago/explained/policy-network/">Policy Network em Detalhes</a> — Como o AlphaGo aprendeu a jogar</li>
<li class=""><strong>Prática hands-on</strong>: <a class="" href="/pt/docs/tech/hands-on/">Execute Sua Primeira IA de Go em 30 Minutos</a> — Experimente você mesmo</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referências">Referências<a href="#referências" class="hash-link" aria-label="Link direto para Referências" title="Link direto para Referências" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Mnih, V., et al. (2015). &quot;Human-level control through deep reinforcement learning.&quot; <em>Nature</em>, 518, 529-533.</li>
<li class="">Hassabis, D. (2017). &quot;Artificial Intelligence: Chess match of the century.&quot; <em>Nature</em>, 544, 413-414.</li>
<li class="">Documentário <em>AlphaGo</em> (2017), Diretor Greg Kohs.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/explained/01-birth-of-alphago.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa página</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Páginas de documentação"><a class="pagination-nav__link pagination-nav__link--prev" href="/pt/docs/alphago/explained/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Análise Completa do AlphaGo</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/pt/docs/alphago/explained/key-matches/"><div class="pagination-nav__sublabel">Próxima</div><div class="pagination-nav__label">Retrospectiva das Partidas-Chave</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#a-fundação-da-deepmind" class="table-of-contents__link toc-highlight">A Fundação da DeepMind</a><ul><li><a href="#demis-hassabis-de-prodígio-a-pioneiro-da-ia" class="table-of-contents__link toc-highlight">Demis Hassabis: De Prodígio a Pioneiro da IA</a></li><li><a href="#cofundadores" class="table-of-contents__link toc-highlight">Cofundadores</a></li><li><a href="#resolver-a-inteligência-usar-a-inteligência-para-resolver-tudo" class="table-of-contents__link toc-highlight">&quot;Resolver a Inteligência, Usar a Inteligência para Resolver Tudo&quot;</a></li></ul></li><li><a href="#avanços-iniciais-jogos-de-atari" class="table-of-contents__link toc-highlight">Avanços Iniciais: Jogos de Atari</a><ul><li><a href="#dqn-a-ia-que-aprendeu-a-jogar" class="table-of-contents__link toc-highlight">DQN: A IA que Aprendeu a Jogar</a></li><li><a href="#por-que-começar-com-jogos" class="table-of-contents__link toc-highlight">Por Que Começar com Jogos?</a></li></ul></li><li><a href="#aquisição-pelo-google" class="table-of-contents__link toc-highlight">Aquisição pelo Google</a><ul><li><a href="#a-aposta-de-500-milhões-de-dólares" class="table-of-contents__link toc-highlight">A Aposta de 500 Milhões de Dólares</a></li><li><a href="#condições-da-aquisição" class="table-of-contents__link toc-highlight">Condições da Aquisição</a></li><li><a href="#estratégia-de-ia-do-google" class="table-of-contents__link toc-highlight">Estratégia de IA do Google</a></li></ul></li><li><a href="#escolhendo-o-go-como-objetivo" class="table-of-contents__link toc-highlight">Escolhendo o Go como Objetivo</a><ul><li><a href="#por-que-o-go" class="table-of-contents__link toc-highlight">Por Que o Go?</a></li></ul></li><li><a href="#equipe-alphago" class="table-of-contents__link toc-highlight">Equipe AlphaGo</a><ul><li><a href="#figuras-principais" class="table-of-contents__link toc-highlight">Figuras Principais</a></li><li><a href="#colaboração-interdisciplinar" class="table-of-contents__link toc-highlight">Colaboração Interdisciplinar</a></li></ul></li><li><a href="#publicação-no-nature" class="table-of-contents__link toc-highlight">Publicação no Nature</a><ul><li><a href="#a-surpresa-secreta" class="table-of-contents__link toc-highlight">A Surpresa Secreta</a></li><li><a href="#contribuições-principais-do-artigo" class="table-of-contents__link toc-highlight">Contribuições Principais do Artigo</a></li><li><a href="#reação-da-comunidade-acadêmica" class="table-of-contents__link toc-highlight">Reação da Comunidade Acadêmica</a></li></ul></li><li><a href="#desafiando-lee-sedol" class="table-of-contents__link toc-highlight">Desafiando Lee Sedol</a><ul><li><a href="#por-que-lee-sedol" class="table-of-contents__link toc-highlight">Por Que Lee Sedol?</a></li><li><a href="#prêmio-de-1-milhão-de-dólares" class="table-of-contents__link toc-highlight">Prêmio de 1 Milhão de Dólares</a></li><li><a href="#previsões-antes-da-partida" class="table-of-contents__link toc-highlight">Previsões Antes da Partida</a></li></ul></li><li><a href="#março-de-2016-cinco-jogos-que-mudaram-o-mundo" class="table-of-contents__link toc-highlight">Março de 2016: Cinco Jogos que Mudaram o Mundo</a><ul><li><a href="#primeiro-jogo-o-choque-começa" class="table-of-contents__link toc-highlight">Primeiro Jogo: O Choque Começa</a></li><li><a href="#segundo-jogo-a-jogada-divina" class="table-of-contents__link toc-highlight">Segundo Jogo: A Jogada Divina</a></li><li><a href="#terceiro-jogo-30" class="table-of-contents__link toc-highlight">Terceiro Jogo: 3:0</a></li><li><a href="#quarto-jogo-o-contra-ataque-humano" class="table-of-contents__link toc-highlight">Quarto Jogo: O Contra-Ataque Humano</a></li><li><a href="#quinto-jogo-placar-final" class="table-of-contents__link toc-highlight">Quinto Jogo: Placar Final</a></li></ul></li><li><a href="#impacto-e-consequências" class="table-of-contents__link toc-highlight">Impacto e Consequências</a><ul><li><a href="#atenção-global" class="table-of-contents__link toc-highlight">Atenção Global</a></li><li><a href="#impacto-no-mundo-do-go" class="table-of-contents__link toc-highlight">Impacto no Mundo do Go</a></li><li><a href="#impacto-no-campo-da-ia" class="table-of-contents__link toc-highlight">Impacto no Campo da IA</a></li></ul></li><li><a href="#correspondência-de-animações" class="table-of-contents__link toc-highlight">Correspondência de Animações</a></li><li><a href="#leitura-adicional" class="table-of-contents__link toc-highlight">Leitura Adicional</a></li><li><a href="#referências" class="table-of-contents__link toc-highlight">Referências</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>