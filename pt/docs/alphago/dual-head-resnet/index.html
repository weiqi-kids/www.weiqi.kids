<!doctype html>
<html lang="pt" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/dual-head-resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Rede de Cabeça Dupla e Rede Residual | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/pt/docs/alphago/dual-head-resnet/"><meta data-rh="true" property="og:locale" content="pt"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Rede de Cabeça Dupla e Rede Residual | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Análise aprofundada da arquitetura de rede neural do AlphaGo Zero - Backbone compartilhado, Policy Head, Value Head e ResNet de 40 camadas"><meta data-rh="true" property="og:description" content="Análise aprofundada da arquitetura de rede neural do AlphaGo Zero - Backbone compartilhado, Policy Head, Value Head e ResNet de 40 camadas"><meta data-rh="true" name="keywords" content="rede de cabeça dupla,rede residual,ResNet,Policy Head,Value Head,aprendizado profundo,arquitetura de rede neural"><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/pt/docs/alphago/dual-head-resnet/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/dual-head-resnet/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/dual-head-resnet/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/dual-head-resnet/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/dual-head-resnet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/dual-head-resnet/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/dual-head-resnet/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/dual-head-resnet/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/dual-head-resnet/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/dual-head-resnet/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/dual-head-resnet/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/dual-head-resnet/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/dual-head-resnet/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/pt/docs/alphago/"},{"@type":"ListItem","position":2,"name":"Rede de Cabeça Dupla e Rede Residual","item":"https://www.weiqi.kids/pt/docs/alphago/dual-head-resnet"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/pt/assets/css/styles.f23bf74b.css">
<script src="/pt/assets/js/runtime~main.1e8211d5.js" defer="defer"></script>
<script src="/pt/assets/js/main.3cea14b7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.svg"><div role="region" aria-label="Pular para o conteúdo principal"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Pular para o conteúdo principal</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navegação" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/pt/docs/learn/">Aprender Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/pt/docs/animations/">Estúdio de Animação</a><a class="navbar__item navbar__link" href="/pt/docs/tech/">Documentação Técnica</a><a class="navbar__item navbar__link" href="/pt/docs/about/">Sobre Nós</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Português</a><ul class="dropdown__menu"><li><a href="/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Volte para o topo" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/intro/"><span title="Guia de Uso" class="linkLabel_REp1">Guia de Uso</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/pt/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Fechar a categoria lateral &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/birth-of-alphago/"><span title="O Nascimento do AlphaGo" class="linkLabel_REp1">O Nascimento do AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/key-matches/"><span title="Retrospectiva das Partidas-Chave" class="linkLabel_REp1">Retrospectiva das Partidas-Chave</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/move-37/"><span title="Análise Profunda da &quot;Jogada Divina&quot;" class="linkLabel_REp1">Análise Profunda da &quot;Jogada Divina&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/why-go-is-hard/"><span title="Por Que o Go É Difícil?" class="linkLabel_REp1">Por Que o Go É Difícil?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/traditional-limits/"><span title="Limites dos Metodos Tradicionais" class="linkLabel_REp1">Limites dos Metodos Tradicionais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/board-representation/"><span title="Representacao do Estado do Tabuleiro" class="linkLabel_REp1">Representacao do Estado do Tabuleiro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/policy-network/"><span title="Detalhes da Policy Network" class="linkLabel_REp1">Detalhes da Policy Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/value-network/"><span title="Detalhes da Value Network" class="linkLabel_REp1">Detalhes da Value Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/input-features/"><span title="Design de Caracteristicas de Entrada" class="linkLabel_REp1">Design de Caracteristicas de Entrada</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/cnn-and-go/"><span title="CNN e Go" class="linkLabel_REp1">CNN e Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/supervised-learning/"><span title="Fase de Aprendizado Supervisionado" class="linkLabel_REp1">Fase de Aprendizado Supervisionado</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/reinforcement-intro/"><span title="Introdução ao Aprendizado por Reforço" class="linkLabel_REp1">Introdução ao Aprendizado por Reforço</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/self-play/"><span title="Autopartida" class="linkLabel_REp1">Autopartida</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/mcts-neural-combo/"><span title="A Combinação de MCTS e Redes Neurais" class="linkLabel_REp1">A Combinação de MCTS e Redes Neurais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/puct-formula/"><span title="Fórmula PUCT em Detalhes" class="linkLabel_REp1">Fórmula PUCT em Detalhes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/alphago-zero/"><span title="Visão Geral do AlphaGo Zero" class="linkLabel_REp1">Visão Geral do AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pt/docs/alphago/dual-head-resnet/"><span title="Rede de Cabeça Dupla e Rede Residual" class="linkLabel_REp1">Rede de Cabeça Dupla e Rede Residual</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/training-from-scratch/"><span title="O Processo de Treinamento do Zero" class="linkLabel_REp1">O Processo de Treinamento do Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/distributed-systems/"><span title="Sistemas Distribuídos e TPU" class="linkLabel_REp1">Sistemas Distribuídos e TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/legacy-and-impact/"><span title="O Legado do AlphaGo" class="linkLabel_REp1">O Legado do AlphaGo</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Expandir a categoria lateral &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Expandir a categoria lateral &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Expandir a categoria lateral &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página Inicial" class="breadcrumbs__link" href="/pt/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Rede de Cabeça Dupla e Rede Residual</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">Nessa página</button></div><div class="theme-doc-markdown markdown"><header><h1>Rede de Cabeça Dupla e Rede Residual</h1></header>
<p>Uma das inovações arquitetônicas mais importantes do AlphaGo Zero é o uso de uma <strong>Rede de Cabeça Dupla (Dual-Head Network)</strong> para substituir o design de rede dupla do AlphaGo original. Esta mudança aparentemente simples trouxe melhorias significativas de desempenho e um processo de aprendizado mais elegante.</p>
<p>Este artigo analisará em profundidade os princípios de design desta arquitetura, as bases matemáticas e por que ela é tão eficaz.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="design-da-rede-de-cabeça-dupla">Design da Rede de Cabeça Dupla<a href="#design-da-rede-de-cabeça-dupla" class="hash-link" aria-label="Link direto para Design da Rede de Cabeça Dupla" title="Link direto para Design da Rede de Cabeça Dupla" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="arquitetura-geral">Arquitetura Geral<a href="#arquitetura-geral" class="hash-link" aria-label="Link direto para Arquitetura Geral" title="Link direto para Arquitetura Geral" translate="no">​</a></h3>
<p>A rede neural do AlphaGo Zero pode ser dividida em três partes:</p>
<!-- -->
<p>Vamos analisar cada parte uma a uma.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="backbone-compartilhado-shared-backbone">Backbone Compartilhado (Shared Backbone)<a href="#backbone-compartilhado-shared-backbone" class="hash-link" aria-label="Link direto para Backbone Compartilhado (Shared Backbone)" title="Link direto para Backbone Compartilhado (Shared Backbone)" translate="no">​</a></h3>
<p>O backbone compartilhado é uma <strong>Rede Residual (ResNet)</strong> profunda, responsável por extrair características do estado do tabuleiro.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalhes-da-arquitetura">Detalhes da Arquitetura<a href="#detalhes-da-arquitetura" class="hash-link" aria-label="Link direto para Detalhes da Arquitetura" title="Link direto para Detalhes da Arquitetura" translate="no">​</a></h4>
<table><thead><tr><th>Componente</th><th>Especificação</th></tr></thead><tbody><tr><td>Camada de entrada</td><td>Convolução 3×3, 256 canais</td></tr><tr><td>Blocos residuais</td><td>40 (ou 20 na versão compacta)</td></tr><tr><td>Por bloco residual</td><td>2 camadas de convolução 3×3, 256 canais</td></tr><tr><td>Função de ativação</td><td>ReLU</td></tr><tr><td>Normalização</td><td>Batch Normalization</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representação-matemática">Representação Matemática<a href="#representação-matemática" class="hash-link" aria-label="Link direto para Representação Matemática" title="Link direto para Representação Matemática" translate="no">​</a></h4>
<p>Seja a entrada x (dimensão 17 x 19 x 19), a saída do backbone compartilhado é:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">f(x) = ResNet_40(Conv_3x3(x))</span><br></span></code></pre></div></div>
<p>Onde f(x) (dimensão 256 x 19 x 19) é a representação de características de alta dimensão.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head-cabeça-de-política">Policy Head (Cabeça de Política)<a href="#policy-head-cabeça-de-política" class="hash-link" aria-label="Link direto para Policy Head (Cabeça de Política)" title="Link direto para Policy Head (Cabeça de Política)" translate="no">​</a></h3>
<p>A Policy Head é responsável por prever a probabilidade de jogada em cada posição.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalhes-da-arquitetura-1">Detalhes da Arquitetura<a href="#detalhes-da-arquitetura-1" class="hash-link" aria-label="Link direto para Detalhes da Arquitetura" title="Link direto para Detalhes da Arquitetura" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Saída do backbone compartilhado (256 × 19 × 19)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Convolução 1×1 (2 canais)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Achatamento (2 × 19 × 19 = 722)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Camada totalmente conectada (362)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Saída: 362 probabilidades (361 posições + Pass)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representação-matemática-1">Representação Matemática<a href="#representação-matemática-1" class="hash-link" aria-label="Link direto para Representação Matemática" title="Link direto para Representação Matemática" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">π = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))</span><br></span></code></pre></div></div>
<p>A saída π é um vetor de 362 dimensões, com todos os elementos não negativos e soma igual a 1.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head-cabeça-de-valor">Value Head (Cabeça de Valor)<a href="#value-head-cabeça-de-valor" class="hash-link" aria-label="Link direto para Value Head (Cabeça de Valor)" title="Link direto para Value Head (Cabeça de Valor)" translate="no">​</a></h3>
<p>A Value Head é responsável por prever a taxa de vitória da posição atual.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalhes-da-arquitetura-2">Detalhes da Arquitetura<a href="#detalhes-da-arquitetura-2" class="hash-link" aria-label="Link direto para Detalhes da Arquitetura" title="Link direto para Detalhes da Arquitetura" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Saída do backbone compartilhado (256 × 19 × 19)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Convolução 1×1 (1 canal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Achatamento (1 × 19 × 19 = 361)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Camada totalmente conectada (256)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Camada totalmente conectada (1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Tanh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Saída: Taxa de vitória [-1, 1]</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representação-matemática-2">Representação Matemática<a href="#representação-matemática-2" class="hash-link" aria-label="Link direto para Representação Matemática" title="Link direto para Representação Matemática" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))</span><br></span></code></pre></div></div>
<p>A saída v está no intervalo [-1, 1]:</p>
<ul>
<li class="">v = 1: O lado atual com certeza ganha</li>
<li class="">v = -1: O lado atual com certeza perde</li>
<li class="">v = 0: Equilibrado</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-compartilhar-o-backbone">Por que Compartilhar o Backbone?<a href="#por-que-compartilhar-o-backbone" class="hash-link" aria-label="Link direto para Por que Compartilhar o Backbone?" title="Link direto para Por que Compartilhar o Backbone?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="compreensão-intuitiva">Compreensão Intuitiva<a href="#compreensão-intuitiva" class="hash-link" aria-label="Link direto para Compreensão Intuitiva" title="Link direto para Compreensão Intuitiva" translate="no">​</a></h3>
<p>&quot;Onde devo jogar a seguir&quot; (Policy) e &quot;Quem vai ganhar&quot; (Value) — estas duas perguntas na verdade precisam entender os mesmos padrões de tabuleiro:</p>
<ul>
<li class=""><strong>Formas</strong>: Quais formas são boas, quais são ruins</li>
<li class=""><strong>Influência</strong>: Qual lado é maior, onde ainda há espaço</li>
<li class=""><strong>Vida e morte</strong>: Quais pedras já estão vivas, quais ainda estão em ko</li>
<li class=""><strong>Combate</strong>: Onde há ataques e capturas, qual é o resultado local</li>
</ul>
<p>Se usar duas redes independentes, estas características precisam ser aprendidas duas vezes. O backbone compartilhado permite que essas características de baixo nível sejam aprendidas apenas uma vez, e ambas as tarefas podem usá-las.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="perspectiva-de-aprendizado-multi-tarefa">Perspectiva de Aprendizado Multi-tarefa<a href="#perspectiva-de-aprendizado-multi-tarefa" class="hash-link" aria-label="Link direto para Perspectiva de Aprendizado Multi-tarefa" title="Link direto para Perspectiva de Aprendizado Multi-tarefa" translate="no">​</a></h3>
<p>Do ponto de vista de aprendizado de máquina, isto é uma forma de <strong>Aprendizado Multi-tarefa (Multi-task Learning)</strong>:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value</span><br></span></code></pre></div></div>
<p>Duas tarefas compartilhando representação de baixo nível traz várias vantagens:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-efeito-de-regularização">1. Efeito de Regularização<a href="#1-efeito-de-regularização" class="hash-link" aria-label="Link direto para 1. Efeito de Regularização" title="Link direto para 1. Efeito de Regularização" translate="no">​</a></h4>
<p>Parâmetros compartilhados equivalem a regularização implícita. Se uma característica é útil apenas para Policy e não para Value (ou vice-versa), é mais difícil ser amplificada excessivamente.</p>
<p>O número efetivo de parâmetros é menor que a soma dos parâmetros de duas redes independentes.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-eficiência-de-dados">2. Eficiência de Dados<a href="#2-eficiência-de-dados" class="hash-link" aria-label="Link direto para 2. Eficiência de Dados" title="Link direto para 2. Eficiência de Dados" translate="no">​</a></h4>
<p>Cada partida produz simultaneamente rótulos de Policy (probabilidades de busca MCTS) e rótulos de Value (resultado final). O backbone compartilhado permite que ambos os rótulos sejam usados para treinar características compartilhadas, aumentando a eficiência de utilização de dados.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-sinais-de-gradiente-mais-ricos">3. Sinais de Gradiente Mais Ricos<a href="#3-sinais-de-gradiente-mais-ricos" class="hash-link" aria-label="Link direto para 3. Sinais de Gradiente Mais Ricos" title="Link direto para 3. Sinais de Gradiente Mais Ricos" translate="no">​</a></h4>
<p>Gradientes de ambas as tarefas fluem para o backbone compartilhado:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂θ_shared = ∂L_policy/∂θ_shared + ∂L_value/∂θ_shared</span><br></span></code></pre></div></div>
<p>Isto fornece sinais de supervisão mais ricos, tornando as características compartilhadas mais robustas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="evidência-experimental">Evidência Experimental<a href="#evidência-experimental" class="hash-link" aria-label="Link direto para Evidência Experimental" title="Link direto para Evidência Experimental" translate="no">​</a></h3>
<p>Experimentos de ablação da DeepMind mostram que a rede de cabeça dupla tem desempenho significativamente melhor que redes duplas separadas:</p>
<table><thead><tr><th>Configuração</th><th>Classificação ELO</th><th>Diferença Relativa</th></tr></thead><tbody><tr><td>Redes Policy + Value separadas</td><td>Linha de base</td><td>-</td></tr><tr><td>Rede de cabeça dupla (backbone compartilhado)</td><td>+300 ELO</td><td>~65% de diferença de taxa de vitória</td></tr></tbody></table>
<p>Uma diferença de 300 ELO significa que a rede de cabeça dupla tem aproximadamente 65% de taxa de vitória contra redes separadas. Esta é uma melhoria significativa.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="princípios-da-rede-residual">Princípios da Rede Residual<a href="#princípios-da-rede-residual" class="hash-link" aria-label="Link direto para Princípios da Rede Residual" title="Link direto para Princípios da Rede Residual" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-dilema-das-redes-profundas">O Dilema das Redes Profundas<a href="#o-dilema-das-redes-profundas" class="hash-link" aria-label="Link direto para O Dilema das Redes Profundas" title="Link direto para O Dilema das Redes Profundas" translate="no">​</a></h3>
<p>Antes da invenção da ResNet, redes neurais profundas enfrentavam um paradoxo:</p>
<blockquote>
<p>Teoricamente, redes mais profundas deveriam ser pelo menos tão boas quanto redes mais rasas (no pior caso, as camadas extras podem aprender o mapeamento identidade). Mas na prática, redes mais profundas frequentemente tinham desempenho pior.</p>
</blockquote>
<p>Este é o <strong>Problema de Degradação (Degradation Problem)</strong>:</p>
<ul>
<li class="">O erro de treinamento aumenta com a profundidade (não é overfitting, é dificuldade de otimização)</li>
<li class="">Gradientes desaparecem gradualmente durante a retropropagação (Vanishing Gradient)</li>
<li class="">Parâmetros de camadas profundas quase não conseguem ser atualizados efetivamente</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="design-do-bloco-residual">Design do Bloco Residual<a href="#design-do-bloco-residual" class="hash-link" aria-label="Link direto para Design do Bloco Residual" title="Link direto para Design do Bloco Residual" translate="no">​</a></h3>
<p>Kaiming He e colaboradores propuseram uma solução elegante e simples em 2015: <strong>Conexão Residual (Skip Connection)</strong>.</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representação-matemática-3">Representação Matemática<a href="#representação-matemática-3" class="hash-link" aria-label="Link direto para Representação Matemática" title="Link direto para Representação Matemática" translate="no">​</a></h4>
<p>Rede tradicional: Aprender mapeamento alvo H(x)</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = H(x)</span><br></span></code></pre></div></div>
<p>Rede residual: Aprender <strong>mapeamento residual</strong> F(x) = H(x) - x</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = F(x) + x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-a-conexão-residual-funciona">Por que a Conexão Residual Funciona?<a href="#por-que-a-conexão-residual-funciona" class="hash-link" aria-label="Link direto para Por que a Conexão Residual Funciona?" title="Link direto para Por que a Conexão Residual Funciona?" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-rodovia-de-gradientes">1. Rodovia de Gradientes<a href="#1-rodovia-de-gradientes" class="hash-link" aria-label="Link direto para 1. Rodovia de Gradientes" title="Link direto para 1. Rodovia de Gradientes" translate="no">​</a></h4>
<p>Considere o gradiente na retropropagação:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂x = ∂L/∂y × ∂y/∂x = ∂L/∂y × (1 + ∂F(x)/∂x)</span><br></span></code></pre></div></div>
<p>A chave está no <strong>+1</strong>. Mesmo se ∂F(x)/∂x for muito pequeno ou zero, o gradiente ainda pode ser passado de volta diretamente através do +1.</p>
<p>É como construir uma &quot;rodovia de gradientes&quot;, permitindo que gradientes fluam livremente da camada de saída de volta para a camada de entrada.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-mapeamento-identidade-é-mais-fácil-de-aprender">2. Mapeamento Identidade é Mais Fácil de Aprender<a href="#2-mapeamento-identidade-é-mais-fácil-de-aprender" class="hash-link" aria-label="Link direto para 2. Mapeamento Identidade é Mais Fácil de Aprender" title="Link direto para 2. Mapeamento Identidade é Mais Fácil de Aprender" translate="no">​</a></h4>
<p>Se a solução ótima está próxima do mapeamento identidade (H(x) aproximadamente igual a x), então:</p>
<ul>
<li class="">Rede tradicional: Precisa aprender H(x) = x, pode ser difícil</li>
<li class="">Rede residual: Só precisa aprender F(x) aproximadamente igual a 0, relativamente fácil</li>
</ul>
<p>Inicializando pesos em zero ou próximo de zero, o bloco residual naturalmente tende ao mapeamento identidade.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-efeito-de-ensemble">3. Efeito de Ensemble<a href="#3-efeito-de-ensemble" class="hash-link" aria-label="Link direto para 3. Efeito de Ensemble" title="Link direto para 3. Efeito de Ensemble" translate="no">​</a></h4>
<p>Uma ResNet profunda pode ser vista como um <strong>ensemble implícito</strong> de muitas redes rasas. Se há n blocos residuais, a informação pode fluir por 2^n caminhos diferentes.</p>
<p>Este efeito de ensemble aumenta a robustez do modelo.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-avanço-da-resnet-no-imagenet">O Avanço da ResNet no ImageNet<a href="#o-avanço-da-resnet-no-imagenet" class="hash-link" aria-label="Link direto para O Avanço da ResNet no ImageNet" title="Link direto para O Avanço da ResNet no ImageNet" translate="no">​</a></h3>
<p>A ResNet alcançou resultados impressionantes na competição ImageNet de 2015:</p>
<table><thead><tr><th>Profundidade</th><th>Taxa de erro Top-5</th></tr></thead><tbody><tr><td>VGG-19 (sem residual)</td><td>7.3%</td></tr><tr><td>ResNet-34</td><td>5.7%</td></tr><tr><td>ResNet-152</td><td>4.5%</td></tr><tr><td>Nível humano</td><td>~5.1%</td></tr></tbody></table>
<p>Uma ResNet de <strong>152 camadas</strong> não só pode ser treinada, mas é muito melhor que a VGG de 19 camadas. Isto prova que a conexão residual realmente resolve o problema de treinamento de redes profundas.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="resnet-de-40-camadas-do-alphago-zero">ResNet de 40 Camadas do AlphaGo Zero<a href="#resnet-de-40-camadas-do-alphago-zero" class="hash-link" aria-label="Link direto para ResNet de 40 Camadas do AlphaGo Zero" title="Link direto para ResNet de 40 Camadas do AlphaGo Zero" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-escolher-40-camadas">Por que Escolher 40 Camadas?<a href="#por-que-escolher-40-camadas" class="hash-link" aria-label="Link direto para Por que Escolher 40 Camadas?" title="Link direto para Por que Escolher 40 Camadas?" translate="no">​</a></h3>
<p>A DeepMind testou ResNets de diferentes profundidades:</p>
<table><thead><tr><th>Número de Blocos Residuais</th><th>Total de Camadas</th><th>Classificação ELO</th></tr></thead><tbody><tr><td>5</td><td>11</td><td>Linha de base</td></tr><tr><td>10</td><td>21</td><td>+200</td></tr><tr><td>20</td><td>41</td><td>+400</td></tr><tr><td>40</td><td>81</td><td>+500</td></tr></tbody></table>
<p>Redes mais profundas são de fato mais fortes, mas o benefício marginal diminui. O AlphaGo Zero usa 20 ou 40 blocos residuais:</p>
<ul>
<li class=""><strong>AlphaGo Zero (versão do paper)</strong>: 40 blocos residuais, 256 canais</li>
<li class=""><strong>Versão compacta</strong>: 20 blocos residuais, 256 canais</li>
</ul>
<p>A configuração de 40 camadas alcança um bom equilíbrio entre força de jogo e custo de treinamento.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="configuração-específica">Configuração Específica<a href="#configuração-específica" class="hash-link" aria-label="Link direto para Configuração Específica" title="Link direto para Configuração Específica" translate="no">​</a></h3>
<p>A configuração da ResNet do AlphaGo Zero é a seguinte:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Entrada: 17 × 19 × 19</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Camada conv: 3×3, 256 canais, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bloco residual ×40:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ Camada conv: 3×3, 256 canais, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ Camada conv: 3×3, 256 canais, BN</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └─ Skip connection + ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Policy Head / Value Head</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="estimativa-de-parâmetros">Estimativa de Parâmetros<a href="#estimativa-de-parâmetros" class="hash-link" aria-label="Link direto para Estimativa de Parâmetros" title="Link direto para Estimativa de Parâmetros" translate="no">​</a></h4>
<table><thead><tr><th>Componente</th><th>Parâmetros (aprox.)</th></tr></thead><tbody><tr><td>Convolução de entrada</td><td>17 × 3 × 3 × 256 ≈ 39K</td></tr><tr><td>Por bloco residual</td><td>2 × 256 × 3 × 3 × 256 ≈ 1.2M</td></tr><tr><td>40 blocos residuais</td><td>40 × 1.2M ≈ 47M</td></tr><tr><td>Policy Head</td><td>~1M</td></tr><tr><td>Value Head</td><td>~0.2M</td></tr><tr><td><strong>Total</strong></td><td><strong>~48M</strong></td></tr></tbody></table>
<p>Aproximadamente 48 milhões de parâmetros, uma rede neural de tamanho médio pelos padrões modernos.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-papel-do-batch-normalization">O Papel do Batch Normalization<a href="#o-papel-do-batch-normalization" class="hash-link" aria-label="Link direto para O Papel do Batch Normalization" title="Link direto para O Papel do Batch Normalization" translate="no">​</a></h3>
<p>Cada camada convolucional é seguida por <strong>Batch Normalization (BN)</strong>, que é crucial para a estabilidade do treinamento:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-normalização-de-ativações">1. Normalização de Ativações<a href="#1-normalização-de-ativações" class="hash-link" aria-label="Link direto para 1. Normalização de Ativações" title="Link direto para 1. Normalização de Ativações" translate="no">​</a></h4>
<p>BN normaliza as ativações de cada camada para média 0 e variância 1:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_B) / sqrt(σ_B² + ε)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y = γ × x_hat + β</span><br></span></code></pre></div></div>
<p>Onde γ e β são parâmetros aprendíveis.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-mitigação-do-internal-covariate-shift">2. Mitigação do Internal Covariate Shift<a href="#2-mitigação-do-internal-covariate-shift" class="hash-link" aria-label="Link direto para 2. Mitigação do Internal Covariate Shift" title="Link direto para 2. Mitigação do Internal Covariate Shift" translate="no">​</a></h4>
<p>Em redes profundas, a distribuição de entrada de cada camada muda à medida que os parâmetros das camadas anteriores são atualizados. BN mantém a distribuição de entrada de cada camada estável, acelerando a convergência do treinamento.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-efeito-de-regularização">3. Efeito de Regularização<a href="#3-efeito-de-regularização" class="hash-link" aria-label="Link direto para 3. Efeito de Regularização" title="Link direto para 3. Efeito de Regularização" translate="no">​</a></h4>
<p>BN usa estatísticas do mini-batch durante o treinamento, introduzindo aleatoriedade, tendo um leve efeito de regularização.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="comparação-com-outras-arquiteturas">Comparação com Outras Arquiteturas<a href="#comparação-com-outras-arquiteturas" class="hash-link" aria-label="Link direto para Comparação com Outras Arquiteturas" title="Link direto para Comparação com Outras Arquiteturas" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-cnn-do-alphago-original">vs. CNN do AlphaGo Original<a href="#vs-cnn-do-alphago-original" class="hash-link" aria-label="Link direto para vs. CNN do AlphaGo Original" title="Link direto para vs. CNN do AlphaGo Original" translate="no">​</a></h3>
<table><thead><tr><th>Característica</th><th>AlphaGo Original</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>Tipo de arquitetura</td><td>CNN padrão</td><td>ResNet</td></tr><tr><td>Profundidade</td><td>13 camadas</td><td>41-81 camadas</td></tr><tr><td>Conexão residual</td><td>Não</td><td>Sim</td></tr><tr><td>Número de redes</td><td>2 (separadas)</td><td>1 (compartilhada)</td></tr><tr><td>BN</td><td>Não</td><td>Sim</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-rede-estilo-vgg">vs. Rede Estilo VGG<a href="#vs-rede-estilo-vgg" class="hash-link" aria-label="Link direto para vs. Rede Estilo VGG" title="Link direto para vs. Rede Estilo VGG" translate="no">​</a></h3>
<p>VGG foi a arquitetura vice-campeã do ImageNet 2014, usando convoluções 3×3 empilhadas:</p>
<table><thead><tr><th>Característica</th><th>VGG</th><th>ResNet</th></tr></thead><tbody><tr><td>Profundidade máxima treinável</td><td>~19 camadas</td><td>152+ camadas</td></tr><tr><td>Fluxo de gradiente</td><td>Diminui por camada</td><td>Tem rodovia</td></tr><tr><td>Dificuldade de treinamento</td><td>Difícil em profundidade</td><td>Profundo é treinável</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-inception--googlenet">vs. Inception / GoogLeNet<a href="#vs-inception--googlenet" class="hash-link" aria-label="Link direto para vs. Inception / GoogLeNet" title="Link direto para vs. Inception / GoogLeNet" translate="no">​</a></h3>
<p>Inception usa convoluções multi-escala em paralelo:</p>
<table><thead><tr><th>Característica</th><th>Inception</th><th>ResNet</th></tr></thead><tbody><tr><td>Destaques</td><td>Características multi-escala</td><td>Empilhamento profundo</td></tr><tr><td>Complexidade</td><td>Maior</td><td>Simples</td></tr><tr><td>Aplicabilidade ao Go</td><td>Média</td><td>Excelente</td></tr></tbody></table>
<p>O design simples da ResNet é mais adequado para Go, uma tarefa que requer raciocínio profundo.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-transformer">vs. Transformer<a href="#vs-transformer" class="hash-link" aria-label="Link direto para vs. Transformer" title="Link direto para vs. Transformer" translate="no">​</a></h3>
<p>A arquitetura Transformer proposta em 2017 teve grande sucesso em NLP. Alguns tentaram aplicar Transformers ao Go:</p>
<table><thead><tr><th>Característica</th><th>ResNet</th><th>Transformer</th></tr></thead><tbody><tr><td>Viés indutivo</td><td>Localidade (convolução)</td><td>Atenção global</td></tr><tr><td>Codificação posicional</td><td>Implícita (convolução)</td><td>Explícita</td></tr><tr><td>Desempenho em Go</td><td>Excelente</td><td>Viável mas não supera ResNet</td></tr><tr><td>Eficiência computacional</td><td>Maior</td><td>Menor (O(n²))</td></tr></tbody></table>
<p>Para problemas com estrutura espacial clara como Go, o viés indutivo de CNN/ResNet é mais apropriado.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="análise-aprofundada-das-escolhas-de-design">Análise Aprofundada das Escolhas de Design<a href="#análise-aprofundada-das-escolhas-de-design" class="hash-link" aria-label="Link direto para Análise Aprofundada das Escolhas de Design" title="Link direto para Análise Aprofundada das Escolhas de Design" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-usar-convoluções-33">Por que usar convoluções 3×3?<a href="#por-que-usar-convoluções-33" class="hash-link" aria-label="Link direto para Por que usar convoluções 3×3?" title="Link direto para Por que usar convoluções 3×3?" translate="no">​</a></h3>
<p>O AlphaGo Zero usa convoluções 3×3 em toda parte, em vez de kernels maiores:</p>
<ol>
<li class=""><strong>Eficiência de parâmetros</strong>: Duas convoluções 3×3 têm campo receptivo igual a uma 5×5, mas menos parâmetros (18 vs 25)</li>
<li class=""><strong>Rede mais profunda</strong>: Com a mesma quantidade de parâmetros, pode empilhar mais camadas</li>
<li class=""><strong>Mais não-linearidade</strong>: ReLU entre cada camada aumenta a expressividade</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-usar-256-canais">Por que usar 256 canais?<a href="#por-que-usar-256-canais" class="hash-link" aria-label="Link direto para Por que usar 256 canais?" title="Link direto para Por que usar 256 canais?" translate="no">​</a></h3>
<p>256 canais é uma escolha empírica:</p>
<ul>
<li class=""><strong>Muito poucos</strong> (como 64): Expressividade insuficiente, não consegue capturar padrões complexos</li>
<li class=""><strong>Muitos</strong> (como 512): Parâmetros dobram, custo de treinamento aumenta muito, mas melhoria de força é limitada</li>
</ul>
<p>Experimentos posteriores do KataGo mostraram que o número de canais pode ser ajustado de acordo com os recursos de treinamento:</p>
<ul>
<li class="">Baixos recursos: 128 canais, 20 blocos</li>
<li class="">Altos recursos: 256 canais, 40 blocos</li>
<li class="">Recursos ainda maiores: 384 canais, 60 blocos</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-policy-head-usa-softmax-e-value-head-usa-tanh">Por que Policy Head usa Softmax e Value Head usa Tanh?<a href="#por-que-policy-head-usa-softmax-e-value-head-usa-tanh" class="hash-link" aria-label="Link direto para Por que Policy Head usa Softmax e Value Head usa Tanh?" title="Link direto para Por que Policy Head usa Softmax e Value Head usa Tanh?" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head-softmax">Policy Head: Softmax<a href="#policy-head-softmax" class="hash-link" aria-label="Link direto para Policy Head: Softmax" title="Link direto para Policy Head: Softmax" translate="no">​</a></h4>
<p>Jogar é um <strong>problema de classificação</strong> — escolher uma entre 361 posições (mais Pass). A saída Softmax satisfaz:</p>
<ul>
<li class="">Todas as probabilidades não negativas: π_i &gt;= 0</li>
<li class="">Soma das probabilidades igual a 1: Σπ_i = 1</li>
</ul>
<p>Isto é consistente com a definição de distribuição de probabilidade.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head-tanh">Value Head: Tanh<a href="#value-head-tanh" class="hash-link" aria-label="Link direto para Value Head: Tanh" title="Link direto para Value Head: Tanh" translate="no">​</a></h4>
<p>A taxa de vitória é um <strong>problema de regressão</strong> — prever um valor contínuo. O intervalo de saída do Tanh é [-1, 1]:</p>
<ul>
<li class="">Limitado: Não produz valores extremos</li>
<li class="">Simétrico: Vitória e derrota tratadas simetricamente</li>
<li class="">Diferenciável: Conveniente para cálculo de gradiente</li>
</ul>
<p>Usar Tanh em vez de saída ilimitada (como camada linear) pode prevenir instabilidade no treinamento.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="detalhes-de-treinamento">Detalhes de Treinamento<a href="#detalhes-de-treinamento" class="hash-link" aria-label="Link direto para Detalhes de Treinamento" title="Link direto para Detalhes de Treinamento" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="função-de-perda">Função de Perda<a href="#função-de-perda" class="hash-link" aria-label="Link direto para Função de Perda" title="Link direto para Função de Perda" translate="no">​</a></h3>
<p>A perda total do AlphaGo Zero é a soma de três termos:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value + L_reg</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-loss">Policy Loss<a href="#policy-loss" class="hash-link" aria-label="Link direto para Policy Loss" title="Link direto para Policy Loss" translate="no">​</a></h4>
<p>Usa <strong>perda de entropia cruzada</strong>, fazendo a saída da rede se aproximar das probabilidades de busca MCTS:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_policy = -Σ π_MCTS(a) × log(π_net(a))</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li class="">π_MCTS(a) é a probabilidade de busca MCTS para a ação a</li>
<li class="">π_net(a) é a probabilidade de saída da rede</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-loss">Value Loss<a href="#value-loss" class="hash-link" aria-label="Link direto para Value Loss" title="Link direto para Value Loss" translate="no">​</a></h4>
<p>Usa <strong>Erro Quadrático Médio (MSE)</strong>, fazendo a saída da rede se aproximar do resultado real:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_value = (v_net - z)²</span><br></span></code></pre></div></div>
<p>Onde:</p>
<ul>
<li class="">v_net é a taxa de vitória prevista pela rede</li>
<li class="">z é o resultado real da partida (+1 ou -1)</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="regularization-loss">Regularization Loss<a href="#regularization-loss" class="hash-link" aria-label="Link direto para Regularization Loss" title="Link direto para Regularization Loss" translate="no">​</a></h4>
<p>Usa <strong>regularização L2</strong> para prevenir overfitting:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_reg = c × ||θ||²</span><br></span></code></pre></div></div>
<p>Onde c é o coeficiente de regularização e θ são os parâmetros da rede.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="configuração-do-otimizador">Configuração do Otimizador<a href="#configuração-do-otimizador" class="hash-link" aria-label="Link direto para Configuração do Otimizador" title="Link direto para Configuração do Otimizador" translate="no">​</a></h3>
<table><thead><tr><th>Parâmetro</th><th>Valor</th></tr></thead><tbody><tr><td>Otimizador</td><td>SGD + Momentum</td></tr><tr><td>Momentum</td><td>0.9</td></tr><tr><td>Taxa de aprendizado inicial</td><td>0.01</td></tr><tr><td>Decaimento da taxa de aprendizado</td><td>Pela metade a cada X passos</td></tr><tr><td>Batch Size</td><td>32 × 2048 = 64K (distribuído)</td></tr><tr><td>Coeficiente de regularização L2</td><td>1e-4</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="data-augmentation">Data Augmentation<a href="#data-augmentation" class="hash-link" aria-label="Link direto para Data Augmentation" title="Link direto para Data Augmentation" translate="no">​</a></h3>
<p>O tabuleiro de Go tem 8 simetrias (4 rotações × 2 reflexões). Durante o treinamento, cada posição pode produzir 8 amostras de treinamento equivalentes.</p>
<p>Isto aumenta os dados de treinamento efetivos em 8 vezes, sem necessidade de auto-jogo adicional.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="considerações-de-implementação">Considerações de Implementação<a href="#considerações-de-implementação" class="hash-link" aria-label="Link direto para Considerações de Implementação" title="Link direto para Considerações de Implementação" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="otimização-de-memória">Otimização de Memória<a href="#otimização-de-memória" class="hash-link" aria-label="Link direto para Otimização de Memória" title="Link direto para Otimização de Memória" translate="no">​</a></h3>
<p>Treinar uma ResNet de 40 camadas requer muita memória:</p>
<ul>
<li class=""><strong>Forward pass</strong>: Precisa armazenar ativações de cada camada (para backpropagation)</li>
<li class=""><strong>Backward pass</strong>: Precisa armazenar gradientes</li>
</ul>
<p>Estratégias de otimização:</p>
<ol>
<li class=""><strong>Gradient Checkpointing</strong>: Armazenar apenas algumas ativações, recalcular quando necessário</li>
<li class=""><strong>Treinamento de precisão mista</strong>: Usar FP16 para reduzir uso de memória</li>
<li class=""><strong>Treinamento distribuído</strong>: Distribuir batch entre múltiplas GPUs/TPUs</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="otimização-de-inferência">Otimização de Inferência<a href="#otimização-de-inferência" class="hash-link" aria-label="Link direto para Otimização de Inferência" title="Link direto para Otimização de Inferência" translate="no">​</a></h3>
<p>Durante inferência, não são necessárias estatísticas de mini-batch do BN, pode usar médias móveis acumuladas durante o treinamento:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_moving) / sqrt(σ_moving² + ε)</span><br></span></code></pre></div></div>
<p>Isto torna a inferência mais rápida e os resultados determinísticos.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="quantização-e-compressão">Quantização e Compressão<a href="#quantização-e-compressão" class="hash-link" aria-label="Link direto para Quantização e Compressão" title="Link direto para Quantização e Compressão" translate="no">​</a></h3>
<p>O deployment pode comprimir ainda mais a rede:</p>
<ul>
<li class=""><strong>Quantização de pesos</strong>: FP32 → INT8, memória reduzida em 4×</li>
<li class=""><strong>Poda</strong>: Remover conexões de pesos pequenos</li>
<li class=""><strong>Destilação de conhecimento</strong>: Usar rede grande para treinar rede pequena</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="correspondência-de-animações">Correspondência de Animações<a href="#correspondência-de-animações" class="hash-link" aria-label="Link direto para Correspondência de Animações" title="Link direto para Correspondência de Animações" translate="no">​</a></h2>
<p>Conceitos centrais discutidos neste artigo e números de animação:</p>
<table><thead><tr><th>Número</th><th>Conceito</th><th>Correspondência Física/Matemática</th></tr></thead><tbody><tr><td>🎬 E3</td><td>Rede de cabeça dupla</td><td>Aprendizado multi-tarefa</td></tr><tr><td>🎬 D12</td><td>Conexão residual</td><td>Rodovia de gradientes</td></tr><tr><td>🎬 D8</td><td>Rede neural convolucional</td><td>Campo receptivo local</td></tr><tr><td>🎬 D10</td><td>Batch Normalization</td><td>Normalização de distribuição</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="leitura-adicional">Leitura Adicional<a href="#leitura-adicional" class="hash-link" aria-label="Link direto para Leitura Adicional" title="Link direto para Leitura Adicional" translate="no">​</a></h2>
<ul>
<li class=""><strong>Artigo anterior</strong>: <a class="" href="/pt/docs/alphago/alphago-zero/">Visão Geral do AlphaGo Zero</a> — Por que não precisa de registros de partidas humanas</li>
<li class=""><strong>Próximo artigo</strong>: <a class="" href="/pt/docs/alphago/training-from-scratch/">O Processo de Treinamento do Zero</a> — Evolução detalhada dos Dias 0-3</li>
<li class=""><strong>Aprofundamento técnico</strong>: <a class="" href="/pt/docs/alphago/cnn-and-go/">CNN e Go Combinados</a> — Por que CNN é adequada para tabuleiros</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referências">Referências<a href="#referências" class="hash-link" aria-label="Link direto para Referências" title="Link direto para Referências" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">He, K., et al. (2016). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR 2016</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&quot; <em>ICML 2015</em>.</li>
<li class="">Caruana, R. (1997). &quot;Multitask Learning.&quot; <em>Machine Learning</em>, 28(1), 41-75.</li>
<li class="">Veit, A., et al. (2016). &quot;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&quot; <em>NeurIPS 2016</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/17-dual-head-resnet.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa página</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Páginas de documentação"><a class="pagination-nav__link pagination-nav__link--prev" href="/pt/docs/alphago/alphago-zero/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Visão Geral do AlphaGo Zero</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/pt/docs/alphago/training-from-scratch/"><div class="pagination-nav__sublabel">Próxima</div><div class="pagination-nav__label">O Processo de Treinamento do Zero</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#design-da-rede-de-cabeça-dupla" class="table-of-contents__link toc-highlight">Design da Rede de Cabeça Dupla</a><ul><li><a href="#arquitetura-geral" class="table-of-contents__link toc-highlight">Arquitetura Geral</a></li><li><a href="#backbone-compartilhado-shared-backbone" class="table-of-contents__link toc-highlight">Backbone Compartilhado (Shared Backbone)</a></li><li><a href="#policy-head-cabeça-de-política" class="table-of-contents__link toc-highlight">Policy Head (Cabeça de Política)</a></li><li><a href="#value-head-cabeça-de-valor" class="table-of-contents__link toc-highlight">Value Head (Cabeça de Valor)</a></li></ul></li><li><a href="#por-que-compartilhar-o-backbone" class="table-of-contents__link toc-highlight">Por que Compartilhar o Backbone?</a><ul><li><a href="#compreensão-intuitiva" class="table-of-contents__link toc-highlight">Compreensão Intuitiva</a></li><li><a href="#perspectiva-de-aprendizado-multi-tarefa" class="table-of-contents__link toc-highlight">Perspectiva de Aprendizado Multi-tarefa</a></li><li><a href="#evidência-experimental" class="table-of-contents__link toc-highlight">Evidência Experimental</a></li></ul></li><li><a href="#princípios-da-rede-residual" class="table-of-contents__link toc-highlight">Princípios da Rede Residual</a><ul><li><a href="#o-dilema-das-redes-profundas" class="table-of-contents__link toc-highlight">O Dilema das Redes Profundas</a></li><li><a href="#design-do-bloco-residual" class="table-of-contents__link toc-highlight">Design do Bloco Residual</a></li><li><a href="#por-que-a-conexão-residual-funciona" class="table-of-contents__link toc-highlight">Por que a Conexão Residual Funciona?</a></li><li><a href="#o-avanço-da-resnet-no-imagenet" class="table-of-contents__link toc-highlight">O Avanço da ResNet no ImageNet</a></li></ul></li><li><a href="#resnet-de-40-camadas-do-alphago-zero" class="table-of-contents__link toc-highlight">ResNet de 40 Camadas do AlphaGo Zero</a><ul><li><a href="#por-que-escolher-40-camadas" class="table-of-contents__link toc-highlight">Por que Escolher 40 Camadas?</a></li><li><a href="#configuração-específica" class="table-of-contents__link toc-highlight">Configuração Específica</a></li><li><a href="#o-papel-do-batch-normalization" class="table-of-contents__link toc-highlight">O Papel do Batch Normalization</a></li></ul></li><li><a href="#comparação-com-outras-arquiteturas" class="table-of-contents__link toc-highlight">Comparação com Outras Arquiteturas</a><ul><li><a href="#vs-cnn-do-alphago-original" class="table-of-contents__link toc-highlight">vs. CNN do AlphaGo Original</a></li><li><a href="#vs-rede-estilo-vgg" class="table-of-contents__link toc-highlight">vs. Rede Estilo VGG</a></li><li><a href="#vs-inception--googlenet" class="table-of-contents__link toc-highlight">vs. Inception / GoogLeNet</a></li><li><a href="#vs-transformer" class="table-of-contents__link toc-highlight">vs. Transformer</a></li></ul></li><li><a href="#análise-aprofundada-das-escolhas-de-design" class="table-of-contents__link toc-highlight">Análise Aprofundada das Escolhas de Design</a><ul><li><a href="#por-que-usar-convoluções-33" class="table-of-contents__link toc-highlight">Por que usar convoluções 3×3?</a></li><li><a href="#por-que-usar-256-canais" class="table-of-contents__link toc-highlight">Por que usar 256 canais?</a></li><li><a href="#por-que-policy-head-usa-softmax-e-value-head-usa-tanh" class="table-of-contents__link toc-highlight">Por que Policy Head usa Softmax e Value Head usa Tanh?</a></li></ul></li><li><a href="#detalhes-de-treinamento" class="table-of-contents__link toc-highlight">Detalhes de Treinamento</a><ul><li><a href="#função-de-perda" class="table-of-contents__link toc-highlight">Função de Perda</a></li><li><a href="#configuração-do-otimizador" class="table-of-contents__link toc-highlight">Configuração do Otimizador</a></li><li><a href="#data-augmentation" class="table-of-contents__link toc-highlight">Data Augmentation</a></li></ul></li><li><a href="#considerações-de-implementação" class="table-of-contents__link toc-highlight">Considerações de Implementação</a><ul><li><a href="#otimização-de-memória" class="table-of-contents__link toc-highlight">Otimização de Memória</a></li><li><a href="#otimização-de-inferência" class="table-of-contents__link toc-highlight">Otimização de Inferência</a></li><li><a href="#quantização-e-compressão" class="table-of-contents__link toc-highlight">Quantização e Compressão</a></li></ul></li><li><a href="#correspondência-de-animações" class="table-of-contents__link toc-highlight">Correspondência de Animações</a></li><li><a href="#leitura-adicional" class="table-of-contents__link toc-highlight">Leitura Adicional</a></li><li><a href="#referências" class="table-of-contents__link toc-highlight">Referências</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>