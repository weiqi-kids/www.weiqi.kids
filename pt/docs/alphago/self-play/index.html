<!doctype html>
<html lang="pt" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/self-play" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Autopartida | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/pt/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/pt/docs/alphago/self-play/"><meta data-rh="true" property="og:locale" content="pt"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="pt"><meta data-rh="true" name="docsearch:language" content="pt"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Autopartida | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Compreensão profunda de como o AlphaGo ultrapassou os limites da força de jogo humana através da autopartida"><meta data-rh="true" property="og:description" content="Compreensão profunda de como o AlphaGo ultrapassou os limites da força de jogo humana através da autopartida"><link data-rh="true" rel="icon" href="/pt/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/pt/docs/alphago/self-play/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/self-play/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/self-play/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/self-play/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/self-play/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/self-play/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/self-play/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/self-play/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/self-play/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/self-play/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/self-play/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/self-play/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/pt/docs/alphago/"},{"@type":"ListItem","position":2,"name":"Autopartida","item":"https://www.weiqi.kids/pt/docs/alphago/self-play"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/pt/assets/css/styles.f23bf74b.css">
<script src="/pt/assets/js/runtime~main.1e8211d5.js" defer="defer"></script>
<script src="/pt/assets/js/main.3cea14b7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/pt/img/logo.svg"><div role="region" aria-label="Pular para o conteúdo principal"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Pular para o conteúdo principal</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar a barra de navegação" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/pt/"><div class="navbar__logo"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/pt/img/logo.svg" alt="Logo da Associação Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/pt/docs/learn/">Aprender Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/pt/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/pt/docs/animations/">Estúdio de Animação</a><a class="navbar__item navbar__link" href="/pt/docs/tech/">Documentação Técnica</a><a class="navbar__item navbar__link" href="/pt/docs/about/">Sobre Nós</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Português</a><ul class="dropdown__menu"><li><a href="/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Volte para o topo" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/intro/"><span title="Guia de Uso" class="linkLabel_REp1">Guia de Uso</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/pt/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Fechar a categoria lateral &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/birth-of-alphago/"><span title="O Nascimento do AlphaGo" class="linkLabel_REp1">O Nascimento do AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/key-matches/"><span title="Retrospectiva das Partidas-Chave" class="linkLabel_REp1">Retrospectiva das Partidas-Chave</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/move-37/"><span title="Análise Profunda da &quot;Jogada Divina&quot;" class="linkLabel_REp1">Análise Profunda da &quot;Jogada Divina&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/why-go-is-hard/"><span title="Por Que o Go É Difícil?" class="linkLabel_REp1">Por Que o Go É Difícil?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/traditional-limits/"><span title="Limites dos Metodos Tradicionais" class="linkLabel_REp1">Limites dos Metodos Tradicionais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/board-representation/"><span title="Representacao do Estado do Tabuleiro" class="linkLabel_REp1">Representacao do Estado do Tabuleiro</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/policy-network/"><span title="Detalhes da Policy Network" class="linkLabel_REp1">Detalhes da Policy Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/value-network/"><span title="Detalhes da Value Network" class="linkLabel_REp1">Detalhes da Value Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/input-features/"><span title="Design de Caracteristicas de Entrada" class="linkLabel_REp1">Design de Caracteristicas de Entrada</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/cnn-and-go/"><span title="CNN e Go" class="linkLabel_REp1">CNN e Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/supervised-learning/"><span title="Fase de Aprendizado Supervisionado" class="linkLabel_REp1">Fase de Aprendizado Supervisionado</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/reinforcement-intro/"><span title="Introdução ao Aprendizado por Reforço" class="linkLabel_REp1">Introdução ao Aprendizado por Reforço</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pt/docs/alphago/self-play/"><span title="Autopartida" class="linkLabel_REp1">Autopartida</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/mcts-neural-combo/"><span title="A Combinação de MCTS e Redes Neurais" class="linkLabel_REp1">A Combinação de MCTS e Redes Neurais</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/puct-formula/"><span title="Fórmula PUCT em Detalhes" class="linkLabel_REp1">Fórmula PUCT em Detalhes</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/alphago-zero/"><span title="Visão Geral do AlphaGo Zero" class="linkLabel_REp1">Visão Geral do AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/dual-head-resnet/"><span title="Rede de Cabeça Dupla e Rede Residual" class="linkLabel_REp1">Rede de Cabeça Dupla e Rede Residual</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/training-from-scratch/"><span title="O Processo de Treinamento do Zero" class="linkLabel_REp1">O Processo de Treinamento do Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/distributed-systems/"><span title="Sistemas Distribuídos e TPU" class="linkLabel_REp1">Sistemas Distribuídos e TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pt/docs/alphago/legacy-and-impact/"><span title="O Legado do AlphaGo" class="linkLabel_REp1">O Legado do AlphaGo</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Expandir a categoria lateral &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/pt/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Expandir a categoria lateral &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/pt/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Expandir a categoria lateral &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página Inicial" class="breadcrumbs__link" href="/pt/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/pt/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Autopartida</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">Nessa página</button></div><div class="theme-doc-markdown markdown"><header><h1>Autopartida</h1></header>
<p>No artigo anterior, apresentamos os conceitos básicos do aprendizado por reforço. Agora, vamos explorar uma das chaves para o sucesso do AlphaGo — <strong>Autopartida (Self-Play)</strong>.</p>
<p>Este é um conceito aparentemente contraditório: <strong>Como a IA pode ficar mais forte jogando contra si mesma?</strong></p>
<p>A resposta é profunda e elegante, envolvendo teoria dos jogos, dinâmica evolutiva e a natureza do aprendizado.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="por-que-a-autopartida-funciona">Por que a autopartida funciona?<a href="#por-que-a-autopartida-funciona" class="hash-link" aria-label="Link direto para Por que a autopartida funciona?" title="Link direto para Por que a autopartida funciona?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="explicação-intuitiva">Explicação intuitiva<a href="#explicação-intuitiva" class="hash-link" aria-label="Link direto para Explicação intuitiva" title="Link direto para Explicação intuitiva" translate="no">​</a></h3>
<p>Imagine que você é um iniciante de Go, praticando sozinho em uma ilha deserta:</p>
<ol>
<li class="">Você joga uma partida, jogando tanto com as pretas quanto com as brancas</li>
<li class="">Após a partida, você analisa quais jogadas foram boas e quais foram ruins</li>
<li class="">Na próxima partida, você tenta evitar os erros anteriores</li>
<li class="">Você repete este processo milhões de vezes</li>
</ol>
<p>Intuitivamente, isso parece problemático:</p>
<ul>
<li class="">Se seu nível é muito baixo, ambos os lados jogam mal, o que você pode aprender?</li>
<li class="">Você poderia cair em &quot;equilíbrio errado&quot; — ambos os lados jogam errado mas se anulam?</li>
</ul>
<p>Mas na realidade, a autopartida pode produzir progresso contínuo. Eis o porquê:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="descoberta-progressiva-de-fraquezas">Descoberta progressiva de fraquezas<a href="#descoberta-progressiva-de-fraquezas" class="hash-link" aria-label="Link direto para Descoberta progressiva de fraquezas" title="Link direto para Descoberta progressiva de fraquezas" translate="no">​</a></h3>
<p>A insight chave é: <strong>mesmo que ambos os lados sejam a mesma IA, o resultado de cada partida ainda contém informação</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Posição A: IA escolheu jogada X, eventualmente venceu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Posição A: IA escolheu jogada Y, eventualmente perdeu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">→ Conclusão: Na posição A, X é melhor que Y</span><br></span></code></pre></div></div>
<p>Através de estatísticas de muitas partidas, a IA pode aprender quais escolhas são melhores em cada posição. Esta é a essência do <strong>gradiente de política</strong>: boas escolhas são reforçadas, más escolhas são suprimidas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="aprendizado-adversarial">Aprendizado adversarial<a href="#aprendizado-adversarial" class="hash-link" aria-label="Link direto para Aprendizado adversarial" title="Link direto para Aprendizado adversarial" translate="no">​</a></h3>
<p>A autopartida tem uma propriedade especial: <strong>o oponente de treinamento se adapta automaticamente ao seu nível</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Ciclo de treinamento 1: IA descobre uma tática eficaz T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Ciclo de treinamento 2: IA como oponente aprende a defender contra T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Ciclo de treinamento 3: IA original é forçada a encontrar tática melhor T&#x27;</span><br></span></code></pre></div></div>
<p>Isso forma uma <strong>corrida armamentista (Arms Race)</strong>, ambos os lados continuamente descobrindo e superando as fraquezas um do outro.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="comparação-com-partidas-humanas">Comparação com partidas humanas<a href="#comparação-com-partidas-humanas" class="hash-link" aria-label="Link direto para Comparação com partidas humanas" title="Link direto para Comparação com partidas humanas" translate="no">​</a></h3>
<table><thead><tr><th>Método de treinamento</th><th>Vantagens</th><th>Desvantagens</th></tr></thead><tbody><tr><td><strong>Partidas humanas</strong></td><td>Aprende a cristalização da sabedoria humana</td><td>Limitado ao nível humano</td></tr><tr><td><strong>Autopartida</strong></td><td>Potencial de melhoria ilimitado</td><td>Pode cair em ótimo local</td></tr><tr><td><strong>Combinação de ambos</strong></td><td>Início rápido + melhoria contínua</td><td>Melhor estratégia</td></tr></tbody></table>
<p>A versão original do AlphaGo primeiro usou partidas humanas para aprendizado supervisionado, depois autopartida para aprendizado por reforço. O AlphaGo Zero provou que apenas autopartida pode alcançar nível super-humano.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="perspectiva-da-teoria-dos-jogos">Perspectiva da teoria dos jogos<a href="#perspectiva-da-teoria-dos-jogos" class="hash-link" aria-label="Link direto para Perspectiva da teoria dos jogos" title="Link direto para Perspectiva da teoria dos jogos" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="equilíbrio-de-nash">Equilíbrio de Nash<a href="#equilíbrio-de-nash" class="hash-link" aria-label="Link direto para Equilíbrio de Nash" title="Link direto para Equilíbrio de Nash" translate="no">​</a></h3>
<p>Na teoria dos jogos, <strong>Equilíbrio de Nash (Nash Equilibrium)</strong> é um estado estável: neste estado, nenhum jogador tem motivo para mudar sua estratégia unilateralmente.</p>
<p>Para <strong>jogos de soma zero com informação perfeita</strong> como Go, o equilíbrio de Nash tem significado especial:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></msub><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^* = \arg\max_\pi \min_{\pi&#x27;} V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>Onde <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> é o valor esperado quando a estratégia <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> joga contra a estratégia <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\pi&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>.</p>
<p>Este é o famoso <strong>Princípio Minimax</strong>: a melhor estratégia é aquela que tem o melhor desempenho no pior cenário.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="autopartida-e-equilíbrio-de-nash">Autopartida e equilíbrio de Nash<a href="#autopartida-e-equilíbrio-de-nash" class="hash-link" aria-label="Link direto para Autopartida e equilíbrio de Nash" title="Link direto para Autopartida e equilíbrio de Nash" translate="no">​</a></h3>
<p>Teoricamente, se a autopartida pode convergir, ela deve convergir para o equilíbrio de Nash. Para jogos determinísticos como Go, o equilíbrio de Nash é o <strong>jogo perfeito</strong>.</p>
<p>Mas o espaço de estados do Go é muito grande (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>170</mn></msup></mrow><annotation encoding="application/x-tex">10^{170}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">170</span></span></span></span></span></span></span></span></span></span></span></span>), é impossível encontrar o verdadeiro equilíbrio de Nash. A autopartida na verdade está <strong>aproximando</strong> este equilíbrio.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="fictitious-play-jogo-fictício">Fictitious Play (Jogo fictício)<a href="#fictitious-play-jogo-fictício" class="hash-link" aria-label="Link direto para Fictitious Play (Jogo fictício)" title="Link direto para Fictitious Play (Jogo fictício)" translate="no">​</a></h3>
<p>A autopartida está relacionada ao conceito de <strong>Fictitious Play</strong> na teoria dos jogos:</p>
<ol>
<li class="">Cada jogador observa o histórico de estratégias do oponente</li>
<li class="">Calcula a distribuição média das estratégias do oponente</li>
<li class="">Escolhe a melhor resposta contra esta distribuição média</li>
</ol>
<p>Sob certas condições, pode-se provar que o Fictitious Play converge para o equilíbrio de Nash.</p>
<p>A autopartida do AlphaGo pode ser vista como uma implementação de rede neural deste conceito.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="mecanismo-da-autopartida">Mecanismo da autopartida<a href="#mecanismo-da-autopartida" class="hash-link" aria-label="Link direto para Mecanismo da autopartida" title="Link direto para Mecanismo da autopartida" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="fluxo-básico">Fluxo básico<a href="#fluxo-básico" class="hash-link" aria-label="Link direto para Fluxo básico" title="Link direto para Fluxo básico" translate="no">​</a></h3>
<p>Fluxo de autopartida do AlphaGo:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Algoritmo: Self-Play Training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Inicialização: Policy Network π_θ (pode começar de aprendizado supervisionado ou inicialização aleatória)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Repetir os seguintes passos até convergência:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Gerar dados de partida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Para i = 1 até N (em paralelo):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. Usar política atual π_θ para uma autopartida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Coletar trajetória: τ_i = (s_0, a_0, r_1, s_1, a_1, ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Registrar resultado final z_i ∈ {-1, +1}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Atualizar política</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Calcular gradiente de política:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ∇J = (1/N) Σ_i Σ_t ∇_θ log π_θ(a_t|s_t) · z_i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Atualizar parâmetros: θ ← θ + α · ∇J</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Atualizar rede de valor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Treinar Value Network com pares (s, z)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Minimizar: L = E[(V_φ(s) - z)²]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Opcional: Avaliar e salvar checkpoint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. Nova política joga contra versões antigas</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. Se taxa de vitória &gt; 55%, atualizar pool de oponentes</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="geração-de-dados-de-treinamento">Geração de dados de treinamento<a href="#geração-de-dados-de-treinamento" class="hash-link" aria-label="Link direto para Geração de dados de treinamento" title="Link direto para Geração de dados de treinamento" translate="no">​</a></h3>
<p>Cada autopartida produz uma <strong>trajetória (trajectory)</strong>:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, s_1, a_1, \ldots, s_T, z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)</span></span></span></span></p>
<p>Onde:</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: estado do tabuleiro no passo <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: ação escolhida no passo <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span>: resultado final (+1 vitória, -1 derrota)</li>
</ul>
<p>Uma partida de 200 movimentos produz 200 amostras de treinamento. Com centenas de milhares de autopartidas por dia, a quantidade de dados de treinamento é impressionante.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="atualização-de-política">Atualização de política<a href="#atualização-de-política" class="hash-link" aria-label="Link direto para Atualização de política" title="Link direto para Atualização de política" translate="no">​</a></h3>
<p>Usar gradiente de política para atualizar a Policy Network:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>z</mi><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \cdot \nabla_\theta \mathbb{E}\left[\sum_t \log \pi_\theta(a_t|s_t) \cdot z\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1308em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose delimcenter" style="top:0em">]</span></span></span></span></span></p>
<p>O efeito desta atualização:</p>
<ul>
<li class="">Se eventualmente vencer (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = +1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>), aumenta a probabilidade de todos os movimentos</li>
<li class="">Se eventualmente perder (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = -1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>), diminui a probabilidade de todos os movimentos</li>
</ul>
<p>Isso parece grosseiro — ao vencer pode haver jogadas ruins, ao perder pode haver boas jogadas. Mas através de estatísticas de muitas partidas, esse &quot;ruído&quot; é nivelado, jogadas verdadeiramente boas são identificadas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="treinamento-da-rede-de-valor">Treinamento da rede de valor<a href="#treinamento-da-rede-de-valor" class="hash-link" aria-label="Link direto para Treinamento da rede de valor" title="Link direto para Treinamento da rede de valor" translate="no">​</a></h3>
<p>A Value Network usa treinamento de <strong>regressão (regression)</strong>:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>←</mo><mi>ϕ</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ϕ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>z</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\phi \leftarrow \phi - \beta \cdot \nabla_\phi \mathbb{E}\left[(V_\phi(s) - z)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>Isso faz a Value Network aprender a prever: a partir da posição atual, qual é a probabilidade de vitória eventual?</p>
<p>O papel da Value Network é:</p>
<ol>
<li class="">Fornecer avaliação de nó folha no MCTS</li>
<li class="">Servir como baseline para gradiente de política</li>
<li class="">Uso direto para avaliação de posição</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="importância-da-aleatoriedade">Importância da aleatoriedade<a href="#importância-da-aleatoriedade" class="hash-link" aria-label="Link direto para Importância da aleatoriedade" title="Link direto para Importância da aleatoriedade" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="evitar-ciclos-determinísticos">Evitar ciclos determinísticos<a href="#evitar-ciclos-determinísticos" class="hash-link" aria-label="Link direto para Evitar ciclos determinísticos" title="Link direto para Evitar ciclos determinísticos" translate="no">​</a></h3>
<p>Se a autopartida for completamente determinística, pode cair em ciclo:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Política A sempre joga abertura fixa</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Política A vs Política A sempre produz mesma partida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Apenas uma partida é repetidamente aprendida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">IA não pode explorar outras possibilidades</span><br></span></code></pre></div></div>
<p>É por isso que <strong>aleatoriedade</strong> é crucial na autopartida.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="fontes-de-aleatoriedade">Fontes de aleatoriedade<a href="#fontes-de-aleatoriedade" class="hash-link" aria-label="Link direto para Fontes de aleatoriedade" title="Link direto para Fontes de aleatoriedade" translate="no">​</a></h3>
<p>Maneiras do AlphaGo introduzir aleatoriedade na autopartida:</p>
<p><strong>1. A própria rede de política é estocástica</strong></p>
<p>A Policy Network produz distribuição de probabilidade, não escolha determinística:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a \sim \pi_\theta(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></p>
<p>Mesma posição, cada vez pode escolher jogada diferente.</p>
<p><strong>2. Parâmetro de temperatura</strong></p>
<p>Usar temperatura mais alta durante treinamento para aumentar diversidade:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow><mrow><msub><mo>∑</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\pi_\tau(a|s) = \frac{\pi_\theta(a|s)^{1/\tau}}{\sum_{a&#x27;} \pi_\theta(a&#x27;|s)^{1/\tau}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7721em;vertical-align:-0.6104em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1617em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2854em"><span style="top:-2.2854em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.6068em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em"><span style="top:-2.8496em;margin-right:0.1em"><span class="pstrut" style="height:2.5556em"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667em"><span style="top:-2.9667em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6104em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: mais aleatório, mais exploração</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: mais determinístico, mais exploitation</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: distribuição original</li>
</ul>
<p><strong>3. Ruído de Dirichlet (Dirichlet Noise)</strong></p>
<p>O AlphaGo Zero adiciona ruído de Dirichlet às probabilidades prévias do nó raiz durante autopartida:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><mo>⋅</mo><msub><mi>η</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">P(s, a) = (1 - \varepsilon) \cdot \pi_\theta(a|s) + \varepsilon \cdot \eta_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>Onde <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>∼</mo><mtext>Dir</mtext><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\eta \sim \text{Dir}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span> (para as 361 ações do Go).</p>
<p>Isso garante que mesmo jogadas de probabilidade muito baixa tenham chance de serem exploradas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="método-de-pool-de-oponentes-population">Método de pool de oponentes (Population)<a href="#método-de-pool-de-oponentes-population" class="hash-link" aria-label="Link direto para Método de pool de oponentes (Population)" title="Link direto para Método de pool de oponentes (Population)" translate="no">​</a></h3>
<p>Outra maneira de aumentar diversidade é manter um <strong>pool de oponentes</strong>:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Pool de oponentes = [π_1, π_2, π_3, ..., π_k] (diferentes versões de políticas)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cada partida:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Selecionar aleatoriamente um oponente do pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Jogar contra esse oponente</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Usar resultado para atualizar política atual</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Periodicamente adicionar políticas melhoradas ao pool</span><br></span></code></pre></div></div>
<p>Benefícios deste método:</p>
<ul>
<li class=""><strong>Diversidade</strong>: oponentes de diferentes estilos</li>
<li class=""><strong>Estabilidade</strong>: evita overfitting a oponente específico</li>
<li class=""><strong>Robustez</strong>: aprende a lidar com várias estratégias</li>
</ul>
<p>Tanto o AlphaGo original quanto o AlphaGo Zero usaram técnicas similares.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="curva-de-crescimento-de-força-de-jogo">Curva de crescimento de força de jogo<a href="#curva-de-crescimento-de-força-de-jogo" class="hash-link" aria-label="Link direto para Curva de crescimento de força de jogo" title="Link direto para Curva de crescimento de força de jogo" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="sistema-de-classificação-elo">Sistema de classificação Elo<a href="#sistema-de-classificação-elo" class="hash-link" aria-label="Link direto para Sistema de classificação Elo" title="Link direto para Sistema de classificação Elo" translate="no">​</a></h3>
<p>Para rastrear mudanças na força de jogo da IA, o AlphaGo usou o <strong>Sistema de classificação Elo</strong>.</p>
<p>Princípio básico do sistema Elo:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>A vence</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>B</mi></msub><mo>−</mo><msub><mi>R</mi><mi>A</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>400</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{A vence}) = \frac{1}{1 + 10^{(R_B - R_A)/400}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">A vence</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3331em;vertical-align:-0.488em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.5703em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8853em"><span style="top:-2.8853em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight">A</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/400</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.488em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>Onde <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">R_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> e <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">R_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> são as pontuações Elo de ambos os lados.</p>
<ul>
<li class="">Diferença de 200: mais forte esperado vencer 75%</li>
<li class="">Diferença de 400: mais forte esperado vencer 90%</li>
<li class="">Diferença de 800: mais forte esperado vencer 99%</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="crescimento-de-força-de-jogo-do-alphago">Crescimento de força de jogo do AlphaGo<a href="#crescimento-de-força-de-jogo-do-alphago" class="hash-link" aria-label="Link direto para Crescimento de força de jogo do AlphaGo" title="Link direto para Crescimento de força de jogo do AlphaGo" translate="no">​</a></h3>
<p>Vamos visualizar o crescimento de força de jogo das várias versões do AlphaGo:</p>
<div>載入中...</div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="análise-de-velocidade-de-crescimento">Análise de velocidade de crescimento<a href="#análise-de-velocidade-de-crescimento" class="hash-link" aria-label="Link direto para Análise de velocidade de crescimento" title="Link direto para Análise de velocidade de crescimento" translate="no">​</a></h3>
<p>Da curva, podemos observar vários fenômenos interessantes:</p>
<p><strong>1. Crescimento rápido inicial</strong></p>
<p>Nas primeiras horas de treinamento, a IA aprende regras básicas e táticas simples. Esta é a fase de <strong>frutos de fácil colheita</strong> — há muitos erros óbvios para corrigir.</p>
<p><strong>2. Crescimento estável no meio</strong></p>
<p>Conforme erros básicos são eliminados, a IA começa a aprender táticas e joseki mais sutis. Velocidade de crescimento diminui, mas ainda estável.</p>
<p><strong>3. Crescimento desacelera no final</strong></p>
<p>Quando a IA já está muito forte, melhorar mais se torna difícil. Pode precisar descobrir estratégias completamente novas, não apenas corrigir erros.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-momento-de-superar-humanos">O momento de superar humanos<a href="#o-momento-de-superar-humanos" class="hash-link" aria-label="Link direto para O momento de superar humanos" title="Link direto para O momento de superar humanos" translate="no">​</a></h3>
<p>Marcos-chave na curva de treinamento do AlphaGo:</p>
<table><thead><tr><th>Marco</th><th>Equivalente a</th><th>Tempo para alcançar</th></tr></thead><tbody><tr><td>Superar amadores fortes</td><td>Elo ~2700</td><td>Cerca de 3 horas</td></tr><tr><td>Superar Fan Hui</td><td>Elo ~3500</td><td>Cerca de 36 horas</td></tr><tr><td>Superar Lee Sedol</td><td>Elo ~4500</td><td>Cerca de 60 horas</td></tr><tr><td>Superar AlphaGo original</td><td>Elo ~5000</td><td>Cerca de 72 horas</td></tr></tbody></table>
<p>Estes números (do AlphaGo Zero) são impressionantes: <strong>a IA em 3 dias do zero superou milhares de anos de sabedoria humana de Go</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="análise-de-convergência">Análise de convergência<a href="#análise-de-convergência" class="hash-link" aria-label="Link direto para Análise de convergência" title="Link direto para Análise de convergência" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-autopartida-converge">A autopartida converge?<a href="#a-autopartida-converge" class="hash-link" aria-label="Link direto para A autopartida converge?" title="Link direto para A autopartida converge?" translate="no">​</a></h3>
<p>Esta é uma importante questão teórica. Resposta curta: <strong>sob certas condições sim, mas Go é muito complexo para provar rigorosamente</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="garantias-teóricas">Garantias teóricas<a href="#garantias-teóricas" class="hash-link" aria-label="Link direto para Garantias teóricas" title="Link direto para Garantias teóricas" translate="no">​</a></h3>
<p>Para jogos mais simples (como jogo da velha), pode-se provar:</p>
<ol>
<li class=""><strong>Existência</strong>: existe equilíbrio de Nash (Teorema Minimax)</li>
<li class=""><strong>Convergência</strong>: certos algoritmos (como Fictitious Play) convergem para equilíbrio de Nash</li>
</ol>
<p>Para Go, não temos garantia rigorosa de convergência, mas evidências experimentais mostram:</p>
<ul>
<li class="">Força de jogo melhora continuamente</li>
<li class="">Sem oscilação óbvia ou degradação</li>
<li class="">Força final supera todos os humanos conhecidos</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="possíveis-modos-de-falha">Possíveis modos de falha<a href="#possíveis-modos-de-falha" class="hash-link" aria-label="Link direto para Possíveis modos de falha" title="Link direto para Possíveis modos de falha" translate="no">​</a></h3>
<p>Problemas que a autopartida pode encontrar:</p>
<p><strong>1. Ciclo de estratégias (Strategy Cycling)</strong></p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Estratégia A derrota estratégia B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Estratégia B derrota estratégia C</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Estratégia C derrota estratégia A</span><br></span></code></pre></div></div>
<p>Isso realmente acontece em alguns jogos (como pedra-papel-tesoura). Mas Go tem complexidade suficiente, este tipo de ciclo puro parece não ocorrer.</p>
<p><strong>2. Overfitting a si mesmo</strong></p>
<p>A IA pode aprender estratégias que só funcionam contra seu próprio estilo, não contra outros estilos de oponentes. Por isso o AlphaGo joga contra diferentes versões de si mesmo, e eventualmente testa contra jogadores humanos.</p>
<p><strong>3. Ótimo local</strong></p>
<p>A IA pode cair em ótimo local — uma estratégia &quot;razoável mas não a melhor&quot;. Aleatoriedade e muitas partidas ajudam a evitar este problema.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="observações-práticas">Observações práticas<a href="#observações-práticas" class="hash-link" aria-label="Link direto para Observações práticas" title="Link direto para Observações práticas" translate="no">​</a></h3>
<p>Das observações do processo de treinamento do AlphaGo:</p>
<ol>
<li class=""><strong>Progresso contínuo</strong>: pontuação Elo sobe continuamente com treinamento</li>
<li class=""><strong>Sem degradação</strong>: não há queda repentina de força de jogo</li>
<li class=""><strong>Evolução de estilo</strong>: estilo de jogo da IA muda gradualmente com treinamento</li>
<li class=""><strong>Descoberta de novos joseki</strong>: IA descobre aberturas e táticas nunca usadas por humanos</li>
</ol>
<p>Estas observações mostram que, embora não tenhamos garantia teórica, a autopartida funciona na prática.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="detalhes-de-implementação">Detalhes de implementação<a href="#detalhes-de-implementação" class="hash-link" aria-label="Link direto para Detalhes de implementação" title="Link direto para Detalhes de implementação" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="autopartida-paralela">Autopartida paralela<a href="#autopartida-paralela" class="hash-link" aria-label="Link direto para Autopartida paralela" title="Link direto para Autopartida paralela" translate="no">​</a></h3>
<p>Para acelerar o treinamento, o AlphaGo usa autopartida massivamente paralela:</p>
<!-- -->
<p><strong>Decisões de design chave</strong>:</p>
<ul>
<li class=""><strong>Síncrono vs assíncrono</strong>: AlphaGo usa atualizações assíncronas, Workers não precisam esperar uns pelos outros</li>
<li class=""><strong>Frequência de atualização</strong>: atualiza parâmetros a cada N partidas completadas</li>
<li class=""><strong>Seleção de oponente</strong>: seleciona aleatoriamente uma das versões recentes como oponente</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="estratégia-de-checkpoint">Estratégia de checkpoint<a href="#estratégia-de-checkpoint" class="hash-link" aria-label="Link direto para Estratégia de checkpoint" title="Link direto para Estratégia de checkpoint" translate="no">​</a></h3>
<p>Salvar checkpoints de modelo periodicamente, para:</p>
<ol>
<li class=""><strong>Pool de oponentes</strong>: manter diferentes versões de oponentes</li>
<li class=""><strong>Avaliação</strong>: rastrear mudanças de força de jogo</li>
<li class=""><strong>Recuperação de falhas</strong>: pode recuperar se treinamento for interrompido</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Pseudocódigo</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">training_loop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> iteration </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_iterations</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Gerar dados de partida</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trajectories </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parallel_self_play</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_games</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Atualizar política</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update_policy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">trajectories</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Avaliar e salvar periodicamente</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> iteration </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate_against_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            save_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> elo</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> elo </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> best_elo</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                add_to_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                best_elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> elo</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="requisitos-de-recursos-de-treinamento">Requisitos de recursos de treinamento<a href="#requisitos-de-recursos-de-treinamento" class="hash-link" aria-label="Link direto para Requisitos de recursos de treinamento" title="Link direto para Requisitos de recursos de treinamento" translate="no">​</a></h3>
<p>A escala de treinamento do AlphaGo é impressionante:</p>
<table><thead><tr><th>Versão</th><th>Hardware</th><th>Tempo de treinamento</th><th>Partidas de autopartida</th></tr></thead><tbody><tr><td>AlphaGo Fan</td><td>176 GPUs</td><td>Vários meses</td><td>~30M</td></tr><tr><td>AlphaGo Lee</td><td>48 TPUs</td><td>Várias semanas</td><td>~30M</td></tr><tr><td>AlphaGo Zero</td><td>4 TPUs</td><td>3 dias</td><td>~5M</td></tr><tr><td>AlphaGo Zero (versão 40 dias)</td><td>4 TPUs</td><td>40 dias</td><td>~30M</td></tr></tbody></table>
<p>Note que o AlphaGo Zero alcançou força maior com menos hardware e menos tempo — isso é melhoria de eficiência algorítmica.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="configuração-de-hiperparâmetros">Configuração de hiperparâmetros<a href="#configuração-de-hiperparâmetros" class="hash-link" aria-label="Link direto para Configuração de hiperparâmetros" title="Link direto para Configuração de hiperparâmetros" translate="no">​</a></h3>
<p>Alguns hiperparâmetros chave:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Configurações de autopartida</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NUM_PARALLEL_GAMES </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Número de partidas simultâneas</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GAMES_PER_ITERATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">25000</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Partidas por iteração</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MCTS_SIMULATIONS </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1600</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Simulações MCTS por movimento</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Configurações de treinamento</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BATCH_SIZE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Tamanho do lote de treinamento</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LEARNING_RATE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># Taxa de aprendizado inicial</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">L2_REGULARIZATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># Weight decay</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Configurações de exploração</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TEMPERATURE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Temperatura para primeiros 30 movimentos</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DIRICHLET_ALPHA </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.03</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># Parâmetro de ruído de Dirichlet</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EXPLORATION_FRACTION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Proporção de ruído</span><br></span></code></pre></div></div>
<p>Estes hiperparâmetros foram ajustados através de muitos experimentos e têm impacto significativo no efeito do treinamento.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="variantes-de-autopartida">Variantes de autopartida<a href="#variantes-de-autopartida" class="hash-link" aria-label="Link direto para Variantes de autopartida" title="Link direto para Variantes de autopartida" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-original">AlphaGo original<a href="#alphago-original" class="hash-link" aria-label="Link direto para AlphaGo original" title="Link direto para AlphaGo original" translate="no">​</a></h3>
<p>Fluxo de treinamento do AlphaGo original:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Aprendizado Supervisionado (SL): aprender de partidas humanas</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Produz SL Policy Network (π_SL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Aprendizado por Reforço (RL): autopartida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Inicializar π_RL = π_SL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Pool de oponentes = [π_SL]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Repetir:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. π_RL joga contra políticas do pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Atualizar π_RL com gradiente de política</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Se π_RL ficou mais forte, adicionar ao pool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Produz RL Policy Network (π_RL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Treinamento da rede de valor:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Usar π_RL para autopartida e gerar posições</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Treinar V(s) para prever taxa de vitória</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero">AlphaGo Zero<a href="#alphago-zero" class="hash-link" aria-label="Link direto para AlphaGo Zero" title="Link direto para AlphaGo Zero" translate="no">​</a></h3>
<p>O AlphaGo Zero simplificou este fluxo:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Autopartida pura (sem dados humanos)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Inicializar rede aleatória f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Repetir:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. Usar MCTS + f_θ para autopartida</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. Treinar cabeça de política e cabeça de valor simultaneamente</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. Atualizar f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → Rede única produz política e valor simultaneamente</span><br></span></code></pre></div></div>
<p>Melhorias chave:</p>
<ul>
<li class=""><strong>Sem necessidade de dados humanos</strong>: começa do zero</li>
<li class=""><strong>Rede única</strong>: política e valor compartilham características</li>
<li class=""><strong>Treinamento mais conciso</strong>: aprendizado end-to-end</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphazero">AlphaZero<a href="#alphazero" class="hash-link" aria-label="Link direto para AlphaZero" title="Link direto para AlphaZero" translate="no">​</a></h3>
<p>O AlphaZero generalizou ainda mais:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Mesmo algoritmo, diferentes jogos:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Go: alcançou nível superior ao AlphaGo Zero</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Xadrez: superou Stockfish</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Shogi: superou Elmo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Única parte específica do jogo: codificação de regras</span><br></span></code></pre></div></div>
<p>Isso prova que autopartida é um <strong>paradigma de aprendizado universal</strong>, não limitado ao Go.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="o-que-os-humanos-aprenderam">O que os humanos aprenderam?<a href="#o-que-os-humanos-aprenderam" class="hash-link" aria-label="Link direto para O que os humanos aprenderam?" title="Link direto para O que os humanos aprenderam?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="novos-joseki-descobertos-pela-ia">Novos joseki descobertos pela IA<a href="#novos-joseki-descobertos-pela-ia" class="hash-link" aria-label="Link direto para Novos joseki descobertos pela IA" title="Link direto para Novos joseki descobertos pela IA" translate="no">​</a></h3>
<p>A autopartida produziu muitas jogadas nunca usadas por humanos:</p>
<p><strong>1. Inovações de abertura</strong></p>
<p>Algumas aberturas preferidas pelo AlphaGo:</p>
<ul>
<li class="">Invasão 3-3: invadir canto cedo</li>
<li class="">Jogadas altas: tradicionalmente consideradas &quot;instáveis&quot;</li>
<li class="">Variação grande avalanche: humanos consideram complexa demais para calcular</li>
</ul>
<p><strong>2. Nova avaliação de posição</strong></p>
<p>A avaliação de certas posições pela IA difere muito da dos humanos:</p>
<ul>
<li class="">Certas formas aparentemente &quot;finas&quot; são na verdade sólidas</li>
<li class="">O valor de certa &quot;espessura&quot; é superestimado</li>
<li class="">Reavaliação de &quot;sente&quot; e &quot;gote&quot;</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="impacto-no-go-humano">Impacto no Go humano<a href="#impacto-no-go-humano" class="hash-link" aria-label="Link direto para Impacto no Go humano" title="Link direto para Impacto no Go humano" translate="no">​</a></h3>
<p>Após o AlphaGo, o Go profissional mudou significativamente:</p>
<ol>
<li class=""><strong>Diversificação de aberturas</strong>: jogadores profissionais começaram a usar novas aberturas descobertas pela IA</li>
<li class=""><strong>Mudança de métodos de treinamento</strong>: IA se tornou ferramenta principal de treinamento de profissionais</li>
<li class=""><strong>Repensando teoria de Go</strong>: muita &quot;teoria&quot; tradicional foi questionada e corrigida</li>
<li class=""><strong>Nova estética</strong>: começando a apreciar Go estilo IA</li>
</ol>
<p>Ke Jie disse após perder para o AlphaGo:</p>
<blockquote>
<p>&quot;O AlphaGo me fez redescobrir o Go. Eu achava que humanos entendiam Go, agora sei que apenas tocamos a superfície.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="reflexões-filosóficas">Reflexões filosóficas<a href="#reflexões-filosóficas" class="hash-link" aria-label="Link direto para Reflexões filosóficas" title="Link direto para Reflexões filosóficas" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-natureza-do-aprendizado">A natureza do aprendizado<a href="#a-natureza-do-aprendizado" class="hash-link" aria-label="Link direto para A natureza do aprendizado" title="Link direto para A natureza do aprendizado" translate="no">​</a></h3>
<p>A autopartida levanta questões profundas sobre aprendizado:</p>
<p><strong>De onde vem o conhecimento?</strong></p>
<ul>
<li class="">Aprendizado humano depende de informação externa (professores, livros, experiência)</li>
<li class="">IA de autopartida só tem regras, sem conhecimento externo</li>
<li class="">Mas ainda pode &quot;descobrir&quot; conhecimento — de onde vem este conhecimento?</li>
</ul>
<p>A resposta pode ser: <strong>o conhecimento está implícito nas regras e estrutura do jogo</strong>. As regras do Go definem o que são boas e más jogadas, a autopartida apenas revela estas estruturas implícitas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="criatividade-e-descoberta">Criatividade e descoberta<a href="#criatividade-e-descoberta" class="hash-link" aria-label="Link direto para Criatividade e descoberta" title="Link direto para Criatividade e descoberta" translate="no">​</a></h3>
<p>Quando a IA joga o &quot;Movimento de Deus&quot; (Movimento 37), isso é criação ou descoberta?</p>
<p>Uma visão é: aquele movimento sempre &quot;existiu&quot; nas regras do Go, a IA apenas o &quot;descobriu&quot;.
Outra visão é: a IA &quot;criou&quot; aquele movimento, porque ninguém (incluindo a própria IA) sabia disso antes.</p>
<p>Esta questão não tem resposta padrão, mas desafia nossa compreensão tradicional de criatividade.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="o-lugar-da-inteligência-humana">O lugar da inteligência humana<a href="#o-lugar-da-inteligência-humana" class="hash-link" aria-label="Link direto para O lugar da inteligência humana" title="Link direto para O lugar da inteligência humana" translate="no">​</a></h3>
<p>Se a IA pode do zero, através de autopartida, superar milhares de anos de sabedoria humana, o que isso significa para os humanos?</p>
<p>Visão otimista:</p>
<ul>
<li class="">IA é uma ferramenta criada por humanos</li>
<li class="">Descobertas da IA podem melhorar a compreensão humana</li>
<li class="">Humanos podem colaborar com IA para alcançar níveis mais altos</li>
</ul>
<p>Visão cautelosa:</p>
<ul>
<li class="">Em certas áreas, computação pura pode superar intuição humana</li>
<li class="">Precisa repensar o valor de &quot;habilidades especializadas&quot;</li>
<li class="">Métodos de educação e treinamento podem precisar mudar</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="correspondência-de-animações">Correspondência de animações<a href="#correspondência-de-animações" class="hash-link" aria-label="Link direto para Correspondência de animações" title="Link direto para Correspondência de animações" translate="no">​</a></h2>
<p>Os conceitos centrais abordados neste artigo e números de animação:</p>
<table><thead><tr><th>Número</th><th>Conceito</th><th>Correspondência física/matemática</th></tr></thead><tbody><tr><td>E5</td><td>Ciclo de autopartida</td><td>Iteração de ponto fixo</td></tr><tr><td>E6</td><td>Evolução de estratégia</td><td>Dinâmica evolutiva</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="resumo">Resumo<a href="#resumo" class="hash-link" aria-label="Link direto para Resumo" title="Link direto para Resumo" translate="no">​</a></h2>
<p>A autopartida é uma das tecnologias-chave para o sucesso do AlphaGo. Aprendemos:</p>
<ol>
<li class=""><strong>Por que funciona</strong>: aprendizado adversarial, descoberta progressiva de fraquezas</li>
<li class=""><strong>Mecanismo</strong>: coleta de trajetórias, gradiente de política, treinamento de rede de valor</li>
<li class=""><strong>Aleatoriedade</strong>: parâmetro de temperatura, ruído de Dirichlet, pool de oponentes</li>
<li class=""><strong>Crescimento de força de jogo</strong>: sistema Elo, análise de curva de crescimento</li>
<li class=""><strong>Convergência</strong>: garantias teóricas e observações práticas</li>
<li class=""><strong>Detalhes de implementação</strong>: treinamento paralelo, estratégia de checkpoint, hiperparâmetros</li>
</ol>
<p>No próximo artigo, exploraremos como o AlphaGo combina redes neurais com MCTS, aproveitando as vantagens de ambos.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="leitura-adicional">Leitura adicional<a href="#leitura-adicional" class="hash-link" aria-label="Link direto para Leitura adicional" title="Link direto para Leitura adicional" translate="no">​</a></h2>
<ul>
<li class=""><strong>Próximo artigo</strong>: <a class="" href="/pt/docs/alphago/mcts-neural-combo/">Combinação de MCTS e Redes Neurais</a> — A combinação perfeita de intuição e raciocínio</li>
<li class=""><strong>Artigo anterior</strong>: <a class="" href="/pt/docs/alphago/reinforcement-intro/">Introdução ao Aprendizado por Reforço</a> — Conceitos básicos de aprendizado por reforço</li>
<li class=""><strong>Relacionado</strong>: <a class="" href="/pt/docs/alphago/alphago-zero/">Visão Geral do AlphaGo Zero</a> — O avanço a partir do zero</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referências">Referências<a href="#referências" class="hash-link" aria-label="Link direto para Referências" title="Link direto para Referências" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">Heinrich, J., &amp; Silver, D. (2016). &quot;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.&quot; <em>arXiv preprint</em>.</li>
<li class="">Lanctot, M., et al. (2017). &quot;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/13-self-play.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar essa página</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Páginas de documentação"><a class="pagination-nav__link pagination-nav__link--prev" href="/pt/docs/alphago/reinforcement-intro/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Introdução ao Aprendizado por Reforço</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/pt/docs/alphago/mcts-neural-combo/"><div class="pagination-nav__sublabel">Próxima</div><div class="pagination-nav__label">A Combinação de MCTS e Redes Neurais</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#por-que-a-autopartida-funciona" class="table-of-contents__link toc-highlight">Por que a autopartida funciona?</a><ul><li><a href="#explicação-intuitiva" class="table-of-contents__link toc-highlight">Explicação intuitiva</a></li><li><a href="#descoberta-progressiva-de-fraquezas" class="table-of-contents__link toc-highlight">Descoberta progressiva de fraquezas</a></li><li><a href="#aprendizado-adversarial" class="table-of-contents__link toc-highlight">Aprendizado adversarial</a></li><li><a href="#comparação-com-partidas-humanas" class="table-of-contents__link toc-highlight">Comparação com partidas humanas</a></li></ul></li><li><a href="#perspectiva-da-teoria-dos-jogos" class="table-of-contents__link toc-highlight">Perspectiva da teoria dos jogos</a><ul><li><a href="#equilíbrio-de-nash" class="table-of-contents__link toc-highlight">Equilíbrio de Nash</a></li><li><a href="#autopartida-e-equilíbrio-de-nash" class="table-of-contents__link toc-highlight">Autopartida e equilíbrio de Nash</a></li><li><a href="#fictitious-play-jogo-fictício" class="table-of-contents__link toc-highlight">Fictitious Play (Jogo fictício)</a></li></ul></li><li><a href="#mecanismo-da-autopartida" class="table-of-contents__link toc-highlight">Mecanismo da autopartida</a><ul><li><a href="#fluxo-básico" class="table-of-contents__link toc-highlight">Fluxo básico</a></li><li><a href="#geração-de-dados-de-treinamento" class="table-of-contents__link toc-highlight">Geração de dados de treinamento</a></li><li><a href="#atualização-de-política" class="table-of-contents__link toc-highlight">Atualização de política</a></li><li><a href="#treinamento-da-rede-de-valor" class="table-of-contents__link toc-highlight">Treinamento da rede de valor</a></li></ul></li><li><a href="#importância-da-aleatoriedade" class="table-of-contents__link toc-highlight">Importância da aleatoriedade</a><ul><li><a href="#evitar-ciclos-determinísticos" class="table-of-contents__link toc-highlight">Evitar ciclos determinísticos</a></li><li><a href="#fontes-de-aleatoriedade" class="table-of-contents__link toc-highlight">Fontes de aleatoriedade</a></li><li><a href="#método-de-pool-de-oponentes-population" class="table-of-contents__link toc-highlight">Método de pool de oponentes (Population)</a></li></ul></li><li><a href="#curva-de-crescimento-de-força-de-jogo" class="table-of-contents__link toc-highlight">Curva de crescimento de força de jogo</a><ul><li><a href="#sistema-de-classificação-elo" class="table-of-contents__link toc-highlight">Sistema de classificação Elo</a></li><li><a href="#crescimento-de-força-de-jogo-do-alphago" class="table-of-contents__link toc-highlight">Crescimento de força de jogo do AlphaGo</a></li><li><a href="#análise-de-velocidade-de-crescimento" class="table-of-contents__link toc-highlight">Análise de velocidade de crescimento</a></li><li><a href="#o-momento-de-superar-humanos" class="table-of-contents__link toc-highlight">O momento de superar humanos</a></li></ul></li><li><a href="#análise-de-convergência" class="table-of-contents__link toc-highlight">Análise de convergência</a><ul><li><a href="#a-autopartida-converge" class="table-of-contents__link toc-highlight">A autopartida converge?</a></li><li><a href="#garantias-teóricas" class="table-of-contents__link toc-highlight">Garantias teóricas</a></li><li><a href="#possíveis-modos-de-falha" class="table-of-contents__link toc-highlight">Possíveis modos de falha</a></li><li><a href="#observações-práticas" class="table-of-contents__link toc-highlight">Observações práticas</a></li></ul></li><li><a href="#detalhes-de-implementação" class="table-of-contents__link toc-highlight">Detalhes de implementação</a><ul><li><a href="#autopartida-paralela" class="table-of-contents__link toc-highlight">Autopartida paralela</a></li><li><a href="#estratégia-de-checkpoint" class="table-of-contents__link toc-highlight">Estratégia de checkpoint</a></li><li><a href="#requisitos-de-recursos-de-treinamento" class="table-of-contents__link toc-highlight">Requisitos de recursos de treinamento</a></li><li><a href="#configuração-de-hiperparâmetros" class="table-of-contents__link toc-highlight">Configuração de hiperparâmetros</a></li></ul></li><li><a href="#variantes-de-autopartida" class="table-of-contents__link toc-highlight">Variantes de autopartida</a><ul><li><a href="#alphago-original" class="table-of-contents__link toc-highlight">AlphaGo original</a></li><li><a href="#alphago-zero" class="table-of-contents__link toc-highlight">AlphaGo Zero</a></li><li><a href="#alphazero" class="table-of-contents__link toc-highlight">AlphaZero</a></li></ul></li><li><a href="#o-que-os-humanos-aprenderam" class="table-of-contents__link toc-highlight">O que os humanos aprenderam?</a><ul><li><a href="#novos-joseki-descobertos-pela-ia" class="table-of-contents__link toc-highlight">Novos joseki descobertos pela IA</a></li><li><a href="#impacto-no-go-humano" class="table-of-contents__link toc-highlight">Impacto no Go humano</a></li></ul></li><li><a href="#reflexões-filosóficas" class="table-of-contents__link toc-highlight">Reflexões filosóficas</a><ul><li><a href="#a-natureza-do-aprendizado" class="table-of-contents__link toc-highlight">A natureza do aprendizado</a></li><li><a href="#criatividade-e-descoberta" class="table-of-contents__link toc-highlight">Criatividade e descoberta</a></li><li><a href="#o-lugar-da-inteligência-humana" class="table-of-contents__link toc-highlight">O lugar da inteligência humana</a></li></ul></li><li><a href="#correspondência-de-animações" class="table-of-contents__link toc-highlight">Correspondência de animações</a></li><li><a href="#resumo" class="table-of-contents__link toc-highlight">Resumo</a></li><li><a href="#leitura-adicional" class="table-of-contents__link toc-highlight">Leitura adicional</a></li><li><a href="#referências" class="table-of-contents__link toc-highlight">Referências</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>