<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-evolution/ai-history/alphago-era" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">AlphaGo 시대 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/evolution/ai-history/alphago-era/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AlphaGo 시대 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="2015년부터 2017년까지, Google DeepMind의 AlphaGo 시리즈 프로그램은 인공지능 역사상 가장 상징적인 돌파구 중 하나를 창출했습니다. 불과 2년 만에 바둑은 &#x27;인공지능이 정복할 수 없는 게임&#x27;에서 &#x27;AI가 완전히 인류를 초월한 영역&#x27;으로 바뀌었습니다."><meta data-rh="true" property="og:description" content="2015년부터 2017년까지, Google DeepMind의 AlphaGo 시리즈 프로그램은 인공지능 역사상 가장 상징적인 돌파구 중 하나를 창출했습니다. 불과 2년 만에 바둑은 &#x27;인공지능이 정복할 수 없는 게임&#x27;에서 &#x27;AI가 완전히 인류를 초월한 영역&#x27;으로 바뀌었습니다."><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/evolution/ai-history/alphago-era/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/evolution/ai-history/alphago-era/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/evolution/ai-history/alphago-era/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/evolution/ai-history/alphago-era/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/evolution/ai-history/alphago-era/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/evolution/ai-history/alphago-era/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/evolution/ai-history/alphago-era/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/evolution/ai-history/alphago-era/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/evolution/ai-history/alphago-era/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/evolution/ai-history/alphago-era/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/evolution/ai-history/alphago-era/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/evolution/ai-history/alphago-era/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/evolution/ai-history/alphago-era/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"바둑 AI 발전 정리","item":"https://www.weiqi.kids/ko/docs/evolution/"},{"@type":"ListItem","position":2,"name":"AI 바둑 발전사","item":"https://www.weiqi.kids/ko/docs/evolution/ai-history/"},{"@type":"ListItem","position":3,"name":"AlphaGo 시대","item":"https://www.weiqi.kids/ko/docs/evolution/ai-history/alphago-era"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會"><link rel="stylesheet" href="/ko/assets/css/styles.752e6637.css">
<script src="/ko/assets/js/runtime~main.9712b5fc.js" defer="defer"></script>
<script src="/ko/assets/js/main.65f677be.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_bFSG" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="My Site Logo" class="themedComponent_Wuuq themedComponent--light_w2On"><img src="/ko/img/logo.svg" alt="My Site Logo" class="themedComponent_Wuuq themedComponent--dark_zC0W"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/ko/docs/for-players/">圍棋棋友</a><a class="navbar__item navbar__link" href="/ko/docs/for-engineers/">AI工程師</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/evolution/">圍棋 AI 演進整理</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ko/docs/aboutus/">協會介紹</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_Zh_g"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/evolution/ai-history/alphago-era/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_I1mA"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_D_Tj colorModeToggle_nf8C"><button class="clean-btn toggleButton_m_sb toggleButtonDisabled_nndi" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_rMtU lightToggleIcon_PeQM"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_rMtU darkToggleIcon_PkGC"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_rMtU systemToggleIcon_n9Iu"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_pmRL"><div class="navbar__search searchBarContainer_nNQu" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_jmZR" value=""><div class="loadingRing_zZTX searchBarLoadingRing_JhV3"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_WlJ3"><div class="docsWrapper_ramL"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_MqxJ" type="button"></button><div class="docRoot_UZ1h"><aside class="theme-doc-sidebar-container docSidebarContainer_y0QC"><div class="sidebarViewport_jAkm"><div class="sidebar_HjkB"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_jqYH"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/">이용 안내</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/ko/docs/for-players/">바둑 기사를 위한 자료</a><button aria-label="사이드바 분류 &#x27;바둑 기사를 위한 자료&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/ko/docs/for-engineers/">엔지니어를 위한 바둑 AI 가이드</a><button aria-label="사이드바 분류 &#x27;엔지니어를 위한 바둑 AI 가이드&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/ko/docs/evolution/">바둑 AI 발전 정리</a><button aria-label="사이드바 분류 &#x27;바둑 AI 발전 정리&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/ko/docs/evolution/human-history/">인류 바둑 발전사</a><button aria-label="사이드바 분류 &#x27;인류 바둑 발전사&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/evolution/ai-history/">AI 바둑 발전사</a><button aria-label="사이드바 분류 &#x27;AI 바둑 발전사&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/evolution/ai-history/alphago-era/">AlphaGo 시대</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/evolution/ai-history/katago-era/">KataGo 시대</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/aboutus/">협회 소개</a></li></ul></nav></div></div></aside><main class="docMainContainer_qMQS"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_Wlt9"><div class="docItemContainer_oLHG"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_M4ek" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_pL7f"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/evolution/"><span>바둑 AI 발전 정리</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/evolution/ai-history/"><span>AI 바둑 발전사</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">AlphaGo 시대</span></li></ul></nav><div class="tocCollapsible_K0FP theme-doc-toc-mobile tocMobile_PzQu"><button type="button" class="clean-btn tocCollapsibleButton_E0oR">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>AlphaGo 시대 (2015-2017)</h1></header>
<p>2015년부터 2017년까지, Google DeepMind의 AlphaGo 시리즈 프로그램은 인공지능 역사상 가장 상징적인 돌파구 중 하나를 창출했습니다. 불과 2년 만에 바둑은 &#x27;인공지능이 정복할 수 없는 게임&#x27;에서 &#x27;AI가 완전히 인류를 초월한 영역&#x27;으로 바뀌었습니다.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="2015년-10월-alphago-판후이-격파">2015년 10월: AlphaGo, 판후이 격파<a href="#2015년-10월-alphago-판후이-격파" class="hash-link" aria-label="2015년 10월: AlphaGo, 판후이 격파에 대한 직접 링크" title="2015년 10월: AlphaGo, 판후이 격파에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="역사적인-비밀-대국">역사적인 비밀 대국<a href="#역사적인-비밀-대국" class="hash-link" aria-label="역사적인 비밀 대국에 대한 직접 링크" title="역사적인 비밀 대국에 대한 직접 링크">​</a></h3>
<p>2015년 10월, 런던의 한 사무실에서 DeepMind는 비밀 대국을 주선했습니다. 상대는 유럽 바둑 챔피언이자 프로 2단 기사 <strong>판후이</strong>였습니다.</p>
<p>대국 결과: AlphaGo가 5:0으로 완승.</p>
<p>이것은 역사상 최초로 컴퓨터 프로그램이 공정한 조건에서(접바둑 없이) 프로 바둑 기사를 꺾은 것입니다. 이 소식은 2016년 1월 공식 발표되어 즉시 전 세계적인 관심을 받았습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="초대-alphago의-기술">초대 AlphaGo의 기술<a href="#초대-alphago의-기술" class="hash-link" aria-label="초대 AlphaGo의 기술에 대한 직접 링크" title="초대 AlphaGo의 기술에 대한 직접 링크">​</a></h3>
<p>이 버전의 AlphaGo는 두 가지 핵심 기술의 결합을 사용했습니다:</p>
<ol>
<li>
<p><strong>심층 신경망</strong>: 수십만 국의 인간 프로 대국을 학습하여 국면을 평가하는 &#x27;가치 네트워크&#x27;와 다음 수를 예측하는 &#x27;정책 네트워크&#x27;를 훈련</p>
</li>
<li>
<p><strong>몬테카를로 트리 탐색(MCTS)</strong>: 신경망의 출력을 활용하여 탐색을 안내하고, 계산해야 할 변화의 수를 대폭 감소</p>
</li>
</ol>
<p>이러한 &#x27;직관&#x27;과 &#x27;계산&#x27;의 결합은 정확히 인간 기사가 문제를 사고하는 방식입니다 — 다만 AI가 두 측면 모두에서 더 잘했습니다.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="2016년-3월-alphago-vs-이세돌">2016년 3월: AlphaGo vs 이세돌<a href="#2016년-3월-alphago-vs-이세돌" class="hash-link" aria-label="2016년 3월: AlphaGo vs 이세돌에 대한 직접 링크" title="2016년 3월: AlphaGo vs 이세돌에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="세기의-대결">세기의 대결<a href="#세기의-대결" class="hash-link" aria-label="세기의 대결에 대한 직접 링크" title="세기의 대결에 대한 직접 링크">​</a></h3>
<p>2016년 3월 9일부터 15일까지, AlphaGo와 세계 정상급 기사 <strong>이세돌</strong>이 서울에서 5번기 대결을 펼쳤습니다. 이 대국은 전 세계 2억 명 이상이 시청하여 인공지능 역사상 가장 주목받은 사건 중 하나가 되었습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="대국-결과">대국 결과<a href="#대국-결과" class="hash-link" aria-label="대국 결과에 대한 직접 링크" title="대국 결과에 대한 직접 링크">​</a></h3>
<table><thead><tr><th>국</th><th>날짜</th><th>결과</th><th>비고</th></tr></thead><tbody><tr><td>제1국</td><td>3월 9일</td><td>AlphaGo 승</td><td>중반 승</td></tr><tr><td>제2국</td><td>3월 10일</td><td>AlphaGo 승</td><td>중반 승, 유명한 &#x27;37수&#x27; 등장</td></tr><tr><td>제3국</td><td>3월 12일</td><td>AlphaGo 승</td><td>중반 승</td></tr><tr><td>제4국</td><td>3월 13일</td><td>이세돌 승</td><td><strong>이세돌 78수 &#x27;신의 한 수&#x27;</strong></td></tr><tr><td>제5국</td><td>3월 15일</td><td>AlphaGo 승</td><td>중반 승</td></tr></tbody></table>
<p>최종 점수: <strong>AlphaGo 4:1 이세돌</strong></p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="제2국-37수-신의-한-수">제2국 37수: &#x27;신의 한 수&#x27;<a href="#제2국-37수-신의-한-수" class="hash-link" aria-label="제2국 37수: &#x27;신의 한 수&#x27;에 대한 직접 링크" title="제2국 37수: &#x27;신의 한 수&#x27;에 대한 직접 링크">​</a></h3>
<p>제2국에서 AlphaGo는 오른쪽에 관전하던 모든 기사들을 당혹스럽게 한 &#x27;어깨짚기&#x27; 한 수를 두었습니다.</p>
<p>이 수는 전혀 이치에 맞지 않는 것처럼 보였으며, 어떤 알려진 정석에도 부합하지 않았습니다. 해설자는 이 수를 인간이 둘 확률을 만분의 일 이하로 추정했습니다. 그러나 대국이 진행되면서 이 수의 깊은 의미가 점차 드러났습니다 — 여러 방향에 동시에 영향을 미치며 효율이 극도로 높았습니다.</p>
<p>이 한 수는 &#x27;신의 한 수&#x27;로 불리며, AI가 이미 인간이 이해할 수 없는 바둑 이념을 발전시켰음을 상징합니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="제4국-78수-인류의-반격">제4국 78수: 인류의 반격<a href="#제4국-78수-인류의-반격" class="hash-link" aria-label="제4국 78수: 인류의 반격에 대한 직접 링크" title="제4국 78수: 인류의 반격에 대한 직접 링크">​</a></h3>
<p>3연패 후, 이세돌은 제4국에서 마찬가지로 놀라운 한 수를 두었습니다 — 78수 &#x27;끼워넣기&#x27;.</p>
<p>이 수는 교묘한 수법으로, 복잡한 전투 중에 AlphaGo가 예견하지 못한 변화를 만들어냈습니다. AlphaGo는 이 수 이후 명백한 혼란을 보였고, 결국 불계패했습니다.</p>
<p>이것은 정식 대국에서 인간이 AlphaGo를 꺾은 유일한 경기이며, 이세돌의 이 수는 영원히 인류 지혜의 상징으로 기억될 것입니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="대국의-영향">대국의 영향<a href="#대국의-영향" class="hash-link" aria-label="대국의 영향에 대한 직접 링크" title="대국의 영향에 대한 직접 링크">​</a></h3>
<p>이 대국의 영향은 바둑계를 훨씬 넘어섰습니다:</p>
<ul>
<li><strong>인공지능의 이정표</strong>: 딥러닝이 극도로 복잡한 문제를 처리할 수 있음을 증명</li>
<li><strong>한국의 전국민적 관심</strong>: 통계에 따르면 한국 인구의 절반 이상이 대국을 시청</li>
<li><strong>바둑의 새 시대</strong>: 프로 기사들이 AI에게 배워야 함을 인식하기 시작</li>
<li><strong>기술 투자 열풍</strong>: 전 세계적으로 AI 연구에 대한 투자를 촉진</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="2017년-1월-master-60연승">2017년 1월: Master 60연승<a href="#2017년-1월-master-60연승" class="hash-link" aria-label="2017년 1월: Master 60연승에 대한 직접 링크" title="2017년 1월: Master 60연승에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="신비로운-온라인-기사">신비로운 온라인 기사<a href="#신비로운-온라인-기사" class="hash-link" aria-label="신비로운 온라인 기사에 대한 직접 링크" title="신비로운 온라인 기사에 대한 직접 링크">​</a></h3>
<p>2016년 말부터 2017년 초까지, &#x27;Master&#x27;라는 계정이 이청(Tygem)과 야호(Fox) 등 바둑 대국 사이트에 나타났습니다. 극도로 빠른 속도로 커제, 박정환, 이야마 유타 등 세계 정상급 기사들을 포함한 모든 도전자를 꺾었습니다.</p>
<p>최종 전적: <strong>60전 60승</strong> (1국은 상대방 연결 끊김으로 무승부 판정 포함)</p>
<p>60국이 끝난 후, DeepMind는 공식 발표했습니다: Master는 AlphaGo의 새 버전입니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="master가-보여준-새로운-이념">Master가 보여준 새로운 이념<a href="#master가-보여준-새로운-이념" class="hash-link" aria-label="Master가 보여준 새로운 이념에 대한 직접 링크" title="Master가 보여준 새로운 이념에 대한 직접 링크">​</a></h3>
<p>Master의 기풍은 1년 전 이세돌을 꺾은 버전과 명확히 달랐습니다:</p>
<ul>
<li><strong>더 빠른 계산 속도</strong>: 매 수에 수십 초만 사용</li>
<li><strong>더 공격적인 착수</strong>: 전통 이론에서 &#x27;좋지 않다&#x27;고 여기는 착수를 빈번히 사용</li>
<li><strong>삼삼 점입이 주류가 됨</strong>: Master는 자주 포석 초반에 직접 삼삼에 점입</li>
</ul>
<p>이러한 착수법은 인류가 수백 년간 축적한 바둑 이론을 완전히 뒤집었고, 프로 기사들은 대량으로 AI의 착수를 모방하기 시작했습니다.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="2017년-5월-alphago-vs-커제">2017년 5월: AlphaGo vs 커제<a href="#2017년-5월-alphago-vs-커제" class="hash-link" aria-label="2017년 5월: AlphaGo vs 커제에 대한 직접 링크" title="2017년 5월: AlphaGo vs 커제에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="인류의-마지막-도전">인류의 마지막 도전<a href="#인류의-마지막-도전" class="hash-link" aria-label="인류의 마지막 도전에 대한 직접 링크" title="인류의 마지막 도전에 대한 직접 링크">​</a></h3>
<p>2017년 5월, 중국 우전에서 AlphaGo와 당시 세계 랭킹 1위 <strong>커제</strong>가 3번기 대결을 펼쳤습니다. 이것은 &#x27;인류의 마지막 도전&#x27;으로 여겨졌습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="대국-결과-1">대국 결과<a href="#대국-결과-1" class="hash-link" aria-label="대국 결과에 대한 직접 링크" title="대국 결과에 대한 직접 링크">​</a></h3>
<table><thead><tr><th>국</th><th>날짜</th><th>결과</th><th>비고</th></tr></thead><tbody><tr><td>제1국</td><td>5월 23일</td><td>AlphaGo 승</td><td>1/4집 승 (최소 차이)</td></tr><tr><td>제2국</td><td>5월 25일</td><td>AlphaGo 승</td><td>중반 승</td></tr><tr><td>제3국</td><td>5월 27일</td><td>AlphaGo 승</td><td>중반 승</td></tr></tbody></table>
<p>최종 점수: <strong>AlphaGo 3:0 커제</strong></p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="커제의-눈물">커제의 눈물<a href="#커제의-눈물" class="hash-link" aria-label="커제의 눈물에 대한 직접 링크" title="커제의 눈물에 대한 직접 링크">​</a></h3>
<p>제2국 대국 중간에 커제는 한때 자리를 비웠다가 돌아왔을 때 눈시울이 붉었습니다. 경기 후 그는 말했습니다:</p>
<blockquote>
<p>&quot;그것은 너무 완벽합니다. 저는 어떤 승리의 희망도 보이지 않습니다.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;AlphaGo와 바둑을 두면서 저는 그것의 바둑에 대한 사랑을 느꼈습니다.&quot;</p>
</blockquote>
<p>이 대국이 끝난 후, DeepMind는 AlphaGo의 은퇴를 선언하며 더 이상 공개 대국에 참가하지 않겠다고 했습니다.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="2017년-10월-alphazero-논문">2017년 10월: AlphaZero 논문<a href="#2017년-10월-alphazero-논문" class="hash-link" aria-label="2017년 10월: AlphaZero 논문에 대한 직접 링크" title="2017년 10월: AlphaZero 논문에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="제로에서-시작한-초월">제로에서 시작한 초월<a href="#제로에서-시작한-초월" class="hash-link" aria-label="제로에서 시작한 초월에 대한 직접 링크" title="제로에서 시작한 초월에 대한 직접 링크">​</a></h3>
<p>2017년 10월, DeepMind는 AlphaZero 논문을 발표하여 더 놀라운 성취를 보여주었습니다.</p>
<p>AlphaZero의 돌파구: <strong>인간 기보가 전혀 필요 없다.</strong></p>
<p>프로그램에게 바둑의 규칙만 알려주고, 자기 대국을 통해 학습하게 했습니다. &#x27;제로&#x27;에서 시작하여, AlphaZero는 단 <strong>40일</strong>의 자기 훈련으로 이전의 모든 AlphaGo 버전을 초월했습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="통합된-지능">통합된 지능<a href="#통합된-지능" class="hash-link" aria-label="통합된 지능에 대한 직접 링크" title="통합된 지능에 대한 직접 링크">​</a></h3>
<p>더 놀라운 것은, 같은 AlphaZero 프로그램(게임 규칙만 변경)이 바둑, 체스, 일본 장기 세 가지 게임에서 모두 모든 인간과 이전 최강 프로그램을 초월하는 수준에 도달했다는 것입니다.</p>
<p>이것은 심층 강화 학습의 범용성을 증명했습니다 — 같은 알고리즘이 완전히 다른 지적 게임들을 마스터할 수 있습니다.</p>
<h2 class="anchor anchorWithStickyNavbar_BVHq" id="기술-해설">기술 해설<a href="#기술-해설" class="hash-link" aria-label="기술 해설에 대한 직접 링크" title="기술 해설에 대한 직접 링크">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="심층-신경망">심층 신경망<a href="#심층-신경망" class="hash-link" aria-label="심층 신경망에 대한 직접 링크" title="심층 신경망에 대한 직접 링크">​</a></h3>
<p>AlphaGo가 사용한 신경망에는 두 가지 주요 부분이 있습니다:</p>
<p><strong>정책 네트워크(Policy Network)</strong></p>
<ul>
<li>입력: 현재 바둑판 국면</li>
<li>출력: 각 위치의 착수 확률</li>
<li>기능: 인간의 &#x27;직관&#x27;을 시뮬레이션하여 탐색 범위를 빠르게 축소</li>
</ul>
<p><strong>가치 네트워크(Value Network)</strong></p>
<ul>
<li>입력: 현재 바둑판 국면</li>
<li>출력: 현재 국면의 승률 추정</li>
<li>기능: 국면의 좋고 나쁨을 평가하여 전통적인 완전 탐색을 대체</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="몬테카를로-트리-탐색mcts">몬테카를로 트리 탐색(MCTS)<a href="#몬테카를로-트리-탐색mcts" class="hash-link" aria-label="몬테카를로 트리 탐색(MCTS)에 대한 직접 링크" title="몬테카를로 트리 탐색(MCTS)에 대한 직접 링크">​</a></h3>
<p>MCTS는 다음 단계로 작동하는 탐색 알고리즘입니다:</p>
<ol>
<li><strong>선택(Selection)</strong>: 루트 노드에서 시작하여 특정 정책에 따라 자식 노드 선택</li>
<li><strong>확장(Expansion)</strong>: 리프 노드에서 새 자식 노드 추가</li>
<li><strong>시뮬레이션(Simulation)</strong>: 새 노드에서 시작하여 게임이 끝날 때까지 무작위 시뮬레이션 수행</li>
<li><strong>역전파(Backpropagation)</strong>: 시뮬레이션 결과를 위로 전달하여 경로상의 모든 노드 통계 업데이트</li>
</ol>
<p>AlphaGo의 혁신은 무작위 시뮬레이션을 신경망으로 대체하여 탐색 효율을 크게 높인 것입니다.</p>
<h3 class="anchor anchorWithStickyNavbar_BVHq" id="강화-학습">강화 학습<a href="#강화-학습" class="hash-link" aria-label="강화 학습에 대한 직접 링크" title="강화 학습에 대한 직접 링크">​</a></h3>
<p>AlphaGo Lee에서 AlphaZero까지, 강화 학습은 점점 더 중요한 역할을 했습니다:</p>
<ul>
<li><strong>AlphaGo Fan</strong> (판후이 격파): 주로 인간 기보 훈련에 의존</li>
<li><strong>AlphaGo Lee</strong> (이세돌 격파): 인간 기보 + 자기 대국</li>
<li><strong>AlphaGo Master</strong> (60연승): 강화된 자기 대국 훈련</li>
<li><strong>AlphaZero</strong>: 완전한 자기 대국, 인간 기보 불필요</li>
</ul>
<p>이 진화 과정은 AI가 궁극적으로 완전히 자기 학습에 의존하여 초인간 수준에 도달할 수 있음을 보여줍니다.</p>
<hr>
<p>AlphaGo 시대는 2017년에 끝났지만, 그것이 개척한 기술과 이념은 바둑과 인공지능 분야에 계속 영향을 미치고 있습니다. 이어지는 KataGo 시대는 이러한 기술을 모든 바둑 애호가의 컴퓨터와 휴대폰으로 가져왔습니다.</p>
<p>다음 편: <a href="/ko/docs/evolution/ai-history/katago-era/">KataGo 시대</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/evolution/ai-history/alphago-era.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_O1mQ" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_hyfO"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/evolution/ai-history/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">AI 바둑 발전사</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/evolution/ai-history/katago-era/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">KataGo 시대</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_tqik thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2015년-10월-alphago-판후이-격파" class="table-of-contents__link toc-highlight">2015년 10월: AlphaGo, 판후이 격파</a><ul><li><a href="#역사적인-비밀-대국" class="table-of-contents__link toc-highlight">역사적인 비밀 대국</a></li><li><a href="#초대-alphago의-기술" class="table-of-contents__link toc-highlight">초대 AlphaGo의 기술</a></li></ul></li><li><a href="#2016년-3월-alphago-vs-이세돌" class="table-of-contents__link toc-highlight">2016년 3월: AlphaGo vs 이세돌</a><ul><li><a href="#세기의-대결" class="table-of-contents__link toc-highlight">세기의 대결</a></li><li><a href="#대국-결과" class="table-of-contents__link toc-highlight">대국 결과</a></li><li><a href="#제2국-37수-신의-한-수" class="table-of-contents__link toc-highlight">제2국 37수: &#39;신의 한 수&#39;</a></li><li><a href="#제4국-78수-인류의-반격" class="table-of-contents__link toc-highlight">제4국 78수: 인류의 반격</a></li><li><a href="#대국의-영향" class="table-of-contents__link toc-highlight">대국의 영향</a></li></ul></li><li><a href="#2017년-1월-master-60연승" class="table-of-contents__link toc-highlight">2017년 1월: Master 60연승</a><ul><li><a href="#신비로운-온라인-기사" class="table-of-contents__link toc-highlight">신비로운 온라인 기사</a></li><li><a href="#master가-보여준-새로운-이념" class="table-of-contents__link toc-highlight">Master가 보여준 새로운 이념</a></li></ul></li><li><a href="#2017년-5월-alphago-vs-커제" class="table-of-contents__link toc-highlight">2017년 5월: AlphaGo vs 커제</a><ul><li><a href="#인류의-마지막-도전" class="table-of-contents__link toc-highlight">인류의 마지막 도전</a></li><li><a href="#대국-결과-1" class="table-of-contents__link toc-highlight">대국 결과</a></li><li><a href="#커제의-눈물" class="table-of-contents__link toc-highlight">커제의 눈물</a></li></ul></li><li><a href="#2017년-10월-alphazero-논문" class="table-of-contents__link toc-highlight">2017년 10월: AlphaZero 논문</a><ul><li><a href="#제로에서-시작한-초월" class="table-of-contents__link toc-highlight">제로에서 시작한 초월</a></li><li><a href="#통합된-지능" class="table-of-contents__link toc-highlight">통합된 지능</a></li></ul></li><li><a href="#기술-해설" class="table-of-contents__link toc-highlight">기술 해설</a><ul><li><a href="#심층-신경망" class="table-of-contents__link toc-highlight">심층 신경망</a></li><li><a href="#몬테카를로-트리-탐색mcts" class="table-of-contents__link toc-highlight">몬테카를로 트리 탐색(MCTS)</a></li><li><a href="#강화-학습" class="table-of-contents__link toc-highlight">강화 학습</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>