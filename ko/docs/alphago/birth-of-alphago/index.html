<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/birth-of-alphago" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">AlphaGo의 탄생 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/alphago/birth-of-alphago/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AlphaGo의 탄생 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="DeepMind 설립부터 Google 인수까지, AlphaGo가 하나의 무모한 아이디어에서 세상을 바꾼 AI로 거듭나기까지"><meta data-rh="true" property="og:description" content="DeepMind 설립부터 Google 인수까지, AlphaGo가 하나의 무모한 아이디어에서 세상을 바꾼 AI로 거듭나기까지"><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/alphago/birth-of-alphago/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/birth-of-alphago/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/birth-of-alphago/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/birth-of-alphago/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/birth-of-alphago/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/birth-of-alphago/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/birth-of-alphago/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/birth-of-alphago/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/birth-of-alphago/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/birth-of-alphago/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/birth-of-alphago/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/birth-of-alphago/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/birth-of-alphago/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/ko/docs/alphago/"},{"@type":"ListItem","position":2,"name":"AlphaGo의 탄생","item":"https://www.weiqi.kids/ko/docs/alphago/birth-of-alphago"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ko/assets/css/styles.f23bf74b.css">
<script src="/ko/assets/js/runtime~main.5f5dfa4d.js" defer="defer"></script>
<script src="/ko/assets/js/main.e347f1ed.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">바둑 키즈</b></a><a class="navbar__item navbar__link" href="/ko/docs/learn/">바둑 배우기</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/ko/docs/animations/">애니메이션 교실</a><a class="navbar__item navbar__link" href="/ko/docs/tech/">기술 문서</a><a class="navbar__item navbar__link" href="/ko/docs/about/">소개</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/"><span title="이용 안내" class="linkLabel_REp1">이용 안내</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ko/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="사이드바 분류 &#x27;AlphaGo&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/alphago/birth-of-alphago/"><span title="AlphaGo의 탄생" class="linkLabel_REp1">AlphaGo의 탄생</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/key-matches/"><span title="주요 대국 리뷰" class="linkLabel_REp1">주요 대국 리뷰</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/move-37/"><span title="&quot;신의 한 수&quot; 심층 분석" class="linkLabel_REp1">&quot;신의 한 수&quot; 심층 분석</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/why-go-is-hard/"><span title="바둑은 왜 어려운가?" class="linkLabel_REp1">바둑은 왜 어려운가?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/traditional-limits/"><span title="전통적 방법의 한계" class="linkLabel_REp1">전통적 방법의 한계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/board-representation/"><span title="바둑판 상태 표현" class="linkLabel_REp1">바둑판 상태 표현</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/policy-network/"><span title="Policy Network 상세 해설" class="linkLabel_REp1">Policy Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/value-network/"><span title="Value Network 상세 해설" class="linkLabel_REp1">Value Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/input-features/"><span title="입력 특성 설계" class="linkLabel_REp1">입력 특성 설계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/cnn-and-go/"><span title="CNN과 바둑의 결합" class="linkLabel_REp1">CNN과 바둑의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/supervised-learning/"><span title="지도 학습 단계" class="linkLabel_REp1">지도 학습 단계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/reinforcement-intro/"><span title="강화 학습 입문" class="linkLabel_REp1">강화 학습 입문</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/self-play/"><span title="자기 대국" class="linkLabel_REp1">자기 대국</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/mcts-neural-combo/"><span title="MCTS와 신경망의 결합" class="linkLabel_REp1">MCTS와 신경망의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/puct-formula/"><span title="PUCT 공식 상세" class="linkLabel_REp1">PUCT 공식 상세</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/alphago-zero/"><span title="AlphaGo Zero 개요" class="linkLabel_REp1">AlphaGo Zero 개요</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/dual-head-resnet/"><span title="이중 헤드 네트워크와 잔차 네트워크" class="linkLabel_REp1">이중 헤드 네트워크와 잔차 네트워크</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/training-from-scratch/"><span title="처음부터 훈련하는 과정" class="linkLabel_REp1">처음부터 훈련하는 과정</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/distributed-systems/"><span title="분산 시스템과 TPU" class="linkLabel_REp1">분산 시스템과 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/legacy-and-impact/"><span title="AlphaGo의 유산" class="linkLabel_REp1">AlphaGo의 유산</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="사이드바 분류 &#x27;學圍棋&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="사이드바 분류 &#x27;技術文件&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="사이드바 분류 &#x27;關於我們&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">AlphaGo의 탄생</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>AlphaGo의 탄생</h1></header>
<p>2016년 3월, AlphaGo가 4:1로 이세돌을 꺾었을 때, 전 세계가 물었습니다: 인공지능 역사를 바꾼 이 프로그램은 대체 어떻게 탄생했을까?</p>
<p>그 답은 한 체스 신동의 꿈에서 시작됩니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="deepmind의-설립">DeepMind의 설립<a href="#deepmind의-설립" class="hash-link" aria-label="DeepMind의 설립에 대한 직접 링크" title="DeepMind의 설립에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="demis-hassabis-신동에서-ai-선구자로">Demis Hassabis: 신동에서 AI 선구자로<a href="#demis-hassabis-신동에서-ai-선구자로" class="hash-link" aria-label="Demis Hassabis: 신동에서 AI 선구자로에 대한 직접 링크" title="Demis Hassabis: 신동에서 AI 선구자로에 대한 직접 링크" translate="no">​</a></h3>
<p><strong>Demis Hassabis</strong>는 DeepMind의 공동 창립자이자 CEO입니다. 그의 인생 경험은 마치 AlphaGo를 만들기 위해 준비된 것처럼 보입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="체스-신동">체스 신동<a href="#체스-신동" class="hash-link" aria-label="체스 신동에 대한 직접 링크" title="체스 신동에 대한 직접 링크" translate="no">​</a></h4>
<p>1975년 런던에서 태어난 Hassabis는 4살에 체스를 배웠고, 13살에 체스 마스터 등급(Elo 2300+)에 도달했습니다. 이는 영국 역사상 두 번째로 어린 나이에 이 수준에 도달한 기록입니다.</p>
<p>이 경험은 그에게 깊은 통찰을 주었습니다:</p>
<ul>
<li class=""><strong>보드 게임은 지능의 시금석이다</strong>: 체스는 계획, 직관, 패턴 인식이 필요합니다</li>
<li class=""><strong>인간 지능의 본질</strong>: 기사들은 어떻게 방대한 가능성 중에서 좋은 수를 찾을까?</li>
<li class=""><strong>컴퓨터의 한계</strong>: 1997년 딥 블루가 카스파로프를 이긴 것은 무차별 검색 덕분이지, 진정한 &quot;이해&quot;가 아니었습니다</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="게임-디자이너">게임 디자이너<a href="#게임-디자이너" class="hash-link" aria-label="게임 디자이너에 대한 직접 링크" title="게임 디자이너에 대한 직접 링크" translate="no">​</a></h4>
<p>17살에 Hassabis는 Bullfrog Productions(《파퓰러스》 창작자 Peter Molyneux가 설립한 게임 회사)에 합류하여 명작 게임 《테마 파크》 개발에 참여했습니다. 이 경험은 그에게 다음을 가르쳐 주었습니다:</p>
<ul>
<li class=""><strong>복잡한 시스템 설계 방법</strong>: 게임은 현실 세계를 단순화한 모델입니다</li>
<li class=""><strong>플레이어 행동 예측</strong>: AI는 인간의 의사결정 과정을 이해해야 합니다</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="인지-신경과학자">인지 신경과학자<a href="#인지-신경과학자" class="hash-link" aria-label="인지 신경과학자에 대한 직접 링크" title="인지 신경과학자에 대한 직접 링크" translate="no">​</a></h4>
<p>케임브리지 대학에서 컴퓨터 과학 학위를 받은 후, Hassabis는 UCL(University College London)에서 인지 신경과학 박사 학위를 받았습니다. 그의 연구 주제는: <strong>해마가 어떻게 인간이 상상하고 계획할 수 있게 하는가</strong>였습니다.</p>
<p>이 연구에서 발견한 것:</p>
<ul>
<li class="">인간의 기억과 상상은 같은 뇌 영역을 사용합니다</li>
<li class="">우리는 &quot;정신적 시간 여행&quot;을 통해 미래를 계획합니다</li>
<li class="">이 능력이 지능의 핵심일 수 있습니다</li>
</ul>
<p>이러한 통찰은 나중에 AlphaGo 설계에 직접적인 영향을 주었습니다—AI가 미래의 수를 &quot;상상&quot;하고 그로부터 학습할 수 있게 했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="공동-창립자">공동 창립자<a href="#공동-창립자" class="hash-link" aria-label="공동 창립자에 대한 직접 링크" title="공동 창립자에 대한 직접 링크" translate="no">​</a></h3>
<p>2010년, Hassabis는 두 명의 파트너와 함께 DeepMind를 설립했습니다:</p>
<table><thead><tr><th>창립자</th><th>배경</th><th>기여</th></tr></thead><tbody><tr><td><strong>Demis Hassabis</strong></td><td>신경과학, 게임 디자인</td><td>비전과 전략</td></tr><tr><td><strong>Shane Legg</strong></td><td>머신러닝 박사</td><td>AGI 이론적 기반</td></tr><tr><td><strong>Mustafa Suleyman</strong></td><td>사회적 기업가</td><td>비즈니스와 응용</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="지능을-해결하고-그것으로-모든-것을-해결한다">&quot;지능을 해결하고, 그것으로 모든 것을 해결한다&quot;<a href="#지능을-해결하고-그것으로-모든-것을-해결한다" class="hash-link" aria-label="&quot;지능을 해결하고, 그것으로 모든 것을 해결한다&quot;에 대한 직접 링크" title="&quot;지능을 해결하고, 그것으로 모든 것을 해결한다&quot;에 대한 직접 링크" translate="no">​</a></h3>
<p>DeepMind의 미션 선언문은:</p>
<blockquote>
<p><strong>&quot;Solve intelligence, and then use that to solve everything else.&quot;</strong></p>
<p>&quot;지능을 해결하고, 그것으로 다른 모든 문제를 해결한다.&quot;</p>
</blockquote>
<p>이것은 평범한 AI 회사가 아닙니다. 그들의 목표는 제품을 만드는 것이 아니라, <strong>범용 인공지능(AGI)</strong>—인간처럼 생각하고, 배우고, 모든 문제를 해결할 수 있는 AI를 만드는 것입니다.</p>
<p>왜 먼저 &quot;지능을 해결&quot;해야 할까요? AGI가 있으면 기후 변화, 질병, 에너지 등 인류 최대의 과제를 해결하는 데 도움이 될 수 있기 때문입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="초기-돌파구-atari-게임">초기 돌파구: Atari 게임<a href="#초기-돌파구-atari-게임" class="hash-link" aria-label="초기 돌파구: Atari 게임에 대한 직접 링크" title="초기 돌파구: Atari 게임에 대한 직접 링크" translate="no">​</a></h2>
<p>바둑에 도전하기 전에, DeepMind는 먼저 자신의 능력을 증명했습니다—AI로 Atari 게임을 플레이했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="dqn-게임을-배우는-ai">DQN: 게임을 배우는 AI<a href="#dqn-게임을-배우는-ai" class="hash-link" aria-label="DQN: 게임을 배우는 AI에 대한 직접 링크" title="DQN: 게임을 배우는 AI에 대한 직접 링크" translate="no">​</a></h3>
<p>2013년, DeepMind는 <strong>DQN(Deep Q-Network)</strong> 알고리즘을 발표했습니다. 이 AI는:</p>
<ol>
<li class=""><strong>화면 픽셀만 보고</strong>—게임 규칙을 알려주지 않습니다</li>
<li class=""><strong>스스로 게임을 배웁니다</strong>—시행착오를 통해</li>
<li class=""><strong>인간 수준에 도달</strong>—일부 게임에서는 인간을 초월합니다</li>
</ol>
<p>DQN은 《브레이크아웃》에서 인간이 발견하는 데 몇 시간이 걸리는 전략을 배웠습니다: <strong>터널을 파서 공이 블록 뒤로 가게 하여 한 번에 많은 블록을 없애는 것</strong>.</p>
<p>이것은 딥러닝 + 강화학습의 조합이 인간이 생각하지 못한 전략을 발견할 수 있다는 것을 증명했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-게임부터-시작했나">왜 게임부터 시작했나?<a href="#왜-게임부터-시작했나" class="hash-link" aria-label="왜 게임부터 시작했나?에 대한 직접 링크" title="왜 게임부터 시작했나?에 대한 직접 링크" translate="no">​</a></h3>
<p>Hassabis가 게임을 연구 플랫폼으로 선택한 이유는:</p>
<ol>
<li class=""><strong>통제 가능한 환경</strong>: 게임은 명확한 규칙과 목표가 있습니다</li>
<li class=""><strong>진전 측정 가능</strong>: AI 능력을 평가할 객관적인 점수가 있습니다</li>
<li class=""><strong>인간 기준</strong>: 인간 플레이어와 비교할 수 있습니다</li>
<li class=""><strong>다양성</strong>: 다른 게임은 다른 능력을 테스트합니다</li>
</ol>
<p>이 방법론은 나중에 바둑에도 사용되었습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="google의-인수">Google의 인수<a href="#google의-인수" class="hash-link" aria-label="Google의 인수에 대한 직접 링크" title="Google의 인수에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="5억-달러의-베팅">5억 달러의 베팅<a href="#5억-달러의-베팅" class="hash-link" aria-label="5억 달러의 베팅에 대한 직접 링크" title="5억 달러의 베팅에 대한 직접 링크" translate="no">​</a></h3>
<p>2014년 1월, Google은 약 <strong>5억 달러</strong>에 DeepMind를 인수했습니다. 이것은 당시 AI 분야에서 가장 큰 인수 중 하나였습니다.</p>
<p>왜 Google은 직원 75명에 제품도 없는 회사에 이렇게 많은 돈을 지불했을까요?</p>
<p>답은 <strong>게임 이론</strong>에 있습니다:</p>
<ul>
<li class=""><strong>Facebook도 입찰 중이었습니다</strong>: Facebook이 4억 달러를 제안했다는 소문이 있었습니다</li>
<li class=""><strong>AI는 미래의 핵심 기술입니다</strong>: AI를 먼저 장악하는 자가 미래를 장악합니다</li>
<li class=""><strong>DeepMind는 최고의 팀입니다</strong>: 그들은 심층 강화학습의 가능성을 증명했습니다</li>
</ul>
<p>Google CEO Larry Page가 직접 나서서 Hassabis를 설득하여 Facebook 대신 Google을 선택하게 했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="인수-조건">인수 조건<a href="#인수-조건" class="hash-link" aria-label="인수 조건에 대한 직접 링크" title="인수 조건에 대한 직접 링크" translate="no">​</a></h3>
<p>Hassabis는 협상에서 몇 가지 핵심 조건을 얻어냈습니다:</p>
<ol>
<li class=""><strong>독립 운영</strong>: DeepMind는 런던 본사를 유지하며 독립적으로 연구개발</li>
<li class=""><strong>학술적 자유</strong>: 논문 발표 가능, 모든 것을 비밀로 할 필요 없음</li>
<li class=""><strong>윤리 위원회</strong>: AI 윤리 심사 메커니즘 설립</li>
<li class=""><strong>장기 연구</strong>: 단기 상업화 압박 없음</li>
</ol>
<p>이러한 조건 덕분에 DeepMind는 장기적이고 고위험 연구를 추구할 수 있었습니다—예를 들어 AI로 바둑을 정복하는 것.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="google의-ai-전략">Google의 AI 전략<a href="#google의-ai-전략" class="hash-link" aria-label="Google의 AI 전략에 대한 직접 링크" title="Google의 AI 전략에 대한 직접 링크" translate="no">​</a></h3>
<p>DeepMind 인수는 Google &quot;AI 우선&quot; 전략의 일부였습니다:</p>
<table><thead><tr><th>시간</th><th>사건</th></tr></thead><tbody><tr><td>2011</td><td>Google Brain 설립</td></tr><tr><td>2013</td><td>DNNresearch(Hinton 팀) 인수</td></tr><tr><td>2014</td><td>DeepMind 인수</td></tr><tr><td>2015</td><td>TensorFlow 오픈소스화</td></tr><tr><td>2016</td><td>TPU 발표</td></tr></tbody></table>
<p>Google은 인식했습니다: 검색, 광고, 번역, 음성—모든 핵심 비즈니스가 AI에 의해 재편될 것입니다. 최고의 AI를 가진 자가 승자입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="바둑을-목표로-선택">바둑을 목표로 선택<a href="#바둑을-목표로-선택" class="hash-link" aria-label="바둑을 목표로 선택에 대한 직접 링크" title="바둑을 목표로 선택에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-바둑인가">왜 바둑인가?<a href="#왜-바둑인가" class="hash-link" aria-label="왜 바둑인가?에 대한 직접 링크" title="왜 바둑인가?에 대한 직접 링크" translate="no">​</a></h3>
<p>Google에 인수된 후, DeepMind는 더 많은 리소스를 갖게 되었습니다. Hassabis는 불가능해 보이는 목표에 도전하기로 결정했습니다: <strong>AI로 인간 바둑 챔피언을 이기는 것</strong>.</p>
<p>왜 다른 문제가 아닌 바둑을 선택했을까요?</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-바둑은-ai의-성배">1. 바둑은 &quot;AI의 성배&quot;<a href="#1-바둑은-ai의-성배" class="hash-link" aria-label="1. 바둑은 &quot;AI의 성배&quot;에 대한 직접 링크" title="1. 바둑은 &quot;AI의 성배&quot;에 대한 직접 링크" translate="no">​</a></h4>
<p>2016년 이전, 전문가들은 AI가 바둑에서 인간을 이기려면 최소 10-20년이 걸릴 것이라고 생각했습니다. 바둑은 &quot;AI의 마지막 보루&quot;라고 불렸습니다.</p>
<p>이유:</p>
<ul>
<li class=""><strong>탐색 공간이 거대</strong>: 10^170가지 가능한 국면(우주의 원자 수는 10^80에 불과)</li>
<li class=""><strong>평가가 어려움</strong>: 체스처럼 명확한 기물 가치가 없음</li>
<li class=""><strong>직관에 의존</strong>: 정상급 기사들은 종종 &quot;이 수가 맞는 느낌&quot;이라고 말하지만 이유를 설명하지 못함</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-딥-블루의-교훈">2. 딥 블루의 교훈<a href="#2-딥-블루의-교훈" class="hash-link" aria-label="2. 딥 블루의 교훈에 대한 직접 링크" title="2. 딥 블루의 교훈에 대한 직접 링크" translate="no">​</a></h4>
<p>1997년, IBM의 딥 블루(Deep Blue)가 체스 세계 챔피언 카스파로프를 이겼습니다. 하지만 이 승리에는 논쟁이 있었습니다:</p>
<ul>
<li class="">딥 블루는 <strong>무차별 검색</strong>에 의존(초당 2억 개의 포지션 평가)</li>
<li class=""><strong>인간 전문가가 설계한 평가 함수</strong> 사용</li>
<li class="">이것은 진정한 &quot;지능&quot;이 아니라 &quot;계산력&quot;</li>
</ul>
<p>Hassabis는 증명하고 싶었습니다: AI는 무차별 검색이 아닌 <strong>학습</strong>으로 문제를 해결할 수 있습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-측정-가능한-목표">3. 측정 가능한 목표<a href="#3-측정-가능한-목표" class="hash-link" aria-label="3. 측정 가능한 목표에 대한 직접 링크" title="3. 측정 가능한 목표에 대한 직접 링크" translate="no">​</a></h4>
<p>바둑은 국제 랭킹 시스템(Elo rating)과 프로 기사가 있어 객관적인 측정 기준을 제공합니다. AI가 세계 챔피언을 이기면 그것은 논쟁의 여지 없는 성공입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="4-신경과학과의-연결">4. 신경과학과의 연결<a href="#4-신경과학과의-연결" class="hash-link" aria-label="4. 신경과학과의 연결에 대한 직접 링크" title="4. 신경과학과의 연결에 대한 직접 링크" translate="no">​</a></h4>
<p>인간 기사의 직관—바둑판을 한 번 보면 어떤 위치가 중요한지 아는 것—은 정확히 Hassabis가 AI로 복제하고 싶은 능력이었습니다. 바둑은 &quot;기계 직관&quot;을 테스트하기에 완벽한 시나리오입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-팀">AlphaGo 팀<a href="#alphago-팀" class="hash-link" aria-label="AlphaGo 팀에 대한 직접 링크" title="AlphaGo 팀에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="핵심-인물">핵심 인물<a href="#핵심-인물" class="hash-link" aria-label="핵심 인물에 대한 직접 링크" title="핵심 인물에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 성공은 다학제 배경을 가진 팀에서 비롯되었습니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="david-silver-수석-연구원">David Silver: 수석 연구원<a href="#david-silver-수석-연구원" class="hash-link" aria-label="David Silver: 수석 연구원에 대한 직접 링크" title="David Silver: 수석 연구원에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>David Silver</strong>는 AlphaGo 논문의 제1저자이자 강화학습 분야의 최고 전문가입니다.</p>
<ul>
<li class=""><strong>배경</strong>: 케임브리지 대학 수학과 졸업, 앨버타 대학 RL 박사</li>
<li class=""><strong>지도교수</strong>: Richard Sutton(강화학습의 아버지)</li>
<li class=""><strong>전문 분야</strong>: 몬테카를로 트리 탐색, 시간차 학습</li>
</ul>
<p>Silver는 박사 논문에서 이미 컴퓨터 바둑을 연구했지만, 당시 기술은 성숙하지 않았습니다. DeepMind에 합류한 후, 그는 마침내 이 꿈을 실현할 기회를 얻었습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="aja-huang-바둑-전문가">Aja Huang: 바둑 전문가<a href="#aja-huang-바둑-전문가" class="hash-link" aria-label="Aja Huang: 바둑 전문가에 대한 직접 링크" title="Aja Huang: 바둑 전문가에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>Aja Huang</strong>(황사걸)은 대만인으로, 아마추어 6단 기사이자 컴퓨터 바둑 분야의 선구자입니다.</p>
<ul>
<li class=""><strong>배경</strong>: 국립대만사범대학 컴퓨터공학 박사</li>
<li class=""><strong>전문 분야</strong>: 컴퓨터 바둑 프로그래밍</li>
<li class=""><strong>대표작</strong>: Erica(초기 컴퓨터 바둑 프로그램)</li>
</ul>
<p>Huang은 AlphaGo 팀에서 핵심적인 역할을 했습니다: 그는 바둑뿐만 아니라 AI도 이해했습니다. 이세돌과의 대국에서 그는 실제로 AlphaGo를 조작한 사람입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="다른-주요-멤버">다른 주요 멤버<a href="#다른-주요-멤버" class="hash-link" aria-label="다른 주요 멤버에 대한 직접 링크" title="다른 주요 멤버에 대한 직접 링크" translate="no">​</a></h4>
<table><thead><tr><th>멤버</th><th>역할</th></tr></thead><tbody><tr><td>Chris J. Maddison</td><td>몬테카를로 트리 탐색 전문가</td></tr><tr><td>Arthur Guez</td><td>강화학습 연구원</td></tr><tr><td>Laurent Sifre</td><td>딥러닝 엔지니어</td></tr><tr><td>George van den Driessche</td><td>분산 시스템 엔지니어</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다학제-협력">다학제 협력<a href="#다학제-협력" class="hash-link" aria-label="다학제 협력에 대한 직접 링크" title="다학제 협력에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 성공은 <strong>다학제 협력</strong>의 힘을 증명했습니다:</p>
<ul>
<li class=""><strong>바둑 전문가</strong>가 도메인 지식 제공</li>
<li class=""><strong>머신러닝 연구원</strong>이 알고리즘 설계</li>
<li class=""><strong>엔지니어</strong>가 대규모 훈련 시스템 구현</li>
<li class=""><strong>신경과학자</strong>가 이론적 영감 제공</li>
</ul>
<p>이러한 팀 구성은 나중에 DeepMind의 표준 모델이 되었습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="nature-논문-발표">Nature 논문 발표<a href="#nature-논문-발표" class="hash-link" aria-label="Nature 논문 발표에 대한 직접 링크" title="Nature 논문 발표에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="비밀의-서프라이즈">비밀의 서프라이즈<a href="#비밀의-서프라이즈" class="hash-link" aria-label="비밀의 서프라이즈에 대한 직접 링크" title="비밀의 서프라이즈에 대한 직접 링크" translate="no">​</a></h3>
<p>2016년 1월 27일, DeepMind는 최고 학술 저널 《Nature》에 논문을 발표했습니다:</p>
<blockquote>
<p><strong>&quot;Mastering the game of Go with deep neural networks and tree search&quot;</strong></p>
</blockquote>
<p>논문은 AlphaGo가 이미:</p>
<ol>
<li class="">다른 모든 바둑 프로그램을 이겼다고 발표</li>
<li class=""><strong>5:0</strong>으로 유럽 챔피언 <strong>판후이</strong>(프로 2단)를 이겼다고 발표</li>
</ol>
<p>이 뉴스는 세계를 충격에 빠뜨렸습니다. 논문이 발표되기 전까지 아무도 DeepMind가 바둑을 연구하고 있다는 것을 몰랐습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="논문의-핵심-기여">논문의 핵심 기여<a href="#논문의-핵심-기여" class="hash-link" aria-label="논문의 핵심 기여에 대한 직접 링크" title="논문의 핵심 기여에 대한 직접 링크" translate="no">​</a></h3>
<p>《Nature》 논문은 AlphaGo의 세 가지 주요 혁신을 설명했습니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-policy-network정책-신경망">1. Policy Network(정책 신경망)<a href="#1-policy-network정책-신경망" class="hash-link" aria-label="1. Policy Network(정책 신경망)에 대한 직접 링크" title="1. Policy Network(정책 신경망)에 대한 직접 링크" translate="no">​</a></h4>
<p>딥 컨볼루션 신경망을 사용하여 인간 기사의 다음 수를 예측합니다. 훈련 데이터는 <strong>3천만 국</strong>의 인간 기보에서 가져왔습니다.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">정확도: 57%(인간 전문가의 다음 수 예측)</span><br></span></code></pre></div></div>
<p>이것은 이전 최고의 컴퓨터 바둑 프로그램보다 10퍼센트 포인트 이상 높았습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-value-network가치-신경망">2. Value Network(가치 신경망)<a href="#2-value-network가치-신경망" class="hash-link" aria-label="2. Value Network(가치 신경망)에 대한 직접 링크" title="2. Value Network(가치 신경망)에 대한 직접 링크" translate="no">​</a></h4>
<p>또 다른 신경망을 사용하여 현재 국면의 승률을 평가합니다. 이것은 전통적인 랜덤 시뮬레이션(Monte Carlo rollout)을 대체했습니다.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">정밀도: 15000번의 랜덤 시뮬레이션과 동등하지만, 계산 속도는 15000배 빠름</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-몬테카를로-트리-탐색-통합">3. 몬테카를로 트리 탐색 통합<a href="#3-몬테카를로-트리-탐색-통합" class="hash-link" aria-label="3. 몬테카를로 트리 탐색 통합에 대한 직접 링크" title="3. 몬테카를로 트리 탐색 통합에 대한 직접 링크" translate="no">​</a></h4>
<p>두 신경망을 MCTS 프레임워크에 통합:</p>
<ul>
<li class="">Policy Network가 탐색 방향을 안내</li>
<li class="">Value Network가 리프 노드를 평가</li>
</ul>
<p>이것은 AlphaGo에게 &quot;직관&quot;(신경망)과 &quot;추론&quot;(트리 탐색) 모두를 갖게 했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="학계의-반응">학계의 반응<a href="#학계의-반응" class="hash-link" aria-label="학계의 반응에 대한 직접 링크" title="학계의 반응에 대한 직접 링크" translate="no">​</a></h3>
<p>논문 발표 후, 학계는 열띤 반응을 보였습니다:</p>
<blockquote>
<p>&quot;이것은 인공지능의 달 착륙 순간입니다.&quot;
— <strong>Stuart Russell</strong>, UC Berkeley 교수, AI 교과서 저자</p>
</blockquote>
<blockquote>
<p>&quot;저는 원래 10년은 더 걸릴 것이라고 생각했는데, 이렇게 빠를 줄 몰랐습니다.&quot;
— <strong>Martin Müller</strong>, 컴퓨터 바둑 전문가</p>
</blockquote>
<p>하지만 회의적인 시각도 있었습니다:</p>
<blockquote>
<p>&quot;판후이는 프로 2단일 뿐, 진정한 정상급 기사가 아닙니다. AlphaGo가 이세돌과 한판 두면 다시 이야기합시다.&quot;</p>
</blockquote>
<p>DeepMind는 이 도전을 받아들였습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="이세돌에게-도전">이세돌에게 도전<a href="#이세돌에게-도전" class="hash-link" aria-label="이세돌에게 도전에 대한 직접 링크" title="이세돌에게 도전에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-이세돌인가">왜 이세돌인가?<a href="#왜-이세돌인가" class="hash-link" aria-label="왜 이세돌인가?에 대한 직접 링크" title="왜 이세돌인가?에 대한 직접 링크" translate="no">​</a></h3>
<p><strong>이세돌</strong>(Lee Sedol)은 한국 기사로, 당시 지난 10년간 가장 강한 기사 중 한 명으로 여겨졌습니다:</p>
<table><thead><tr><th>지표</th><th>데이터</th></tr></thead><tbody><tr><td>세계 챔피언 타이틀</td><td>18개</td></tr><tr><td>국제전 우승</td><td>32개</td></tr><tr><td>최고 세계 랭킹</td><td>1위</td></tr><tr><td>스타일</td><td>&quot;천재&quot; &quot;신산&quot;</td></tr></tbody></table>
<p>이세돌을 선택함으로써, DeepMind는 가장 강한 인간 상대에게 도전하는 것이었습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="100만-달러-상금">100만 달러 상금<a href="#100만-달러-상금" class="hash-link" aria-label="100만 달러 상금에 대한 직접 링크" title="100만 달러 상금에 대한 직접 링크" translate="no">​</a></h3>
<p>Google은 이 대국에 <strong>100만 달러</strong> 상금을 제공했습니다:</p>
<ul>
<li class="">이세돌이 이기면: 상금은 이세돌에게</li>
<li class="">AlphaGo가 이기면: 상금은 UNICEF, STEM 교육 등 자선 단체에 기부</li>
</ul>
<p>이것은 단순한 기술 시연이 아니라, 전 세계가 주목하는 스포츠 이벤트이기도 했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="대국-전-예측">대국 전 예측<a href="#대국-전-예측" class="hash-link" aria-label="대국 전 예측에 대한 직접 링크" title="대국 전 예측에 대한 직접 링크" translate="no">​</a></h3>
<p>대국 전, 대부분의 프로 기사들은 이세돌이 쉽게 이길 것이라고 예측했습니다:</p>
<blockquote>
<p>&quot;AlphaGo가 한 판 이길 수도 있지만, 5번기에서 저는 5:0으로 이길 것입니다.&quot;
— <strong>이세돌</strong>, 대국 전 인터뷰</p>
</blockquote>
<blockquote>
<p>&quot;컴퓨터는 바둑을 딱딱하게 두기 때문에, 정상급 기사가 약점을 찾기 쉽습니다.&quot;
— 어느 프로 9단</p>
</blockquote>
<p>하지만 DeepMind 팀은 다른 견해를 가지고 있었습니다. David Silver는 나중에 밝혔습니다:</p>
<blockquote>
<p>&quot;내부 테스트에서 우리는 이미 AlphaGo가 판후이 버전과 500판을 두게 했습니다. 새 버전이 499판을 이겼습니다.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="2016년-3월-세상을-바꾼-다섯-판의-바둑">2016년 3월: 세상을 바꾼 다섯 판의 바둑<a href="#2016년-3월-세상을-바꾼-다섯-판의-바둑" class="hash-link" aria-label="2016년 3월: 세상을 바꾼 다섯 판의 바둑에 대한 직접 링크" title="2016년 3월: 세상을 바꾼 다섯 판의 바둑에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="제1국-충격의-시작">제1국: 충격의 시작<a href="#제1국-충격의-시작" class="hash-link" aria-label="제1국: 충격의 시작에 대한 직접 링크" title="제1국: 충격의 시작에 대한 직접 링크" translate="no">​</a></h3>
<p>2016년 3월 9일, 서울 포시즌스 호텔.</p>
<p>이세돌이 흑을 잡고 선공했고, AlphaGo가 백을 잡았습니다. 3시간 28분의 대국 끝에, AlphaGo가 중반 불계승으로 이겼습니다.</p>
<p>이것은 인간 정상급 기사가 처음으로 공식적으로 AI에게 진 것입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="제2국-신의-한-수">제2국: 신의 한 수<a href="#제2국-신의-한-수" class="hash-link" aria-label="제2국: 신의 한 수에 대한 직접 링크" title="제2국: 신의 한 수에 대한 직접 링크" translate="no">​</a></h3>
<p>제2국에서는 &quot;<strong>신의 한 수</strong>&quot;로 불리는 37수가 탄생했습니다—AlphaGo가 5선에 어깨짚기를 두었고, 모든 프로 기사들이 실수라고 생각했지만, 결과적으로 승리의 관건이 되었습니다.</p>
<p>(다음 글 참조: <a class="" href="/ko/docs/alphago/move-37/">&quot;신의 한 수&quot; 심층 분석</a>)</p>
<p>AlphaGo가 다시 승리했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="제3국-30">제3국: 3:0<a href="#제3국-30" class="hash-link" aria-label="제3국: 3:0에 대한 직접 링크" title="제3국: 3:0에 대한 직접 링크" translate="no">​</a></h3>
<p>제3국에서 이세돌은 비전통적인 포석을 시도했지만, AlphaGo는 자연스럽게 대응했습니다. 3:0.</p>
<p>전 세계가 인식하기 시작했습니다: 이것은 우연이 아니라, AI가 정말로 인간을 초월했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="제4국-인간의-반격">제4국: 인간의 반격<a href="#제4국-인간의-반격" class="hash-link" aria-label="제4국: 인간의 반격에 대한 직접 링크" title="제4국: 인간의 반격에 대한 직접 링크" translate="no">​</a></h3>
<p>제4국에서 이세돌은 &quot;<strong>신의 한 수</strong>&quot;로 불리는 78수를 두었습니다—절묘한 끊기로, AlphaGo를 혼란에 빠뜨렸습니다.</p>
<p>AlphaGo는 이후 몇 수에서 명백한 악수를 두었고, 결국 항복했습니다.</p>
<p>이 승리는 증명했습니다: AI에게도 약점이 있습니다. 이세돌이 그것을 찾았습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="제5국-최종-결과">제5국: 최종 결과<a href="#제5국-최종-결과" class="hash-link" aria-label="제5국: 최종 결과에 대한 직접 링크" title="제5국: 최종 결과에 대한 직접 링크" translate="no">​</a></h3>
<p>제5국에서 AlphaGo는 정상으로 돌아와 중반 불계승으로 대국을 끝냈습니다.</p>
<p><strong>최종 결과: AlphaGo 4:1 이세돌</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="영향과-여파">영향과 여파<a href="#영향과-여파" class="hash-link" aria-label="영향과 여파에 대한 직접 링크" title="영향과 여파에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="전-세계의-관심">전 세계의 관심<a href="#전-세계의-관심" class="hash-link" aria-label="전 세계의 관심에 대한 직접 링크" title="전 세계의 관심에 대한 직접 링크" translate="no">​</a></h3>
<p>이 대국의 영향은 바둑계를 훨씬 넘어섰습니다:</p>
<ul>
<li class=""><strong>전 세계 2억 명</strong>이 생중계를 시청</li>
<li class="">《뉴욕 타임스》, 《이코노미스트》 등 주요 언론이 대대적으로 보도</li>
<li class="">Google 주가가 대국 기간 동안 상승</li>
<li class="">&quot;인공지능&quot;이 그해 가장 핫한 기술 화제가 됨</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="바둑계에-대한-영향">바둑계에 대한 영향<a href="#바둑계에-대한-영향" class="hash-link" aria-label="바둑계에 대한 영향에 대한 직접 링크" title="바둑계에 대한 영향에 대한 직접 링크" translate="no">​</a></h3>
<p>대국 후, 프로 기사들의 태도는 &quot;경시&quot;에서 &quot;경외&quot;로 바뀌었습니다:</p>
<blockquote>
<p>&quot;우리는 예전에 인간이 바둑을 이해한다고 생각했는데, 지금 보니 우리는 겉핥기만 했습니다.&quot;
— <strong>커제</strong>, 중국 기사, 당시 세계 랭킹 1위</p>
</blockquote>
<p>많은 프로 기사들이 AI를 사용하여 훈련하기 시작했고, 바둑의 두는 방식도 이로 인해 변했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ai-분야에-대한-영향">AI 분야에 대한 영향<a href="#ai-분야에-대한-영향" class="hash-link" aria-label="AI 분야에 대한 영향에 대한 직접 링크" title="AI 분야에 대한 영향에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo는 몇 가지를 증명했습니다:</p>
<ol>
<li class=""><strong>딥러닝은 전문가 수준의 문제를 해결할 수 있습니다</strong>: 고양이와 개를 인식하는 것뿐 아니라, 바둑도 둘 수 있습니다</li>
<li class=""><strong>강화학습은 인간을 초월할 수 있습니다</strong>: 자가 대국을 통해 AI는 인간이 모르는 전략을 발견할 수 있습니다</li>
<li class=""><strong>신경망 + 탐색은 강력한 조합입니다</strong>: 직관 + 추론 = 더 강한 지능</li>
</ol>
<p>이러한 통찰은 나중에 다음에 응용되었습니다:</p>
<ul>
<li class=""><strong>AlphaFold</strong>: 단백질 구조 예측(2020 노벨상급 업적)</li>
<li class=""><strong>AlphaZero</strong>: 범용 게임 AI</li>
<li class=""><strong>MuZero</strong>: 규칙 없이 학습</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="애니메이션-대응">애니메이션 대응<a href="#애니메이션-대응" class="hash-link" aria-label="애니메이션 대응에 대한 직접 링크" title="애니메이션 대응에 대한 직접 링크" translate="no">​</a></h2>
<p>본 글에서 다루는 핵심 개념과 애니메이션 번호:</p>
<table><thead><tr><th>번호</th><th>개념</th><th>물리/수학 대응</th></tr></thead><tbody><tr><td>E7</td><td>제로부터 시작</td><td>자기 조직화</td></tr><tr><td>E5</td><td>자가 대국</td><td>고정점 수렴</td></tr><tr><td>F8</td><td>창발 능력</td><td>상전이</td></tr><tr><td>H4</td><td>정책 경사법</td><td>확률적 최적화</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="추가-읽기">추가 읽기<a href="#추가-읽기" class="hash-link" aria-label="추가 읽기에 대한 직접 링크" title="추가 읽기에 대한 직접 링크" translate="no">​</a></h2>
<ul>
<li class=""><strong>다음 글</strong>: <a class="" href="/ko/docs/alphago/key-matches/">주요 대국 회고</a> — 판후이, 이세돌, 커제의 완전한 대국 분석</li>
<li class=""><strong>기술 세부 사항</strong>: <a class="" href="/ko/docs/alphago/policy-network/">Policy Network 상세 해설</a> — AlphaGo가 어떻게 바둑을 배웠는지</li>
<li class=""><strong>직접 실습</strong>: <a class="" href="/ko/docs/tech/hands-on/">30분 만에 첫 바둑 AI 실행하기</a> — 직접 체험</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="참고-자료">참고 자료<a href="#참고-자료" class="hash-link" aria-label="참고 자료에 대한 직접 링크" title="참고 자료에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Mnih, V., et al. (2015). &quot;Human-level control through deep reinforcement learning.&quot; <em>Nature</em>, 518, 529-533.</li>
<li class="">Hassabis, D. (2017). &quot;Artificial Intelligence: Chess match of the century.&quot; <em>Nature</em>, 544, 413-414.</li>
<li class="">《AlphaGo》 다큐멘터리 (2017), 감독 Greg Kohs.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/01-birth-of-alphago.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/alphago/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">AlphaGo</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/alphago/key-matches/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">주요 대국 리뷰</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#deepmind의-설립" class="table-of-contents__link toc-highlight">DeepMind의 설립</a><ul><li><a href="#demis-hassabis-신동에서-ai-선구자로" class="table-of-contents__link toc-highlight">Demis Hassabis: 신동에서 AI 선구자로</a></li><li><a href="#공동-창립자" class="table-of-contents__link toc-highlight">공동 창립자</a></li><li><a href="#지능을-해결하고-그것으로-모든-것을-해결한다" class="table-of-contents__link toc-highlight">&quot;지능을 해결하고, 그것으로 모든 것을 해결한다&quot;</a></li></ul></li><li><a href="#초기-돌파구-atari-게임" class="table-of-contents__link toc-highlight">초기 돌파구: Atari 게임</a><ul><li><a href="#dqn-게임을-배우는-ai" class="table-of-contents__link toc-highlight">DQN: 게임을 배우는 AI</a></li><li><a href="#왜-게임부터-시작했나" class="table-of-contents__link toc-highlight">왜 게임부터 시작했나?</a></li></ul></li><li><a href="#google의-인수" class="table-of-contents__link toc-highlight">Google의 인수</a><ul><li><a href="#5억-달러의-베팅" class="table-of-contents__link toc-highlight">5억 달러의 베팅</a></li><li><a href="#인수-조건" class="table-of-contents__link toc-highlight">인수 조건</a></li><li><a href="#google의-ai-전략" class="table-of-contents__link toc-highlight">Google의 AI 전략</a></li></ul></li><li><a href="#바둑을-목표로-선택" class="table-of-contents__link toc-highlight">바둑을 목표로 선택</a><ul><li><a href="#왜-바둑인가" class="table-of-contents__link toc-highlight">왜 바둑인가?</a></li></ul></li><li><a href="#alphago-팀" class="table-of-contents__link toc-highlight">AlphaGo 팀</a><ul><li><a href="#핵심-인물" class="table-of-contents__link toc-highlight">핵심 인물</a></li><li><a href="#다학제-협력" class="table-of-contents__link toc-highlight">다학제 협력</a></li></ul></li><li><a href="#nature-논문-발표" class="table-of-contents__link toc-highlight">Nature 논문 발표</a><ul><li><a href="#비밀의-서프라이즈" class="table-of-contents__link toc-highlight">비밀의 서프라이즈</a></li><li><a href="#논문의-핵심-기여" class="table-of-contents__link toc-highlight">논문의 핵심 기여</a></li><li><a href="#학계의-반응" class="table-of-contents__link toc-highlight">학계의 반응</a></li></ul></li><li><a href="#이세돌에게-도전" class="table-of-contents__link toc-highlight">이세돌에게 도전</a><ul><li><a href="#왜-이세돌인가" class="table-of-contents__link toc-highlight">왜 이세돌인가?</a></li><li><a href="#100만-달러-상금" class="table-of-contents__link toc-highlight">100만 달러 상금</a></li><li><a href="#대국-전-예측" class="table-of-contents__link toc-highlight">대국 전 예측</a></li></ul></li><li><a href="#2016년-3월-세상을-바꾼-다섯-판의-바둑" class="table-of-contents__link toc-highlight">2016년 3월: 세상을 바꾼 다섯 판의 바둑</a><ul><li><a href="#제1국-충격의-시작" class="table-of-contents__link toc-highlight">제1국: 충격의 시작</a></li><li><a href="#제2국-신의-한-수" class="table-of-contents__link toc-highlight">제2국: 신의 한 수</a></li><li><a href="#제3국-30" class="table-of-contents__link toc-highlight">제3국: 3:0</a></li><li><a href="#제4국-인간의-반격" class="table-of-contents__link toc-highlight">제4국: 인간의 반격</a></li><li><a href="#제5국-최종-결과" class="table-of-contents__link toc-highlight">제5국: 최종 결과</a></li></ul></li><li><a href="#영향과-여파" class="table-of-contents__link toc-highlight">영향과 여파</a><ul><li><a href="#전-세계의-관심" class="table-of-contents__link toc-highlight">전 세계의 관심</a></li><li><a href="#바둑계에-대한-영향" class="table-of-contents__link toc-highlight">바둑계에 대한 영향</a></li><li><a href="#ai-분야에-대한-영향" class="table-of-contents__link toc-highlight">AI 분야에 대한 영향</a></li></ul></li><li><a href="#애니메이션-대응" class="table-of-contents__link toc-highlight">애니메이션 대응</a></li><li><a href="#추가-읽기" class="table-of-contents__link toc-highlight">추가 읽기</a></li><li><a href="#참고-자료" class="table-of-contents__link toc-highlight">참고 자료</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>