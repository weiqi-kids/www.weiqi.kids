<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/cnn-and-go" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">CNN과 바둑의 결합 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/alphago/cnn-and-go/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="CNN과 바둑의 결합 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="합성곱 신경망이 왜 바둑에 특히 적합한지, 수용 영역부터 배치 정규화까지 완전 분석"><meta data-rh="true" property="og:description" content="합성곱 신경망이 왜 바둑에 특히 적합한지, 수용 영역부터 배치 정규화까지 완전 분석"><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/alphago/cnn-and-go/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/cnn-and-go/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/cnn-and-go/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/cnn-and-go/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/cnn-and-go/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/cnn-and-go/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/cnn-and-go/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/cnn-and-go/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/cnn-and-go/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/cnn-and-go/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/cnn-and-go/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/cnn-and-go/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/cnn-and-go/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/ko/docs/alphago/"},{"@type":"ListItem","position":2,"name":"CNN과 바둑의 결합","item":"https://www.weiqi.kids/ko/docs/alphago/cnn-and-go"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ko/assets/css/styles.f23bf74b.css">
<script src="/ko/assets/js/runtime~main.5f5dfa4d.js" defer="defer"></script>
<script src="/ko/assets/js/main.e347f1ed.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">바둑 키즈</b></a><a class="navbar__item navbar__link" href="/ko/docs/learn/">바둑 배우기</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/ko/docs/animations/">애니메이션 교실</a><a class="navbar__item navbar__link" href="/ko/docs/tech/">기술 문서</a><a class="navbar__item navbar__link" href="/ko/docs/about/">소개</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/"><span title="이용 안내" class="linkLabel_REp1">이용 안내</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ko/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="사이드바 분류 &#x27;AlphaGo&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/birth-of-alphago/"><span title="AlphaGo의 탄생" class="linkLabel_REp1">AlphaGo의 탄생</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/key-matches/"><span title="주요 대국 리뷰" class="linkLabel_REp1">주요 대국 리뷰</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/move-37/"><span title="&quot;신의 한 수&quot; 심층 분석" class="linkLabel_REp1">&quot;신의 한 수&quot; 심층 분석</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/why-go-is-hard/"><span title="바둑은 왜 어려운가?" class="linkLabel_REp1">바둑은 왜 어려운가?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/traditional-limits/"><span title="전통적 방법의 한계" class="linkLabel_REp1">전통적 방법의 한계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/board-representation/"><span title="바둑판 상태 표현" class="linkLabel_REp1">바둑판 상태 표현</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/policy-network/"><span title="Policy Network 상세 해설" class="linkLabel_REp1">Policy Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/value-network/"><span title="Value Network 상세 해설" class="linkLabel_REp1">Value Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/input-features/"><span title="입력 특성 설계" class="linkLabel_REp1">입력 특성 설계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/alphago/cnn-and-go/"><span title="CNN과 바둑의 결합" class="linkLabel_REp1">CNN과 바둑의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/supervised-learning/"><span title="지도 학습 단계" class="linkLabel_REp1">지도 학습 단계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/reinforcement-intro/"><span title="강화 학습 입문" class="linkLabel_REp1">강화 학습 입문</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/self-play/"><span title="자기 대국" class="linkLabel_REp1">자기 대국</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/mcts-neural-combo/"><span title="MCTS와 신경망의 결합" class="linkLabel_REp1">MCTS와 신경망의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/puct-formula/"><span title="PUCT 공식 상세" class="linkLabel_REp1">PUCT 공식 상세</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/alphago-zero/"><span title="AlphaGo Zero 개요" class="linkLabel_REp1">AlphaGo Zero 개요</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/dual-head-resnet/"><span title="이중 헤드 네트워크와 잔차 네트워크" class="linkLabel_REp1">이중 헤드 네트워크와 잔차 네트워크</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/training-from-scratch/"><span title="처음부터 훈련하는 과정" class="linkLabel_REp1">처음부터 훈련하는 과정</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/distributed-systems/"><span title="분산 시스템과 TPU" class="linkLabel_REp1">분산 시스템과 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/alphago/legacy-and-impact/"><span title="AlphaGo의 유산" class="linkLabel_REp1">AlphaGo의 유산</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="사이드바 분류 &#x27;學圍棋&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="사이드바 분류 &#x27;技術文件&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="사이드바 분류 &#x27;關於我們&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">CNN과 바둑의 결합</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>CNN과 바둑의 결합</h1></header>
<p>DeepMind가 **합성곱 신경망(CNN)**을 사용하여 바둑을 처리하기로 결정한 것은 천재적인 설계 결정이었습니다.</p>
<p>CNN은 원래 이미지 인식을 위해 설계되었습니다. 왜 바둑에도 적합할까요? 이 글에서는 CNN의 작동 원리와 바둑과의 완벽한 조합에 대해 깊이 살펴보겠습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-cnn이-바둑판에-적합한가">왜 CNN이 바둑판에 적합한가?<a href="#왜-cnn이-바둑판에-적합한가" class="hash-link" aria-label="왜 CNN이 바둑판에 적합한가?에 대한 직접 링크" title="왜 CNN이 바둑판에 적합한가?에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="바둑판은-이미지이다">바둑판은 &#x27;이미지&#x27;이다<a href="#바둑판은-이미지이다" class="hash-link" aria-label="바둑판은 &#x27;이미지&#x27;이다에 대한 직접 링크" title="바둑판은 &#x27;이미지&#x27;이다에 대한 직접 링크" translate="no">​</a></h3>
<p>어떤 관점에서 보면, 19×19 바둑판은 하나의 <strong>이미지</strong>입니다:</p>
<table><thead><tr><th>이미지</th><th>바둑판</th></tr></thead><tbody><tr><td>픽셀</td><td>교차점</td></tr><tr><td>RGB 채널</td><td>특징 평면(흑, 백, 빈칸...)</td></tr><tr><td>224×224</td><td>19×19</td></tr><tr><td>개와 고양이 인식</td><td>좋은 수와 나쁜 수 판단</td></tr></tbody></table>
<p>이 비유는 우연이 아닙니다. CNN이 이미지에 뛰어난 이유가 바둑판에도 적용됩니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="세-가지-핵심-특성">세 가지 핵심 특성<a href="#세-가지-핵심-특성" class="hash-link" aria-label="세 가지 핵심 특성에 대한 직접 링크" title="세 가지 핵심 특성에 대한 직접 링크" translate="no">​</a></h3>
<p>CNN에는 바둑판 유형의 데이터에 특히 적합한 세 가지 특성이 있습니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-지역-연결local-connectivity">1. 지역 연결(Local Connectivity)<a href="#1-지역-연결local-connectivity" class="hash-link" aria-label="1. 지역 연결(Local Connectivity)에 대한 직접 링크" title="1. 지역 연결(Local Connectivity)에 대한 직접 링크" translate="no">​</a></h4>
<p>CNN의 합성곱 커널은 지역 영역만 봅니다. 이는 바둑의 특성과 완벽하게 일치합니다:</p>
<table><thead><tr><th>이미지 인식</th><th>바둑</th></tr></thead><tbody><tr><td>고양이 귀는 지역 특징</td><td>&#x27;집&#x27;은 지역 바둑 형태</td></tr><tr><td>전체 이미지를 볼 필요 없음</td><td>전체 바둑판을 볼 필요 없음</td></tr></tbody></table>
<p><strong>3×3 영역 예시 (집):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">○</td><td style="text-align:center">●</td><td style="text-align:center">○</td></tr><tr><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">●</td></tr><tr><td style="text-align:center">○</td><td style="text-align:center">●</td><td style="text-align:center">○</td></tr></tbody></table>
<p>많은 바둑 개념이 &#x27;지역적&#x27;입니다:</p>
<ul>
<li class=""><strong>집</strong>: 2×2 또는 3×3 영역</li>
<li class=""><strong>단수</strong>: 3×3 영역</li>
<li class=""><strong>연결, 끊기</strong>: 2×2 영역</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-가중치-공유weight-sharing">2. 가중치 공유(Weight Sharing)<a href="#2-가중치-공유weight-sharing" class="hash-link" aria-label="2. 가중치 공유(Weight Sharing)에 대한 직접 링크" title="2. 가중치 공유(Weight Sharing)에 대한 직접 링크" translate="no">​</a></h4>
<p>동일한 합성곱 커널이 전체 바둑판을 스캔합니다. 이는 다음을 의미합니다:</p>
<blockquote>
<p><strong>바둑판 왼쪽 상단의 &#x27;집&#x27;과 오른쪽 하단의 &#x27;집&#x27;을 같은 방식으로 인식한다</strong></p>
</blockquote>
<p>이것은 합리적입니다—바둑 규칙은 위치에 따라 다르지 않습니다(변과 귀는 예외지만, 변/귀 특징 평면으로 처리할 수 있습니다).</p>
<p>가중치 공유는 또한 파라미터 수를 크게 줄입니다:</p>
<table><thead><tr><th>방법</th><th>파라미터 수</th></tr></thead><tbody><tr><td>완전 연결 네트워크</td><td>361 × 361 × 채널 수 = 수천만</td></tr><tr><td>CNN</td><td>3 × 3 × 채널 수 × 필터 수 = 수백만</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-이동-등변성translation-equivariance">3. 이동 등변성(Translation Equivariance)<a href="#3-이동-등변성translation-equivariance" class="hash-link" aria-label="3. 이동 등변성(Translation Equivariance)에 대한 직접 링크" title="3. 이동 등변성(Translation Equivariance)에 대한 직접 링크" translate="no">​</a></h4>
<p>입력이 이동하면 CNN의 출력도 그에 맞게 이동합니다:</p>
<p><strong>입력:</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>2</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>출력 (고확률 영역):</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>2</td><td style="text-align:center">·</td><td style="text-align:center">*</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>입력 이동 후:</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>2</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>출력도 이동:</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>2</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">*</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p>이것은 바둑에서 매우 중요합니다: 동일한 지역 바둑 형태는 바둑판 어디에 나타나든 비슷한 평가를 받아야 합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="합성곱-연산">합성곱 연산<a href="#합성곱-연산" class="hash-link" aria-label="합성곱 연산에 대한 직접 링크" title="합성곱 연산에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="기본-원리">기본 원리<a href="#기본-원리" class="hash-link" aria-label="기본 원리에 대한 직접 링크" title="기본 원리에 대한 직접 링크" translate="no">​</a></h3>
<p>합성곱 연산은 CNN의 핵심입니다. 이것은 &#x27;슬라이딩 윈도우&#x27; 연산입니다:</p>
<!-- -->
<p>계산 과정(중심점을 예로):</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">출력[2,2] = 1×1 + 1×0 + 1×1 +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            1×0 + 1×1 + 1×0 +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            1×1 + 1×0 + 1×1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          = 5</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다중-채널-합성곱">다중 채널 합성곱<a href="#다중-채널-합성곱" class="hash-link" aria-label="다중 채널 합성곱에 대한 직접 링크" title="다중 채널 합성곱에 대한 직접 링크" translate="no">​</a></h3>
<p>입력에 여러 채널(예: 48개의 특징 평면)이 있을 때, 합성곱 커널도 3D가 됩니다:</p>
<!-- -->
<p>각 합성곱 커널은 모든 입력 채널에서 계산하여 하나의 출력 채널을 생성합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다중-필터">다중 필터<a href="#다중-필터" class="hash-link" aria-label="다중 필터에 대한 직접 링크" title="다중 필터에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo는 192개의 필터를 사용하며, 각 필터는 다른 특징을 학습합니다:</p>
<!-- -->
<p>각 필터는 다른 바둑 형태를 학습할 수 있습니다:</p>
<ul>
<li class="">필터 1: 집 감지</li>
<li class="">필터 2: 단점 감지</li>
<li class="">필터 3: 연결 감지</li>
<li class="">...</li>
<li class="">필터 192: 어떤 복잡한 패턴</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="수용-영역">수용 영역<a href="#수용-영역" class="hash-link" aria-label="수용 영역에 대한 직접 링크" title="수용 영역에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="수용-영역이란">수용 영역이란?<a href="#수용-영역이란" class="hash-link" aria-label="수용 영역이란?에 대한 직접 링크" title="수용 영역이란?에 대한 직접 링크" translate="no">​</a></h3>
<p>**수용 영역(Receptive Field)**은 출력의 한 위치가 입력의 어떤 위치들에 의해 영향을 받는지를 나타냅니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="단일-층-합성곱">단일 층 합성곱<a href="#단일-층-합성곱" class="hash-link" aria-label="단일 층 합성곱에 대한 직접 링크" title="단일 층 합성곱에 대한 직접 링크" translate="no">​</a></h4>
<p>3×3 합성곱 커널을 사용할 때, 출력의 각 위치는 입력의 3×3 영역에만 영향을 받습니다:</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="다중-층-합성곱">다중 층 합성곱<a href="#다중-층-합성곱" class="hash-link" aria-label="다중 층 합성곱에 대한 직접 링크" title="다중 층 합성곱에 대한 직접 링크" translate="no">​</a></h4>
<p>여러 층의 합성곱을 쌓으면 수용 영역이 확장됩니다:</p>
<table><thead><tr><th>층 수</th><th>수용 영역</th><th>계산</th></tr></thead><tbody><tr><td>1</td><td>3×3</td><td>3</td></tr><tr><td>2</td><td>5×5</td><td>3 + (3-1) = 5</td></tr><tr><td>3</td><td>7×7</td><td>5 + (3-1) = 7</td></tr><tr><td>...</td><td>...</td><td>...</td></tr><tr><td>12</td><td>25×25</td><td>3 + 11×2 = 25</td></tr></tbody></table>
<p>AlphaGo의 12층 합성곱은 <strong>25×25의 수용 영역</strong>을 제공하며, 이는 이미 19×19 바둑판을 초과합니다!</p>
<p>이것은 다음을 의미합니다:</p>
<ul>
<li class=""><strong>출력의 각 위치가 전체 바둑판을 &#x27;볼&#x27; 수 있다</strong></li>
<li class="">하지만 &#x27;보는&#x27; 방식이 다릅니다: 가까운 곳은 자세히, 먼 곳은 개괄적으로</li>
<li class="">이것은 인간 기사의 사고 방식과 유사합니다</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="수용-영역과-바둑">수용 영역과 바둑<a href="#수용-영역과-바둑" class="hash-link" aria-label="수용 영역과 바둑에 대한 직접 링크" title="수용 영역과 바둑에 대한 직접 링크" translate="no">​</a></h3>
<p>수용 영역의 개념은 AlphaGo가 &#x27;전역&#x27; 문제를 처리할 수 있는 이유를 설명합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">지역 문제(3×3 수용 영역):     전역 문제(25×25 수용 영역):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 여기에 집이 있는가?          - 이 그룹에 집이 있는가?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 단수를 부를 수 있는가?       - 축이 유리한가?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 연결할 수 있는가?            - 전체 형세가 어떠한가?</span><br></span></code></pre></div></div>
<p>얕은 층은 지역 특징을 처리하고, 깊은 층은 전역 특징을 처리합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="지역-vs-전역-특징">지역 vs 전역 특징<a href="#지역-vs-전역-특징" class="hash-link" aria-label="지역 vs 전역 특징에 대한 직접 링크" title="지역 vs 전역 특징에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="cnn의-계층-구조">CNN의 계층 구조<a href="#cnn의-계층-구조" class="hash-link" aria-label="CNN의 계층 구조에 대한 직접 링크" title="CNN의 계층 구조에 대한 직접 링크" translate="no">​</a></h3>
<p>CNN은 자연스럽게 계층 구조를 형성합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">입력층:        흑돌, 백돌, 빈칸</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">얕은 층 (1-3):    집, 연결, 끊기, 단수</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">중간 층 (4-8):    바둑 형태, 삶, 죽음</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">깊은 층 (9-12):   세력, 두께, 큰 장소</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">출력층:        착수 확률 / 승률</span><br></span></code></pre></div></div>
<p>이것은 인간이 바둑을 배우는 과정과 놀랍도록 유사합니다:</p>
<ol>
<li class="">먼저 규칙을 배운다(어디에 돌이 있는지)</li>
<li class="">그 다음 전술을 배운다(어떻게 돌을 잡는지)</li>
<li class="">그 다음 바둑 형태를 배운다(좋은 모양이 무엇인지)</li>
<li class="">마지막으로 대국관을 배운다(전체 판단)</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="은닉층-시각화">은닉층 시각화<a href="#은닉층-시각화" class="hash-link" aria-label="은닉층 시각화에 대한 직접 링크" title="은닉층 시각화에 대한 직접 링크" translate="no">​</a></h3>
<p>연구자들은 CNN의 은닉층이 실제로 의미 있는 특징을 학습한다는 것을 발견했습니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="얕은-층-필터">얕은 층 필터<a href="#얕은-층-필터" class="hash-link" aria-label="얕은 층 필터에 대한 직접 링크" title="얕은 층 필터에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>필터 A (집 감지):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td></tr></tbody></table>
<p><strong>필터 B (단수 감지):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="깊은-층-필터">깊은 층 필터<a href="#깊은-층-필터" class="hash-link" aria-label="깊은 층 필터에 대한 직접 링크" title="깊은 층 필터에 대한 직접 링크" translate="no">​</a></h4>
<p>깊은 층의 필터는 더 추상적이며 직접 설명하기 어렵지만, 복잡한 바둑 형태 패턴을 포착합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="활성화-함수-선택">활성화 함수 선택<a href="#활성화-함수-선택" class="hash-link" aria-label="활성화 함수 선택에 대한 직접 링크" title="활성화 함수 선택에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="relu-단순하지만-효과적">ReLU: 단순하지만 효과적<a href="#relu-단순하지만-효과적" class="hash-link" aria-label="ReLU: 단순하지만 효과적에 대한 직접 링크" title="ReLU: 단순하지만 효과적에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo는 모든 합성곱 층 뒤에 **ReLU(Rectified Linear Unit)**를 사용합니다:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><strong>ReLU 함수 동작:</strong></p>
<ul>
<li class="">음수 입력 값의 경우: 출력 = 0 (x축을 따라 수평선)</li>
<li class="">양수 입력 값의 경우: 출력 = 입력 (45도 상승선)</li>
<li class="">이 함수는 원점에서 시작하는 &#x27;경사&#x27;를 형성함</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-다른-함수를-사용하지-않는가">왜 다른 함수를 사용하지 않는가?<a href="#왜-다른-함수를-사용하지-않는가" class="hash-link" aria-label="왜 다른 함수를 사용하지 않는가?에 대한 직접 링크" title="왜 다른 함수를 사용하지 않는가?에 대한 직접 링크" translate="no">​</a></h3>
<table><thead><tr><th>활성화 함수</th><th>공식</th><th>장점</th><th>단점</th></tr></thead><tbody><tr><td>ReLU</td><td>max(0, x)</td><td>계산이 빠름, 좋은 기울기</td><td>음수 값 사망</td></tr><tr><td>Sigmoid</td><td>1/(1+e^-x)</td><td>출력이 제한됨</td><td>기울기 소실</td></tr><tr><td>Tanh</td><td>(e^x-e^-x)/(e^x+e^-x)</td><td>0 중심</td><td>기울기 소실</td></tr><tr><td>LeakyReLU</td><td>max(0.01x, x)</td><td>사망 문제 해결</td><td>하이퍼파라미터 추가</td></tr></tbody></table>
<p>깊은 네트워크에서 ReLU의 장점은 분명합니다:</p>
<ol>
<li class=""><strong>계산이 간단함</strong>: 비교와 최댓값만</li>
<li class=""><strong>기울기 소실 없음</strong>: 양의 영역에서 기울기가 항상 1</li>
<li class=""><strong>희소 활성화</strong>: 많은 뉴런이 0을 출력하여 효율성 향상</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="바둑에서-relu의-의미">바둑에서 ReLU의 의미<a href="#바둑에서-relu의-의미" class="hash-link" aria-label="바둑에서 ReLU의 의미에 대한 직접 링크" title="바둑에서 ReLU의 의미에 대한 직접 링크" translate="no">​</a></h3>
<p>ReLU의 희소성은 바둑에서 흥미로운 해석이 있습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">어떤 필터가 &#x27;단점&#x27;을 감지:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 단점 있음 → 양수 출력(활성화)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 단점 없음 → 0 출력(비활성화)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">이것은 기사가 &#x27;문제가 있는&#x27; 위치에만 주목하는 것과 같다</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="배치-정규화">배치 정규화<a href="#배치-정규화" class="hash-link" aria-label="배치 정규화에 대한 직접 링크" title="배치 정규화에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="배치-정규화란">배치 정규화란?<a href="#배치-정규화란" class="hash-link" aria-label="배치 정규화란?에 대한 직접 링크" title="배치 정규화란?에 대한 직접 링크" translate="no">​</a></h3>
<p>**배치 정규화(Batch Normalization)**는 각 층의 출력이 안정적인 분포를 유지하게 하는 기술입니다:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">batch_norm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> gamma</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> beta</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 배치의 평균과 표준편차 계산</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mean</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">std</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 정규화</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x_norm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> mean</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">std </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-8</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 스케일링과 이동</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> gamma </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> x_norm </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> beta</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-필요한가">왜 필요한가?<a href="#왜-필요한가" class="hash-link" aria-label="왜 필요한가?에 대한 직접 링크" title="왜 필요한가?에 대한 직접 링크" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="내부-공변량-이동">내부 공변량 이동<a href="#내부-공변량-이동" class="hash-link" aria-label="내부 공변량 이동에 대한 직접 링크" title="내부 공변량 이동에 대한 직접 링크" translate="no">​</a></h4>
<p>네트워크가 훈련될 때, 각 층의 입력 분포는 이전 층의 가중치 변화에 따라 변합니다. 이를 &#x27;내부 공변량 이동&#x27;이라고 합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">첫 번째 층 가중치 업데이트 → 첫 번째 층 출력 분포 변경</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               두 번째 층 입력 분포 변경 → 두 번째 층이 다시 적응해야 함</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                   ... (계속 전파됨)</span><br></span></code></pre></div></div>
<p>배치 정규화는 각 층의 입력이 고정된 분포(평균 0, 표준편차 1)를 갖도록 강제하여 훈련을 안정화합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago에서의-적용">AlphaGo에서의 적용<a href="#alphago에서의-적용" class="hash-link" aria-label="AlphaGo에서의 적용에 대한 직접 링크" title="AlphaGo에서의 적용에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo는 각 합성곱 층 뒤, 활성화 함수 전에 배치 정규화를 사용합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Conv → BatchNorm → ReLU → Conv → BatchNorm → ReLU → ...</span><br></span></code></pre></div></div>
<p>장점:</p>
<ol>
<li class=""><strong>더 빠른 훈련</strong>: 더 큰 학습률 사용 가능</li>
<li class=""><strong>더 안정적</strong>: 초기화에 대한 민감도 감소</li>
<li class=""><strong>정규화 효과</strong>: 약간의 dropout 효과</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="추론-시-처리">추론 시 처리<a href="#추론-시-처리" class="hash-link" aria-label="추론 시 처리에 대한 직접 링크" title="추론 시 처리에 대한 직접 링크" translate="no">​</a></h3>
<p>훈련 시에는 현재 배치의 통계를 사용합니다. 추론 시에는 전체 훈련 세트의 통계(이동 평균)를 사용합니다:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 훈련 시</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch_mean</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch_var</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 추론 시</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> running_mean  </span><span class="token comment" style="color:#999988;font-style:italic"># 훈련 중 누적된 평균</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> running_var    </span><span class="token comment" style="color:#999988;font-style:italic"># 훈련 중 누적된 분산</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago의-구체적-구성">AlphaGo의 구체적 구성<a href="#alphago의-구체적-구성" class="hash-link" aria-label="AlphaGo의 구체적 구성에 대한 직접 링크" title="AlphaGo의 구체적 구성에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="전체-아키텍처">전체 아키텍처<a href="#전체-아키텍처" class="hash-link" aria-label="전체 아키텍처에 대한 직접 링크" title="전체 아키텍처에 대한 직접 링크" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">입력: 19×19×48</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">제 1층:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(5×5, 192 filters, padding=&#x27;same&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  BatchNorm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  출력: 19×19×192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">제 2-12층 (총 11층):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(3×3, 192 filters, padding=&#x27;same&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  BatchNorm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  출력: 19×19×192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">출력층 (Policy):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(1×1, 1 filter)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Flatten</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  출력: 361차원 확률</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">출력층 (Value):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(1×1, 1 filter)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Flatten</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Dense(256)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Dense(1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Tanh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  출력: 단일 값</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="파라미터-구성">파라미터 구성<a href="#파라미터-구성" class="hash-link" aria-label="파라미터 구성에 대한 직접 링크" title="파라미터 구성에 대한 직접 링크" translate="no">​</a></h3>
<table><thead><tr><th>파라미터</th><th>값</th><th>설명</th></tr></thead><tbody><tr><td>입력 채널</td><td>48</td><td>특징 평면 수</td></tr><tr><td>필터 수</td><td>192</td><td>각 층의 채널 수</td></tr><tr><td>합성곱 커널 크기</td><td>3×3(첫 번째 층 5×5)</td><td>수용 영역</td></tr><tr><td>층 수</td><td>13(출력층 포함)</td><td>깊이</td></tr><tr><td>활성화 함수</td><td>ReLU</td><td>비선형성</td></tr><tr><td>정규화</td><td>BatchNorm</td><td>훈련 안정화</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pytorch-구현">PyTorch 구현<a href="#pytorch-구현" class="hash-link" aria-label="PyTorch 구현에 대한 직접 링크" title="PyTorch 구현에 대한 직접 링크" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">AlphaGoCNN</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> input_channels</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">48</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">192</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_layers</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">12</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 첫 번째 층(5×5 합성곱)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_channels</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">BatchNorm2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 중간 층(3×3 합성곱)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">BatchNorm2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_layers </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Policy 출력 헤드</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">policy_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Flatten</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Softmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Value 출력 헤드</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">value_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Flatten</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">361</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Tanh</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">forward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 공유 특징 추출</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 분리된 출력</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">policy_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        value </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">value_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> value</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="다른-아키텍처와의-비교">다른 아키텍처와의 비교<a href="#다른-아키텍처와의-비교" class="hash-link" aria-label="다른 아키텍처와의 비교에 대한 직접 링크" title="다른 아키텍처와의 비교에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="완전-연결-네트워크">완전 연결 네트워크<a href="#완전-연결-네트워크" class="hash-link" aria-label="완전 연결 네트워크에 대한 직접 링크" title="완전 연결 네트워크에 대한 직접 링크" translate="no">​</a></h3>
<p>바둑을 완전 연결 네트워크로 처리한다면:</p>
<table><thead><tr><th>특성</th><th>완전 연결</th><th>CNN</th></tr></thead><tbody><tr><td>파라미터 수</td><td>매우 큼(수억)</td><td>비교적 작음(수백만)</td></tr><tr><td>위치 불변성</td><td>없음</td><td>있음</td></tr><tr><td>지역 특징</td><td>학습하기 어려움</td><td>자연스럽게 포착</td></tr><tr><td>훈련 효율성</td><td>낮음</td><td>높음</td></tr></tbody></table>
<p>완전 연결 네트워크는 바둑판의 공간 구조를 활용할 수 없어 효율이 매우 낮습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="순환-신경망rnn">순환 신경망(RNN)<a href="#순환-신경망rnn" class="hash-link" aria-label="순환 신경망(RNN)에 대한 직접 링크" title="순환 신경망(RNN)에 대한 직접 링크" translate="no">​</a></h3>
<p>RNN은 순서 데이터(대국 기록 등)에 적합하지만:</p>
<table><thead><tr><th>특성</th><th>RNN</th><th>CNN</th></tr></thead><tbody><tr><td>공간 처리</td><td>약함</td><td>강함</td></tr><tr><td>순서 처리</td><td>강함</td><td>약함(기록 평면 필요)</td></tr><tr><td>병렬화</td><td>어려움</td><td>쉬움</td></tr><tr><td>장거리 의존성</td><td>LSTM 필요</td><td>깊은 층으로 가능</td></tr></tbody></table>
<p>AlphaGo는 CNN + RNN이 아닌 CNN + 기록 평면을 선택했습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="잔차-네트워크resnet">잔차 네트워크(ResNet)<a href="#잔차-네트워크resnet" class="hash-link" aria-label="잔차 네트워크(ResNet)에 대한 직접 링크" title="잔차 네트워크(ResNet)에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero는 ResNet으로 업그레이드되었습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">일반 CNN:                ResNet:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  x                        x</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> Conv                     Conv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> ReLU                    ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> Conv                     Conv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  y                      y + x  ← 잔차 연결</span><br></span></code></pre></div></div>
<p>잔차 연결은 기울기가 더 쉽게 흐르게 하여 더 깊은 네트워크(12층 vs 40층)를 훈련할 수 있습니다.</p>
<p>자세한 내용은 <a class="" href="/ko/docs/alphago/dual-head-resnet/">이중 헤드 네트워크와 잔차 네트워크</a>를 참조하세요.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="시각적-이해">시각적 이해<a href="#시각적-이해" class="hash-link" aria-label="시각적 이해에 대한 직접 링크" title="시각적 이해에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="합성곱-과정">합성곱 과정<a href="#합성곱-과정" class="hash-link" aria-label="합성곱 과정에 대한 직접 링크" title="합성곱 과정에 대한 직접 링크" translate="no">​</a></h3>
<p><strong>입력 바둑판 (5×5로 단순화):</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>2</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">○</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td>4</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td></tr><tr><td>5</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>어떤 필터 (3×3, &#x27;십자 모양&#x27; 감지):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>합성곱 출력:</strong></p>
<table><thead><tr><th></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td>1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>2</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>3</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center"><strong>1</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>4</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td>5</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p>중심에 강한 반응 (십자 모양 일치)</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다층-특징">다층 특징<a href="#다층-특징" class="hash-link" aria-label="다층 특징에 대한 직접 링크" title="다층 특징에 대한 직접 링크" translate="no">​</a></h3>
<p>제 1층 출력 (192개 채널 중 4개):</p>
<p><strong>채널 1 (집):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center"><strong>0.9</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>채널 2 (변):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>채널 3 (단점):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center"><strong>0.7</strong></td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>채널 4 (연결):</strong></p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p>이러한 특징들은 더 깊은 층에서 더 복잡한 개념으로 결합됩니다...</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="애니메이션-대응">애니메이션 대응<a href="#애니메이션-대응" class="hash-link" aria-label="애니메이션 대응에 대한 직접 링크" title="애니메이션 대응에 대한 직접 링크" translate="no">​</a></h2>
<p>이 글에서 다루는 핵심 개념과 애니메이션 번호:</p>
<table><thead><tr><th>번호</th><th>개념</th><th>물리/수학 대응</th></tr></thead><tbody><tr><td>D9</td><td>합성곱 연산</td><td>필터 응답</td></tr><tr><td>D10</td><td>수용 영역</td><td>지역→전역</td></tr><tr><td>D11</td><td>배치 정규화</td><td>분포 안정화</td></tr><tr><td>D1</td><td>다중 채널 입력</td><td>텐서 연산</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="추가-자료">추가 자료<a href="#추가-자료" class="hash-link" aria-label="추가 자료에 대한 직접 링크" title="추가 자료에 대한 직접 링크" translate="no">​</a></h2>
<ul>
<li class=""><strong>이전 글</strong>: <a class="" href="/ko/docs/alphago/input-features/">입력 특징 설계</a> — 48개 특징 평면 상세 설명</li>
<li class=""><strong>다음 글</strong>: <a class="" href="/ko/docs/alphago/supervised-learning/">지도 학습 단계</a> — 인간 기보에서 배우는 방법</li>
<li class=""><strong>고급 주제</strong>: <a class="" href="/ko/docs/alphago/dual-head-resnet/">이중 헤드 네트워크와 잔차 네트워크</a> — AlphaGo Zero의 네트워크 업그레이드</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="핵심-요점">핵심 요점<a href="#핵심-요점" class="hash-link" aria-label="핵심 요점에 대한 직접 링크" title="핵심 요점에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class=""><strong>CNN은 바둑판에 자연스럽게 적합</strong>: 지역 연결, 가중치 공유, 이동 등변성</li>
<li class=""><strong>합성곱이 지역 특징 추출</strong>: 3×3 영역의 패턴 인식</li>
<li class=""><strong>깊은 네트워크가 전역 시야 획득</strong>: 12층 → 25×25 수용 영역</li>
<li class=""><strong>ReLU가 빠르고 효과적</strong>: 단순한 비선형 활성화</li>
<li class=""><strong>BatchNorm이 훈련 안정화</strong>: 각 층 출력 표준화</li>
</ol>
<p>CNN은 AlphaGo가 바둑판을 &#x27;볼&#x27; 수 있게 합니다—마치 인간이 이미지를 눈으로 보는 것처럼 자연스럽게.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="참고-자료">참고 자료<a href="#참고-자료" class="hash-link" aria-label="참고 자료에 대한 직접 링크" title="참고 자료에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). &quot;Deep learning.&quot; <em>Nature</em>, 521, 436-444.</li>
<li class="">He, K., et al. (2015). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training.&quot; <em>ICML</em>.</li>
<li class="">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). &quot;ImageNet Classification with Deep Convolutional Neural Networks.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/10-cnn-and-go.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/alphago/input-features/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">입력 특성 설계</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/alphago/supervised-learning/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">지도 학습 단계</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#왜-cnn이-바둑판에-적합한가" class="table-of-contents__link toc-highlight">왜 CNN이 바둑판에 적합한가?</a><ul><li><a href="#바둑판은-이미지이다" class="table-of-contents__link toc-highlight">바둑판은 &#39;이미지&#39;이다</a></li><li><a href="#세-가지-핵심-특성" class="table-of-contents__link toc-highlight">세 가지 핵심 특성</a></li></ul></li><li><a href="#합성곱-연산" class="table-of-contents__link toc-highlight">합성곱 연산</a><ul><li><a href="#기본-원리" class="table-of-contents__link toc-highlight">기본 원리</a></li><li><a href="#다중-채널-합성곱" class="table-of-contents__link toc-highlight">다중 채널 합성곱</a></li><li><a href="#다중-필터" class="table-of-contents__link toc-highlight">다중 필터</a></li></ul></li><li><a href="#수용-영역" class="table-of-contents__link toc-highlight">수용 영역</a><ul><li><a href="#수용-영역이란" class="table-of-contents__link toc-highlight">수용 영역이란?</a></li><li><a href="#수용-영역과-바둑" class="table-of-contents__link toc-highlight">수용 영역과 바둑</a></li></ul></li><li><a href="#지역-vs-전역-특징" class="table-of-contents__link toc-highlight">지역 vs 전역 특징</a><ul><li><a href="#cnn의-계층-구조" class="table-of-contents__link toc-highlight">CNN의 계층 구조</a></li><li><a href="#은닉층-시각화" class="table-of-contents__link toc-highlight">은닉층 시각화</a></li></ul></li><li><a href="#활성화-함수-선택" class="table-of-contents__link toc-highlight">활성화 함수 선택</a><ul><li><a href="#relu-단순하지만-효과적" class="table-of-contents__link toc-highlight">ReLU: 단순하지만 효과적</a></li><li><a href="#왜-다른-함수를-사용하지-않는가" class="table-of-contents__link toc-highlight">왜 다른 함수를 사용하지 않는가?</a></li><li><a href="#바둑에서-relu의-의미" class="table-of-contents__link toc-highlight">바둑에서 ReLU의 의미</a></li></ul></li><li><a href="#배치-정규화" class="table-of-contents__link toc-highlight">배치 정규화</a><ul><li><a href="#배치-정규화란" class="table-of-contents__link toc-highlight">배치 정규화란?</a></li><li><a href="#왜-필요한가" class="table-of-contents__link toc-highlight">왜 필요한가?</a></li><li><a href="#alphago에서의-적용" class="table-of-contents__link toc-highlight">AlphaGo에서의 적용</a></li><li><a href="#추론-시-처리" class="table-of-contents__link toc-highlight">추론 시 처리</a></li></ul></li><li><a href="#alphago의-구체적-구성" class="table-of-contents__link toc-highlight">AlphaGo의 구체적 구성</a><ul><li><a href="#전체-아키텍처" class="table-of-contents__link toc-highlight">전체 아키텍처</a></li><li><a href="#파라미터-구성" class="table-of-contents__link toc-highlight">파라미터 구성</a></li><li><a href="#pytorch-구현" class="table-of-contents__link toc-highlight">PyTorch 구현</a></li></ul></li><li><a href="#다른-아키텍처와의-비교" class="table-of-contents__link toc-highlight">다른 아키텍처와의 비교</a><ul><li><a href="#완전-연결-네트워크" class="table-of-contents__link toc-highlight">완전 연결 네트워크</a></li><li><a href="#순환-신경망rnn" class="table-of-contents__link toc-highlight">순환 신경망(RNN)</a></li><li><a href="#잔차-네트워크resnet" class="table-of-contents__link toc-highlight">잔차 네트워크(ResNet)</a></li></ul></li><li><a href="#시각적-이해" class="table-of-contents__link toc-highlight">시각적 이해</a><ul><li><a href="#합성곱-과정" class="table-of-contents__link toc-highlight">합성곱 과정</a></li><li><a href="#다층-특징" class="table-of-contents__link toc-highlight">다층 특징</a></li></ul></li><li><a href="#애니메이션-대응" class="table-of-contents__link toc-highlight">애니메이션 대응</a></li><li><a href="#추가-자료" class="table-of-contents__link toc-highlight">추가 자료</a></li><li><a href="#핵심-요점" class="table-of-contents__link toc-highlight">핵심 요점</a></li><li><a href="#참고-자료" class="table-of-contents__link toc-highlight">참고 자료</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>