<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/policy-network" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Policy Network 상세 해설 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Policy Network 상세 해설 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="AlphaGo의 정책 네트워크 아키텍처, 학습 방법 및 실제 응용에 대한 심층 이해, 13층 컨볼루션에서 Softmax 출력까지"><meta data-rh="true" property="og:description" content="AlphaGo의 정책 네트워크 아키텍처, 학습 방법 및 실제 응용에 대한 심층 이해, 13층 컨볼루션에서 Softmax 출력까지"><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/policy-network/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/ko/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"Policy Network 상세 해설","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ko/assets/css/styles.f23bf74b.css">
<script src="/ko/assets/js/runtime~main.b152227b.js" defer="defer"></script>
<script src="/ko/assets/js/main.7cf510df.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">바둑 키즈</b></a><a class="navbar__item navbar__link" href="/ko/docs/for-players/">바둑 플레이어</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/for-engineers/">엔지니어</a><a class="navbar__item navbar__link" href="/ko/docs/about/">협회 소개</a><a class="navbar__item navbar__link" href="/ko/docs/activities/">활동 실적</a><a class="navbar__item navbar__link" href="/ko/docs/references/">참고 자료</a><a class="navbar__item navbar__link" href="/ko/docs/sop/">표준 운영 절차</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/policy-network/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/"><span title="이용 안내" class="linkLabel_REp1">이용 안내</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="사이드바 분류 &#x27;關於協會&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="사이드바 분류 &#x27;活動實績&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/for-players/"><span title="바둑 기사를 위한 자료" class="categoryLinkLabel_ezQx">바둑 기사를 위한 자료</span></a><button aria-label="사이드바 분류 &#x27;바둑 기사를 위한 자료&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="사이드바 분류 &#x27;參考資料&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="사이드바 분류 &#x27;標準作業流程&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ko/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="사이드바 분류 &#x27;給工程師的圍棋 AI 指南&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/deep-dive/"><span title="심층 연구를 원하는 분들을 위해" class="categoryLinkLabel_ezQx">심층 연구를 원하는 분들을 위해</span></a><button aria-label="사이드바 분류 &#x27;심층 연구를 원하는 분들을 위해&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;30 分鐘跑起第一個圍棋 AI&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;一篇文章搞懂圍棋 AI&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="사이드바 분류 &#x27;AlphaGo 完整解析&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="AlphaGo의 탄생" class="linkLabel_REp1">AlphaGo의 탄생</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="주요 대국 리뷰" class="linkLabel_REp1">주요 대국 리뷰</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="&quot;신의 한 수&quot; 심층 분석" class="linkLabel_REp1">&quot;신의 한 수&quot; 심층 분석</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="바둑은 왜 어려운가?" class="linkLabel_REp1">바둑은 왜 어려운가?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="전통적 방법의 한계" class="linkLabel_REp1">전통적 방법의 한계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="바둑판 상태 표현" class="linkLabel_REp1">바둑판 상태 표현</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="Policy Network 상세 해설" class="linkLabel_REp1">Policy Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="Value Network 상세 해설" class="linkLabel_REp1">Value Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="입력 특성 설계" class="linkLabel_REp1">입력 특성 설계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="CNN과 바둑의 결합" class="linkLabel_REp1">CNN과 바둑의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="지도 학습 단계" class="linkLabel_REp1">지도 학습 단계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="강화 학습 입문" class="linkLabel_REp1">강화 학습 입문</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="자기 대국" class="linkLabel_REp1">자기 대국</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="MCTS와 신경망의 결합" class="linkLabel_REp1">MCTS와 신경망의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="PUCT 공식 상세" class="linkLabel_REp1">PUCT 공식 상세</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="AlphaGo Zero 개요" class="linkLabel_REp1">AlphaGo Zero 개요</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="이중 헤드 네트워크와 잔차 네트워크" class="linkLabel_REp1">이중 헤드 네트워크와 잔차 네트워크</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="처음부터 훈련하는 과정" class="linkLabel_REp1">처음부터 훈련하는 과정</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="분산 시스템과 TPU" class="linkLabel_REp1">분산 시스템과 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="AlphaGo의 유산" class="linkLabel_REp1">AlphaGo의 유산</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 產業現況&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 能做什麼？&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Policy Network 상세 해설</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>Policy Network 상세 해설</h1></header>
<p>바둑의 어떤 국면에서든 합법적인 수는 평균 250가지가 있습니다. 컴퓨터가 무작위로 선택하게 하면, 결코 좋은 수를 둘 수 없습니다.</p>
<p>AlphaGo의 돌파구는 바로 이것입니다: &#x27;바둑판을 한 번 보고, 어떤 위치가 고려할 가치가 있는지 아는 것&#x27;을 배웠습니다.</p>
<p>이 능력은 **Policy Network(정책 네트워크)**에서 옵니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-network란-무엇인가">Policy Network란 무엇인가?<a href="#policy-network란-무엇인가" class="hash-link" aria-label="Policy Network란 무엇인가?에 대한 직접 링크" title="Policy Network란 무엇인가?에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="핵심-기능">핵심 기능<a href="#핵심-기능" class="hash-link" aria-label="핵심 기능에 대한 직접 링크" title="핵심 기능에 대한 직접 링크" translate="no">​</a></h3>
<p>Policy Network는 심층 컨볼루션 신경망으로, 그 임무는 다음과 같습니다:</p>
<blockquote>
<p><strong>현재 바둑판 상태가 주어지면, 각 위치에 돌을 놓을 확률을 출력한다</strong></p>
</blockquote>
<p>수학적으로 표현하면:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">p = f_θ(s)</span><br></span></code></pre></div></div>
<p>여기서:</p>
<ul>
<li class=""><code>s</code>: 현재 바둑판 상태 (19×19 바둑판 + 기타 특성)</li>
<li class=""><code>f_θ</code>: Policy Network (θ는 네트워크 파라미터)</li>
<li class=""><code>p</code>: 361개 위치의 확률 분포 (pass 포함)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="직관적-이해">직관적 이해<a href="#직관적-이해" class="hash-link" aria-label="직관적 이해에 대한 직접 링크" title="직관적 이해에 대한 직접 링크" translate="no">​</a></h3>
<p>당신이 프로 기사라고 상상해 보세요. 어떤 국면을 보면, 당신의 뇌는 자동으로 몇 개의 중요한 위치를 &#x27;밝게&#x27; 합니다 — 이것들이 당신이 직관적으로 고려할 가치가 있다고 생각하는 점입니다.</p>
<p>Policy Network는 바로 이 과정을 시뮬레이션하는 것입니다.</p>
<div>載入中...</div>
<p>위의 히트맵은 Policy Network의 출력을 보여줍니다. 색상이 밝을수록 모델이 그 위치에 두는 것이 가치 있다고 생각합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-policy-network가-필요한가">왜 Policy Network가 필요한가?<a href="#왜-policy-network가-필요한가" class="hash-link" aria-label="왜 Policy Network가 필요한가?에 대한 직접 링크" title="왜 Policy Network가 필요한가?에 대한 직접 링크" translate="no">​</a></h3>
<p>바둑의 탐색 공간은 너무 큽니다. 모든 가능한 수를 필터링 없이 탐색하면:</p>
<table><thead><tr><th>전략</th><th>수마다 고려하는 착수</th><th>10수 탐색의 노드 수</th></tr></thead><tbody><tr><td>전부 고려</td><td>361</td><td>361^10 ≈ 10^25</td></tr><tr><td>Policy Network 필터링</td><td>~20</td><td>20^10 ≈ 10^13</td></tr></tbody></table>
<p>Policy Network는 탐색 공간을 <strong>10^12배</strong>(1조 배) 축소했습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="네트워크-아키텍처">네트워크 아키텍처<a href="#네트워크-아키텍처" class="hash-link" aria-label="네트워크 아키텍처에 대한 직접 링크" title="네트워크 아키텍처에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="전체-구조">전체 구조<a href="#전체-구조" class="hash-link" aria-label="전체 구조에 대한 직접 링크" title="전체 구조에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 Policy Network는 심층 컨볼루션 신경망(CNN) 아키텍처를 채택합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">입력층 → 컨볼루션층 ×12 → 출력 컨볼루션층 → Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ↓         ↓            ↓           ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">19×19×48   19×19×192   19×19×1     362개 확률</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="입력층">입력층<a href="#입력층" class="hash-link" aria-label="입력층에 대한 직접 링크" title="입력층에 대한 직접 링크" translate="no">​</a></h3>
<p>입력은 <strong>19×19×48</strong> 특성 텐서입니다:</p>
<ul>
<li class=""><strong>19×19</strong>: 바둑판 크기</li>
<li class=""><strong>48</strong>: 48개 특성 평면 (자세한 내용은 <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/input-features/">입력 특성 설계</a> 참조)</li>
</ul>
<p>이 48개 평면에는 다음이 포함됩니다:</p>
<ul>
<li class="">흑돌 위치, 백돌 위치</li>
<li class="">최근 8수의 기록</li>
<li class="">활로 수, 단수, 축머리 등 특성</li>
<li class="">합법성 (어떤 위치에 둘 수 있는지)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="컨볼루션층">컨볼루션층<a href="#컨볼루션층" class="hash-link" aria-label="컨볼루션층에 대한 직접 링크" title="컨볼루션층에 대한 직접 링크" translate="no">​</a></h3>
<p>네트워크는 <strong>12개의 컨볼루션층</strong>을 포함하며, 각 층의 구성:</p>
<table><thead><tr><th>파라미터</th><th>값</th><th>설명</th></tr></thead><tbody><tr><td>필터 수</td><td>192</td><td>각 층에서 192개 특성 맵 출력</td></tr><tr><td>커널 크기</td><td>3×3 (첫 번째 층은 5×5)</td><td>매번 3×3 영역을 봄</td></tr><tr><td>패딩 방식</td><td>same</td><td>19×19 크기 유지</td></tr><tr><td>활성화 함수</td><td>ReLU</td><td>max(0, x)</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-192개-필터인가">왜 192개 필터인가?<a href="#왜-192개-필터인가" class="hash-link" aria-label="왜 192개 필터인가?에 대한 직접 링크" title="왜 192개 필터인가?에 대한 직접 링크" translate="no">​</a></h4>
<p>이것은 경험적인 값입니다. 너무 적으면 모델 용량이 제한되고, 너무 많으면 계산량과 과적합 위험이 증가합니다. DeepMind 팀은 실험을 통해 192가 좋은 균형점임을 확인했습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-33-커널인가">왜 3×3 커널인가?<a href="#왜-33-커널인가" class="hash-link" aria-label="왜 3×3 커널인가?에 대한 직접 링크" title="왜 3×3 커널인가?에 대한 직접 링크" translate="no">​</a></h4>
<p>3×3은 컨볼루션 신경망에서 가장 일반적으로 사용되는 크기입니다. 이유는:</p>
<ol>
<li class=""><strong>국소 패턴 포착에 충분</strong>: 바둑의 눈, 이음, 끊음 등이 모두 3×3 범위 내에 있음</li>
<li class=""><strong>계산 효율이 높음</strong>: 큰 커널에 비해 3×3은 파라미터가 적음</li>
<li class=""><strong>쌓을 수 있음</strong>: 여러 층의 3×3 컨볼루션은 큰 수용 영역 효과를 낼 수 있음</li>
</ol>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="첫-번째-층은-왜-55를-사용하는가">첫 번째 층은 왜 5×5를 사용하는가?<a href="#첫-번째-층은-왜-55를-사용하는가" class="hash-link" aria-label="첫 번째 층은 왜 5×5를 사용하는가?에 대한 직접 링크" title="첫 번째 층은 왜 5×5를 사용하는가?에 대한 직접 링크" translate="no">​</a></h4>
<p>첫 번째 층은 더 큰 5×5 커널을 사용하는데, 이는 입력층에서 바로 약간 더 큰 범위의 패턴(예: 소목, 한 칸 뜀)을 포착하기 위해서입니다. 이것은 설계 선택이며, 나중에 AlphaGo Zero는 통일하여 3×3을 사용합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="relu-활성화-함수">ReLU 활성화 함수<a href="#relu-활성화-함수" class="hash-link" aria-label="ReLU 활성화 함수에 대한 직접 링크" title="ReLU 활성화 함수에 대한 직접 링크" translate="no">​</a></h3>
<p>각 컨볼루션층 뒤에 ReLU(Rectified Linear Unit) 활성화 함수가 붙습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">ReLU(x) = max(0, x)</span><br></span></code></pre></div></div>
<p>왜 ReLU를 사용하는가?</p>
<ol>
<li class=""><strong>계산이 간단함</strong>: 최댓값만 취하면 되어 sigmoid보다 훨씬 빠름</li>
<li class=""><strong>기울기 소실 완화</strong>: 양의 영역에서 기울기가 항상 1</li>
<li class=""><strong>희소 활성화</strong>: 음수 값은 0으로 되어 희소 표현 생성</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="출력층">출력층<a href="#출력층" class="hash-link" aria-label="출력층에 대한 직접 링크" title="출력층에 대한 직접 링크" translate="no">​</a></h3>
<p>마지막 층은 특별한 컨볼루션층입니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">19×19×192 → 컨볼루션(1×1, 1개 필터) → 19×19×1 → 평탄화 → 362차원 벡터 → Softmax</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="11-컨볼루션">1×1 컨볼루션<a href="#11-컨볼루션" class="hash-link" aria-label="1×1 컨볼루션에 대한 직접 링크" title="1×1 컨볼루션에 대한 직접 링크" translate="no">​</a></h4>
<p>출력층은 1×1 컨볼루션을 사용하여 192개 채널을 1개로 압축합니다. 이는 각 위치의 192차원 특성에 선형 결합을 하는 것과 같습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="softmax-출력">Softmax 출력<a href="#softmax-출력" class="hash-link" aria-label="Softmax 출력에 대한 직접 링크" title="Softmax 출력에 대한 직접 링크" translate="no">​</a></h4>
<p>362차원 벡터(361개 바둑판 위치 + 1개 pass)는 Softmax 함수를 거칩니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Softmax(z_i) = exp(z_i) / Σ_j exp(z_j)</span><br></span></code></pre></div></div>
<p>Softmax는 출력이 합법적인 확률 분포가 되도록 보장합니다:</p>
<ul>
<li class="">모든 값이 0과 1 사이</li>
<li class="">모든 값의 합이 1</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="파라미터-수">파라미터 수<a href="#파라미터-수" class="hash-link" aria-label="파라미터 수에 대한 직접 링크" title="파라미터 수에 대한 직접 링크" translate="no">​</a></h3>
<p>네트워크의 총 파라미터 수를 계산해 봅시다:</p>
<table><thead><tr><th>층</th><th>계산</th><th>파라미터 수</th></tr></thead><tbody><tr><td>첫 번째 컨볼루션층</td><td>5×5×48×192 + 192</td><td>230,592</td></tr><tr><td>중간 컨볼루션층 ×11</td><td>(3×3×192×192 + 192) × 11</td><td>3,633,792</td></tr><tr><td>출력 컨볼루션층</td><td>1×1×192×1 + 1</td><td>193</td></tr><tr><td><strong>총계</strong></td><td></td><td><strong>~3.9M</strong></td></tr></tbody></table>
<p>약 <strong>390만 개의 파라미터</strong>로, 오늘날의 기준으로는 작은 네트워크입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="학습-목표와-방법">학습 목표와 방법<a href="#학습-목표와-방법" class="hash-link" aria-label="학습 목표와 방법에 대한 직접 링크" title="학습 목표와 방법에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="학습-데이터">학습 데이터<a href="#학습-데이터" class="hash-link" aria-label="학습 데이터에 대한 직접 링크" title="학습 데이터에 대한 직접 링크" translate="no">​</a></h3>
<p>Policy Network는 <strong>지도 학습</strong>을 사용하여 인간 기보에서 학습합니다.</p>
<p>데이터 출처:</p>
<ul>
<li class=""><strong>KGS Go Server</strong>: 아마추어와 프로 기사의 대국</li>
<li class=""><strong>약 3천만 국면</strong>: 16만 대국에서 샘플링</li>
<li class=""><strong>레이블</strong>: 각 국면에 대응하는 인간의 다음 수</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="교차-엔트로피-손실-함수">교차 엔트로피 손실 함수<a href="#교차-엔트로피-손실-함수" class="hash-link" aria-label="교차 엔트로피 손실 함수에 대한 직접 링크" title="교차 엔트로피 손실 함수에 대한 직접 링크" translate="no">​</a></h3>
<p>학습 목표는 인간 착수를 예측할 확률을 최대화하는 것입니다. 교차 엔트로피 손실 함수를 사용합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L(θ) = -Σ log p_θ(a | s)</span><br></span></code></pre></div></div>
<p>여기서:</p>
<ul>
<li class=""><code>s</code>: 바둑판 상태</li>
<li class=""><code>a</code>: 인간이 실제로 둔 위치</li>
<li class=""><code>p_θ(a | s)</code>: 모델이 해당 위치를 예측한 확률</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="직관적-이해-1">직관적 이해<a href="#직관적-이해-1" class="hash-link" aria-label="직관적 이해에 대한 직접 링크" title="직관적 이해에 대한 직접 링크" translate="no">​</a></h4>
<p>교차 엔트로피 손실은 간단한 의미를 가집니다:</p>
<blockquote>
<p><strong>모델이 정확한 위치를 예측할 확률이 높을수록, 손실이 낮다</strong></p>
</blockquote>
<p>만약 인간이 K10에 두었고, 모델이 K10에 준 확률이:</p>
<ul>
<li class="">0.9 → 손실 = -log(0.9) ≈ 0.1 (매우 낮음, 좋음)</li>
<li class="">0.1 → 손실 = -log(0.1) ≈ 2.3 (높음, 나쁨)</li>
<li class="">0.01 → 손실 = -log(0.01) ≈ 4.6 (매우 높음, 매우 나쁨)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="학습-과정">학습 과정<a href="#학습-과정" class="hash-link" aria-label="학습 과정에 대한 직접 링크" title="학습 과정에 대한 직접 링크" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 의사 코드</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> epoch </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_epochs</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> batch </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> dataloader</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        states</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 순전파</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> network</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">states</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 361차원 확률 벡터</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 손실 계산 (교차 엔트로피)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cross_entropy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 역전파</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>학습 세부사항:</p>
<ul>
<li class=""><strong>옵티마이저</strong>: SGD with momentum</li>
<li class=""><strong>학습률</strong>: 초기 0.003, 점진적 감소</li>
<li class=""><strong>배치 크기</strong>: 16</li>
<li class=""><strong>학습 시간</strong>: 약 3주 (50 GPUs)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="데이터-증강">데이터 증강<a href="#데이터-증강" class="hash-link" aria-label="데이터 증강에 대한 직접 링크" title="데이터 증강에 대한 직접 링크" translate="no">​</a></h3>
<p>바둑판은 8중 대칭성(4개 회전 × 2개 거울 반사)을 가집니다. 각 학습 샘플은 8개의 등가 샘플로 변환될 수 있습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">원본 → 90° 회전 → 180° 회전 → 270° 회전</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ↓       ↓         ↓          ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">수평 뒤집기 → ...</span><br></span></code></pre></div></div>
<p>이렇게 하면 유효 학습 데이터가 8배 증가하고, 모델이 배운 패턴이 방향에 의존하지 않도록 보장합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="학습-결과">학습 결과<a href="#학습-결과" class="hash-link" aria-label="학습 결과에 대한 직접 링크" title="학습 결과에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="57-정확도">57% 정확도<a href="#57-정확도" class="hash-link" aria-label="57% 정확도에 대한 직접 링크" title="57% 정확도에 대한 직접 링크" translate="no">​</a></h3>
<p>학습 후, Policy Network는 <strong>57%의 top-1 정확도</strong>를 달성했습니다.</p>
<p>이것은 의미합니다: 어떤 국면이 주어져도, 모델이 인간 전문가가 실제로 둔 수를 예측할 확률이 57%입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="이-정확도가-높은가">이 정확도가 높은가?<a href="#이-정확도가-높은가" class="hash-link" aria-label="이 정확도가 높은가?에 대한 직접 링크" title="이 정확도가 높은가?에 대한 직접 링크" translate="no">​</a></h4>
<p>각 국면에서 평균 250개의 합법적인 착수가 있다는 점을 고려하면, 무작위 추측의 정확도는 0.4%에 불과합니다.</p>
<table><thead><tr><th>방법</th><th>Top-1 정확도</th></tr></thead><tbody><tr><td>무작위 추측</td><td>0.4%</td></tr><tr><td>이전 최강 컴퓨터 바둑</td><td>~44%</td></tr><tr><td>AlphaGo Policy Network</td><td><strong>57%</strong></td></tr></tbody></table>
<p>13 퍼센트 포인트 향상은 적어 보이지만, 의미가 큽니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="기력-향상">기력 향상<a href="#기력-향상" class="hash-link" aria-label="기력 향상에 대한 직접 링크" title="기력 향상에 대한 직접 링크" translate="no">​</a></h3>
<p>순수하게 Policy Network만 사용하여(탐색 없이) 대국하면, 어느 정도 기력에 도달할 수 있을까요?</p>
<table><thead><tr><th>구성</th><th>Elo 평점</th><th>대략적 등급</th></tr></thead><tbody><tr><td>이전 최강 프로그램 (Pachi)</td><td>2,500</td><td>아마추어 4-5단</td></tr><tr><td>Policy Network 단독</td><td>2,800</td><td>아마추어 6-7단</td></tr><tr><td>+ MCTS 1600 시뮬레이션</td><td>3,200+</td><td>프로 수준</td></tr></tbody></table>
<p>Policy Network 단독으로도 이미 아마추어 고단이고, MCTS를 더하면 프로 수준으로 도약합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-57밖에-안-되는가">왜 57%밖에 안 되는가?<a href="#왜-57밖에-안-되는가" class="hash-link" aria-label="왜 57%밖에 안 되는가?에 대한 직접 링크" title="왜 57%밖에 안 되는가?에 대한 직접 링크" translate="no">​</a></h3>
<p>인간 기보에는 다음과 같은 특성이 있어 정확도를 제한합니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-여러-개의-좋은-수">1. 여러 개의 좋은 수<a href="#1-여러-개의-좋은-수" class="hash-link" aria-label="1. 여러 개의 좋은 수에 대한 직접 링크" title="1. 여러 개의 좋은 수에 대한 직접 링크" translate="no">​</a></h4>
<p>많은 국면에서 여러 수가 모두 좋은 수입니다. 예를 들어 &#x27;화점 걸침&#x27;과 &#x27;화점 지킴&#x27;이 모두 올바른 선택일 수 있습니다. 모델이 다른 좋은 수를 선택하면, &#x27;오류&#x27;로 계산됩니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-스타일-차이">2. 스타일 차이<a href="#2-스타일-차이" class="hash-link" aria-label="2. 스타일 차이에 대한 직접 링크" title="2. 스타일 차이에 대한 직접 링크" translate="no">​</a></h4>
<p>다른 기사들은 다른 스타일을 가집니다. 공격형 기사와 안정형 기사는 같은 국면에서 다른 수를 둘 수 있습니다. 모델이 배우는 것은 &#x27;평균&#x27; 스타일입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-인간도-실수한다">3. 인간도 실수한다<a href="#3-인간도-실수한다" class="hash-link" aria-label="3. 인간도 실수한다에 대한 직접 링크" title="3. 인간도 실수한다에 대한 직접 링크" translate="no">​</a></h4>
<p>KGS 데이터에는 아마추어 기사의 대국이 포함되어 있어, 그들의 선택이 반드시 최선은 아닙니다. 모델이 일부 &#x27;실수&#x27;를 배우는 것은 정상입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="mcts에서의-역할">MCTS에서의 역할<a href="#mcts에서의-역할" class="hash-link" aria-label="MCTS에서의 역할에 대한 직접 링크" title="MCTS에서의 역할에 대한 직접 링크" translate="no">​</a></h2>
<p>Policy Network는 AlphaGo의 MCTS에서 두 가지 핵심 역할을 합니다:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="1-탐색-방향-안내">1. 탐색 방향 안내<a href="#1-탐색-방향-안내" class="hash-link" aria-label="1. 탐색 방향 안내에 대한 직접 링크" title="1. 탐색 방향 안내에 대한 직접 링크" translate="no">​</a></h3>
<p>MCTS의 <strong>Selection</strong> 단계에서, Policy Network의 출력은 UCB(Upper Confidence Bound) 계산에 사용됩니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">UCB(s, a) = Q(s, a) + c_puct × P(s, a) × √(N(s)) / (1 + N(s, a))</span><br></span></code></pre></div></div>
<p>여기서 <code>P(s, a)</code>가 바로 Policy Network가 제공한 확률입니다.</p>
<p>이것은 의미합니다:</p>
<ul>
<li class=""><strong>높은 확률의 착수가 우선 탐색됨</strong></li>
<li class=""><strong>낮은 확률의 착수도 탐색 기회가 있음</strong> (탐색 항이 있기 때문)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="2-노드-확장-시-사전-확률">2. 노드 확장 시 사전 확률<a href="#2-노드-확장-시-사전-확률" class="hash-link" aria-label="2. 노드 확장 시 사전 확률에 대한 직접 링크" title="2. 노드 확장 시 사전 확률에 대한 직접 링크" translate="no">​</a></h3>
<p>MCTS가 새 노드를 확장할 때, Policy Network는 모든 자식 노드의 <strong>사전 확률</strong>을 제공합니다.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">노드 s 확장:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  for each action a:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child = Node()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.prior = policy_network(s)[a]  # 사전 확률</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.value = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    child.visits = 0</span><br></span></code></pre></div></div>
<p>이러한 사전 확률은 MCTS가 어떤 자식 노드가 더 탐색할 가치가 있는지 &#x27;알 수&#x27; 있게 해줍니다, 그것들이 아직 방문되지 않았더라도.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="경량-버전-vs-완전-버전">경량 버전 vs 완전 버전<a href="#경량-버전-vs-완전-버전" class="hash-link" aria-label="경량 버전 vs 완전 버전에 대한 직접 링크" title="경량 버전 vs 완전 버전에 대한 직접 링크" translate="no">​</a></h2>
<p>AlphaGo에는 실제로 두 개의 Policy Network가 있습니다:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="완전-버전-sl-policy-network">완전 버전 (SL Policy Network)<a href="#완전-버전-sl-policy-network" class="hash-link" aria-label="완전 버전 (SL Policy Network)에 대한 직접 링크" title="완전 버전 (SL Policy Network)에 대한 직접 링크" translate="no">​</a></h3>
<ul>
<li class=""><strong>아키텍처</strong>: 13층 CNN, 192 filters</li>
<li class=""><strong>정확도</strong>: 57%</li>
<li class=""><strong>추론 시간</strong>: 약 3 밀리초/국면</li>
<li class=""><strong>용도</strong>: MCTS에서 Selection과 Expansion</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="경량-버전-rollout-policy-network">경량 버전 (Rollout Policy Network)<a href="#경량-버전-rollout-policy-network" class="hash-link" aria-label="경량 버전 (Rollout Policy Network)에 대한 직접 링크" title="경량 버전 (Rollout Policy Network)에 대한 직접 링크" translate="no">​</a></h3>
<ul>
<li class=""><strong>아키텍처</strong>: 선형 모델 + 수작업 특성</li>
<li class=""><strong>정확도</strong>: 24%</li>
<li class=""><strong>추론 시간</strong>: 약 2 마이크로초/국면 (1500배 빠름)</li>
<li class=""><strong>용도</strong>: 빠른 시뮬레이션 (rollout)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-경량-버전이-필요한가">왜 경량 버전이 필요한가?<a href="#왜-경량-버전이-필요한가" class="hash-link" aria-label="왜 경량 버전이 필요한가?에 대한 직접 링크" title="왜 경량 버전이 필요한가?에 대한 직접 링크" translate="no">​</a></h3>
<p>MCTS의 <strong>Simulation</strong> 단계에서, 현재 노드에서 게임 종료까지 계속 두어야 하며, 100수 이상이 필요할 수 있습니다. 매 수마다 완전 버전 Policy Network를 사용하면, 너무 느립니다.</p>
<p>경량 버전은 정확도가 24%밖에 안 되지만, 속도는 1500배 빠릅니다. rollout에서는 속도가 정밀도보다 중요합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="경량-버전의-특성">경량 버전의 특성<a href="#경량-버전의-특성" class="hash-link" aria-label="경량 버전의 특성에 대한 직접 링크" title="경량 버전의 특성에 대한 직접 링크" translate="no">​</a></h3>
<p>경량 버전은 수작업으로 설계된 특성을 사용하며, 다음을 포함합니다:</p>
<table><thead><tr><th>특성 유형</th><th>예시</th></tr></thead><tbody><tr><td>국소 패턴</td><td>3×3 영역의 돌 배치</td></tr><tr><td>전역 특성</td><td>변, 귀인지, 대장</td></tr><tr><td>전술 특성</td><td>단수, 축머리, 연결</td></tr></tbody></table>
<p>이러한 특성들은 선형 모델(은닉층 없음)에 입력되어, 계산 속도가 매우 빠릅니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero의-개선">AlphaGo Zero의 개선<a href="#alphago-zero의-개선" class="hash-link" aria-label="AlphaGo Zero의 개선에 대한 직접 링크" title="AlphaGo Zero의 개선에 대한 직접 링크" translate="no">​</a></h3>
<p>이후의 AlphaGo Zero는 경량 버전과 rollout을 완전히 폐기했습니다. Value Network로 직접 리프 노드를 평가하며, 빠른 시뮬레이션이 필요 없습니다. 이것은 중대한 단순화입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="강화학습-미세조정-rl-policy-network">강화학습 미세조정 (RL Policy Network)<a href="#강화학습-미세조정-rl-policy-network" class="hash-link" aria-label="강화학습 미세조정 (RL Policy Network)에 대한 직접 링크" title="강화학습 미세조정 (RL Policy Network)에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="지도-학습의-한계">지도 학습의 한계<a href="#지도-학습의-한계" class="hash-link" aria-label="지도 학습의 한계에 대한 직접 링크" title="지도 학습의 한계에 대한 직접 링크" translate="no">​</a></h3>
<p>지도 학습으로 훈련된 Policy Network에는 근본적인 문제가 있습니다:</p>
<blockquote>
<p><strong>&#x27;인간 모방&#x27;을 배웠지, &#x27;승리&#x27;를 배우지 않았다</strong></p>
</blockquote>
<p>이것은 인간의 나쁜 습관을 배우게 되고, 인간이 한 번도 만나지 못한 국면에서 성능이 좋지 않다는 것을 의미합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="셀프-플레이-강화">셀프 플레이 강화<a href="#셀프-플레이-강화" class="hash-link" aria-label="셀프 플레이 강화에 대한 직접 링크" title="셀프 플레이 강화에 대한 직접 링크" translate="no">​</a></h3>
<p>DeepMind의 해결책은 <strong>정책 그래디언트</strong>(Policy Gradient) 방법으로 강화학습을 수행하는 것입니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. Policy Network로 셀프 플레이</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 각 대국의 모든 착수 기록</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 승패에 따라 파라미터 조정:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - 이김 → 이 착수들의 확률 증가</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - 짐 → 이 착수들의 확률 감소</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="reinforce-알고리즘">REINFORCE 알고리즘<a href="#reinforce-알고리즘" class="hash-link" aria-label="REINFORCE 알고리즘에 대한 직접 링크" title="REINFORCE 알고리즘에 대한 직접 링크" translate="no">​</a></h3>
<p>구체적으로 REINFORCE 알고리즘을 사용합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∇J(θ) = E[Σ_t ∇log π_θ(a_t | s_t) × z]</span><br></span></code></pre></div></div>
<p>여기서:</p>
<ul>
<li class=""><code>z</code>: 이 대국의 결과 (+1 이김, -1 짐)</li>
<li class=""><code>π_θ(a_t | s_t)</code>: 상태 <code>s_t</code>에서 행동 <code>a_t</code>를 선택할 확률</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="결과">결과<a href="#결과" class="hash-link" aria-label="결과에 대한 직접 링크" title="결과에 대한 직접 링크" translate="no">​</a></h3>
<p>약 1일간의 셀프 플레이 훈련(128만 대국) 후, RL Policy Network:</p>
<table><thead><tr><th>지표</th><th>SL Policy</th><th>RL Policy</th></tr></thead><tbody><tr><td>SL Policy와 대전</td><td>50%</td><td><strong>80%</strong></td></tr><tr><td>Elo 향상</td><td>-</td><td>+100</td></tr></tbody></table>
<p>정확도는 약간 하락할 수 있지만(더 이상 인간을 완전히 모방하지 않기 때문), 실제 대전 승률은 크게 향상됩니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="모방에서-혁신으로">&#x27;모방&#x27;에서 &#x27;혁신&#x27;으로<a href="#모방에서-혁신으로" class="hash-link" aria-label="&#x27;모방&#x27;에서 &#x27;혁신&#x27;으로에 대한 직접 링크" title="&#x27;모방&#x27;에서 &#x27;혁신&#x27;으로에 대한 직접 링크" translate="no">​</a></h3>
<p>강화학습은 Policy Network가 인간이 생각하지 못한 착수를 배우게 합니다. 이러한 착수는 학습 데이터에 한 번도 나타나지 않았지만, 효과적입니다.</p>
<p>이것이 AlphaGo가 &#x27;신의 한 수&#x27;를 둘 수 있는 이유입니다 — 인간의 경험에 제한받지 않습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="시각화-분석">시각화 분석<a href="#시각화-분석" class="hash-link" aria-label="시각화 분석에 대한 직접 링크" title="시각화 분석에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다른-국면의-확률-분포">다른 국면의 확률 분포<a href="#다른-국면의-확률-분포" class="hash-link" aria-label="다른 국면의 확률 분포에 대한 직접 링크" title="다른 국면의 확률 분포에 대한 직접 링크" translate="no">​</a></h3>
<p>다른 국면에서 Policy Network의 출력을 살펴봅시다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="초반-포석-단계">초반 (포석 단계)<a href="#초반-포석-단계" class="hash-link" aria-label="초반 (포석 단계)에 대한 직접 링크" title="초반 (포석 단계)에 대한 직접 링크" translate="no">​</a></h4>
<div>載入中...</div>
<p>초반에 확률은 주로 다음에 집중됩니다:</p>
<ul>
<li class="">귀 (화점 차지)</li>
<li class="">변 (화점 걸침, 화점 지킴)</li>
<li class="">&#x27;대장&#x27; 위치</li>
</ul>
<p>이것은 바둑의 기본 원리와 일치합니다: 금귀은변초복.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="전투-중인-국면">전투 중인 국면<a href="#전투-중인-국면" class="hash-link" aria-label="전투 중인 국면에 대한 직접 링크" title="전투 중인 국면에 대한 직접 링크" translate="no">​</a></h4>
<div>載入中...</div>
<p>전투 시 확률은 다음에 집중됩니다:</p>
<ul>
<li class="">핵심 끊음점</li>
<li class="">단수, 연결</li>
<li class="">눈 만들기, 눈 부수기</li>
</ul>
<p>이것은 모델이 국소 전술을 배웠음을 보여줍니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="끝내기-단계">끝내기 단계<a href="#끝내기-단계" class="hash-link" aria-label="끝내기 단계에 대한 직접 링크" title="끝내기 단계에 대한 직접 링크" translate="no">​</a></h4>
<div>載入中...</div>
<p>끝내기에서 확률은 각 끝내기 점에 분산되어, 정확한 집 계산이 필요합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="은닉층은-무엇을-배웠나">은닉층은 무엇을 배웠나?<a href="#은닉층은-무엇을-배웠나" class="hash-link" aria-label="은닉층은 무엇을 배웠나?에 대한 직접 링크" title="은닉층은 무엇을 배웠나?에 대한 직접 링크" translate="no">​</a></h3>
<p>컨볼루션층의 출력을 시각화하면, 모델이 배운 &#x27;특성&#x27;을 볼 수 있습니다:</p>
<ul>
<li class=""><strong>낮은 층</strong>: 기본 형태 (눈, 끊음점)</li>
<li class=""><strong>중간 층</strong>: 전술 패턴 (단수, 축머리)</li>
<li class=""><strong>높은 층</strong>: 전역 개념 (세력, 두께)</li>
</ul>
<p>이것은 인간이 바둑을 인지하는 계층 구조와 매우 유사합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="구현-포인트">구현 포인트<a href="#구현-포인트" class="hash-link" aria-label="구현 포인트에 대한 직접 링크" title="구현 포인트에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pytorch-구현">PyTorch 구현<a href="#pytorch-구현" class="hash-link" aria-label="PyTorch 구현에 대한 직접 링크" title="PyTorch 구현에 대한 직접 링크" translate="no">​</a></h3>
<p>다음은 단순화된 Policy Network 구현입니다:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">functional </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> F</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">PolicyNetwork</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> input_channels</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">48</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">192</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_layers</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">12</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 첫 번째 컨볼루션층 (5×5)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_channels</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                               kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 중간 컨볼루션층 (3×3) ×11</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ModuleList</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                     kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_layers </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 출력 컨볼루션층 (1×1)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_out </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">forward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># x: (batch, 48, 19, 19)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 첫 번째 층</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 중간 층</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> conv </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">conv</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 출력층</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_out</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 1, 19, 19)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 평탄화 + Softmax</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">view</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 361)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">softmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="학습-루프">학습 루프<a href="#학습-루프" class="hash-link" aria-label="학습 루프에 대한 직접 링크" title="학습 루프에 대한 직접 링크" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">train_step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> optimizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> states</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    states: (batch, 48, 19, 19) - 바둑판 특성</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    actions: (batch,) - 인간이 둔 위치 (0-360)</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 순전파</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">states</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (batch, 361)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 교차 엔트로피 손실</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loss </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> F</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cross_entropy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">policy </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-8</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># log(0) 방지</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        actions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 역전파</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 정확도 계산</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    predictions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    accuracy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">predictions </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> actions</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">float</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mean</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> loss</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">item</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> accuracy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">item</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="추론-시-주의사항">추론 시 주의사항<a href="#추론-시-주의사항" class="hash-link" aria-label="추론 시 주의사항에 대한 직접 링크" title="추론 시 주의사항에 대한 직접 링크" translate="no">​</a></h3>
<p>실제 대국에서 주의해야 할 점:</p>
<ol>
<li class=""><strong>불법 착수 필터링</strong>: 불법 위치의 확률을 0으로 설정하고, 다시 정규화</li>
<li class=""><strong>온도 조절</strong>: 온도 파라미터로 확률 분포의 &#x27;날카로움&#x27; 제어 가능</li>
<li class=""><strong>배치 추론</strong>: MCTS에서 여러 국면을 배치 처리 가능</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">get_move_probabilities</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> state</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> legal_moves</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> temperature</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;합법적인 착수의 확률 분포 얻기&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">state</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># (361,)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 합법적인 착수만 유지</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mask </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">361</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mask</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">legal_moves</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> mask</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 온도 조절</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> temperature </span><span class="token operator" style="color:#393A34">!=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">**</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> temperature</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 다시 정규화</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> policy </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> policy</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="애니메이션-대응">애니메이션 대응<a href="#애니메이션-대응" class="hash-link" aria-label="애니메이션 대응에 대한 직접 링크" title="애니메이션 대응에 대한 직접 링크" translate="no">​</a></h2>
<p>이 글에서 다루는 핵심 개념과 애니메이션 번호:</p>
<table><thead><tr><th>번호</th><th>개념</th><th>물리/수학 대응</th></tr></thead><tbody><tr><td>🎬 E1</td><td>Policy Network</td><td>확률장</td></tr><tr><td>🎬 D9</td><td>CNN 특성 추출</td><td>필터 응답</td></tr><tr><td>🎬 D3</td><td>지도 학습</td><td>최대 우도 추정</td></tr><tr><td>🎬 H4</td><td>정책 그래디언트</td><td>확률적 최적화</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="추가-읽기">추가 읽기<a href="#추가-읽기" class="hash-link" aria-label="추가 읽기에 대한 직접 링크" title="추가 읽기에 대한 직접 링크" translate="no">​</a></h2>
<ul>
<li class=""><strong>다음 편</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/value-network/">Value Network 상세 해설</a> — AlphaGo가 국면을 평가하는 방법</li>
<li class=""><strong>관련 주제</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/input-features/">입력 특성 설계</a> — 48개 특성 평면 상세</li>
<li class=""><strong>심층 원리</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/">CNN과 바둑의 결합</a> — 왜 컨볼루션 신경망이 바둑판에 적합한가</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="핵심-포인트">핵심 포인트<a href="#핵심-포인트" class="hash-link" aria-label="핵심 포인트에 대한 직접 링크" title="핵심 포인트에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class=""><strong>Policy Network는 확률 분포 생성기</strong>: 바둑판을 입력하면, 361개 위치의 확률 출력</li>
<li class=""><strong>13층 CNN + Softmax</strong>: 심층 컨볼루션으로 특성 추출, Softmax로 확률 출력</li>
<li class=""><strong>57% 정확도</strong>: 이전의 컴퓨터 바둑 프로그램을 훨씬 초과</li>
<li class=""><strong>두 버전</strong>: 완전 버전은 MCTS 의사결정에, 경량 버전은 빠른 시뮬레이션에 사용</li>
<li class=""><strong>강화학습 미세조정</strong>: &#x27;인간 모방&#x27;에서 &#x27;승리 추구&#x27;로 진화</li>
</ol>
<p>Policy Network는 AlphaGo의 &#x27;직관&#x27;입니다 — AI가 인간처럼 고려할 가치가 있는 착수를 빠르게 식별할 수 있게 해줍니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="참고-자료">참고 자료<a href="#참고-자료" class="hash-link" aria-label="참고 자료에 대한 직접 링크" title="참고 자료에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Maddison, C. J., et al. (2014). &quot;Move Evaluation in Go Using Deep Convolutional Neural Networks.&quot; <em>arXiv:1412.6564</em>.</li>
<li class="">Sutton, R. S., &amp; Barto, A. G. (2018). <em>Reinforcement Learning: An Introduction</em>. MIT Press.</li>
<li class="">LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). &quot;Deep learning.&quot; <em>Nature</em>, 521, 436-444.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/07-policy-network.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">바둑판 상태 표현</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/for-engineers/how-it-works/alphago-explained/value-network/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">Value Network 상세 해설</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#policy-network란-무엇인가" class="table-of-contents__link toc-highlight">Policy Network란 무엇인가?</a><ul><li><a href="#핵심-기능" class="table-of-contents__link toc-highlight">핵심 기능</a></li><li><a href="#직관적-이해" class="table-of-contents__link toc-highlight">직관적 이해</a></li><li><a href="#왜-policy-network가-필요한가" class="table-of-contents__link toc-highlight">왜 Policy Network가 필요한가?</a></li></ul></li><li><a href="#네트워크-아키텍처" class="table-of-contents__link toc-highlight">네트워크 아키텍처</a><ul><li><a href="#전체-구조" class="table-of-contents__link toc-highlight">전체 구조</a></li><li><a href="#입력층" class="table-of-contents__link toc-highlight">입력층</a></li><li><a href="#컨볼루션층" class="table-of-contents__link toc-highlight">컨볼루션층</a></li><li><a href="#relu-활성화-함수" class="table-of-contents__link toc-highlight">ReLU 활성화 함수</a></li><li><a href="#출력층" class="table-of-contents__link toc-highlight">출력층</a></li><li><a href="#파라미터-수" class="table-of-contents__link toc-highlight">파라미터 수</a></li></ul></li><li><a href="#학습-목표와-방법" class="table-of-contents__link toc-highlight">학습 목표와 방법</a><ul><li><a href="#학습-데이터" class="table-of-contents__link toc-highlight">학습 데이터</a></li><li><a href="#교차-엔트로피-손실-함수" class="table-of-contents__link toc-highlight">교차 엔트로피 손실 함수</a></li><li><a href="#학습-과정" class="table-of-contents__link toc-highlight">학습 과정</a></li><li><a href="#데이터-증강" class="table-of-contents__link toc-highlight">데이터 증강</a></li></ul></li><li><a href="#학습-결과" class="table-of-contents__link toc-highlight">학습 결과</a><ul><li><a href="#57-정확도" class="table-of-contents__link toc-highlight">57% 정확도</a></li><li><a href="#기력-향상" class="table-of-contents__link toc-highlight">기력 향상</a></li><li><a href="#왜-57밖에-안-되는가" class="table-of-contents__link toc-highlight">왜 57%밖에 안 되는가?</a></li></ul></li><li><a href="#mcts에서의-역할" class="table-of-contents__link toc-highlight">MCTS에서의 역할</a><ul><li><a href="#1-탐색-방향-안내" class="table-of-contents__link toc-highlight">1. 탐색 방향 안내</a></li><li><a href="#2-노드-확장-시-사전-확률" class="table-of-contents__link toc-highlight">2. 노드 확장 시 사전 확률</a></li></ul></li><li><a href="#경량-버전-vs-완전-버전" class="table-of-contents__link toc-highlight">경량 버전 vs 완전 버전</a><ul><li><a href="#완전-버전-sl-policy-network" class="table-of-contents__link toc-highlight">완전 버전 (SL Policy Network)</a></li><li><a href="#경량-버전-rollout-policy-network" class="table-of-contents__link toc-highlight">경량 버전 (Rollout Policy Network)</a></li><li><a href="#왜-경량-버전이-필요한가" class="table-of-contents__link toc-highlight">왜 경량 버전이 필요한가?</a></li><li><a href="#경량-버전의-특성" class="table-of-contents__link toc-highlight">경량 버전의 특성</a></li><li><a href="#alphago-zero의-개선" class="table-of-contents__link toc-highlight">AlphaGo Zero의 개선</a></li></ul></li><li><a href="#강화학습-미세조정-rl-policy-network" class="table-of-contents__link toc-highlight">강화학습 미세조정 (RL Policy Network)</a><ul><li><a href="#지도-학습의-한계" class="table-of-contents__link toc-highlight">지도 학습의 한계</a></li><li><a href="#셀프-플레이-강화" class="table-of-contents__link toc-highlight">셀프 플레이 강화</a></li><li><a href="#reinforce-알고리즘" class="table-of-contents__link toc-highlight">REINFORCE 알고리즘</a></li><li><a href="#결과" class="table-of-contents__link toc-highlight">결과</a></li><li><a href="#모방에서-혁신으로" class="table-of-contents__link toc-highlight">&#39;모방&#39;에서 &#39;혁신&#39;으로</a></li></ul></li><li><a href="#시각화-분석" class="table-of-contents__link toc-highlight">시각화 분석</a><ul><li><a href="#다른-국면의-확률-분포" class="table-of-contents__link toc-highlight">다른 국면의 확률 분포</a></li><li><a href="#은닉층은-무엇을-배웠나" class="table-of-contents__link toc-highlight">은닉층은 무엇을 배웠나?</a></li></ul></li><li><a href="#구현-포인트" class="table-of-contents__link toc-highlight">구현 포인트</a><ul><li><a href="#pytorch-구현" class="table-of-contents__link toc-highlight">PyTorch 구현</a></li><li><a href="#학습-루프" class="table-of-contents__link toc-highlight">학습 루프</a></li><li><a href="#추론-시-주의사항" class="table-of-contents__link toc-highlight">추론 시 주의사항</a></li></ul></li><li><a href="#애니메이션-대응" class="table-of-contents__link toc-highlight">애니메이션 대응</a></li><li><a href="#추가-읽기" class="table-of-contents__link toc-highlight">추가 읽기</a></li><li><a href="#핵심-포인트" class="table-of-contents__link toc-highlight">핵심 포인트</a></li><li><a href="#참고-자료" class="table-of-contents__link toc-highlight">참고 자료</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>