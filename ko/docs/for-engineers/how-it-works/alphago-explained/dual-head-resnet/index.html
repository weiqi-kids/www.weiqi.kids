<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/dual-head-resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">이중 헤드 네트워크와 잔차 네트워크 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="이중 헤드 네트워크와 잔차 네트워크 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="AlphaGo Zero의 신경망 아키텍처 심층 분석 - 공유 백본, Policy Head, Value Head와 40층 ResNet"><meta data-rh="true" property="og:description" content="AlphaGo Zero의 신경망 아키텍처 심층 분석 - 공유 백본, Policy Head, Value Head와 40층 ResNet"><meta data-rh="true" name="keywords" content="이중 헤드 네트워크,잔차 네트워크,ResNet,Policy Head,Value Head,딥러닝,신경망 아키텍처"><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/ko/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"이중 헤드 네트워크와 잔차 네트워크","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ko/assets/css/styles.f23bf74b.css">
<script src="/ko/assets/js/runtime~main.b152227b.js" defer="defer"></script>
<script src="/ko/assets/js/main.7cf510df.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">바둑 키즈</b></a><a class="navbar__item navbar__link" href="/ko/docs/for-players/">바둑 플레이어</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/for-engineers/">엔지니어</a><a class="navbar__item navbar__link" href="/ko/docs/about/">협회 소개</a><a class="navbar__item navbar__link" href="/ko/docs/activities/">활동 실적</a><a class="navbar__item navbar__link" href="/ko/docs/references/">참고 자료</a><a class="navbar__item navbar__link" href="/ko/docs/sop/">표준 운영 절차</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/"><span title="이용 안내" class="linkLabel_REp1">이용 안내</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="사이드바 분류 &#x27;關於協會&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="사이드바 분류 &#x27;活動實績&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/for-players/"><span title="바둑 기사를 위한 자료" class="categoryLinkLabel_ezQx">바둑 기사를 위한 자료</span></a><button aria-label="사이드바 분류 &#x27;바둑 기사를 위한 자료&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="사이드바 분류 &#x27;參考資料&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="사이드바 분류 &#x27;標準作業流程&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ko/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="사이드바 분류 &#x27;給工程師的圍棋 AI 指南&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/deep-dive/"><span title="심층 연구를 원하는 분들을 위해" class="categoryLinkLabel_ezQx">심층 연구를 원하는 분들을 위해</span></a><button aria-label="사이드바 분류 &#x27;심층 연구를 원하는 분들을 위해&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;30 分鐘跑起第一個圍棋 AI&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;一篇文章搞懂圍棋 AI&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="사이드바 분류 &#x27;AlphaGo 完整解析&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="AlphaGo의 탄생" class="linkLabel_REp1">AlphaGo의 탄생</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="주요 대국 리뷰" class="linkLabel_REp1">주요 대국 리뷰</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="&quot;신의 한 수&quot; 심층 분석" class="linkLabel_REp1">&quot;신의 한 수&quot; 심층 분석</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="바둑은 왜 어려운가?" class="linkLabel_REp1">바둑은 왜 어려운가?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="전통적 방법의 한계" class="linkLabel_REp1">전통적 방법의 한계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="바둑판 상태 표현" class="linkLabel_REp1">바둑판 상태 표현</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="Policy Network 상세 해설" class="linkLabel_REp1">Policy Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="Value Network 상세 해설" class="linkLabel_REp1">Value Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="입력 특성 설계" class="linkLabel_REp1">입력 특성 설계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="CNN과 바둑의 결합" class="linkLabel_REp1">CNN과 바둑의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="지도 학습 단계" class="linkLabel_REp1">지도 학습 단계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="강화 학습 입문" class="linkLabel_REp1">강화 학습 입문</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="자기 대국" class="linkLabel_REp1">자기 대국</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="MCTS와 신경망의 결합" class="linkLabel_REp1">MCTS와 신경망의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="PUCT 공식 상세" class="linkLabel_REp1">PUCT 공식 상세</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="AlphaGo Zero 개요" class="linkLabel_REp1">AlphaGo Zero 개요</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="이중 헤드 네트워크와 잔차 네트워크" class="linkLabel_REp1">이중 헤드 네트워크와 잔차 네트워크</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="처음부터 훈련하는 과정" class="linkLabel_REp1">처음부터 훈련하는 과정</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="분산 시스템과 TPU" class="linkLabel_REp1">분산 시스템과 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="AlphaGo의 유산" class="linkLabel_REp1">AlphaGo의 유산</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 產業現況&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 能做什麼？&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">이중 헤드 네트워크와 잔차 네트워크</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>이중 헤드 네트워크와 잔차 네트워크</h1></header>
<p>AlphaGo Zero의 가장 중요한 아키텍처 혁신 중 하나는 원본 AlphaGo의 이중 네트워크 설계를 **이중 헤드 네트워크(Dual-Head Network)**로 대체한 것입니다. 이 단순해 보이는 변화가 상당한 성능 향상과 더 우아한 학습 과정을 가져왔습니다.</p>
<p>이 글에서는 이 아키텍처의 설계 원리, 수학적 기초, 그리고 왜 이렇게 효과적인지 심층 분석합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="이중-헤드-네트워크-설계">이중 헤드 네트워크 설계<a href="#이중-헤드-네트워크-설계" class="hash-link" aria-label="이중 헤드 네트워크 설계에 대한 직접 링크" title="이중 헤드 네트워크 설계에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="전체-아키텍처">전체 아키텍처<a href="#전체-아키텍처" class="hash-link" aria-label="전체 아키텍처에 대한 직접 링크" title="전체 아키텍처에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero의 신경망은 세 부분으로 나눌 수 있습니다:</p>
<!-- -->
<p>각 부분을 하나씩 분석해 보겠습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="공유-백본shared-backbone">공유 백본(Shared Backbone)<a href="#공유-백본shared-backbone" class="hash-link" aria-label="공유 백본(Shared Backbone)에 대한 직접 링크" title="공유 백본(Shared Backbone)에 대한 직접 링크" translate="no">​</a></h3>
<p>공유 백본은 깊은 **잔차 네트워크(ResNet)**로, 바둑판 상태에서 특징을 추출하는 역할을 합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="아키텍처-세부사항">아키텍처 세부사항<a href="#아키텍처-세부사항" class="hash-link" aria-label="아키텍처 세부사항에 대한 직접 링크" title="아키텍처 세부사항에 대한 직접 링크" translate="no">​</a></h4>
<table><thead><tr><th>구성요소</th><th>사양</th></tr></thead><tbody><tr><td>입력층</td><td>3×3 컨볼루션, 256 채널</td></tr><tr><td>잔차 블록</td><td>40개(또는 20개 경량 버전)</td></tr><tr><td>각 잔차 블록</td><td>2층 3×3 컨볼루션, 256 채널</td></tr><tr><td>활성화 함수</td><td>ReLU</td></tr><tr><td>정규화</td><td>Batch Normalization</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="수학적-표현">수학적 표현<a href="#수학적-표현" class="hash-link" aria-label="수학적 표현에 대한 직접 링크" title="수학적 표현에 대한 직접 링크" translate="no">​</a></h4>
<p>입력을 x(차원 17 x 19 x 19)라 하면, 공유 백본의 출력은:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">f(x) = ResNet_40(Conv_3x3(x))</span><br></span></code></pre></div></div>
<p>여기서 f(x)(차원 256 x 19 x 19)는 고차원 특징 표현입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head정책-헤드">Policy Head(정책 헤드)<a href="#policy-head정책-헤드" class="hash-link" aria-label="Policy Head(정책 헤드)에 대한 직접 링크" title="Policy Head(정책 헤드)에 대한 직접 링크" translate="no">​</a></h3>
<p>Policy Head는 각 위치의 착점 확률을 예측하는 역할을 합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="아키텍처-세부사항-1">아키텍처 세부사항<a href="#아키텍처-세부사항-1" class="hash-link" aria-label="아키텍처 세부사항에 대한 직접 링크" title="아키텍처 세부사항에 대한 직접 링크" translate="no">​</a></h4>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="수학적-표현-1">수학적 표현<a href="#수학적-표현-1" class="hash-link" aria-label="수학적 표현에 대한 직접 링크" title="수학적 표현에 대한 직접 링크" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">π = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))</span><br></span></code></pre></div></div>
<p>출력 π는 362차원 벡터로, 모든 요소가 음이 아니고 합이 1입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head가치-헤드">Value Head(가치 헤드)<a href="#value-head가치-헤드" class="hash-link" aria-label="Value Head(가치 헤드)에 대한 직접 링크" title="Value Head(가치 헤드)에 대한 직접 링크" translate="no">​</a></h3>
<p>Value Head는 현재 국면의 승률을 예측하는 역할을 합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="아키텍처-세부사항-2">아키텍처 세부사항<a href="#아키텍처-세부사항-2" class="hash-link" aria-label="아키텍처 세부사항에 대한 직접 링크" title="아키텍처 세부사항에 대한 직접 링크" translate="no">​</a></h4>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="수학적-표현-2">수학적 표현<a href="#수학적-표현-2" class="hash-link" aria-label="수학적 표현에 대한 직접 링크" title="수학적 표현에 대한 직접 링크" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))</span><br></span></code></pre></div></div>
<p>출력 v는 [-1, 1] 범위:</p>
<ul>
<li class="">v = 1: 현재 측 필승</li>
<li class="">v = -1: 현재 측 필패</li>
<li class="">v = 0: 세력 균형</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-백본을-공유하는가">왜 백본을 공유하는가?<a href="#왜-백본을-공유하는가" class="hash-link" aria-label="왜 백본을 공유하는가?에 대한 직접 링크" title="왜 백본을 공유하는가?에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="직관적-이해">직관적 이해<a href="#직관적-이해" class="hash-link" aria-label="직관적 이해에 대한 직접 링크" title="직관적 이해에 대한 직접 링크" translate="no">​</a></h3>
<p>&quot;다음 수를 어디에 둘 것인가&quot;(Policy)와 &quot;누가 이길 것인가&quot;(Value) 이 두 질문은 실제로 동일한 바둑판 패턴 이해가 필요합니다:</p>
<ul>
<li class=""><strong>모양</strong>: 어떤 형태가 좋고, 어떤 것이 나쁜지</li>
<li class=""><strong>세력</strong>: 어느 쪽이 더 크고, 어디에 아직 공간이 있는지</li>
<li class=""><strong>사활</strong>: 어떤 돌이 이미 살았고, 어떤 것이 아직 패싸움 중인지</li>
<li class=""><strong>전투</strong>: 어디에 공격과 방어가 있고, 국소 승패가 어떤지</li>
</ul>
<p>두 개의 독립적인 네트워크를 사용하면 이러한 특징을 두 번 학습해야 합니다. 공유 백본으로 이러한 저수준 특징을 한 번만 학습하고 두 작업 모두 사용할 수 있습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="다중-작업-학습-관점">다중 작업 학습 관점<a href="#다중-작업-학습-관점" class="hash-link" aria-label="다중 작업 학습 관점에 대한 직접 링크" title="다중 작업 학습 관점에 대한 직접 링크" translate="no">​</a></h3>
<p>기계 학습 관점에서 이것은 **다중 작업 학습(Multi-task Learning)**입니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value</span><br></span></code></pre></div></div>
<p>두 작업이 저수준 표현을 공유하며, 이로 인한 장점:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-정규화-효과">1. 정규화 효과<a href="#1-정규화-효과" class="hash-link" aria-label="1. 정규화 효과에 대한 직접 링크" title="1. 정규화 효과에 대한 직접 링크" translate="no">​</a></h4>
<p>공유 매개변수는 암묵적 정규화와 같습니다. 특징이 Policy에만 유용하고 Value에는 무용하면(또는 반대로), 과도하게 증폭되기 어렵습니다.</p>
<p>유효 매개변수 양은 두 개의 독립 네트워크의 매개변수 양보다 작습니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-데이터-효율성">2. 데이터 효율성<a href="#2-데이터-효율성" class="hash-link" aria-label="2. 데이터 효율성에 대한 직접 링크" title="2. 데이터 효율성에 대한 직접 링크" translate="no">​</a></h4>
<p>각 대국이 동시에 Policy 라벨(MCTS 탐색 확률)과 Value 라벨(최종 승패)을 생성합니다. 공유 백본으로 두 라벨 모두 공유 특징 훈련에 사용되어 데이터 활용 효율이 높아집니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-풍부한-그래디언트-신호">3. 풍부한 그래디언트 신호<a href="#3-풍부한-그래디언트-신호" class="hash-link" aria-label="3. 풍부한 그래디언트 신호에 대한 직접 링크" title="3. 풍부한 그래디언트 신호에 대한 직접 링크" translate="no">​</a></h4>
<p>두 작업의 그래디언트가 모두 공유 백본으로 흐릅니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂θ_shared = ∂L_policy/∂θ_shared + ∂L_value/∂θ_shared</span><br></span></code></pre></div></div>
<p>더 풍부한 감독 신호를 제공하여 공유 특징이 더 견고해집니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="실험적-증거">실험적 증거<a href="#실험적-증거" class="hash-link" aria-label="실험적 증거에 대한 직접 링크" title="실험적 증거에 대한 직접 링크" translate="no">​</a></h3>
<p>DeepMind의 ablation 실험에 따르면, 이중 헤드 네트워크가 분리된 이중 네트워크보다 상당히 우수합니다:</p>
<table><thead><tr><th>구성</th><th>ELO 평점</th><th>상대적 격차</th></tr></thead><tbody><tr><td>분리된 Policy + Value 네트워크</td><td>기준</td><td>-</td></tr><tr><td>이중 헤드 네트워크(공유 백본)</td><td>+300 ELO</td><td>~65% 승률 격차</td></tr></tbody></table>
<p>300 ELO의 격차는 이중 헤드 네트워크가 분리된 네트워크에 대해 약 65%의 승률을 가진다는 것을 의미합니다. 이것은 상당한 향상입니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="잔차-네트워크-원리">잔차 네트워크 원리<a href="#잔차-네트워크-원리" class="hash-link" aria-label="잔차 네트워크 원리에 대한 직접 링크" title="잔차 네트워크 원리에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="심층-네트워크의-딜레마">심층 네트워크의 딜레마<a href="#심층-네트워크의-딜레마" class="hash-link" aria-label="심층 네트워크의 딜레마에 대한 직접 링크" title="심층 네트워크의 딜레마에 대한 직접 링크" translate="no">​</a></h3>
<p>ResNet 발명 전에 심층 신경망은 역설에 직면했습니다:</p>
<blockquote>
<p>이론적으로 더 깊은 네트워크는 적어도 얕은 네트워크만큼 좋아야 합니다(최악의 경우 추가 층이 항등 매핑을 학습할 수 있음). 하지만 실제로 더 깊은 네트워크가 종종 더 나쁜 성능을 보입니다.</p>
</blockquote>
<p>이것이 **퇴화 문제(Degradation Problem)**입니다:</p>
<ul>
<li class="">훈련 오류가 깊이 증가에 따라 증가(과적합이 아니라 최적화 어려움)</li>
<li class="">역전파 시 그래디언트가 점점 사라짐(Vanishing Gradient)</li>
<li class="">심층의 매개변수가 거의 효과적으로 업데이트되지 않음</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="잔차-블록-설계">잔차 블록 설계<a href="#잔차-블록-설계" class="hash-link" aria-label="잔차 블록 설계에 대한 직접 링크" title="잔차 블록 설계에 대한 직접 링크" translate="no">​</a></h3>
<p>허카이밍 등이 2015년에 간결하고 우아한 해결책을 제안했습니다: <strong>잔차 연결(Skip Connection)</strong>.</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="수학적-표현-3">수학적 표현<a href="#수학적-표현-3" class="hash-link" aria-label="수학적 표현에 대한 직접 링크" title="수학적 표현에 대한 직접 링크" translate="no">​</a></h4>
<p>전통적 네트워크: 목표 매핑 H(x) 학습</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = H(x)</span><br></span></code></pre></div></div>
<p>잔차 네트워크: <strong>잔차 매핑</strong> F(x) = H(x) - x 학습</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = F(x) + x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-잔차-연결이-효과적인가">왜 잔차 연결이 효과적인가?<a href="#왜-잔차-연결이-효과적인가" class="hash-link" aria-label="왜 잔차 연결이 효과적인가?에 대한 직접 링크" title="왜 잔차 연결이 효과적인가?에 대한 직접 링크" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-그래디언트-고속도로">1. 그래디언트 고속도로<a href="#1-그래디언트-고속도로" class="hash-link" aria-label="1. 그래디언트 고속도로에 대한 직접 링크" title="1. 그래디언트 고속도로에 대한 직접 링크" translate="no">​</a></h4>
<p>역전파의 그래디언트를 고려하면:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂x = ∂L/∂y × ∂y/∂x = ∂L/∂y × (1 + ∂F(x)/∂x)</span><br></span></code></pre></div></div>
<p>핵심은 그 <strong>+1</strong>입니다. ∂F(x)/∂x가 매우 작거나 0이어도 그래디언트는 +1을 통해 직접 전달될 수 있습니다.</p>
<p>이것은 마치 &#x27;그래디언트 고속도로&#x27;를 건설하여 그래디언트가 출력층에서 입력층으로 막힘 없이 전달되게 합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-항등-매핑이-학습하기-더-쉬움">2. 항등 매핑이 학습하기 더 쉬움<a href="#2-항등-매핑이-학습하기-더-쉬움" class="hash-link" aria-label="2. 항등 매핑이 학습하기 더 쉬움에 대한 직접 링크" title="2. 항등 매핑이 학습하기 더 쉬움에 대한 직접 링크" translate="no">​</a></h4>
<p>최적해가 항등 매핑에 가까우면(H(x) ≈ x):</p>
<ul>
<li class="">전통적 네트워크: H(x) = x를 학습해야 함, 어려울 수 있음</li>
<li class="">잔차 네트워크: F(x) ≈ 0만 학습하면 됨, 상대적으로 쉬움</li>
</ul>
<p>가중치를 0 또는 0에 가깝게 초기화하면 잔차 블록이 자연스럽게 항등 매핑을 향합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-앙상블-효과">3. 앙상블 효과<a href="#3-앙상블-효과" class="hash-link" aria-label="3. 앙상블 효과에 대한 직접 링크" title="3. 앙상블 효과에 대한 직접 링크" translate="no">​</a></h4>
<p>심층 ResNet은 많은 얕은 네트워크의 <strong>암묵적 앙상블</strong>로 볼 수 있습니다. n개의 잔차 블록이 있으면 정보가 2^n 가지 다른 경로로 흐를 수 있습니다.</p>
<p>이 앙상블 효과가 모델의 견고성을 증가시킵니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="resnet의-imagenet-돌파">ResNet의 ImageNet 돌파<a href="#resnet의-imagenet-돌파" class="hash-link" aria-label="ResNet의 ImageNet 돌파에 대한 직접 링크" title="ResNet의 ImageNet 돌파에 대한 직접 링크" translate="no">​</a></h3>
<p>ResNet은 2015년 ImageNet 대회에서 놀라운 성과를 달성했습니다:</p>
<table><thead><tr><th>깊이</th><th>Top-5 오류율</th></tr></thead><tbody><tr><td>VGG-19(잔차 없음)</td><td>7.3%</td></tr><tr><td>ResNet-34</td><td>5.7%</td></tr><tr><td>ResNet-152</td><td>4.5%</td></tr><tr><td>인간 수준</td><td>~5.1%</td></tr></tbody></table>
<p><strong>152층</strong>의 ResNet이 훈련 가능할 뿐만 아니라 19층 VGG보다 훨씬 좋습니다. 이것은 잔차 연결이 심층 네트워크의 훈련 문제를 확실히 해결했음을 증명합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero의-40층-resnet">AlphaGo Zero의 40층 ResNet<a href="#alphago-zero의-40층-resnet" class="hash-link" aria-label="AlphaGo Zero의 40층 ResNet에 대한 직접 링크" title="AlphaGo Zero의 40층 ResNet에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-40층을-선택했는가">왜 40층을 선택했는가?<a href="#왜-40층을-선택했는가" class="hash-link" aria-label="왜 40층을 선택했는가?에 대한 직접 링크" title="왜 40층을 선택했는가?에 대한 직접 링크" translate="no">​</a></h3>
<p>DeepMind는 다른 깊이의 ResNet을 테스트했습니다:</p>
<table><thead><tr><th>잔차 블록 수</th><th>총 층 수</th><th>ELO 평점</th></tr></thead><tbody><tr><td>5</td><td>11</td><td>기준</td></tr><tr><td>10</td><td>21</td><td>+200</td></tr><tr><td>20</td><td>41</td><td>+400</td></tr><tr><td>40</td><td>81</td><td>+500</td></tr></tbody></table>
<p>더 깊은 네트워크가 확실히 더 강하지만 한계 효용이 체감합니다. AlphaGo Zero는 20개 또는 40개 잔차 블록을 사용합니다:</p>
<ul>
<li class=""><strong>AlphaGo Zero(논문 버전)</strong>: 40개 잔차 블록, 256 채널</li>
<li class=""><strong>경량 버전</strong>: 20개 잔차 블록, 256 채널</li>
</ul>
<p>40층 구성이 기력과 훈련 비용 사이에서 좋은 균형을 이룹니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="구체적-구성">구체적 구성<a href="#구체적-구성" class="hash-link" aria-label="구체적 구성에 대한 직접 링크" title="구체적 구성에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero의 ResNet 구성:</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="매개변수-양-추정">매개변수 양 추정<a href="#매개변수-양-추정" class="hash-link" aria-label="매개변수 양 추정에 대한 직접 링크" title="매개변수 양 추정에 대한 직접 링크" translate="no">​</a></h4>
<table><thead><tr><th>구성요소</th><th>매개변수 양(약)</th></tr></thead><tbody><tr><td>입력 컨볼루션</td><td>17 × 3 × 3 × 256 ≈ 39K</td></tr><tr><td>각 잔차 블록</td><td>2 × 256 × 3 × 3 × 256 ≈ 1.2M</td></tr><tr><td>40개 잔차 블록</td><td>40 × 1.2M ≈ 47M</td></tr><tr><td>Policy Head</td><td>~1M</td></tr><tr><td>Value Head</td><td>~0.2M</td></tr><tr><td><strong>총계</strong></td><td><strong>~48M</strong></td></tr></tbody></table>
<p>약 4,800만 매개변수로, 현대 기준으로는 중간 규모의 신경망입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="batch-normalization의-역할">Batch Normalization의 역할<a href="#batch-normalization의-역할" class="hash-link" aria-label="Batch Normalization의 역할에 대한 직접 링크" title="Batch Normalization의 역할에 대한 직접 링크" translate="no">​</a></h3>
<p>각 컨볼루션층 다음에 **Batch Normalization(BN)**이 있으며, 훈련 안정성에 매우 중요합니다:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-활성값-정규화">1. 활성값 정규화<a href="#1-활성값-정규화" class="hash-link" aria-label="1. 활성값 정규화에 대한 직접 링크" title="1. 활성값 정규화에 대한 직접 링크" translate="no">​</a></h4>
<p>BN은 각 층의 활성값을 평균 0, 분산 1로 정규화합니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_B) / sqrt(σ_B² + ε)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y = γ × x_hat + β</span><br></span></code></pre></div></div>
<p>여기서 γ와 β는 학습 가능한 매개변수입니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-내부-공변량-이동-완화">2. 내부 공변량 이동 완화<a href="#2-내부-공변량-이동-완화" class="hash-link" aria-label="2. 내부 공변량 이동 완화에 대한 직접 링크" title="2. 내부 공변량 이동 완화에 대한 직접 링크" translate="no">​</a></h4>
<p>심층 네트워크에서 각 층의 입력 분포가 이전 층의 매개변수 업데이트에 따라 변합니다. BN은 각 층의 입력 분포를 안정적으로 유지하여 훈련 수렴을 가속화합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-정규화-효과">3. 정규화 효과<a href="#3-정규화-효과" class="hash-link" aria-label="3. 정규화 효과에 대한 직접 링크" title="3. 정규화 효과에 대한 직접 링크" translate="no">​</a></h4>
<p>BN은 훈련 시 mini-batch의 통계량을 사용하여 무작위성을 도입하고 경미한 정규화 효과가 있습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="다른-아키텍처와의-비교">다른 아키텍처와의 비교<a href="#다른-아키텍처와의-비교" class="hash-link" aria-label="다른 아키텍처와의 비교에 대한 직접 링크" title="다른 아키텍처와의 비교에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-원본-alphago의-cnn">vs. 원본 AlphaGo의 CNN<a href="#vs-원본-alphago의-cnn" class="hash-link" aria-label="vs. 원본 AlphaGo의 CNN에 대한 직접 링크" title="vs. 원본 AlphaGo의 CNN에 대한 직접 링크" translate="no">​</a></h3>
<table><thead><tr><th>특성</th><th>AlphaGo 원본</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>아키텍처 유형</td><td>표준 CNN</td><td>ResNet</td></tr><tr><td>깊이</td><td>13층</td><td>41-81층</td></tr><tr><td>잔차 연결</td><td>없음</td><td>있음</td></tr><tr><td>네트워크 수</td><td>2(분리)</td><td>1(공유)</td></tr><tr><td>BN</td><td>없음</td><td>있음</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-vgg-스타일-네트워크">vs. VGG 스타일 네트워크<a href="#vs-vgg-스타일-네트워크" class="hash-link" aria-label="vs. VGG 스타일 네트워크에 대한 직접 링크" title="vs. VGG 스타일 네트워크에 대한 직접 링크" translate="no">​</a></h3>
<p>VGG는 2014년 ImageNet 준우승 아키텍처로, 적층된 3×3 컨볼루션 사용:</p>
<table><thead><tr><th>특성</th><th>VGG</th><th>ResNet</th></tr></thead><tbody><tr><td>훈련 가능 최대 깊이</td><td>~19층</td><td>152+층</td></tr><tr><td>그래디언트 흐름</td><td>층별 감소</td><td>고속도로 있음</td></tr><tr><td>훈련 난이도</td><td>심층 어려움</td><td>심층 훈련 가능</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-inception--googlenet">vs. Inception / GoogLeNet<a href="#vs-inception--googlenet" class="hash-link" aria-label="vs. Inception / GoogLeNet에 대한 직접 링크" title="vs. Inception / GoogLeNet에 대한 직접 링크" translate="no">​</a></h3>
<p>Inception은 다중 스케일 컨볼루션 병렬 사용:</p>
<table><thead><tr><th>특성</th><th>Inception</th><th>ResNet</th></tr></thead><tbody><tr><td>특징</td><td>다중 스케일 특징</td><td>깊이 적층</td></tr><tr><td>복잡도</td><td>높음</td><td>간결</td></tr><tr><td>바둑 적용성</td><td>일반적</td><td>우수</td></tr></tbody></table>
<p>ResNet의 간결한 설계가 바둑처럼 깊은 추론이 필요한 작업에 더 적합합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-transformer">vs. Transformer<a href="#vs-transformer" class="hash-link" aria-label="vs. Transformer에 대한 직접 링크" title="vs. Transformer에 대한 직접 링크" translate="no">​</a></h3>
<p>2017년 제안된 Transformer 아키텍처는 NLP 분야에서 큰 성공을 거뒀습니다. 누군가 Transformer를 바둑에 적용하려 시도했습니다:</p>
<table><thead><tr><th>특성</th><th>ResNet</th><th>Transformer</th></tr></thead><tbody><tr><td>귀납적 편향</td><td>지역성(컨볼루션)</td><td>전역 주의</td></tr><tr><td>위치 인코딩</td><td>암묵적(컨볼루션)</td><td>명시적</td></tr><tr><td>바둑 성능</td><td>우수</td><td>가능하지만 ResNet보다 낫지 않음</td></tr><tr><td>계산 효율</td><td>높음</td><td>낮음(O(n²))</td></tr></tbody></table>
<p>바둑처럼 명확한 공간 구조가 있는 문제에는 CNN/ResNet의 귀납적 편향이 더 적합합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="설계-선택의-심층-분석">설계 선택의 심층 분석<a href="#설계-선택의-심층-분석" class="hash-link" aria-label="설계 선택의 심층 분석에 대한 직접 링크" title="설계 선택의 심층 분석에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-33-컨볼루션을-사용하는가">왜 3×3 컨볼루션을 사용하는가?<a href="#왜-33-컨볼루션을-사용하는가" class="hash-link" aria-label="왜 3×3 컨볼루션을 사용하는가?에 대한 직접 링크" title="왜 3×3 컨볼루션을 사용하는가?에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero는 전체적으로 3×3 컨볼루션을 사용하고 더 큰 커널은 사용하지 않습니다:</p>
<ol>
<li class=""><strong>매개변수 효율</strong>: 두 개의 3×3 컨볼루션의 수용 영역은 하나의 5×5와 같지만 매개변수가 더 적음(18 vs 25)</li>
<li class=""><strong>더 깊은 네트워크</strong>: 같은 매개변수 양으로 더 많은 층 적층 가능</li>
<li class=""><strong>더 많은 비선형성</strong>: 층 사이에 ReLU가 있어 표현력 증가</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-256-채널을-사용하는가">왜 256 채널을 사용하는가?<a href="#왜-256-채널을-사용하는가" class="hash-link" aria-label="왜 256 채널을 사용하는가?에 대한 직접 링크" title="왜 256 채널을 사용하는가?에 대한 직접 링크" translate="no">​</a></h3>
<p>256 채널은 경험적 선택입니다:</p>
<ul>
<li class=""><strong>너무 적음</strong>(예: 64): 표현력 부족, 복잡한 패턴 포착 불가</li>
<li class=""><strong>너무 많음</strong>(예: 512): 매개변수 양 두 배, 훈련 비용 크게 증가, 기력 향상은 제한적</li>
</ul>
<p>나중에 KataGo 실험에 따르면 채널 수는 훈련 자원에 따라 조정 가능:</p>
<ul>
<li class="">저자원: 128 채널, 20 블록</li>
<li class="">고자원: 256 채널, 40 블록</li>
<li class="">더 높은 자원: 384 채널, 60 블록</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-policy-head는-softmax-value-head는-tanh를-사용하는가">왜 Policy Head는 Softmax, Value Head는 Tanh를 사용하는가?<a href="#왜-policy-head는-softmax-value-head는-tanh를-사용하는가" class="hash-link" aria-label="왜 Policy Head는 Softmax, Value Head는 Tanh를 사용하는가?에 대한 직접 링크" title="왜 Policy Head는 Softmax, Value Head는 Tanh를 사용하는가?에 대한 직접 링크" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head-softmax">Policy Head: Softmax<a href="#policy-head-softmax" class="hash-link" aria-label="Policy Head: Softmax에 대한 직접 링크" title="Policy Head: Softmax에 대한 직접 링크" translate="no">​</a></h4>
<p>착점은 <strong>분류 문제</strong>—361개 위치(플러스 Pass) 중 하나 선택. Softmax 출력은:</p>
<ul>
<li class="">모든 확률이 음이 아님: π_i &gt;= 0</li>
<li class="">확률 합이 1: Σπ_i = 1</li>
</ul>
<p>확률 분포의 정의와 일치합니다.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head-tanh">Value Head: Tanh<a href="#value-head-tanh" class="hash-link" aria-label="Value Head: Tanh에 대한 직접 링크" title="Value Head: Tanh에 대한 직접 링크" translate="no">​</a></h4>
<p>승률은 <strong>회귀 문제</strong>—연속 값 예측. Tanh 출력 범위는 [-1, 1]:</p>
<ul>
<li class="">유계: 극단값 생성 안 함</li>
<li class="">대칭: 승과 패를 대칭적으로 처리</li>
<li class="">미분 가능: 그래디언트 계산 편리</li>
</ul>
<p>무계 출력(예: 선형층) 대신 Tanh 사용으로 훈련 불안정 방지.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="훈련-세부사항">훈련 세부사항<a href="#훈련-세부사항" class="hash-link" aria-label="훈련 세부사항에 대한 직접 링크" title="훈련 세부사항에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="손실-함수">손실 함수<a href="#손실-함수" class="hash-link" aria-label="손실 함수에 대한 직접 링크" title="손실 함수에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero의 총 손실은 세 항의 합:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value + L_reg</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-loss">Policy Loss<a href="#policy-loss" class="hash-link" aria-label="Policy Loss에 대한 직접 링크" title="Policy Loss에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>크로스 엔트로피 손실</strong> 사용, 네트워크 출력이 MCTS 탐색 확률에 근접하도록:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_policy = -Σ π_MCTS(a) × log(π_net(a))</span><br></span></code></pre></div></div>
<p>여기서:</p>
<ul>
<li class="">π_MCTS(a)는 행동 a에 대한 MCTS의 탐색 확률</li>
<li class="">π_net(a)는 네트워크가 출력한 확률</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-loss">Value Loss<a href="#value-loss" class="hash-link" aria-label="Value Loss에 대한 직접 링크" title="Value Loss에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>평균 제곱 오차(MSE)</strong> 사용, 네트워크 출력이 실제 승패에 근접하도록:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_value = (v_net - z)²</span><br></span></code></pre></div></div>
<p>여기서:</p>
<ul>
<li class="">v_net은 네트워크가 예측한 승률</li>
<li class="">z는 실제 경기 결과(+1 또는 -1)</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="regularization-loss">Regularization Loss<a href="#regularization-loss" class="hash-link" aria-label="Regularization Loss에 대한 직접 링크" title="Regularization Loss에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>L2 정규화</strong> 사용으로 과적합 방지:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_reg = c × ||θ||²</span><br></span></code></pre></div></div>
<p>여기서 c는 정규화 계수, θ는 네트워크 매개변수.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="옵티마이저-구성">옵티마이저 구성<a href="#옵티마이저-구성" class="hash-link" aria-label="옵티마이저 구성에 대한 직접 링크" title="옵티마이저 구성에 대한 직접 링크" translate="no">​</a></h3>
<table><thead><tr><th>매개변수</th><th>값</th></tr></thead><tbody><tr><td>옵티마이저</td><td>SGD + Momentum</td></tr><tr><td>모멘텀</td><td>0.9</td></tr><tr><td>초기 학습률</td><td>0.01</td></tr><tr><td>학습률 감소</td><td>매 X 스텝마다 반감</td></tr><tr><td>Batch Size</td><td>32 × 2048 = 64K(분산)</td></tr><tr><td>L2 정규화 계수</td><td>1e-4</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="데이터-증강">데이터 증강<a href="#데이터-증강" class="hash-link" aria-label="데이터 증강에 대한 직접 링크" title="데이터 증강에 대한 직접 링크" translate="no">​</a></h3>
<p>바둑판은 8중 대칭성(4번 회전 × 2번 뒤집기)이 있습니다. 훈련 시 각 국면이 8개의 동등한 훈련 샘플을 생성할 수 있습니다.</p>
<p>유효 훈련 데이터가 8배 증가하며 추가 자기 대국이 필요 없습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="구현-고려사항">구현 고려사항<a href="#구현-고려사항" class="hash-link" aria-label="구현 고려사항에 대한 직접 링크" title="구현 고려사항에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="메모리-최적화">메모리 최적화<a href="#메모리-최적화" class="hash-link" aria-label="메모리 최적화에 대한 직접 링크" title="메모리 최적화에 대한 직접 링크" translate="no">​</a></h3>
<p>40층 ResNet 훈련은 많은 메모리가 필요합니다:</p>
<ul>
<li class=""><strong>순전파</strong>: 각 층의 활성값 저장 필요(역전파용)</li>
<li class=""><strong>역전파</strong>: 그래디언트 저장 필요</li>
</ul>
<p>최적화 전략:</p>
<ol>
<li class=""><strong>그래디언트 체크포인팅(Gradient Checkpointing)</strong>: 일부 활성값만 저장, 필요 시 재계산</li>
<li class=""><strong>혼합 정밀도 훈련</strong>: FP16 사용으로 메모리 점유 감소</li>
<li class=""><strong>분산 훈련</strong>: batch를 여러 GPU/TPU에 분산</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="추론-최적화">추론 최적화<a href="#추론-최적화" class="hash-link" aria-label="추론 최적화에 대한 직접 링크" title="추론 최적화에 대한 직접 링크" translate="no">​</a></h3>
<p>추론 시 BN의 mini-batch 통계량이 필요 없으며, 훈련 시 누적된 이동 평균 사용 가능:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_moving) / sqrt(σ_moving² + ε)</span><br></span></code></pre></div></div>
<p>추론 속도가 더 빠르고 결과가 결정적입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="양자화와-압축">양자화와 압축<a href="#양자화와-압축" class="hash-link" aria-label="양자화와 압축에 대한 직접 링크" title="양자화와 압축에 대한 직접 링크" translate="no">​</a></h3>
<p>배포 시 네트워크를 더 압축 가능:</p>
<ul>
<li class=""><strong>가중치 양자화</strong>: FP32 → INT8, 메모리 4배 감소</li>
<li class=""><strong>가지치기</strong>: 작은 가중치 연결 제거</li>
<li class=""><strong>지식 증류</strong>: 큰 네트워크로 작은 네트워크 훈련</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="애니메이션-대응">애니메이션 대응<a href="#애니메이션-대응" class="hash-link" aria-label="애니메이션 대응에 대한 직접 링크" title="애니메이션 대응에 대한 직접 링크" translate="no">​</a></h2>
<p>이 글에서 다루는 핵심 개념과 애니메이션 번호:</p>
<table><thead><tr><th>번호</th><th>개념</th><th>물리/수학 대응</th></tr></thead><tbody><tr><td>E3</td><td>이중 헤드 네트워크</td><td>다중 작업 학습</td></tr><tr><td>D12</td><td>잔차 연결</td><td>그래디언트 고속도로</td></tr><tr><td>D8</td><td>컨볼루션 신경망</td><td>국소 수용 영역</td></tr><tr><td>D10</td><td>Batch Normalization</td><td>분포 정규화</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="더-읽을거리">더 읽을거리<a href="#더-읽을거리" class="hash-link" aria-label="더 읽을거리에 대한 직접 링크" title="더 읽을거리에 대한 직접 링크" translate="no">​</a></h2>
<ul>
<li class=""><strong>이전 글</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/">AlphaGo Zero 개요</a> — 왜 인간 기보가 필요 없는가</li>
<li class=""><strong>다음 글</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/">처음부터의 훈련 과정</a> — Day 0-3의 상세 진화</li>
<li class=""><strong>기술 심화</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/">CNN과 바둑의 결합</a> — 왜 CNN이 바둑판에 적합한가</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="참고-자료">참고 자료<a href="#참고-자료" class="hash-link" aria-label="참고 자료에 대한 직접 링크" title="참고 자료에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">He, K., et al. (2016). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR 2016</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&quot; <em>ICML 2015</em>.</li>
<li class="">Caruana, R. (1997). &quot;Multitask Learning.&quot; <em>Machine Learning</em>, 28(1), 41-75.</li>
<li class="">Veit, A., et al. (2016). &quot;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&quot; <em>NeurIPS 2016</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/17-dual-head-resnet.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">AlphaGo Zero 개요</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">처음부터 훈련하는 과정</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#이중-헤드-네트워크-설계" class="table-of-contents__link toc-highlight">이중 헤드 네트워크 설계</a><ul><li><a href="#전체-아키텍처" class="table-of-contents__link toc-highlight">전체 아키텍처</a></li><li><a href="#공유-백본shared-backbone" class="table-of-contents__link toc-highlight">공유 백본(Shared Backbone)</a></li><li><a href="#policy-head정책-헤드" class="table-of-contents__link toc-highlight">Policy Head(정책 헤드)</a></li><li><a href="#value-head가치-헤드" class="table-of-contents__link toc-highlight">Value Head(가치 헤드)</a></li></ul></li><li><a href="#왜-백본을-공유하는가" class="table-of-contents__link toc-highlight">왜 백본을 공유하는가?</a><ul><li><a href="#직관적-이해" class="table-of-contents__link toc-highlight">직관적 이해</a></li><li><a href="#다중-작업-학습-관점" class="table-of-contents__link toc-highlight">다중 작업 학습 관점</a></li><li><a href="#실험적-증거" class="table-of-contents__link toc-highlight">실험적 증거</a></li></ul></li><li><a href="#잔차-네트워크-원리" class="table-of-contents__link toc-highlight">잔차 네트워크 원리</a><ul><li><a href="#심층-네트워크의-딜레마" class="table-of-contents__link toc-highlight">심층 네트워크의 딜레마</a></li><li><a href="#잔차-블록-설계" class="table-of-contents__link toc-highlight">잔차 블록 설계</a></li><li><a href="#왜-잔차-연결이-효과적인가" class="table-of-contents__link toc-highlight">왜 잔차 연결이 효과적인가?</a></li><li><a href="#resnet의-imagenet-돌파" class="table-of-contents__link toc-highlight">ResNet의 ImageNet 돌파</a></li></ul></li><li><a href="#alphago-zero의-40층-resnet" class="table-of-contents__link toc-highlight">AlphaGo Zero의 40층 ResNet</a><ul><li><a href="#왜-40층을-선택했는가" class="table-of-contents__link toc-highlight">왜 40층을 선택했는가?</a></li><li><a href="#구체적-구성" class="table-of-contents__link toc-highlight">구체적 구성</a></li><li><a href="#batch-normalization의-역할" class="table-of-contents__link toc-highlight">Batch Normalization의 역할</a></li></ul></li><li><a href="#다른-아키텍처와의-비교" class="table-of-contents__link toc-highlight">다른 아키텍처와의 비교</a><ul><li><a href="#vs-원본-alphago의-cnn" class="table-of-contents__link toc-highlight">vs. 원본 AlphaGo의 CNN</a></li><li><a href="#vs-vgg-스타일-네트워크" class="table-of-contents__link toc-highlight">vs. VGG 스타일 네트워크</a></li><li><a href="#vs-inception--googlenet" class="table-of-contents__link toc-highlight">vs. Inception / GoogLeNet</a></li><li><a href="#vs-transformer" class="table-of-contents__link toc-highlight">vs. Transformer</a></li></ul></li><li><a href="#설계-선택의-심층-분석" class="table-of-contents__link toc-highlight">설계 선택의 심층 분석</a><ul><li><a href="#왜-33-컨볼루션을-사용하는가" class="table-of-contents__link toc-highlight">왜 3×3 컨볼루션을 사용하는가?</a></li><li><a href="#왜-256-채널을-사용하는가" class="table-of-contents__link toc-highlight">왜 256 채널을 사용하는가?</a></li><li><a href="#왜-policy-head는-softmax-value-head는-tanh를-사용하는가" class="table-of-contents__link toc-highlight">왜 Policy Head는 Softmax, Value Head는 Tanh를 사용하는가?</a></li></ul></li><li><a href="#훈련-세부사항" class="table-of-contents__link toc-highlight">훈련 세부사항</a><ul><li><a href="#손실-함수" class="table-of-contents__link toc-highlight">손실 함수</a></li><li><a href="#옵티마이저-구성" class="table-of-contents__link toc-highlight">옵티마이저 구성</a></li><li><a href="#데이터-증강" class="table-of-contents__link toc-highlight">데이터 증강</a></li></ul></li><li><a href="#구현-고려사항" class="table-of-contents__link toc-highlight">구현 고려사항</a><ul><li><a href="#메모리-최적화" class="table-of-contents__link toc-highlight">메모리 최적화</a></li><li><a href="#추론-최적화" class="table-of-contents__link toc-highlight">추론 최적화</a></li><li><a href="#양자화와-압축" class="table-of-contents__link toc-highlight">양자화와 압축</a></li></ul></li><li><a href="#애니메이션-대응" class="table-of-contents__link toc-highlight">애니메이션 대응</a></li><li><a href="#더-읽을거리" class="table-of-contents__link toc-highlight">더 읽을거리</a></li><li><a href="#참고-자료" class="table-of-contents__link toc-highlight">참고 자료</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>