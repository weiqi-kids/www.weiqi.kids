<!doctype html>
<html lang="ko" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/self-play" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">자기 대국 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ko/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/"><meta data-rh="true" property="og:locale" content="ko"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="자기 대국 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="AlphaGo가 자기 대국을 통해 인간 기력의 한계를 어떻게 돌파했는지 깊이 이해하기"><meta data-rh="true" property="og:description" content="AlphaGo가 자기 대국을 통해 인간 기력의 한계를 어떻게 돌파했는지 깊이 이해하기"><link data-rh="true" rel="icon" href="/ko/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/self-play/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/ko/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"자기 대국","item":"https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/self-play"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ko/assets/css/styles.f23bf74b.css">
<script src="/ko/assets/js/runtime~main.b152227b.js" defer="defer"></script>
<script src="/ko/assets/js/main.7cf510df.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ko/img/logo.svg"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ko/"><div class="navbar__logo"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ko/img/logo.svg" alt="호기보보협회 로고" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">바둑 키즈</b></a><a class="navbar__item navbar__link" href="/ko/docs/for-players/">바둑 플레이어</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ko/docs/for-engineers/">엔지니어</a><a class="navbar__item navbar__link" href="/ko/docs/about/">협회 소개</a><a class="navbar__item navbar__link" href="/ko/docs/activities/">활동 실적</a><a class="navbar__item navbar__link" href="/ko/docs/references/">참고 자료</a><a class="navbar__item navbar__link" href="/ko/docs/sop/">표준 운영 절차</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ko/docs/intro/"><span title="이용 안내" class="linkLabel_REp1">이용 안내</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="사이드바 분류 &#x27;關於協會&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="사이드바 분류 &#x27;活動實績&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/for-players/"><span title="바둑 기사를 위한 자료" class="categoryLinkLabel_ezQx">바둑 기사를 위한 자료</span></a><button aria-label="사이드바 분류 &#x27;바둑 기사를 위한 자료&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="사이드바 분류 &#x27;參考資料&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ko/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="사이드바 분류 &#x27;標準作業流程&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ko/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="사이드바 분류 &#x27;給工程師的圍棋 AI 指南&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/deep-dive/"><span title="심층 연구를 원하는 분들을 위해" class="categoryLinkLabel_ezQx">심층 연구를 원하는 분들을 위해</span></a><button aria-label="사이드바 분류 &#x27;심층 연구를 원하는 분들을 위해&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;30 分鐘跑起第一個圍棋 AI&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="사이드바 분류 &#x27;一篇文章搞懂圍棋 AI&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="사이드바 분류 &#x27;AlphaGo 完整解析&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="AlphaGo의 탄생" class="linkLabel_REp1">AlphaGo의 탄생</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="주요 대국 리뷰" class="linkLabel_REp1">주요 대국 리뷰</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="&quot;신의 한 수&quot; 심층 분석" class="linkLabel_REp1">&quot;신의 한 수&quot; 심층 분석</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="바둑은 왜 어려운가?" class="linkLabel_REp1">바둑은 왜 어려운가?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="전통적 방법의 한계" class="linkLabel_REp1">전통적 방법의 한계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="바둑판 상태 표현" class="linkLabel_REp1">바둑판 상태 표현</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="Policy Network 상세 해설" class="linkLabel_REp1">Policy Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="Value Network 상세 해설" class="linkLabel_REp1">Value Network 상세 해설</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="입력 특성 설계" class="linkLabel_REp1">입력 특성 설계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="CNN과 바둑의 결합" class="linkLabel_REp1">CNN과 바둑의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="지도 학습 단계" class="linkLabel_REp1">지도 학습 단계</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="강화 학습 입문" class="linkLabel_REp1">강화 학습 입문</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="자기 대국" class="linkLabel_REp1">자기 대국</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="MCTS와 신경망의 결합" class="linkLabel_REp1">MCTS와 신경망의 결합</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="PUCT 공식 상세" class="linkLabel_REp1">PUCT 공식 상세</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="AlphaGo Zero 개요" class="linkLabel_REp1">AlphaGo Zero 개요</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="이중 헤드 네트워크와 잔차 네트워크" class="linkLabel_REp1">이중 헤드 네트워크와 잔차 네트워크</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="처음부터 훈련하는 과정" class="linkLabel_REp1">처음부터 훈련하는 과정</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="분산 시스템과 TPU" class="linkLabel_REp1">분산 시스템과 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="AlphaGo의 유산" class="linkLabel_REp1">AlphaGo의 유산</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ko/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 產業現況&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ko/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="사이드바 분류 &#x27;圍棋 AI 能做什麼？&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ko/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">자기 대국</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>자기 대국</h1></header>
<p>이전 글에서 강화 학습의 기본 개념을 소개했습니다. 이제 AlphaGo 성공의 핵심 중 하나인 **자기 대국(Self-Play)**을 탐구해 보겠습니다.</p>
<p>이것은 모순처럼 보이는 개념입니다: <strong>AI가 어떻게 자신과 바둑을 두면서 더 강해질 수 있을까요?</strong></p>
<p>답은 깊고 우아하며, 게임 이론, 진화 역학, 그리고 학습의 본질에 관련됩니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="왜-자기-대국이-효과적인가">왜 자기 대국이 효과적인가?<a href="#왜-자기-대국이-효과적인가" class="hash-link" aria-label="왜 자기 대국이 효과적인가?에 대한 직접 링크" title="왜 자기 대국이 효과적인가?에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="직관적-설명">직관적 설명<a href="#직관적-설명" class="hash-link" aria-label="직관적 설명에 대한 직접 링크" title="직관적 설명에 대한 직접 링크" translate="no">​</a></h3>
<p>당신이 바둑 초보자이고, 무인도에서 혼자 연습한다고 상상해 보세요:</p>
<ol>
<li class="">한 판을 두며, 흑과 백 양쪽을 동시에 담당함</li>
<li class="">대국이 끝난 후, 어떤 수가 좋았고 어떤 수가 나빴는지 분석함</li>
<li class="">다음 대국에서 이전의 실수를 피하려고 시도함</li>
<li class="">이 과정을 수백만 번 반복함</li>
</ol>
<p>직관적으로 이것은 문제가 있어 보입니다:</p>
<ul>
<li class="">수준이 매우 낮다면, 흑백 양쪽 모두 나쁜 수를 두는데, 무엇을 배울 수 있을까?</li>
<li class="">&#x27;잘못된 균형&#x27;에 빠지지 않을까—양쪽 모두 나쁜 수를 두지만 서로 상쇄되는?</li>
</ul>
<p>그러나 실제로 자기 대국은 지속적인 향상을 만들어낼 수 있습니다. 이유는 다음과 같습니다:</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="점진적-약점-발견">점진적 약점 발견<a href="#점진적-약점-발견" class="hash-link" aria-label="점진적 약점 발견에 대한 직접 링크" title="점진적 약점 발견에 대한 직접 링크" translate="no">​</a></h3>
<p>핵심 통찰은: <strong>양쪽 모두 같은 AI라도, 각 대국의 결과에는 여전히 정보가 포함되어 있습니다</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">국면 A: AI가 수법 X를 선택, 최종 승리</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">국면 A: AI가 수법 Y를 선택, 최종 패배</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">→ 결론: 국면 A에서 X가 Y보다 좋음</span><br></span></code></pre></div></div>
<p>많은 대국의 통계를 통해, AI는 각 국면에서 어떤 선택이 더 좋은지 학습할 수 있습니다. 이것이 <strong>정책 경사</strong>의 본질입니다: 좋은 선택은 강화되고, 나쁜 선택은 억제됩니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="적대적-학습">적대적 학습<a href="#적대적-학습" class="hash-link" aria-label="적대적 학습에 대한 직접 링크" title="적대적 학습에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국에는 특별한 특성이 있습니다: <strong>훈련 상대가 자동으로 당신의 수준에 맞춰집니다</strong>.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">훈련 주기 1: AI가 효과적인 전술 T를 발견함</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">훈련 주기 2: 상대로서의 AI가 T에 대한 방어법을 배움</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">훈련 주기 3: 원래 AI가 더 좋은 전술 T&#x27;를 찾도록 강제됨</span><br></span></code></pre></div></div>
<p>이것은 **군비 경쟁(Arms Race)**을 형성하며, 양쪽이 끊임없이 서로의 약점을 발견하고 극복합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="인간-기보와의-비교">인간 기보와의 비교<a href="#인간-기보와의-비교" class="hash-link" aria-label="인간 기보와의 비교에 대한 직접 링크" title="인간 기보와의 비교에 대한 직접 링크" translate="no">​</a></h3>
<table><thead><tr><th>훈련 방식</th><th>장점</th><th>단점</th></tr></thead><tbody><tr><td><strong>인간 기보</strong></td><td>인간 지혜의 결정체 학습</td><td>인간 수준에 제한됨</td></tr><tr><td><strong>자기 대국</strong></td><td>무제한 향상 잠재력</td><td>국소 최적에 빠질 수 있음</td></tr><tr><td><strong>둘의 결합</strong></td><td>빠른 시작 + 지속적 향상</td><td>최적의 전략</td></tr></tbody></table>
<p>AlphaGo 원본은 먼저 인간 기보로 지도 학습을 하고, 그 다음 자기 대국으로 강화 학습을 했습니다. AlphaGo Zero는 자기 대국만으로도 초인간 수준에 도달할 수 있음을 증명했습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="게임-이론-관점">게임 이론 관점<a href="#게임-이론-관점" class="hash-link" aria-label="게임 이론 관점에 대한 직접 링크" title="게임 이론 관점에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="내시-균형">내시 균형<a href="#내시-균형" class="hash-link" aria-label="내시 균형에 대한 직접 링크" title="내시 균형에 대한 직접 링크" translate="no">​</a></h3>
<p>게임 이론에서 **내시 균형(Nash Equilibrium)**은 안정 상태입니다: 이 상태에서 어떤 플레이어도 일방적으로 전략을 변경할 동기가 없습니다.</p>
<p>바둑과 같은 <strong>제로섬, 완전 정보 게임</strong>에서 내시 균형은 특별한 의미가 있습니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></msub><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^* = \arg\max_\pi \min_{\pi&#x27;} V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>여기서 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>는 전략 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span>가 전략 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\pi&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>와 대결할 때의 기대 가치입니다.</p>
<p>이것이 유명한 <strong>Minimax 원리</strong>입니다: 최적의 전략은 최악의 상황에서 가장 잘 수행하는 전략입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="자기-대국과-내시-균형">자기 대국과 내시 균형<a href="#자기-대국과-내시-균형" class="hash-link" aria-label="자기 대국과 내시 균형에 대한 직접 링크" title="자기 대국과 내시 균형에 대한 직접 링크" translate="no">​</a></h3>
<p>이론적으로, 자기 대국이 수렴한다면, 내시 균형으로 수렴해야 합니다. 바둑과 같은 결정적 게임에서 내시 균형은 <strong>완벽한 플레이</strong>입니다.</p>
<p>그러나 바둑의 상태 공간은 너무 큽니다(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>170</mn></msup></mrow><annotation encoding="application/x-tex">10^{170}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">170</span></span></span></span></span></span></span></span></span></span></span></span>). 진정한 내시 균형을 찾는 것은 불가능합니다. 자기 대국은 실제로 이 균형을 <strong>근사</strong>합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="가상-대국fictitious-play">가상 대국(Fictitious Play)<a href="#가상-대국fictitious-play" class="hash-link" aria-label="가상 대국(Fictitious Play)에 대한 직접 링크" title="가상 대국(Fictitious Play)에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국은 게임 이론의 <strong>가상 대국</strong> 개념과 관련이 있습니다:</p>
<ol>
<li class="">각 플레이어가 상대의 역사적 전략을 관찰함</li>
<li class="">상대 전략의 평균 분포를 계산함</li>
<li class="">이 평균 분포에 대한 최적의 응답을 선택함</li>
</ol>
<p>어떤 조건에서 가상 대국은 내시 균형으로 수렴한다고 증명할 수 있습니다.</p>
<p>AlphaGo의 자기 대국은 이 개념의 신경망 구현으로 볼 수 있습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="자기-대국의-메커니즘">자기 대국의 메커니즘<a href="#자기-대국의-메커니즘" class="hash-link" aria-label="자기 대국의 메커니즘에 대한 직접 링크" title="자기 대국의 메커니즘에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="기본-흐름">기본 흐름<a href="#기본-흐름" class="hash-link" aria-label="기본 흐름에 대한 직접 링크" title="기본 흐름에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 자기 대국 흐름:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">알고리즘: Self-Play Training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">초기화: Policy Network π_θ(지도 학습 또는 무작위 초기화에서 시작 가능)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">수렴할 때까지 다음 단계 반복:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. 대국 데이터 생성</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   i = 1부터 N까지(병렬 진행):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. 현재 정책 π_θ로 한 판 자기 대국 진행</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 궤적 수집: τ_i = (s_0, a_0, r_1, s_1, a_1, ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. 최종 결과 기록 z_i ∈ {-1, +1}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 정책 업데이트</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 정책 경사 계산:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ∇J = (1/N) Σ_i Σ_t ∇_θ log π_θ(a_t|s_t) · z_i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 파라미터 업데이트: θ ← θ + α · ∇J</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 가치 네트워크 업데이트</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. (s, z) 쌍으로 Value Network 훈련</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 최소화: L = E[(V_φ(s) - z)²]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 선택: 평가하고 체크포인트 저장</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 새 정책이 이전 버전과 대결</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 승률 &gt; 55%이면 상대 풀 업데이트</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="훈련-데이터-생성">훈련 데이터 생성<a href="#훈련-데이터-생성" class="hash-link" aria-label="훈련 데이터 생성에 대한 직접 링크" title="훈련 데이터 생성에 대한 직접 링크" translate="no">​</a></h3>
<p>각 자기 대국은 **궤적(trajectory)**을 생성합니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, s_1, a_1, \ldots, s_T, z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)</span></span></span></span></p>
<p>여기서:</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: 시간 단계 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span>의 바둑판 상태</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: 시간 단계 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span>에서 선택한 행동</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span>: 최종 결과(+1 승리, -1 패배)</li>
</ul>
<p>200수의 대국은 200개의 훈련 샘플을 생성합니다. 매일 수십만 판의 자기 대국을 진행하면 훈련 데이터 양은 놀랍습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="정책-업데이트">정책 업데이트<a href="#정책-업데이트" class="hash-link" aria-label="정책 업데이트에 대한 직접 링크" title="정책 업데이트에 대한 직접 링크" translate="no">​</a></h3>
<p>정책 경사를 사용하여 Policy Network 업데이트:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>z</mi><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \cdot \nabla_\theta \mathbb{E}\left[\sum_t \log \pi_\theta(a_t|s_t) \cdot z\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1308em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose delimcenter" style="top:0em">]</span></span></span></span></span></p>
<p>이 업데이트의 효과:</p>
<ul>
<li class="">최종적으로 승리(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = +1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>)하면, 둔 모든 수의 확률을 높임</li>
<li class="">최종적으로 패배(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = -1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>)하면, 둔 모든 수의 확률을 낮춤</li>
</ul>
<p>이것은 조잡해 보입니다—이긴 대국에도 나쁜 수가 있을 수 있고, 진 대국에도 좋은 수가 있을 수 있습니다. 그러나 많은 대국의 통계를 통해 이러한 &#x27;잡음&#x27;은 평균화되고, 진정으로 좋은 수가 식별됩니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="가치-네트워크-훈련">가치 네트워크 훈련<a href="#가치-네트워크-훈련" class="hash-link" aria-label="가치 네트워크 훈련에 대한 직접 링크" title="가치 네트워크 훈련에 대한 직접 링크" translate="no">​</a></h3>
<p>Value Network는 **회귀(regression)**로 훈련됩니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>←</mo><mi>ϕ</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ϕ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>z</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\phi \leftarrow \phi - \beta \cdot \nabla_\phi \mathbb{E}\left[(V_\phi(s) - z)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>이것은 Value Network가 예측하는 방법을 배우게 합니다: 현재 국면에서 시작하여 최종적으로 승리할 확률은 얼마인가?</p>
<p>Value Network의 역할은:</p>
<ol>
<li class="">MCTS에서 리프 노드 평가 제공</li>
<li class="">정책 경사의 기준선(baseline) 역할</li>
<li class="">직접적인 국면 평가에 사용</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="무작위화의-중요성">무작위화의 중요성<a href="#무작위화의-중요성" class="hash-link" aria-label="무작위화의 중요성에 대한 직접 링크" title="무작위화의 중요성에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="결정적-순환-피하기">결정적 순환 피하기<a href="#결정적-순환-피하기" class="hash-link" aria-label="결정적 순환 피하기에 대한 직접 링크" title="결정적 순환 피하기에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국이 완전히 결정적이라면, 순환에 빠질 수 있습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">전략 A가 항상 고정된 오프닝을 둠</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">전략 A 대 전략 A는 항상 같은 대국을 생성</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">한 대국만 반복적으로 학습됨</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">AI가 다른 가능성을 탐색할 수 없음</span><br></span></code></pre></div></div>
<p>이것이 자기 대국에서 <strong>무작위성</strong>이 중요한 이유입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="무작위화의-원천">무작위화의 원천<a href="#무작위화의-원천" class="hash-link" aria-label="무작위화의 원천에 대한 직접 링크" title="무작위화의 원천에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo가 자기 대국에서 무작위성을 도입하는 방법:</p>
<p><strong>1. 정책 네트워크 자체가 확률적</strong></p>
<p>Policy Network는 결정적 선택이 아닌 확률 분포를 출력합니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a \sim \pi_\theta(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></p>
<p>같은 국면에서 매번 다른 착수를 선택할 수 있습니다.</p>
<p><strong>2. 온도 파라미터</strong></p>
<p>훈련 시 다양성을 높이기 위해 높은 온도를 사용합니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow><mrow><msub><mo>∑</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\pi_\tau(a|s) = \frac{\pi_\theta(a|s)^{1/\tau}}{\sum_{a&#x27;} \pi_\theta(a&#x27;|s)^{1/\tau}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7721em;vertical-align:-0.6104em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1617em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2854em"><span style="top:-2.2854em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.6068em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em"><span style="top:-2.8496em;margin-right:0.1em"><span class="pstrut" style="height:2.5556em"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667em"><span style="top:-2.9667em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6104em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: 더 무작위, 더 많은 탐색</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: 더 결정적, 더 많은 활용</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>: 원래 분포</li>
</ul>
<p><strong>3. 디리클레 노이즈(Dirichlet Noise)</strong></p>
<p>AlphaGo Zero는 자기 대국 시 루트 노드의 사전 확률에 디리클레 노이즈를 추가합니다:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><mo>⋅</mo><msub><mi>η</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">P(s, a) = (1 - \varepsilon) \cdot \pi_\theta(a|s) + \varepsilon \cdot \eta_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>여기서 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>∼</mo><mtext>Dir</mtext><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\eta \sim \text{Dir}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mclose">)</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span>(바둑의 361개 행동에 대해).</p>
<p>이것은 매우 낮은 확률의 수법도 탐색될 기회가 있음을 보장합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="대국-풀population-방법">대국 풀(Population) 방법<a href="#대국-풀population-방법" class="hash-link" aria-label="대국 풀(Population) 방법에 대한 직접 링크" title="대국 풀(Population) 방법에 대한 직접 링크" translate="no">​</a></h3>
<p>다양성을 높이는 또 다른 방법은 <strong>대국 풀</strong>을 유지하는 것입니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">대국 풀 = [π_1, π_2, π_3, ..., π_k](다른 버전의 전략)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">각 대국:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. 풀에서 무작위로 상대 선택</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 해당 상대와 대국</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 결과로 현재 정책 업데이트</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 정기적으로 개선된 정책을 풀에 추가</span><br></span></code></pre></div></div>
<p>이 방법의 장점:</p>
<ul>
<li class=""><strong>다양성</strong>: 다른 스타일의 상대</li>
<li class=""><strong>안정성</strong>: 특정 상대에 과적합 방지</li>
<li class=""><strong>견고성</strong>: 다양한 전략에 대응하는 법 학습</li>
</ul>
<p>AlphaGo 원본과 AlphaGo Zero 모두 비슷한 기술을 사용했습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="기력-성장-곡선">기력 성장 곡선<a href="#기력-성장-곡선" class="hash-link" aria-label="기력 성장 곡선에 대한 직접 링크" title="기력 성장 곡선에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="elo-평점-시스템">Elo 평점 시스템<a href="#elo-평점-시스템" class="hash-link" aria-label="Elo 평점 시스템에 대한 직접 링크" title="Elo 평점 시스템에 대한 직접 링크" translate="no">​</a></h3>
<p>AI 기력의 변화를 추적하기 위해 AlphaGo는 <strong>Elo 평점 시스템</strong>을 사용했습니다.</p>
<p>Elo 시스템의 기본 원리:</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>A 승리</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>B</mi></msub><mo>−</mo><msub><mi>R</mi><mi>A</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>400</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{A 승리}) = \frac{1}{1 + 10^{(R_B - R_A)/400}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">A </span><span class="mord hangul_fallback">승리</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3331em;vertical-align:-0.488em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.5703em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8853em"><span style="top:-2.8853em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight">A</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/400</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.488em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>여기서 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">R_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>와 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">R_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>는 양측의 Elo 점수입니다.</p>
<ul>
<li class="">점수 차이 200: 강자가 예상 75% 승리</li>
<li class="">점수 차이 400: 강자가 예상 90% 승리</li>
<li class="">점수 차이 800: 강자가 예상 99% 승리</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago의-기력-성장">AlphaGo의 기력 성장<a href="#alphago의-기력-성장" class="hash-link" aria-label="AlphaGo의 기력 성장에 대한 직접 링크" title="AlphaGo의 기력 성장에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo 각 버전의 기력 성장을 시각화해 보겠습니다:</p>
<div>載入中...</div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="성장-속도-분석">성장 속도 분석<a href="#성장-속도-분석" class="hash-link" aria-label="성장 속도 분석에 대한 직접 링크" title="성장 속도 분석에 대한 직접 링크" translate="no">​</a></h3>
<p>곡선에서 몇 가지 흥미로운 현상을 관찰할 수 있습니다:</p>
<p><strong>1. 초기 빠른 성장</strong></p>
<p>훈련의 처음 몇 시간 동안 AI는 기본 규칙과 간단한 전술을 배웠습니다. 이것은 <strong>저매달림 과일</strong> 단계입니다—수정할 명백한 실수가 너무 많습니다.</p>
<p><strong>2. 중기 안정적 성장</strong></p>
<p>기본 실수가 제거됨에 따라 AI는 더 정교한 전술과 정석을 학습하기 시작합니다. 성장 속도는 느려지지만 여전히 안정적입니다.</p>
<p><strong>3. 후기 성장 둔화</strong></p>
<p>AI가 이미 매우 강할 때, 추가 향상이 어려워집니다. 실수를 수정하는 것뿐만 아니라 완전히 새로운 전략을 발견해야 할 수 있습니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="인간을-초월하는-순간">인간을 초월하는 순간<a href="#인간을-초월하는-순간" class="hash-link" aria-label="인간을 초월하는 순간에 대한 직접 링크" title="인간을 초월하는 순간에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo 훈련 곡선의 주요 이정표:</p>
<table><thead><tr><th>이정표</th><th>해당 수준</th><th>달성 시간</th></tr></thead><tbody><tr><td>아마추어 강자 초월</td><td>Elo ~2700</td><td>약 3시간</td></tr><tr><td>Fan Hui 초월</td><td>Elo ~3500</td><td>약 36시간</td></tr><tr><td>이세돌 초월</td><td>Elo ~4500</td><td>약 60시간</td></tr><tr><td>원본 AlphaGo 초월</td><td>Elo ~5000</td><td>약 72시간</td></tr></tbody></table>
<p>이 숫자들(AlphaGo Zero에서)은 충격적입니다: <strong>AI가 3일 만에 처음부터 인류 수천 년의 바둑 지혜를 초월했습니다</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="수렴성-분석">수렴성 분석<a href="#수렴성-분석" class="hash-link" aria-label="수렴성 분석에 대한 직접 링크" title="수렴성 분석에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="자기-대국이-수렴하는가">자기 대국이 수렴하는가?<a href="#자기-대국이-수렴하는가" class="hash-link" aria-label="자기 대국이 수렴하는가?에 대한 직접 링크" title="자기 대국이 수렴하는가?에 대한 직접 링크" translate="no">​</a></h3>
<p>이것은 중요한 이론적 문제입니다. 짧은 답은: <strong>특정 조건에서는 그렇지만, 바둑은 너무 복잡해서 엄밀하게 증명할 수 없습니다</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="이론적-보장">이론적 보장<a href="#이론적-보장" class="hash-link" aria-label="이론적 보장에 대한 직접 링크" title="이론적 보장에 대한 직접 링크" translate="no">​</a></h3>
<p>더 단순한 게임(예: 틱택토)에서는 증명할 수 있습니다:</p>
<ol>
<li class=""><strong>존재성</strong>: 내시 균형이 존재함(Minimax 정리)</li>
<li class=""><strong>수렴성</strong>: 어떤 알고리즘(예: 가상 대국)은 내시 균형으로 수렴함</li>
</ol>
<p>바둑에 대해서는 엄밀한 수렴 보장이 없지만, 실험적 증거는 다음을 보여줍니다:</p>
<ul>
<li class="">기력이 지속적으로 향상됨</li>
<li class="">명백한 진동이나 퇴화가 나타나지 않음</li>
<li class="">최종 기력이 모든 알려진 인간을 초월함</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="가능한-실패-모드">가능한 실패 모드<a href="#가능한-실패-모드" class="hash-link" aria-label="가능한 실패 모드에 대한 직접 링크" title="가능한 실패 모드에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국이 겪을 수 있는 문제:</p>
<p><strong>1. 전략 순환(Strategy Cycling)</strong></p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">전략 A가 전략 B를 이김</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">전략 B가 전략 C를 이김</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">전략 C가 전략 A를 이김</span><br></span></code></pre></div></div>
<p>이것은 일부 게임(예: 가위바위보)에서 실제로 발생합니다. 그러나 바둑은 충분히 복잡해서 이런 순수한 순환은 발생하지 않는 것 같습니다.</p>
<p><strong>2. 자신에게 과적합</strong></p>
<p>AI가 자신의 스타일만을 위한 전략을 배워, 다른 스타일의 상대에 대응하지 못할 수 있습니다. 이것이 AlphaGo가 자신의 다른 버전과 대국하고, 최종적으로 인간 기사와 테스트하는 이유입니다.</p>
<p><strong>3. 국소 최적</strong></p>
<p>AI가 국소 최적에 빠질 수 있습니다—&#x27;나쁘지 않지만 최선은 아닌&#x27; 전략. 무작위화와 많은 대국이 이 문제를 피하는 데 도움이 됩니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="실제-관찰">실제 관찰<a href="#실제-관찰" class="hash-link" aria-label="실제 관찰에 대한 직접 링크" title="실제 관찰에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 훈련 과정에서 관찰된 것:</p>
<ol>
<li class=""><strong>지속적 향상</strong>: Elo 점수가 훈련에 따라 계속 상승</li>
<li class=""><strong>퇴화 없음</strong>: 기력이 갑자기 떨어지는 일 없음</li>
<li class=""><strong>스타일 진화</strong>: AI의 바둑 스타일이 훈련에 따라 점차 변화</li>
<li class=""><strong>새로운 정석 발견</strong>: AI가 인간이 사용한 적 없는 오프닝과 전술을 발견</li>
</ol>
<p>이러한 관찰은 이론적 보장은 없지만, 자기 대국이 실제로 효과적임을 보여줍니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="구현-세부사항">구현 세부사항<a href="#구현-세부사항" class="hash-link" aria-label="구현 세부사항에 대한 직접 링크" title="구현 세부사항에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="병렬-자기-대국">병렬 자기 대국<a href="#병렬-자기-대국" class="hash-link" aria-label="병렬 자기 대국에 대한 직접 링크" title="병렬 자기 대국에 대한 직접 링크" translate="no">​</a></h3>
<p>훈련을 가속하기 위해 AlphaGo는 대규모 병렬 자기 대국을 사용합니다:</p>
<!-- -->
<p><strong>주요 설계 결정</strong>:</p>
<ul>
<li class=""><strong>동기 vs 비동기</strong>: AlphaGo는 비동기 업데이트 사용, Worker들이 서로 기다릴 필요 없음</li>
<li class=""><strong>업데이트 빈도</strong>: N 대국 완료할 때마다 파라미터 업데이트</li>
<li class=""><strong>상대 선택</strong>: 최근 몇 버전 중 하나를 무작위로 상대로 선택</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="체크포인트-전략">체크포인트 전략<a href="#체크포인트-전략" class="hash-link" aria-label="체크포인트 전략에 대한 직접 링크" title="체크포인트 전략에 대한 직접 링크" translate="no">​</a></h3>
<p>정기적으로 모델 체크포인트 저장, 용도:</p>
<ol>
<li class=""><strong>대국 풀</strong>: 다른 버전의 상대 유지</li>
<li class=""><strong>평가</strong>: 기력 변화 추적</li>
<li class=""><strong>장애 복구</strong>: 훈련 중단 시 복구 가능</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 의사 코드</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">training_loop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> iteration </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_iterations</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 대국 데이터 생성</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trajectories </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parallel_self_play</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_games</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 정책 업데이트</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update_policy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">trajectories</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 정기적 평가 및 저장</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> iteration </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate_against_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            save_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> elo</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> elo </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> best_elo</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                add_to_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                best_elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> elo</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="훈련-자원-요구">훈련 자원 요구<a href="#훈련-자원-요구" class="hash-link" aria-label="훈련 자원 요구에 대한 직접 링크" title="훈련 자원 요구에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo의 훈련 규모는 인상적입니다:</p>
<table><thead><tr><th>버전</th><th>하드웨어</th><th>훈련 시간</th><th>자기 대국 판 수</th></tr></thead><tbody><tr><td>AlphaGo Fan</td><td>176 GPU</td><td>수개월</td><td>~30M</td></tr><tr><td>AlphaGo Lee</td><td>48 TPU</td><td>수주</td><td>~30M</td></tr><tr><td>AlphaGo Zero</td><td>4 TPU</td><td>3일</td><td>~5M</td></tr><tr><td>AlphaGo Zero (40일 버전)</td><td>4 TPU</td><td>40일</td><td>~30M</td></tr></tbody></table>
<p>AlphaGo Zero가 더 적은 하드웨어와 더 짧은 시간으로 더 강한 기력을 달성했음을 주목하세요—이것은 알고리즘 효율성의 향상입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="하이퍼파라미터-설정">하이퍼파라미터 설정<a href="#하이퍼파라미터-설정" class="hash-link" aria-label="하이퍼파라미터 설정에 대한 직접 링크" title="하이퍼파라미터 설정에 대한 직접 링크" translate="no">​</a></h3>
<p>몇 가지 주요 하이퍼파라미터:</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 자기 대국 설정</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NUM_PARALLEL_GAMES </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># 동시 진행 대국 수</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GAMES_PER_ITERATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">25000</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 각 반복의 대국 수</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MCTS_SIMULATIONS </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1600</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 각 수의 MCTS 시뮬레이션 횟수</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 훈련 설정</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BATCH_SIZE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 훈련 배치 크기</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LEARNING_RATE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># 초기 학습률</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">L2_REGULARIZATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># 가중치 감쇠</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 탐색 설정</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TEMPERATURE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 오프닝 30수의 온도</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DIRICHLET_ALPHA </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.03</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># 디리클레 노이즈 파라미터</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EXPLORATION_FRACTION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 노이즈 비율</span><br></span></code></pre></div></div>
<p>이러한 하이퍼파라미터는 많은 실험을 통해 조정되었으며, 훈련 효과에 상당한 영향을 미칩니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="자기-대국의-변형">자기 대국의 변형<a href="#자기-대국의-변형" class="hash-link" aria-label="자기 대국의 변형에 대한 직접 링크" title="자기 대국의 변형에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-원본">AlphaGo 원본<a href="#alphago-원본" class="hash-link" aria-label="AlphaGo 원본에 대한 직접 링크" title="AlphaGo 원본에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo 원본의 훈련 흐름:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 지도 학습 (SL): 인간 기보에서 학습</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → SL Policy Network 생성 (π_SL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 강화 학습 (RL): 자기 대국</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   π_RL = π_SL로 초기화</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   상대 풀 = [π_SL]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   반복:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. π_RL이 풀의 전략과 대국</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 정책 경사로 π_RL 업데이트</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. π_RL이 강해지면 풀에 추가</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → RL Policy Network 생성 (π_RL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 가치 네트워크 훈련:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   π_RL로 자기 대국하여 국면 생성</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   V(s)가 승률 예측하도록 훈련</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero">AlphaGo Zero<a href="#alphago-zero" class="hash-link" aria-label="AlphaGo Zero에 대한 직접 링크" title="AlphaGo Zero에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo Zero는 이 흐름을 단순화했습니다:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 순수 자기 대국(인간 데이터 없음)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   무작위 네트워크 f_θ로 초기화</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   반복:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. MCTS + f_θ로 자기 대국 진행</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 정책 헤드와 가치 헤드 동시 훈련</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. f_θ 업데이트</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → 단일 네트워크가 정책과 가치 동시 출력</span><br></span></code></pre></div></div>
<p>주요 개선:</p>
<ul>
<li class=""><strong>인간 데이터 불필요</strong>: 처음부터 시작</li>
<li class=""><strong>단일 네트워크</strong>: 정책과 가치가 특징 공유</li>
<li class=""><strong>더 간결한 훈련</strong>: 엔드투엔드 학습</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphazero">AlphaZero<a href="#alphazero" class="hash-link" aria-label="AlphaZero에 대한 직접 링크" title="AlphaZero에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaZero는 더욱 일반화:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">같은 알고리즘, 다른 게임:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 바둑: AlphaGo Zero 수준 초과 달성</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 체스: Stockfish 초월</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 장기: Elmo 초월</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">유일한 게임 특정 부분: 규칙 인코딩</span><br></span></code></pre></div></div>
<p>이것은 자기 대국이 바둑에 국한되지 않는 <strong>범용 학습 패러다임</strong>임을 증명했습니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="인간이-배운-것">인간이 배운 것<a href="#인간이-배운-것" class="hash-link" aria-label="인간이 배운 것에 대한 직접 링크" title="인간이 배운 것에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ai가-발견한-새로운-정석">AI가 발견한 새로운 정석<a href="#ai가-발견한-새로운-정석" class="hash-link" aria-label="AI가 발견한 새로운 정석에 대한 직접 링크" title="AI가 발견한 새로운 정석에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국은 인간이 사용한 적 없는 많은 수법을 만들어냈습니다:</p>
<p><strong>1. 오프닝 혁신</strong></p>
<p>AlphaGo가 선호하는 일부 오프닝:</p>
<ul>
<li class="">3-3 침입: 초기에 귀를 침입</li>
<li class="">높은 수: 전통적으로 &#x27;불안정&#x27;으로 여겨짐</li>
<li class="">대눈사태 변화: 인간이 복잡해서 계산하기 어렵다고 생각</li>
</ul>
<p><strong>2. 새로운 형세 판단</strong></p>
<p>AI의 일부 국면에 대한 평가는 인간과 크게 다릅니다:</p>
<ul>
<li class="">어떤 &#x27;얇아&#x27; 보이는 형태가 실제로 매우 견고함</li>
<li class="">어떤 &#x27;두터움&#x27;의 가치가 과대평가됨</li>
<li class="">&#x27;선수&#x27;와 &#x27;후수&#x27;에 대한 재평가</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="인간-바둑에-미친-영향">인간 바둑에 미친 영향<a href="#인간-바둑에-미친-영향" class="hash-link" aria-label="인간 바둑에 미친 영향에 대한 직접 링크" title="인간 바둑에 미친 영향에 대한 직접 링크" translate="no">​</a></h3>
<p>AlphaGo 이후, 프로 바둑에 상당한 변화가 있었습니다:</p>
<ol>
<li class=""><strong>오프닝 다양화</strong>: 프로 기사들이 AI가 발견한 새 오프닝 사용 시작</li>
<li class=""><strong>훈련 방식 변화</strong>: AI가 프로 기사의 주요 훈련 도구가 됨</li>
<li class=""><strong>바둑 이론 재고</strong>: 많은 전통적 &#x27;바둑 이론&#x27;이 의문시되고 수정됨</li>
<li class=""><strong>새로운 미학</strong>: AI 스타일의 바둑을 감상하기 시작</li>
</ol>
<p>커제는 AlphaGo에게 진 후 말했습니다:</p>
<blockquote>
<p>&quot;AlphaGo가 바둑을 다시 인식하게 해주었습니다. 이전에는 인간이 바둑을 이해한다고 생각했지만, 이제는 우리가 표면만 긁었다는 것을 압니다.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="철학적-사고">철학적 사고<a href="#철학적-사고" class="hash-link" aria-label="철학적 사고에 대한 직접 링크" title="철학적 사고에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="학습의-본질">학습의 본질<a href="#학습의-본질" class="hash-link" aria-label="학습의 본질에 대한 직접 링크" title="학습의 본질에 대한 직접 링크" translate="no">​</a></h3>
<p>자기 대국은 학습에 관한 깊은 질문을 제기합니다:</p>
<p><strong>지식은 어디서 오는가?</strong></p>
<ul>
<li class="">인간 학습은 외부 정보(선생님, 책, 경험)에 의존함</li>
<li class="">자기 대국 AI는 규칙만 있고, 외부 지식이 없음</li>
<li class="">그러나 여전히 지식을 &#x27;발견&#x27;할 수 있음—이 지식은 어디서 왔는가?</li>
</ul>
<p>답은 아마도: <strong>지식은 게임의 규칙과 구조에 암묵적으로 포함되어 있습니다</strong>. 바둑의 규칙이 무엇이 좋은 수이고 나쁜 수인지 정의하며, 자기 대국은 이러한 암묵적 구조를 드러낼 뿐입니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="창의성과-발견">창의성과 발견<a href="#창의성과-발견" class="hash-link" aria-label="창의성과 발견에 대한 직접 링크" title="창의성과 발견에 대한 직접 링크" translate="no">​</a></h3>
<p>AI가 &#x27;신의 한 수&#x27;(37번째 수)를 둘 때, 이것은 창조인가 발견인가?</p>
<p>한 가지 관점: 그 수는 항상 바둑 규칙 안에 &#x27;존재&#x27;했고, AI는 그것을 &#x27;발견&#x27;했을 뿐입니다.
다른 관점: AI가 그 수를 &#x27;창조&#x27;했습니다. 왜냐하면 아무도(AI 자신 포함) 미리 알지 못했기 때문입니다.</p>
<p>이 질문에는 표준 답이 없지만, 창의성에 대한 전통적 이해에 도전합니다.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="인간-지능의-위치">인간 지능의 위치<a href="#인간-지능의-위치" class="hash-link" aria-label="인간 지능의 위치에 대한 직접 링크" title="인간 지능의 위치에 대한 직접 링크" translate="no">​</a></h3>
<p>AI가 처음부터, 자기 대국을 통해 인류 수천 년의 지혜를 초월할 수 있다면, 이것이 인간에게 무엇을 의미하는가?</p>
<p>낙관적 견해:</p>
<ul>
<li class="">AI는 인간이 창조한 도구</li>
<li class="">AI의 발견이 인간의 이해를 향상시킬 수 있음</li>
<li class="">인간이 AI와 협력하여 더 높은 수준에 도달할 수 있음</li>
</ul>
<p>신중한 견해:</p>
<ul>
<li class="">일부 영역에서 순수한 계산이 인간 직관을 초월할 수 있음</li>
<li class="">&#x27;전문 기술&#x27;의 가치를 재고할 필요</li>
<li class="">교육과 훈련 방식이 변경될 필요가 있을 수 있음</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="애니메이션-대응">애니메이션 대응<a href="#애니메이션-대응" class="hash-link" aria-label="애니메이션 대응에 대한 직접 링크" title="애니메이션 대응에 대한 직접 링크" translate="no">​</a></h2>
<p>이 글에서 다루는 핵심 개념과 애니메이션 번호:</p>
<table><thead><tr><th>번호</th><th>개념</th><th>물리/수학 대응</th></tr></thead><tbody><tr><td>E5</td><td>자기 대국 순환</td><td>고정점 반복</td></tr><tr><td>E6</td><td>전략 진화</td><td>진화 역학</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="요약">요약<a href="#요약" class="hash-link" aria-label="요약에 대한 직접 링크" title="요약에 대한 직접 링크" translate="no">​</a></h2>
<p>자기 대국은 AlphaGo 성공의 핵심 기술 중 하나입니다. 우리가 배운 것:</p>
<ol>
<li class=""><strong>왜 효과적인가</strong>: 적대적 학습, 점진적 약점 발견</li>
<li class=""><strong>메커니즘</strong>: 궤적 수집, 정책 경사, 가치 네트워크 훈련</li>
<li class=""><strong>무작위화</strong>: 온도 파라미터, 디리클레 노이즈, 대국 풀</li>
<li class=""><strong>기력 성장</strong>: Elo 시스템, 성장 곡선 분석</li>
<li class=""><strong>수렴성</strong>: 이론적 보장과 실제 관찰</li>
<li class=""><strong>구현 세부사항</strong>: 병렬 훈련, 체크포인트 전략, 하이퍼파라미터</li>
</ol>
<p>다음 글에서는 AlphaGo가 신경망과 MCTS를 결합하여 양자의 장점을 발휘하는 방법을 탐구합니다.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="추가-자료">추가 자료<a href="#추가-자료" class="hash-link" aria-label="추가 자료에 대한 직접 링크" title="추가 자료에 대한 직접 링크" translate="no">​</a></h2>
<ul>
<li class=""><strong>다음 글</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/">MCTS와 신경망의 결합</a> — 직관과 추론의 완벽한 결합</li>
<li class=""><strong>이전 글</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/">강화 학습 입문</a> — 강화 학습의 기본 개념</li>
<li class=""><strong>관련</strong>: <a class="" href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/">AlphaGo Zero 개요</a> — 처음부터의 돌파구</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="참고-자료">참고 자료<a href="#참고-자료" class="hash-link" aria-label="참고 자료에 대한 직접 링크" title="참고 자료에 대한 직접 링크" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">Heinrich, J., &amp; Silver, D. (2016). &quot;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.&quot; <em>arXiv preprint</em>.</li>
<li class="">Lanctot, M., et al. (2017). &quot;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/13-self-play.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ko/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">강화 학습 입문</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ko/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">MCTS와 신경망의 결합</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#왜-자기-대국이-효과적인가" class="table-of-contents__link toc-highlight">왜 자기 대국이 효과적인가?</a><ul><li><a href="#직관적-설명" class="table-of-contents__link toc-highlight">직관적 설명</a></li><li><a href="#점진적-약점-발견" class="table-of-contents__link toc-highlight">점진적 약점 발견</a></li><li><a href="#적대적-학습" class="table-of-contents__link toc-highlight">적대적 학습</a></li><li><a href="#인간-기보와의-비교" class="table-of-contents__link toc-highlight">인간 기보와의 비교</a></li></ul></li><li><a href="#게임-이론-관점" class="table-of-contents__link toc-highlight">게임 이론 관점</a><ul><li><a href="#내시-균형" class="table-of-contents__link toc-highlight">내시 균형</a></li><li><a href="#자기-대국과-내시-균형" class="table-of-contents__link toc-highlight">자기 대국과 내시 균형</a></li><li><a href="#가상-대국fictitious-play" class="table-of-contents__link toc-highlight">가상 대국(Fictitious Play)</a></li></ul></li><li><a href="#자기-대국의-메커니즘" class="table-of-contents__link toc-highlight">자기 대국의 메커니즘</a><ul><li><a href="#기본-흐름" class="table-of-contents__link toc-highlight">기본 흐름</a></li><li><a href="#훈련-데이터-생성" class="table-of-contents__link toc-highlight">훈련 데이터 생성</a></li><li><a href="#정책-업데이트" class="table-of-contents__link toc-highlight">정책 업데이트</a></li><li><a href="#가치-네트워크-훈련" class="table-of-contents__link toc-highlight">가치 네트워크 훈련</a></li></ul></li><li><a href="#무작위화의-중요성" class="table-of-contents__link toc-highlight">무작위화의 중요성</a><ul><li><a href="#결정적-순환-피하기" class="table-of-contents__link toc-highlight">결정적 순환 피하기</a></li><li><a href="#무작위화의-원천" class="table-of-contents__link toc-highlight">무작위화의 원천</a></li><li><a href="#대국-풀population-방법" class="table-of-contents__link toc-highlight">대국 풀(Population) 방법</a></li></ul></li><li><a href="#기력-성장-곡선" class="table-of-contents__link toc-highlight">기력 성장 곡선</a><ul><li><a href="#elo-평점-시스템" class="table-of-contents__link toc-highlight">Elo 평점 시스템</a></li><li><a href="#alphago의-기력-성장" class="table-of-contents__link toc-highlight">AlphaGo의 기력 성장</a></li><li><a href="#성장-속도-분석" class="table-of-contents__link toc-highlight">성장 속도 분석</a></li><li><a href="#인간을-초월하는-순간" class="table-of-contents__link toc-highlight">인간을 초월하는 순간</a></li></ul></li><li><a href="#수렴성-분석" class="table-of-contents__link toc-highlight">수렴성 분석</a><ul><li><a href="#자기-대국이-수렴하는가" class="table-of-contents__link toc-highlight">자기 대국이 수렴하는가?</a></li><li><a href="#이론적-보장" class="table-of-contents__link toc-highlight">이론적 보장</a></li><li><a href="#가능한-실패-모드" class="table-of-contents__link toc-highlight">가능한 실패 모드</a></li><li><a href="#실제-관찰" class="table-of-contents__link toc-highlight">실제 관찰</a></li></ul></li><li><a href="#구현-세부사항" class="table-of-contents__link toc-highlight">구현 세부사항</a><ul><li><a href="#병렬-자기-대국" class="table-of-contents__link toc-highlight">병렬 자기 대국</a></li><li><a href="#체크포인트-전략" class="table-of-contents__link toc-highlight">체크포인트 전략</a></li><li><a href="#훈련-자원-요구" class="table-of-contents__link toc-highlight">훈련 자원 요구</a></li><li><a href="#하이퍼파라미터-설정" class="table-of-contents__link toc-highlight">하이퍼파라미터 설정</a></li></ul></li><li><a href="#자기-대국의-변형" class="table-of-contents__link toc-highlight">자기 대국의 변형</a><ul><li><a href="#alphago-원본" class="table-of-contents__link toc-highlight">AlphaGo 원본</a></li><li><a href="#alphago-zero" class="table-of-contents__link toc-highlight">AlphaGo Zero</a></li><li><a href="#alphazero" class="table-of-contents__link toc-highlight">AlphaZero</a></li></ul></li><li><a href="#인간이-배운-것" class="table-of-contents__link toc-highlight">인간이 배운 것</a><ul><li><a href="#ai가-발견한-새로운-정석" class="table-of-contents__link toc-highlight">AI가 발견한 새로운 정석</a></li><li><a href="#인간-바둑에-미친-영향" class="table-of-contents__link toc-highlight">인간 바둑에 미친 영향</a></li></ul></li><li><a href="#철학적-사고" class="table-of-contents__link toc-highlight">철학적 사고</a><ul><li><a href="#학습의-본질" class="table-of-contents__link toc-highlight">학습의 본질</a></li><li><a href="#창의성과-발견" class="table-of-contents__link toc-highlight">창의성과 발견</a></li><li><a href="#인간-지능의-위치" class="table-of-contents__link toc-highlight">인간 지능의 위치</a></li></ul></li><li><a href="#애니메이션-대응" class="table-of-contents__link toc-highlight">애니메이션 대응</a></li><li><a href="#요약" class="table-of-contents__link toc-highlight">요약</a></li><li><a href="#추가-자료" class="table-of-contents__link toc-highlight">추가 자료</a></li><li><a href="#참고-자료" class="table-of-contents__link toc-highlight">참고 자료</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>