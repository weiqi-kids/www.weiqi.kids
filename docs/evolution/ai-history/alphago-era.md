---
sidebar_position: 1
title: AlphaGo 時代
---

# AlphaGo 時代（2015-2017）

2015 年至 2017 年，Google DeepMind 的 AlphaGo 系列程式創造了人工智慧歷史上最具標誌性的突破之一。在短短兩年內，圍棋從「人工智慧無法征服的遊戲」變成了「AI 完全超越人類的領域」。

## 2015 年 10 月：AlphaGo 擊敗樊麾

### 歷史性的秘密對局

2015 年 10 月，在倫敦的一間辦公室裡，DeepMind 安排了一場秘密對局。對手是歐洲圍棋冠軍、職業二段棋手**樊麾**。

比賽結果：AlphaGo 以 5:0 完勝。

這是歷史上第一次有電腦程式在公平條件下（無讓子）擊敗職業圍棋棋手。消息在 2016 年 1 月正式公布，立即引起全球轟動。

### 初代 AlphaGo 的技術

這一版本的 AlphaGo 使用了兩個關鍵技術的結合：

1. **深度神經網路**：通過學習數十萬局人類職業對局，訓練出能夠評估局面的「價值網路」和能夠預測下一手的「策略網路」

2. **蒙特卡羅樹搜索（MCTS）**：利用神經網路的輸出來指導搜索，大幅減少需要計算的變化數量

這種「直覺」加「計算」的結合，正是人類棋手思考問題的方式——只是 AI 在兩方面都做得更好。

## 2016 年 3 月：AlphaGo vs 李世乭

### 世紀對決

2016 年 3 月 9 日至 15 日，AlphaGo 與世界頂尖棋手**李世乭**在首爾進行五番棋對決。這場比賽吸引了全球超過兩億人觀看，成為人工智慧歷史上最受關注的事件之一。

### 比賽結果

| 局數 | 日期 | 結果 | 備註 |
|------|------|------|------|
| 第 1 局 | 3 月 9 日 | AlphaGo 勝 | 中盤勝 |
| 第 2 局 | 3 月 10 日 | AlphaGo 勝 | 中盤勝，出現著名的「第 37 手」 |
| 第 3 局 | 3 月 12 日 | AlphaGo 勝 | 中盤勝 |
| 第 4 局 | 3 月 13 日 | 李世乭勝 | **李世乭第 78 手「神之一手」** |
| 第 5 局 | 3 月 15 日 | AlphaGo 勝 | 中盤勝 |

最終比分：**AlphaGo 4:1 李世乭**

### 第 2 局第 37 手：「神之一手」

在第二局中，AlphaGo 在右邊下出了一手讓所有觀戰棋手困惑的「肩衝」。

這手棋看起來毫無道理，不符合任何人類已知的定式。解說員估計這手棋的人類下出機率不到萬分之一。然而，隨著棋局進行，這手棋的深意逐漸顯現——它同時對多個方向施加影響，效率極高。

這一手棋被稱為「神之一手」，象徵著 AI 已經發展出人類無法理解的圍棋理念。

### 第 4 局第 78 手：人類的反擊

在連輸三局後，李世乭在第四局中下出了同樣驚人的一手——第 78 手「挖」。

這手棋是一個巧妙的手筋，在複雜的纏鬥中製造了 AlphaGo 未能預見的變化。AlphaGo 在這手棋之後出現了明顯的混亂，最終認輸。

這是人類在正式比賽中唯一一次擊敗 AlphaGo，李世乭的這手棋被永遠銘記為人類智慧的象徵。

### 比賽的影響

這場比賽的影響遠超圍棋界：

- **人工智慧的里程碑**：證明了深度學習可以處理極其複雜的問題
- **韓國的全民關注**：據統計，韓國有超過一半的人口觀看了比賽
- **圍棋的新紀元**：職業棋手開始意識到必須向 AI 學習
- **科技投資熱潮**：推動了全球對 AI 研究的投資

## 2017 年 1 月：Master 60 連勝

### 神秘的線上棋手

2016 年底至 2017 年初，一個名為「Master」的帳號出現在弈城和野狐等圍棋對弈網站上。它以極快的速度擊敗了所有挑戰者，包括柯潔、朴廷桓、井山裕太等世界頂尖棋手。

最終戰績：**60 戰 60 勝**（包括一局因對手掉線判和）

在第 60 局結束後，DeepMind 正式宣布：Master 就是 AlphaGo 的新版本。

### Master 展現的新理念

Master 的棋風與一年前擊敗李世乭的版本明顯不同：

- **更快的計算速度**：每手棋只用幾十秒
- **更激進的下法**：頻繁使用傳統理論認為「不好」的下法
- **點三三成為主流**：Master 經常在開局直接點三三

這些下法徹底顛覆了人類數百年積累的圍棋理論，職業棋手開始大量模仿 AI 的下法。

## 2017 年 5 月：AlphaGo vs 柯潔

### 人類的最後挑戰

2017 年 5 月，在中國烏鎮，AlphaGo 與當時世界排名第一的**柯潔**進行三番棋對決。這被視為「人類最後的挑戰」。

### 比賽結果

| 局數 | 日期 | 結果 | 備註 |
|------|------|------|------|
| 第 1 局 | 5 月 23 日 | AlphaGo 勝 | 1/4 子勝（最小差距） |
| 第 2 局 | 5 月 25 日 | AlphaGo 勝 | 中盤勝 |
| 第 3 局 | 5 月 27 日 | AlphaGo 勝 | 中盤勝 |

最終比分：**AlphaGo 3:0 柯潔**

### 柯潔的眼淚

在第二局比賽中途，柯潔一度離席，回來時眼眶泛紅。賽後他說：

> 「它太完美了，我看不到任何勝利的希望。」

> 「和 AlphaGo 下棋，我感受到的是它對圍棋的熱愛。」

這場比賽結束後，DeepMind 宣布 AlphaGo 退役，不再參加公開比賽。

## 2017 年 10 月：AlphaZero 論文

### 從零開始的超越

2017 年 10 月，DeepMind 發表了 AlphaZero 論文，展示了更驚人的成就。

AlphaZero 的突破在於：**它完全不需要人類棋譜**。

程式只被告知圍棋的規則，然後通過自我對弈學習。從「零」開始，AlphaZero 僅用 **40 天** 的自我訓練，就超越了所有之前的 AlphaGo 版本。

### 統一的智慧

更令人驚奇的是，同樣的 AlphaZero 程式（只改變遊戲規則）在圍棋、國際象棋、日本將棋三種遊戲中，都達到了超越所有人類和之前最強程式的水平。

這證明了深度強化學習的通用性——同樣的演算法可以掌握完全不同的智力遊戲。

## 技術解析

### 深度神經網路

AlphaGo 使用的神經網路有兩個主要部分：

**策略網路（Policy Network）**
- 輸入：當前棋盤局面
- 輸出：每一個位置的落子機率
- 功能：模擬人類的「直覺」，快速縮小搜索範圍

**價值網路（Value Network）**
- 輸入：當前棋盤局面
- 輸出：當前局面的勝率估計
- 功能：評估局面的好壞，替代傳統的窮舉搜索

### 蒙特卡羅樹搜索（MCTS）

MCTS 是一種搜索演算法，通過以下步驟工作：

1. **選擇（Selection）**：從根節點開始，根據某種策略選擇子節點
2. **擴展（Expansion）**：在葉節點處增加新的子節點
3. **模擬（Simulation）**：從新節點開始，進行隨機模擬直到遊戲結束
4. **反向傳播（Backpropagation）**：將模擬結果向上傳遞，更新路徑上所有節點的統計資料

AlphaGo 的創新在於用神經網路取代了隨機模擬，大大提高了搜索效率。

### 強化學習

從 AlphaGo Lee 到 AlphaZero，強化學習扮演了越來越重要的角色：

- **AlphaGo Fan**（擊敗樊麾）：主要依靠人類棋譜訓練
- **AlphaGo Lee**（擊敗李世乭）：人類棋譜 + 自我對弈
- **AlphaGo Master**（60 連勝）：增強的自我對弈訓練
- **AlphaZero**：完全的自我對弈，無需人類棋譜

這個演進過程顯示，AI 最終可以完全依靠自我學習達到超人類水平。

---

AlphaGo 的時代在 2017 年結束，但它開創的技術和理念繼續影響著圍棋和人工智慧領域。接下來的 KataGo 時代，讓這些技術走進了每一個圍棋愛好者的電腦和手機。

下一篇：[KataGo 時代](/docs/evolution/ai-history/katago-era)
