<!doctype html>
<html lang="zh-tw" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/cnn-and-go" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">CNN 與圍棋的結合 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/docs/alphago/cnn-and-go/"><meta data-rh="true" property="og:locale" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="zh-tw"><meta data-rh="true" name="docsearch:language" content="zh-tw"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="CNN 與圍棋的結合 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="深入探討卷積神經網路為何特別適合圍棋，從感受野到批次正規化的完整解析"><meta data-rh="true" property="og:description" content="深入探討卷積神經網路為何特別適合圍棋，從感受野到批次正規化的完整解析"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/docs/alphago/cnn-and-go/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/cnn-and-go/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/cnn-and-go/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/cnn-and-go/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/cnn-and-go/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/cnn-and-go/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/cnn-and-go/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/cnn-and-go/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/cnn-and-go/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/cnn-and-go/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/cnn-and-go/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/cnn-and-go/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/cnn-and-go/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/docs/alphago/"},{"@type":"ListItem","position":2,"name":"CNN 與圍棋的結合","item":"https://www.weiqi.kids/docs/alphago/cnn-and-go"}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/10-cnn-and-go/#webpage","url":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/10-cnn-and-go/","name":"CNN 與圍棋的結合","description":"深入探討卷積神經網路為何特別適合圍棋，從感受野到批次正規化的完整解析","inLanguage":"zh-TW","isPartOf":{"@id":"https://www.weiqi.kids#website"},"primaryImageOfPage":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/social-card.png"},"datePublished":"2024-01-15","dateModified":"2024-02-22","speakable":{"@type":"SpeakableSpecification","cssSelector":[".article-summary",".speakable-content",".key-takeaway",".key-answer",".expert-quote",".actionable-steps li",".faq-answer-content"]}},{"@type":"Article","@id":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/10-cnn-and-go/#article","mainEntityOfPage":{"@id":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/10-cnn-and-go/#webpage","significantLink":["https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/"]},"headline":"CNN 與圍棋的結合","description":"深入探討卷積神經網路為何特別適合圍棋，從感受野到批次正規化的完整解析","image":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/social-card.png","width":1200,"height":630},"author":{"@id":"https://www.weiqi.kids/docs/about/#person"},"publisher":{"@id":"https://www.weiqi.kids#organization"},"datePublished":"2024-01-15","dateModified":"2024-02-22","articleSection":"AlphaGo 完整解析","keywords":"CNN, 卷積神經網路, AlphaGo, 感受野, 批次正規化, ReLU, 深度學習, 圍棋AI","wordCount":4000,"inLanguage":"zh-TW","isAccessibleForFree":true,"isPartOf":{"@type":"WebSite","@id":"https://www.weiqi.kids#website"}},{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"首頁","item":"https://www.weiqi.kids"},{"@type":"ListItem","position":2,"name":"給工程師","item":"https://www.weiqi.kids/docs/for-engineers/"},{"@type":"ListItem","position":3,"name":"技術原理","item":"https://www.weiqi.kids/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":4,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/"}]},{"@type":"Person","@id":"https://www.weiqi.kids/docs/about/#person","name":"好棋寶寶協會編輯團隊","url":"https://www.weiqi.kids/docs/about/","worksFor":{"@id":"https://www.weiqi.kids#organization"},"description":"專注於圍棋 AI 研究與教育推廣的技術團隊","knowsAbout":["圍棋 AI","AlphaGo","KataGo","機器學習","深度學習"],"hasCredential":[{"@type":"EducationalOccupationalCredential","name":"AI 圍棋研究專家","credentialCategory":"技術認證"}]},{"@type":"ImageObject","@id":"https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/10-cnn-and-go/#primaryimage","url":"https://www.weiqi.kids/img/social-card.png","width":1200,"height":630,"caption":"CNN 與圍棋的結合 - 好棋寶寶協會","representativeOfPage":true,"license":"https://creativecommons.org/licenses/by-nc-sa/4.0/","creditText":"台灣好棋寶寶協會"}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"FAQPage","mainEntity":[{"@type":"Question","name":"為什麼 CNN 比全連接網路更適合圍棋？","acceptedAnswer":{"@type":"Answer","text":"CNN 利用棋盤的空間結構，通過權重共享大幅減少參數量（數百萬 vs 數千萬），同時自然捕捉局部棋形特徵，訓練效率遠高於全連接網路。"}},{"@type":"Question","name":"感受野在圍棋中的意義是什麼？","acceptedAnswer":{"@type":"Answer","text":"感受野決定了網路能「看到」多大的範圍。淺層處理局部特徵（眼、叫吃），深層處理全局特徵（勢力、厚薄）。12 層網路的 25x25 感受野已超過 19x19 棋盤。"}},{"@type":"Question","name":"為什麼 AlphaGo 使用 ReLU 而非其他激活函數？","acceptedAnswer":{"@type":"Answer","text":"ReLU 計算簡單、梯度不消失，且產生稀疏激活（很多神經元輸出 0），這在圍棋中可解釋為「只關注有事的位置」，提高效率的同時保持良好的訓練特性。"}}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.f23bf74b.css">
<script src="/assets/js/runtime~main.1011f191.js" defer="defer"></script>
<script src="/assets/js/main.5e37ffeb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="跳至主要内容"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">跳至主要内容</a></div><nav aria-label="主導航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切換導覽列" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="好棋寶寶協會標誌" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/img/logo.svg" alt="好棋寶寶協會標誌" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">好棋寶寶</b></a><a class="navbar__item navbar__link" href="/docs/learn/">學圍棋</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/docs/animations/">動畫教室</a><a class="navbar__item navbar__link" href="/docs/tech/">技術文件</a><a class="navbar__item navbar__link" href="/docs/about/">關於我們</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>繁體中文</a><ul class="dropdown__menu"><li><a href="/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/cnn-and-go/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="回到頂部" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="文件側邊欄" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro/"><span title="使用指南" class="linkLabel_REp1">使用指南</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="收起側邊欄分類 &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/birth-of-alphago/"><span title="AlphaGo 的誕生" class="linkLabel_REp1">AlphaGo 的誕生</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/key-matches/"><span title="關鍵對局回顧" class="linkLabel_REp1">關鍵對局回顧</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/move-37/"><span title="「神之一手」深度分析" class="linkLabel_REp1">「神之一手」深度分析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/why-go-is-hard/"><span title="圍棋為什麼難？" class="linkLabel_REp1">圍棋為什麼難？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/traditional-limits/"><span title="傳統方法的極限" class="linkLabel_REp1">傳統方法的極限</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/board-representation/"><span title="棋盤狀態表示" class="linkLabel_REp1">棋盤狀態表示</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/policy-network/"><span title="Policy Network 詳解" class="linkLabel_REp1">Policy Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/value-network/"><span title="Value Network 詳解" class="linkLabel_REp1">Value Network 詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/input-features/"><span title="輸入特徵設計" class="linkLabel_REp1">輸入特徵設計</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/alphago/cnn-and-go/"><span title="CNN 與圍棋的結合" class="linkLabel_REp1">CNN 與圍棋的結合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/supervised-learning/"><span title="監督學習階段" class="linkLabel_REp1">監督學習階段</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/reinforcement-intro/"><span title="強化學習入門" class="linkLabel_REp1">強化學習入門</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/self-play/"><span title="自我對弈" class="linkLabel_REp1">自我對弈</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/mcts-neural-combo/"><span title="MCTS 與神經網路的結合" class="linkLabel_REp1">MCTS 與神經網路的結合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/puct-formula/"><span title="PUCT 公式詳解" class="linkLabel_REp1">PUCT 公式詳解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/alphago-zero/"><span title="AlphaGo Zero 概述" class="linkLabel_REp1">AlphaGo Zero 概述</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/dual-head-resnet/"><span title="雙頭網路與殘差網路" class="linkLabel_REp1">雙頭網路與殘差網路</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/training-from-scratch/"><span title="從零訓練的過程" class="linkLabel_REp1">從零訓練的過程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/distributed-systems/"><span title="分散式系統與 TPU" class="linkLabel_REp1">分散式系統與 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/alphago/legacy-and-impact/"><span title="AlphaGo 的遺產" class="linkLabel_REp1">AlphaGo 的遺產</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="展開側邊欄分類 &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="展開側邊欄分類 &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="展開側邊欄分類 &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="頁面路徑"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主頁面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">CNN 與圍棋的結合</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">本頁導覽</button></div><div class="theme-doc-markdown markdown">
<header><h1>CNN 與圍棋的結合</h1></header>
<p>當 DeepMind 選擇用**卷積神經網路（CNN）**來處理圍棋時，這是一個天才的設計決策。</p>
<p>CNN 原本是為圖像識別設計的。為什麼它也適合圍棋？這篇文章將深入探討 CNN 的運作原理，以及它與圍棋的完美契合。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="為什麼-cnn-適合棋盤">為什麼 CNN 適合棋盤？<a href="#為什麼-cnn-適合棋盤" class="hash-link" aria-label="為什麼 CNN 適合棋盤？的直接連結" title="為什麼 CNN 適合棋盤？的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="棋盤是圖像">棋盤是「圖像」<a href="#棋盤是圖像" class="hash-link" aria-label="棋盤是「圖像」的直接連結" title="棋盤是「圖像」的直接連結" translate="no">​</a></h3>
<p>從某種角度看，19×19 的圍棋棋盤就是一張<strong>圖像</strong>：</p>
<table><thead><tr><th>圖像</th><th>圍棋棋盤</th></tr></thead><tbody><tr><td>像素</td><td>交叉點</td></tr><tr><td>RGB 通道</td><td>特徵平面（黑、白、空...）</td></tr><tr><td>224×224</td><td>19×19</td></tr><tr><td>辨識貓狗</td><td>判斷好棋壞棋</td></tr></tbody></table>
<p>這個類比並非偶然。CNN 擅長圖像的原因，也讓它擅長棋盤。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="三個關鍵特性">三個關鍵特性<a href="#三個關鍵特性" class="hash-link" aria-label="三個關鍵特性的直接連結" title="三個關鍵特性的直接連結" translate="no">​</a></h3>
<p>CNN 有三個特性，讓它特別適合棋盤類型的資料：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-局部連接local-connectivity">1. 局部連接（Local Connectivity）<a href="#1-局部連接local-connectivity" class="hash-link" aria-label="1. 局部連接（Local Connectivity）的直接連結" title="1. 局部連接（Local Connectivity）的直接連結" translate="no">​</a></h4>
<p>CNN 的卷積核只看局部區域，這與圍棋的特性完美匹配：</p>
<table><thead><tr><th>圖像識別</th><th>圍棋</th></tr></thead><tbody><tr><td>貓耳朵是局部特徵</td><td>「眼」是局部棋形</td></tr><tr><td>不需要看整張圖</td><td>不需要看整個棋盤</td></tr></tbody></table>
<p><strong>3×3 區域範例（眼位）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">○</td><td style="text-align:center">●</td><td style="text-align:center">○</td></tr><tr><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">●</td></tr><tr><td style="text-align:center">○</td><td style="text-align:center">●</td><td style="text-align:center">○</td></tr></tbody></table>
<p>很多圍棋概念都是「局部」的：</p>
<ul>
<li class=""><strong>眼</strong>：2×2 或 3×3 的區域</li>
<li class=""><strong>叫吃</strong>：3×3 的區域</li>
<li class=""><strong>接、斷</strong>：2×2 的區域</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-權重共享weight-sharing">2. 權重共享（Weight Sharing）<a href="#2-權重共享weight-sharing" class="hash-link" aria-label="2. 權重共享（Weight Sharing）的直接連結" title="2. 權重共享（Weight Sharing）的直接連結" translate="no">​</a></h4>
<p>同一個卷積核會掃描整個棋盤，這意味著：</p>
<blockquote>
<p><strong>棋盤左上角的「眼」和右下角的「眼」，用同樣的方式識別</strong></p>
</blockquote>
<p>這是合理的——圍棋規則不因位置而異（邊角例外，但可以用邊角特徵平面處理）。</p>
<p>權重共享也大幅減少了參數量：</p>
<table><thead><tr><th>方法</th><th>參數量</th></tr></thead><tbody><tr><td>全連接網路</td><td>361 × 361 × 通道數 = 數千萬</td></tr><tr><td>CNN</td><td>3 × 3 × 通道數 × 濾波器數 = 數百萬</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-平移等變性translation-equivariance">3. 平移等變性（Translation Equivariance）<a href="#3-平移等變性translation-equivariance" class="hash-link" aria-label="3. 平移等變性（Translation Equivariance）的直接連結" title="3. 平移等變性（Translation Equivariance）的直接連結" translate="no">​</a></h4>
<p>如果輸入平移，CNN 的輸出也會相應平移：</p>
<p><strong>輸入與輸出（高機率區域）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p>輸出 → B2 位置有高機率（*）</p>
<p><strong>輸入平移後，輸出也平移</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p>輸出 → C3 位置有高機率（*）</p>
<p>這對圍棋很重要：相同的局部棋形，無論出現在棋盤哪裡，應該有類似的評估。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="卷積運算">卷積運算<a href="#卷積運算" class="hash-link" aria-label="卷積運算的直接連結" title="卷積運算的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="基本原理">基本原理<a href="#基本原理" class="hash-link" aria-label="基本原理的直接連結" title="基本原理的直接連結" translate="no">​</a></h3>
<p>卷積運算是 CNN 的核心。它是一種「滑動窗口」操作：</p>
<!-- -->
<p>計算過程（以中心點為例）：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">輸出[2,2] = 1×1 + 1×0 + 1×1 +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            1×0 + 1×1 + 1×0 +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            1×1 + 1×0 + 1×1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          = 5</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="多通道卷積">多通道卷積<a href="#多通道卷積" class="hash-link" aria-label="多通道卷積的直接連結" title="多通道卷積的直接連結" translate="no">​</a></h3>
<p>當輸入有多個通道（如 48 個特徵平面）時，卷積核也變成 3D：</p>
<!-- -->
<p>每個卷積核會跨所有輸入通道計算，產生一個輸出通道。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="多個濾波器">多個濾波器<a href="#多個濾波器" class="hash-link" aria-label="多個濾波器的直接連結" title="多個濾波器的直接連結" translate="no">​</a></h3>
<p>AlphaGo 使用 192 個濾波器，每個濾波器學習不同的特徵：</p>
<!-- -->
<p>每個濾波器可能學到不同的棋形：</p>
<ul>
<li class="">濾波器 1：眼位檢測</li>
<li class="">濾波器 2：斷點檢測</li>
<li class="">濾波器 3：連接檢測</li>
<li class="">...</li>
<li class="">濾波器 192：某種複雜模式</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="感受野">感受野<a href="#感受野" class="hash-link" aria-label="感受野的直接連結" title="感受野的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="什麼是感受野">什麼是感受野？<a href="#什麼是感受野" class="hash-link" aria-label="什麼是感受野？的直接連結" title="什麼是感受野？的直接連結" translate="no">​</a></h3>
<p>**感受野（Receptive Field）**是指輸出的一個位置，受到輸入的哪些位置影響。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="單層卷積">單層卷積<a href="#單層卷積" class="hash-link" aria-label="單層卷積的直接連結" title="單層卷積的直接連結" translate="no">​</a></h4>
<p>使用 3×3 卷積核時，輸出的每個位置只受輸入 3×3 區域影響：</p>
<p><strong>輸入</strong>（感受野 3x3 標記為 X）：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">X</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>輸出</strong>（對應位置標記為 Y）：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">Y</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="多層卷積">多層卷積<a href="#多層卷積" class="hash-link" aria-label="多層卷積的直接連結" title="多層卷積的直接連結" translate="no">​</a></h4>
<p>堆疊多層卷積後，感受野會擴大：</p>
<table><thead><tr><th>層數</th><th>感受野</th><th>計算</th></tr></thead><tbody><tr><td>1</td><td>3×3</td><td>3</td></tr><tr><td>2</td><td>5×5</td><td>3 + (3-1) = 5</td></tr><tr><td>3</td><td>7×7</td><td>5 + (3-1) = 7</td></tr><tr><td>...</td><td>...</td><td>...</td></tr><tr><td>12</td><td>25×25</td><td>3 + 11×2 = 25</td></tr></tbody></table>
<p>AlphaGo 的 12 層卷積給出 <strong>25×25 的感受野</strong>，已經超過 19×19 的棋盤！</p>
<p>這意味著：</p>
<ul>
<li class=""><strong>輸出的每個位置都能「看到」整個棋盤</strong></li>
<li class="">但「看」的方式不同：近處細節清楚，遠處概括</li>
<li class="">這與人類棋手的思維方式類似</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="感受野與圍棋">感受野與圍棋<a href="#感受野與圍棋" class="hash-link" aria-label="感受野與圍棋的直接連結" title="感受野與圍棋的直接連結" translate="no">​</a></h3>
<p>感受野的概念解釋了為什麼 AlphaGo 能處理「全局」問題：</p>
<table><thead><tr><th>局部問題（3x3 感受野）</th><th>全局問題（25x25 感受野）</th></tr></thead><tbody><tr><td>這裡有眼嗎？</td><td>這塊棋有眼位嗎？</td></tr><tr><td>可以叫吃嗎？</td><td>征子有利嗎？</td></tr><tr><td>能接上嗎？</td><td>全局形勢如何？</td></tr></tbody></table>
<p>淺層處理局部特徵，深層處理全局特徵。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="局部-vs-全局特徵">局部 vs 全局特徵<a href="#局部-vs-全局特徵" class="hash-link" aria-label="局部 vs 全局特徵的直接連結" title="局部 vs 全局特徵的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="cnn-的層次結構">CNN 的層次結構<a href="#cnn-的層次結構" class="hash-link" aria-label="CNN 的層次結構的直接連結" title="CNN 的層次結構的直接連結" translate="no">​</a></h3>
<p>CNN 自然形成層次結構：</p>
<!-- -->
<p>這與人類學習圍棋的過程驚人地相似：</p>
<ol>
<li class="">先學規則（哪裡有子）</li>
<li class="">再學戰術（如何吃子）</li>
<li class="">然後學棋形（什麼是好形）</li>
<li class="">最後學大局觀（全局判斷）</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="視覺化隱藏層">視覺化隱藏層<a href="#視覺化隱藏層" class="hash-link" aria-label="視覺化隱藏層的直接連結" title="視覺化隱藏層的直接連結" translate="no">​</a></h3>
<p>研究人員發現，CNN 的隱藏層確實學到了有意義的特徵：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="淺層濾波器">淺層濾波器<a href="#淺層濾波器" class="hash-link" aria-label="淺層濾波器的直接連結" title="淺層濾波器的直接連結" translate="no">​</a></h4>
<p><strong>濾波器 A（眼位檢測）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">+</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">+</td></tr></tbody></table>
<p><strong>濾波器 B（叫吃檢測）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">+</td><td style="text-align:center">+</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="深層濾波器">深層濾波器<a href="#深層濾波器" class="hash-link" aria-label="深層濾波器的直接連結" title="深層濾波器的直接連結" translate="no">​</a></h4>
<p>深層的濾波器更抽象，難以直接解釋，但它們捕捉了複雜的棋形模式。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="激活函數的選擇">激活函數的選擇<a href="#激活函數的選擇" class="hash-link" aria-label="激活函數的選擇的直接連結" title="激活函數的選擇的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="relu簡單而有效">ReLU：簡單而有效<a href="#relu簡單而有效" class="hash-link" aria-label="ReLU：簡單而有效的直接連結" title="ReLU：簡單而有效的直接連結" translate="no">​</a></h3>
<p>AlphaGo 在所有卷積層後使用 <strong>ReLU（Rectified Linear Unit）</strong>：</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">relu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token builtin">max</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>ReLU 函數的特性：當輸入為負數時輸出為 0，當輸入為正數時輸出等於輸入本身。這是一條從原點開始、斜率為 1 的直線（僅在正半軸）。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="為什麼不用其他函數">為什麼不用其他函數？<a href="#為什麼不用其他函數" class="hash-link" aria-label="為什麼不用其他函數？的直接連結" title="為什麼不用其他函數？的直接連結" translate="no">​</a></h3>
<table><thead><tr><th>激活函數</th><th>公式</th><th>優點</th><th>缺點</th></tr></thead><tbody><tr><td>ReLU</td><td>max(0, x)</td><td>計算快、梯度好</td><td>負值死亡</td></tr><tr><td>Sigmoid</td><td>1/(1+e^-x)</td><td>輸出有界</td><td>梯度消失</td></tr><tr><td>Tanh</td><td>(e^x-e^-x)/(e^x+e^-x)</td><td>零中心</td><td>梯度消失</td></tr><tr><td>LeakyReLU</td><td>max(0.01x, x)</td><td>解決死亡問題</td><td>多一個超參數</td></tr></tbody></table>
<p>對於深度網路，ReLU 的優勢明顯：</p>
<ol>
<li class=""><strong>計算簡單</strong>：只是比較和取最大值</li>
<li class=""><strong>梯度不消失</strong>：正區間梯度恆為 1</li>
<li class=""><strong>稀疏激活</strong>：很多神經元輸出 0，提高效率</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="relu-在圍棋中的含義">ReLU 在圍棋中的含義<a href="#relu-在圍棋中的含義" class="hash-link" aria-label="ReLU 在圍棋中的含義的直接連結" title="ReLU 在圍棋中的含義的直接連結" translate="no">​</a></h3>
<p>ReLU 的稀疏性在圍棋中有有趣的解釋：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">某個濾波器檢測「斷點」:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 有斷點 → 正值輸出（激活）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 無斷點 → 零輸出（不激活）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">這就像棋手只關注「有事」的位置</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="批次正規化">批次正規化<a href="#批次正規化" class="hash-link" aria-label="批次正規化的直接連結" title="批次正規化的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="什麼是批次正規化">什麼是批次正規化？<a href="#什麼是批次正規化" class="hash-link" aria-label="什麼是批次正規化？的直接連結" title="什麼是批次正規化？的直接連結" translate="no">​</a></h3>
<p>**批次正規化（Batch Normalization）**是一種技術，讓每層的輸出維持穩定的分布：</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">batch_norm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> gamma</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> beta</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 計算批次的均值和標準差</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mean</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    std </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">std</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 正規化</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    x_norm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> mean</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">/</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">std </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-8</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 縮放和平移</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> gamma </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> x_norm </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> beta</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="為什麼需要">為什麼需要？<a href="#為什麼需要" class="hash-link" aria-label="為什麼需要？的直接連結" title="為什麼需要？的直接連結" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="內部協變量偏移">內部協變量偏移<a href="#內部協變量偏移" class="hash-link" aria-label="內部協變量偏移的直接連結" title="內部協變量偏移的直接連結" translate="no">​</a></h4>
<p>當網路訓練時，每層的輸入分布會隨著前面層的權重變化而改變。這被稱為「內部協變量偏移」：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">第一層權重更新 → 第一層輸出分布改變</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               第二層輸入分布改變 → 第二層需要重新適應</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                   ... (傳遞下去)</span><br></span></code></pre></div></div>
<p>批次正規化通過強制每層輸入有固定的分布（均值 0，標準差 1），來穩定訓練。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="在-alphago-中的應用">在 AlphaGo 中的應用<a href="#在-alphago-中的應用" class="hash-link" aria-label="在 AlphaGo 中的應用的直接連結" title="在 AlphaGo 中的應用的直接連結" translate="no">​</a></h3>
<p>AlphaGo 在每個卷積層後、激活函數前使用批次正規化：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Conv → BatchNorm → ReLU → Conv → BatchNorm → ReLU → ...</span><br></span></code></pre></div></div>
<p>好處：</p>
<ol>
<li class=""><strong>訓練更快</strong>：可以使用更大的學習率</li>
<li class=""><strong>更穩定</strong>：減少對初始化的敏感性</li>
<li class=""><strong>正則化效果</strong>：有輕微的 dropout 效果</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="推理時的處理">推理時的處理<a href="#推理時的處理" class="hash-link" aria-label="推理時的處理的直接連結" title="推理時的處理的直接連結" translate="no">​</a></h3>
<p>訓練時，使用當前批次的統計量。推理時，使用整個訓練集的統計量（移動平均）：</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 訓練時</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch_mean</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> batch_var</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 推理時</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mean </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> running_mean  </span><span class="token comment" style="color:#999988;font-style:italic"># 訓練期間累積的均值</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">var </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> running_var    </span><span class="token comment" style="color:#999988;font-style:italic"># 訓練期間累積的方差</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-的具體配置">AlphaGo 的具體配置<a href="#alphago-的具體配置" class="hash-link" aria-label="AlphaGo 的具體配置的直接連結" title="AlphaGo 的具體配置的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="完整架構">完整架構<a href="#完整架構" class="hash-link" aria-label="完整架構的直接連結" title="完整架構的直接連結" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">輸入: 19×19×48</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">第 1 層:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(5×5, 192 filters, padding=&#x27;same&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  BatchNorm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  輸出: 19×19×192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">第 2-12 層 (共 11 層):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(3×3, 192 filters, padding=&#x27;same&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  BatchNorm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  輸出: 19×19×192</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">輸出層 (Policy):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(1×1, 1 filter)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Flatten</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  輸出: 361 維機率</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">輸出層 (Value):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Conv2D(1×1, 1 filter)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Flatten</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Dense(256)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Dense(1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Tanh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  輸出: 單一數值</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="參數配置">參數配置<a href="#參數配置" class="hash-link" aria-label="參數配置的直接連結" title="參數配置的直接連結" translate="no">​</a></h3>
<table><thead><tr><th>參數</th><th>數值</th><th>說明</th></tr></thead><tbody><tr><td>輸入通道</td><td>48</td><td>特徵平面數</td></tr><tr><td>濾波器數</td><td>192</td><td>每層的通道數</td></tr><tr><td>卷積核大小</td><td>3×3（第一層 5×5）</td><td>感受野</td></tr><tr><td>層數</td><td>13（含輸出層）</td><td>深度</td></tr><tr><td>激活函數</td><td>ReLU</td><td>非線性</td></tr><tr><td>正規化</td><td>BatchNorm</td><td>穩定訓練</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pytorch-實現">PyTorch 實現<a href="#pytorch-實現" class="hash-link" aria-label="PyTorch 實現的直接連結" title="PyTorch 實現的直接連結" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">AlphaGoCNN</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> input_channels</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">48</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">192</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_layers</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">12</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 第一層（5×5 卷積）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1 </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">input_channels</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">BatchNorm2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 中間層（3×3 卷積）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> padding</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">BatchNorm2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_layers </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Policy 輸出頭</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">policy_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Flatten</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Softmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">dim</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Value 輸出頭</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">value_head </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_filters</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Flatten</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">361</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inplace</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Tanh</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">forward</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 共享特徵提取</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv1</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        x </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">conv_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 分頭輸出</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        policy </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">policy_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        value </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">value_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> value</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="與其他架構的比較">與其他架構的比較<a href="#與其他架構的比較" class="hash-link" aria-label="與其他架構的比較的直接連結" title="與其他架構的比較的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="全連接網路">全連接網路<a href="#全連接網路" class="hash-link" aria-label="全連接網路的直接連結" title="全連接網路的直接連結" translate="no">​</a></h3>
<p>如果用全連接網路處理圍棋：</p>
<table><thead><tr><th>特性</th><th>全連接</th><th>CNN</th></tr></thead><tbody><tr><td>參數量</td><td>極大（數億）</td><td>較小（數百萬）</td></tr><tr><td>位置不變性</td><td>無</td><td>有</td></tr><tr><td>局部特徵</td><td>難學</td><td>自然捕捉</td></tr><tr><td>訓練效率</td><td>低</td><td>高</td></tr></tbody></table>
<p>全連接網路無法利用棋盤的空間結構，效率極低。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="循環神經網路rnn">循環神經網路（RNN）<a href="#循環神經網路rnn" class="hash-link" aria-label="循環神經網路（RNN）的直接連結" title="循環神經網路（RNN）的直接連結" translate="no">​</a></h3>
<p>RNN 適合序列資料（如棋局歷史），但：</p>
<table><thead><tr><th>特性</th><th>RNN</th><th>CNN</th></tr></thead><tbody><tr><td>空間處理</td><td>弱</td><td>強</td></tr><tr><td>序列處理</td><td>強</td><td>弱（需要歷史平面）</td></tr><tr><td>並行化</td><td>難</td><td>易</td></tr><tr><td>長距離依賴</td><td>需要 LSTM</td><td>深層即可</td></tr></tbody></table>
<p>AlphaGo 選擇 CNN + 歷史平面，而非 CNN + RNN。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="殘差網路resnet">殘差網路（ResNet）<a href="#殘差網路resnet" class="hash-link" aria-label="殘差網路（ResNet）的直接連結" title="殘差網路（ResNet）的直接連結" translate="no">​</a></h3>
<p>AlphaGo Zero 升級為 ResNet：</p>
<!-- -->
<p>殘差連接讓梯度更容易流動，可以訓練更深的網路（40 層 vs 12 層）。</p>
<p>詳見 <a class="" href="/docs/alphago/dual-head-resnet/">雙頭網路與殘差網路</a>。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="視覺化理解">視覺化理解<a href="#視覺化理解" class="hash-link" aria-label="視覺化理解的直接連結" title="視覺化理解的直接連結" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="卷積過程">卷積過程<a href="#卷積過程" class="hash-link" aria-label="卷積過程的直接連結" title="卷積過程的直接連結" translate="no">​</a></h3>
<p><strong>輸入棋盤（簡化為 5x5）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">○</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">●</td><td style="text-align:center">·</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td><td style="text-align:center">·</td></tr></tbody></table>
<p><strong>濾波器（3x3，檢測「十字形」）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>卷積輸出</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center">A</th><th style="text-align:center">B</th><th style="text-align:center">C</th><th style="text-align:center">D</th><th style="text-align:center">E</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center"><strong>1</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p>C3 位置有強響應（十字形匹配）。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="多層特徵">多層特徵<a href="#多層特徵" class="hash-link" aria-label="多層特徵的直接連結" title="多層特徵的直接連結" translate="no">​</a></h3>
<p>第 1 層輸出（192 個通道中的 4 個）：</p>
<p><strong>通道 1（眼位）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center"><strong>0.9</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>通道 2（邊線）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>通道 3（斷點）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center"><strong>0.7</strong></td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p><strong>通道 4（連接）</strong>：</p>
<table><thead><tr><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center"><strong>0.8</strong></td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">0</td><td style="text-align:center">0.5</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table>
<p>這些特徵在更深層會被組合成更複雜的概念...</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="動畫對應">動畫對應<a href="#動畫對應" class="hash-link" aria-label="動畫對應的直接連結" title="動畫對應的直接連結" translate="no">​</a></h2>
<p>本文涉及的核心概念與動畫編號：</p>
<table><thead><tr><th>編號</th><th>概念</th><th>物理/數學對應</th></tr></thead><tbody><tr><td>🎬 D9</td><td>卷積運算</td><td>濾波器響應</td></tr><tr><td>🎬 D10</td><td>感受野</td><td>局部→全局</td></tr><tr><td>🎬 D11</td><td>批次正規化</td><td>分布穩定</td></tr><tr><td>🎬 D1</td><td>多通道輸入</td><td>張量運算</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="延伸閱讀">延伸閱讀<a href="#延伸閱讀" class="hash-link" aria-label="延伸閱讀的直接連結" title="延伸閱讀的直接連結" translate="no">​</a></h2>
<ul>
<li class=""><strong>上一篇</strong>：<a class="" href="/docs/alphago/input-features/">輸入特徵設計</a> — 48 個特徵平面詳解</li>
<li class=""><strong>下一篇</strong>：<a class="" href="/docs/alphago/supervised-learning/">監督學習階段</a> — 如何從人類棋譜學習</li>
<li class=""><strong>進階主題</strong>：<a class="" href="/docs/alphago/dual-head-resnet/">雙頭網路與殘差網路</a> — AlphaGo Zero 的網路升級</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="關鍵要點">關鍵要點<a href="#關鍵要點" class="hash-link" aria-label="關鍵要點的直接連結" title="關鍵要點的直接連結" translate="no">​</a></h2>
<ol>
<li class=""><strong>CNN 天然適合棋盤</strong>：局部連接、權重共享、平移等變性</li>
<li class=""><strong>卷積提取局部特徵</strong>：3×3 區域的模式識別</li>
<li class=""><strong>深層網路獲得全局視野</strong>：12 層 → 25×25 感受野</li>
<li class=""><strong>ReLU 快速有效</strong>：簡單的非線性激活</li>
<li class=""><strong>BatchNorm 穩定訓練</strong>：標準化每層輸出</li>
</ol>
<p>CNN 讓 AlphaGo 能夠「看」棋盤——就像人類用眼睛看圖像一樣自然。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="參考資料">參考資料<a href="#參考資料" class="hash-link" aria-label="參考資料的直接連結" title="參考資料的直接連結" translate="no">​</a></h2>
<ol>
<li class="">LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). &quot;Deep learning.&quot; <em>Nature</em>, 521, 436-444.</li>
<li class="">He, K., et al. (2015). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training.&quot; <em>ICML</em>.</li>
<li class="">Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). &quot;ImageNet Classification with Deep Convolutional Neural Networks.&quot; <em>NeurIPS</em>.</li>
</ol>
<hr>
<div class="key-takeaway" style="background-color:var(--ifm-color-success-lightest);padding:1rem;border-radius:8px;border:1px solid var(--ifm-color-success);margin-bottom:1rem"><strong style="display:block;margin-bottom:0.5rem">📌 重點摘要</strong><p>本文重點：</p><ul>
<li class="">CNN 的局部連接、權重共享和平移等變性三大特性，讓它天然適合處理棋盤資料</li>
<li class="">12 層卷積堆疊產生 25x25 的感受野，讓輸出每個位置都能「看到」整個棋盤</li>
<li class="">BatchNorm 和 ReLU 的組合確保深度網路的穩定訓練</li>
</ul></div>
<div class="faq-section" style="margin-top:2rem"><h2>常見問題</h2><details style="margin-bottom:1rem;padding:1rem;background-color:var(--ifm-color-gray-100);border-radius:8px"><summary style="font-weight:bold;cursor:pointer;margin-bottom:0.5rem">為什麼 CNN 比全連接網路更適合圍棋？</summary><p class="faq-answer-content" style="margin-top:0.5rem">CNN 利用棋盤的空間結構，通過權重共享大幅減少參數量（數百萬 vs 數千萬），同時自然捕捉局部棋形特徵，訓練效率遠高於全連接網路。</p></details><details style="margin-bottom:1rem;padding:1rem;background-color:var(--ifm-color-gray-100);border-radius:8px"><summary style="font-weight:bold;cursor:pointer;margin-bottom:0.5rem">感受野在圍棋中的意義是什麼？</summary><p class="faq-answer-content" style="margin-top:0.5rem">感受野決定了網路能「看到」多大的範圍。淺層處理局部特徵（眼、叫吃），深層處理全局特徵（勢力、厚薄）。12 層網路的 25x25 感受野已超過 19x19 棋盤。</p></details><details style="margin-bottom:1rem;padding:1rem;background-color:var(--ifm-color-gray-100);border-radius:8px"><summary style="font-weight:bold;cursor:pointer;margin-bottom:0.5rem">為什麼 AlphaGo 使用 ReLU 而非其他激活函數？</summary><p class="faq-answer-content" style="margin-top:0.5rem">ReLU 計算簡單、梯度不消失，且產生稀疏激活（很多神經元輸出 0），這在圍棋中可解釋為「只關注有事的位置」，提高效率的同時保持良好的訓練特性。</p></details></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/10-cnn-and-go.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>編輯此頁</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件選項卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/alphago/input-features/"><div class="pagination-nav__sublabel">上一頁</div><div class="pagination-nav__label">輸入特徵設計</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/alphago/supervised-learning/"><div class="pagination-nav__sublabel">下一頁</div><div class="pagination-nav__label">監督學習階段</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#為什麼-cnn-適合棋盤" class="table-of-contents__link toc-highlight">為什麼 CNN 適合棋盤？</a><ul><li><a href="#棋盤是圖像" class="table-of-contents__link toc-highlight">棋盤是「圖像」</a></li><li><a href="#三個關鍵特性" class="table-of-contents__link toc-highlight">三個關鍵特性</a></li></ul></li><li><a href="#卷積運算" class="table-of-contents__link toc-highlight">卷積運算</a><ul><li><a href="#基本原理" class="table-of-contents__link toc-highlight">基本原理</a></li><li><a href="#多通道卷積" class="table-of-contents__link toc-highlight">多通道卷積</a></li><li><a href="#多個濾波器" class="table-of-contents__link toc-highlight">多個濾波器</a></li></ul></li><li><a href="#感受野" class="table-of-contents__link toc-highlight">感受野</a><ul><li><a href="#什麼是感受野" class="table-of-contents__link toc-highlight">什麼是感受野？</a></li><li><a href="#感受野與圍棋" class="table-of-contents__link toc-highlight">感受野與圍棋</a></li></ul></li><li><a href="#局部-vs-全局特徵" class="table-of-contents__link toc-highlight">局部 vs 全局特徵</a><ul><li><a href="#cnn-的層次結構" class="table-of-contents__link toc-highlight">CNN 的層次結構</a></li><li><a href="#視覺化隱藏層" class="table-of-contents__link toc-highlight">視覺化隱藏層</a></li></ul></li><li><a href="#激活函數的選擇" class="table-of-contents__link toc-highlight">激活函數的選擇</a><ul><li><a href="#relu簡單而有效" class="table-of-contents__link toc-highlight">ReLU：簡單而有效</a></li><li><a href="#為什麼不用其他函數" class="table-of-contents__link toc-highlight">為什麼不用其他函數？</a></li><li><a href="#relu-在圍棋中的含義" class="table-of-contents__link toc-highlight">ReLU 在圍棋中的含義</a></li></ul></li><li><a href="#批次正規化" class="table-of-contents__link toc-highlight">批次正規化</a><ul><li><a href="#什麼是批次正規化" class="table-of-contents__link toc-highlight">什麼是批次正規化？</a></li><li><a href="#為什麼需要" class="table-of-contents__link toc-highlight">為什麼需要？</a></li><li><a href="#在-alphago-中的應用" class="table-of-contents__link toc-highlight">在 AlphaGo 中的應用</a></li><li><a href="#推理時的處理" class="table-of-contents__link toc-highlight">推理時的處理</a></li></ul></li><li><a href="#alphago-的具體配置" class="table-of-contents__link toc-highlight">AlphaGo 的具體配置</a><ul><li><a href="#完整架構" class="table-of-contents__link toc-highlight">完整架構</a></li><li><a href="#參數配置" class="table-of-contents__link toc-highlight">參數配置</a></li><li><a href="#pytorch-實現" class="table-of-contents__link toc-highlight">PyTorch 實現</a></li></ul></li><li><a href="#與其他架構的比較" class="table-of-contents__link toc-highlight">與其他架構的比較</a><ul><li><a href="#全連接網路" class="table-of-contents__link toc-highlight">全連接網路</a></li><li><a href="#循環神經網路rnn" class="table-of-contents__link toc-highlight">循環神經網路（RNN）</a></li><li><a href="#殘差網路resnet" class="table-of-contents__link toc-highlight">殘差網路（ResNet）</a></li></ul></li><li><a href="#視覺化理解" class="table-of-contents__link toc-highlight">視覺化理解</a><ul><li><a href="#卷積過程" class="table-of-contents__link toc-highlight">卷積過程</a></li><li><a href="#多層特徵" class="table-of-contents__link toc-highlight">多層特徵</a></li></ul></li><li><a href="#動畫對應" class="table-of-contents__link toc-highlight">動畫對應</a></li><li><a href="#延伸閱讀" class="table-of-contents__link toc-highlight">延伸閱讀</a></li><li><a href="#關鍵要點" class="table-of-contents__link toc-highlight">關鍵要點</a></li><li><a href="#參考資料" class="table-of-contents__link toc-highlight">參考資料</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>