---
sidebar_position: 2
title: AlphaGo 的誕生
description: 從 DeepMind 創立到 Google 收購，AlphaGo 如何從一個瘋狂的想法變成改變世界的 AI
---

import { ArticleSchema, KeyTakeaway, FAQ } from '@site/src/components/SEO';

<ArticleSchema
  title="AlphaGo 的誕生"
  description="從 DeepMind 創立到 Google 收購，AlphaGo 如何從一個瘋狂的想法變成改變世界的 AI"
  slug="for-engineers/how-it-works/alphago-explained/01-birth-of-alphago"
  datePublished="2024-01-15"
  dateModified="2024-02-22"
  section="AlphaGo 完整解析"
  keywords={["AlphaGo", "DeepMind", "Demis Hassabis", "Google AI", "圍棋AI", "李世乭", "人工智慧歷史", "深度學習"]}
  wordCount={3200}
/>

# AlphaGo 的誕生

2016 年 3 月，當 AlphaGo 以 4:1 擊敗李世乭時，全世界都在問：這個改變人工智慧歷史的程式，究竟是怎麼誕生的？

答案要從一位西洋棋神童的夢想說起。

---

## DeepMind 的創立

### Demis Hassabis：從神童到 AI 先驅

**Demis Hassabis** 是 DeepMind 的共同創辦人兼執行長。他的人生經歷，幾乎就是為創造 AlphaGo 而準備的。

#### 西洋棋神童

1975 年出生於倫敦的 Hassabis，在 4 歲時學會下西洋棋，13 歲時達到西洋棋大師等級（Elo 2300+），是英國史上第二年輕達到此水平的棋手。

這段經歷讓他深刻理解：
- **棋類遊戲是智能的試金石**：下棋需要規劃、直覺、模式識別
- **人類智能的本質**：棋手如何在龐大的可能性中找到好棋？
- **電腦的侷限**：1997 年深藍擊敗卡斯帕洛夫靠的是暴力搜索，而非真正的「理解」

#### 遊戲設計師

17 歲時，Hassabis 加入 Bullfrog Productions（由《上帝也瘋狂》創作者 Peter Molyneux 創立的遊戲公司），參與開發了經典遊戲《乾坤大挪移》（Theme Park）。這段經歷教會他：

- **如何設計複雜系統**：遊戲是模擬現實世界的簡化模型
- **玩家行為預測**：AI 需要理解人類的決策過程

#### 認知神經科學家

在劍橋大學取得電腦科學學位後，Hassabis 在倫敦大學學院（UCL）取得認知神經科學博士學位。他的研究主題是：**海馬迴如何讓人類進行想像與規劃**。

這項研究發現：
- 人類的記憶與想像使用相同的腦區
- 我們透過「心理時間旅行」來規劃未來
- 這種能力可能是智能的核心

這些洞見直接影響了後來 AlphaGo 的設計——讓 AI 能夠「想像」未來的走法，並從中學習。

### 共同創辦人

2010 年，Hassabis 與兩位夥伴共同創立 DeepMind：

| 創辦人 | 背景 | 貢獻 |
|--------|------|------|
| **Demis Hassabis** | 神經科學、遊戲設計 | 願景與策略 |
| **Shane Legg** | 機器學習博士 | AGI 理論基礎 |
| **Mustafa Suleyman** | 社會企業家 | 商業與應用 |

### 「解決智能，用智能解決一切」

DeepMind 的使命宣言是：

> **"Solve intelligence, and then use that to solve everything else."**
>
> 「解決智能，然後用它來解決所有其他問題。」

這不是一家普通的 AI 公司。他們的目標不是做產品，而是創造**通用人工智慧（AGI）**——一種能像人類一樣思考、學習、解決任何問題的 AI。

為什麼要先「解決智能」？因為一旦我們有了 AGI，它就能幫助我們解決氣候變遷、疾病、能源等人類最大的挑戰。

---

## 早期突破：Atari 遊戲

在挑戰圍棋之前，DeepMind 首先證明了自己的能力——用 AI 玩 Atari 遊戲。

### DQN：學會玩遊戲的 AI

2013 年，DeepMind 發表了 **DQN（Deep Q-Network）** 演算法。這個 AI 能夠：

1. **只看螢幕像素**——不給它任何遊戲規則
2. **自己學會玩遊戲**——透過嘗試錯誤
3. **達到人類水平**——甚至在某些遊戲超越人類

DQN 在《打磚塊》（Breakout）中學會了一個人類需要幾個小時才能發現的策略：**挖隧道讓球跑到磚塊後面，一次消除一大片**。

這證明了深度學習 + 強化學習的組合，能夠發現人類未曾想過的策略。

### 為什麼從遊戲開始？

Hassabis 選擇遊戲作為研究平台，有幾個原因：

1. **環境可控**：遊戲有明確的規則和目標
2. **可測量進步**：有客觀的分數來評估 AI 能力
3. **人類基準**：可以與人類玩家比較
4. **多樣性**：不同遊戲測試不同能力

這套方法論，後來也用在圍棋上。

---

## Google 的收購

### 5 億美元的賭注

2014 年 1 月，Google 以約 **5 億美元**收購 DeepMind。這是當時 AI 領域最大的收購案之一。

為什麼 Google 願意付這麼多錢買一家只有 75 人、還沒有產品的公司？

答案在於 **賽局理論**：

- **Facebook 也在競標**：傳聞 Facebook 出價 4 億美元
- **AI 是未來的關鍵技術**：誰先掌握 AI，誰就掌握未來
- **DeepMind 是最好的團隊**：他們證明了深度強化學習的可行性

Google 執行長 Larry Page 親自出面，才說服 Hassabis 選擇 Google 而非 Facebook。

### 收購條件

Hassabis 在談判中爭取到幾個關鍵條件：

1. **獨立運營**：DeepMind 保持倫敦總部，獨立研發
2. **學術自由**：可以發表論文，而非全部保密
3. **倫理委員會**：成立 AI 倫理審查機制
4. **長期研究**：不需要短期商業化壓力

這些條件讓 DeepMind 能夠追求長期、高風險的研究——比如用 AI 征服圍棋。

### Google 的 AI 戰略

收購 DeepMind 是 Google 「AI 優先」戰略的一部分：

| 時間 | 事件 |
|------|------|
| 2011 | 成立 Google Brain |
| 2013 | 收購 DNNresearch（Hinton 團隊） |
| 2014 | 收購 DeepMind |
| 2015 | TensorFlow 開源 |
| 2016 | TPU 發表 |

Google 意識到：搜尋、廣告、翻譯、語音——所有核心業務都將被 AI 重塑。誰有最好的 AI，誰就是贏家。

---

## 選擇圍棋作為目標

### 為什麼是圍棋？

被 Google 收購後，DeepMind 有了更多資源。Hassabis 決定挑戰一個看似不可能的目標：**用 AI 擊敗人類圍棋冠軍**。

為什麼選擇圍棋，而不是其他問題？

#### 1. 圍棋是「AI 的聖杯」

2016 年之前，專家普遍認為 AI 至少需要 10-20 年才能在圍棋上擊敗人類。圍棋被稱為「AI 最後的堡壘」。

原因：
- **搜索空間巨大**：10^170 種可能的局面（宇宙原子數只有 10^80）
- **評估困難**：不像西洋棋有明確的棋子價值
- **直覺依賴**：頂尖棋手常說「這步棋感覺對」，卻無法解釋原因

#### 2. 深藍的啟示

1997 年，IBM 的深藍（Deep Blue）擊敗了西洋棋世界冠軍卡斯帕洛夫。但這個勝利有爭議：

- 深藍靠的是**暴力搜索**（每秒評估 2 億個位置）
- 使用**人類專家設計的評估函數**
- 這不是真正的「智能」，而是「計算力」

Hassabis 想證明：AI 可以用**學習**而非暴力搜索來解決問題。

#### 3. 可測量的目標

圍棋有國際排名系統（Elo rating）和職業棋手，提供了客觀的衡量標準。如果 AI 能擊敗世界冠軍，就是無可爭辯的成功。

#### 4. 與神經科學的連結

人類棋手的直覺——看一眼棋盤就知道哪些位置重要——正是 Hassabis 想用 AI 複製的能力。圍棋是測試「機器直覺」的完美場景。

---

## AlphaGo 團隊

### 核心人物

AlphaGo 的成功，來自一支多學科背景的團隊：

#### David Silver：首席研究員

**David Silver** 是 AlphaGo 論文的第一作者，也是強化學習領域的頂尖專家。

- **背景**：劍橋大學數學系畢業，阿爾伯塔大學 RL 博士
- **導師**：Richard Sutton（強化學習教父）
- **專長**：蒙地卡羅樹搜索、時序差分學習

Silver 在博士論文中就研究過電腦圍棋，但當時的技術遠未成熟。加入 DeepMind 後，他終於有機會實現這個夢想。

#### Aja Huang：圍棋專家

**Aja Huang**（黃士傑）是台灣人，業餘六段棋手，也是電腦圍棋領域的先驅。

- **背景**：國立台灣師範大學資工博士
- **專長**：電腦圍棋程式設計
- **著名作品**：Erica（早期電腦圍棋程式）

Huang 在 AlphaGo 團隊中扮演關鍵角色：他不只理解圍棋，也理解 AI。在與李世乭的對局中，他是實際操作 AlphaGo 的人。

#### 其他關鍵成員

| 成員 | 角色 |
|------|------|
| Chris J. Maddison | 蒙地卡羅樹搜索專家 |
| Arthur Guez | 強化學習研究員 |
| Laurent Sifre | 深度學習工程師 |
| George van den Driessche | 分散式系統工程師 |

### 跨領域合作

AlphaGo 的成功證明了**跨領域合作**的力量：

- **圍棋專家**提供領域知識
- **機器學習研究員**設計演算法
- **工程師**實現大規模訓練系統
- **神經科學家**提供理論靈感

這種團隊組成，後來成為 DeepMind 的標準模式。

---

## Nature 論文發表

### 秘密的驚喜

2016 年 1 月 27 日，DeepMind 在頂級學術期刊《Nature》發表論文：

> **"Mastering the game of Go with deep neural networks and tree search"**

論文宣布 AlphaGo 已經：
1. 擊敗了所有其他圍棋程式
2. 以 **5:0** 擊敗了歐洲冠軍 **樊麾**（職業二段）

這個消息震驚了世界。在論文發表之前，沒有人知道 DeepMind 在研究圍棋。

### 論文的核心貢獻

《Nature》論文描述了 AlphaGo 的三大創新：

#### 1. Policy Network（策略網路）

用深度卷積神經網路預測人類棋手的下一步。訓練資料來自 **3000 萬局** 的人類棋譜。

```
準確率：57%（預測人類專家的下一步）
```

這比之前最好的電腦圍棋程式高出 10 個百分點以上。

#### 2. Value Network（價值網路）

用另一個神經網路評估當前局面的勝率。這取代了傳統的隨機模擬（Monte Carlo rollout）。

```
精度：與 15000 次隨機模擬相當，但計算速度快 15000 倍
```

#### 3. 蒙地卡羅樹搜索整合

將兩個神經網路整合進 MCTS 框架：
- Policy Network 引導搜索方向
- Value Network 評估葉節點

這讓 AlphaGo 既有「直覺」（神經網路），又有「推理」（樹搜索）。

### 學術界的反應

論文發表後，學術界反應熱烈：

> "這是人工智慧的登月時刻。"
> — **Stuart Russell**，UC Berkeley 教授，AI 教科書作者

> "我原本認為還要 10 年，沒想到這麼快。"
> — **Martin Müller**，電腦圍棋專家

但也有人持懷疑態度：

> "樊麾只是職業二段，不是真正的頂尖棋手。讓 AlphaGo 和 Lee Sedol 下一場再說。"

DeepMind 接受了這個挑戰。

---

## 挑戰李世乭

### 為什麼是李世乭？

**李世乭**（Lee Sedol）是韓國棋手，當時被認為是過去十年最強的棋手之一：

| 指標 | 數據 |
|------|------|
| 世界冠軍頭銜 | 18 個 |
| 國際賽冠軍 | 32 個 |
| 最高世界排名 | 第 1 |
| 風格 | 「天才」「神算」 |

選擇李世乭，DeepMind 是在挑戰最強的人類對手。

### 1 百萬美元獎金

Google 為這場比賽提供了 **100 萬美元** 獎金：

- 如果李世乭獲勝：獎金歸李世乭
- 如果 AlphaGo 獲勝：獎金捐給 UNICEF、STEM 教育等慈善機構

這不只是一場技術展示，也是全球矚目的體育賽事。

### 比賽前的預測

比賽前，多數職業棋手預測李世乭會輕鬆獲勝：

> "AlphaGo 可能贏一盤，但 5 盤比賽我會 5:0 獲勝。"
> — **李世乭**，賽前訪談

> "電腦下棋死板，頂尖棋手很容易找到弱點。"
> — 某位職業九段

但 DeepMind 團隊有不同的看法。David Silver 後來透露：

> "我們在內部測試中，已經讓 AlphaGo 對陣樊麾的版本下了 500 盤。新版本贏了 499 盤。"

---

## 2016 年 3 月：改變世界的五盤棋

### 第一盤：震驚開始

2016 年 3 月 9 日，首爾四季酒店。

李世乭執黑先行，AlphaGo 執白。經過 3 小時 28 分的對弈，AlphaGo 中盤勝出。

這是人類頂尖棋手首次正式輸給 AI。

### 第二盤：神之一手

第二盤誕生了被稱為「**神之一手**」的第 37 手——AlphaGo 在五路下出一步肩衝，所有職業棋手都認為是失誤，結果證明是致勝關鍵。

（詳見下一篇：[「神之一手」深度分析](../move-37)）

AlphaGo 再次獲勝。

### 第三盤：3:0

第三盤，李世乭嘗試了非傳統的開局，但 AlphaGo 應對自如。3:0。

全世界開始意識到：這不是偶然，AI 真的超越了人類。

### 第四盤：人類的反擊

第四盤，李世乭下出了被稱為「**神之一手**」的第 78 手——一步精妙的挖，讓 AlphaGo 出現了混亂。

AlphaGo 在接下來的幾步中下出明顯的壞棋，最終認輸。

這場勝利證明：AI 也有弱點。李世乭找到了它。

### 第五盤：最終比數

第五盤，AlphaGo 恢復正常，以中盤勝結束比賽。

**最終比數：AlphaGo 4:1 李世乭**

---

## 影響與餘波

### 全球關注

這場比賽的影響遠超圍棋界：

- **全球 2 億人** 觀看了直播
- 《紐約時報》、《經濟學人》等主流媒體大篇幅報導
- Google 股價在比賽期間上漲
- 「人工智慧」成為當年最熱門的科技話題

### 對圍棋界的影響

比賽後，職業棋手的態度從「輕視」轉為「敬畏」：

> "我們以前認為人類理解圍棋，現在發現我們只是懂一點皮毛。"
> — **柯潔**，中國棋手，當時世界排名第一

許多職業棋手開始使用 AI 來訓練，圍棋的下法也因此改變。

### 對 AI 領域的影響

AlphaGo 證明了幾件事：

1. **深度學習可以解決專家級問題**：不只是識別貓狗，還能下圍棋
2. **強化學習可以超越人類**：透過自我對弈，AI 可以發現人類未知的策略
3. **神經網路 + 搜索是強大的組合**：直覺 + 推理 = 更強的智能

這些洞見後來被應用到：
- **AlphaFold**：蛋白質結構預測（2020 諾貝爾獎級成就）
- **AlphaZero**：通用遊戲 AI
- **MuZero**：不需要規則的學習

---

## 動畫對應

本文涉及的核心概念與動畫編號：

| 編號 | 概念 | 物理/數學對應 |
|------|------|--------------|
| 🎬 E7 | 從零開始 | 自組織 |
| 🎬 E5 | 自我對弈 | 不動點收斂 |
| 🎬 F8 | 湧現能力 | 相變 |
| 🎬 H4 | 策略梯度 | 隨機優化 |

---

## 延伸閱讀

- **下一篇**：[關鍵對局回顧](../key-matches) — 樊麾、李世乭、柯潔的完整對局分析
- **技術細節**：[Policy Network 詳解](../policy-network) — AlphaGo 如何學會下棋
- **動手實作**：[30 分鐘跑起第一個圍棋 AI](/docs/tech/hands-on/) — 親自體驗

---

## 參考資料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. 《AlphaGo》紀錄片 (2017)，導演 Greg Kohs。

---

<KeyTakeaway>
本文重點：
- DeepMind 由 Demis Hassabis 創立，結合神經科學、遊戲設計與機器學習背景，目標是創造通用人工智慧（AGI）
- AlphaGo 的成功來自跨領域團隊合作：圍棋專家（黃士傑）、強化學習專家（David Silver）與工程師的結合
- 2016 年 AlphaGo 以 4:1 擊敗李世乭，證明深度學習與強化學習能解決傳統 AI 無法攻克的複雜問題
</KeyTakeaway>

<FAQ items={[
  { question: "DeepMind 為什麼選擇圍棋作為 AI 研究目標？", answer: "圍棋被稱為「AI 的聖杯」，因為它的搜索空間（10^170）遠超宇宙原子數，且需要直覺判斷而非暴力計算。攻克圍棋代表 AI 在複雜決策問題上的重大突破。" },
  { question: "AlphaGo 的核心創新是什麼？", answer: "AlphaGo 結合了三大創新：Policy Network（策略網路）預測下一步、Value Network（價值網路）評估局面勝率、以及將這兩個神經網路整合進蒙地卡羅樹搜索（MCTS）框架。" },
  { question: "李世乭為什麼能在第四盤贏 AlphaGo？", answer: "李世乭下出了精妙的第 78 手「神之一手」，這步棋暴露了 AlphaGo 在特定複雜局面下的評估錯誤，導致它在後續幾步下出明顯的壞棋而認輸。" }
]} />
