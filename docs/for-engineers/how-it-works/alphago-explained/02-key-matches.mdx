---
sidebar_position: 3
title: 關鍵對局回顧
description: 從樊麾的秘密對局到柯潔的三番勝負，完整回顧 AlphaGo 的每一場重要對局
---

# 關鍵對局回顧

AlphaGo 的歷史，是由一場場震撼世界的對局寫成的。從 2015 年 10 月在倫敦的秘密對局，到 2017 年 5 月在烏鎮的告別演出，每一盤棋都在改寫人類對圍棋與人工智慧的認知。

本文將完整回顧這些關鍵對局的背景、過程與意義。

---

## 樊麾對局（2015.10）：秘密進行的 5:0

### 背景：為什麼選擇樊麾？

在 AlphaGo 挑戰世界頂尖棋手之前，DeepMind 需要一個「測試場」。他們需要一位職業棋手來驗證 AlphaGo 的真實實力，但這位棋手必須滿足幾個條件：

1. **真正的職業水準**：業餘棋手無法準確測試 AI 實力
2. **願意保密**：在論文發表前不能洩露消息
3. **地理位置方便**：便於進行多盤正式對局
4. **開放心態**：願意認真對待 AI 對手

**樊麾**完美符合這些條件。這位出生於中國西安的職業棋手，1996 年入段，2000 年升為二段，後移居法國並成為歐洲圍棋冠軍。他是當時歐洲最強的職業棋手，同時也對人工智慧抱持開放態度。

### 對局安排

2015 年 10 月，樊麾受邀前往倫敦 DeepMind 總部。在簽署保密協議後，他與 AlphaGo 進行了 **5 盤正式對局**。

對局條件：
- **用時**：每方 1 小時，每手 30 秒讀秒
- **規則**：中國規則，7.5 目貼目
- **環境**：DeepMind 辦公室，由 Aja Huang 代為落子

### 5:0 的震撼

結果令所有人震驚：**AlphaGo 5:0 完勝**。

| 盤次 | 日期 | 結果 | 備註 |
|------|------|------|------|
| 第 1 盤 | 10 月 5 日 | AlphaGo 中盤勝 | 樊麾執黑 |
| 第 2 盤 | 10 月 6 日 | AlphaGo 中盤勝 | 樊麾執白 |
| 第 3 盤 | 10 月 7 日 | AlphaGo 中盤勝 | 樊麾執黑 |
| 第 4 盤 | 10 月 8 日 | AlphaGo 1.5 目勝 | 樊麾執白 |
| 第 5 盤 | 10 月 9 日 | AlphaGo 中盤勝 | 樊麾執黑 |

🎬 E1：這 5 盤棋展示了 Policy Network 如何引導搜索方向

樊麾後來回憶：

> 「第一盤我輸了，我想一定是我大意了。第二盤輸了，我開始認真。第三盤、第四盤、第五盤全輸了，我知道這不是我的問題——是圍棋變了。」

### 為什麼保密？

DeepMind 選擇保密有幾個原因：

1. **學術發表**：論文需要經過同行審查才能發表
2. **驗證時間**：需要時間確認結果的可重複性
3. **商業策略**：選擇最佳時機公布消息
4. **保護樊麾**：避免他在消息公開前承受壓力

這個秘密被保守了整整三個月，直到 2016 年 1 月《Nature》論文發表。

### 樊麾的轉變

輸掉這 5 盤棋後，樊麾並沒有感到沮喪。相反，他成為了 AlphaGo 團隊的一員，負責測試和改進系統。

> 「我不是被 AI 擊敗了，我是成為了 AI 發展的一部分。這是榮幸，不是恥辱。」

這種開放心態，後來成為圍棋界面對 AI 的典範。

---

## 李世乭對局（2016.03）：改變世界的五盤棋

### 世紀對決的籌備

2016 年 1 月 27 日，《Nature》論文發表後，DeepMind 宣布將挑戰世界頂尖棋手。目標人選：**李世乭**（Lee Sedol）。

為什麼是李世乭？

- **18 個世界冠軍頭銜**：過去十年最成功的棋手之一
- **「神算」的美譽**：以精準計算著稱
- **戰鬥型風格**：喜歡複雜、激烈的對局
- **35 歲正值巔峰**：經驗與體力的最佳平衡

🎬 E3：李世乭的風格正好能測試 MCTS 的極限

### 比賽設置

- **地點**：韓國首爾四季酒店
- **日期**：2016 年 3 月 9-15 日
- **獎金**：100 萬美元（勝者得，平分或捐贈慈善）
- **規則**：中國規則，7.5 目貼目
- **用時**：每方 2 小時，每手 1 分鐘讀秒 3 次

全球 200 多個國家和地區進行直播，預計觀眾超過 **2 億人**。

### 第一盤：震驚的開始

**2016 年 3 月 9 日**

李世乭執黑先行。開局階段，雙方中規中矩。但到了中盤，AlphaGo 展現了驚人的大局觀。

在第 102 手時，AlphaGo 下出一步看似退讓的棋，讓出了右邊的實地。職業棋手們紛紛表示不解。但 20 手後，這步棋的妙處顯現——AlphaGo 用犧牲的棋子建立了中央厚勢，最終在全盤取得優勢。

**結果：AlphaGo 中盤勝**

賽後，李世乭表示：

> 「我很震驚。我沒想到會輸，更沒想到會輸得這麼徹底。」

🎬 E5：這盤棋展示了 Value Network 評估全局的能力

### 第二盤：「神之一手」的誕生

**2016 年 3 月 10 日**

這盤棋誕生了被稱為「**神之一手**」的第 37 手。（詳見下一篇：[「神之一手」深度分析](../move-37)）

AlphaGo 在右上角下出一步「五路肩衝」——一個人類幾乎不會考慮的位置。解說員當場表示這是「失誤」，但 50 手後，這步棋被證明是制勝關鍵。

**結果：AlphaGo 中盤勝**

韓國解說員金成龍九段賽後說：

> 「我下了 50 年的棋，從沒見過這樣的棋。AlphaGo 讓我重新思考什麼是圍棋。」

🎬 E7：第 37 手展示了 AI 如何發現人類未知的策略

### 第三盤：絕望的 3:0

**2016 年 3 月 12 日**

李世乭在這盤棋嘗試了非常規開局，希望將 AlphaGo 帶入未知領域。他採用了「小林流」布局的變形，企圖用複雜的戰鬥取勝。

但 AlphaGo 的應對依然從容。它展現了驚人的適應能力——無論人類如何出招，它都能找到最佳應手。

**結果：AlphaGo 中盤勝**

比數來到 3:0，比賽已經失去懸念。但所有人都在期待：人類能否贏得一盤？

### 第四盤：人類的反擊

**2016 年 3 月 13 日**

這盤棋將永載史冊——不是因為 AI 的神奇，而是因為**人類的反擊**。

局面進行到第 78 手時，李世乭在讀秒中下出了一步驚世之作：**五路的妙手**。

這是一步「挖」的手筋，看似普通，卻讓 AlphaGo 陷入混亂。在接下來的幾手棋中，AlphaGo 的勝率評估出現劇烈波動，它下出了幾步明顯的壞棋。

🎬 E9：這盤棋暴露了 MCTS 在特定局面下的弱點

DeepMind 團隊後來分析，AlphaGo 在那個局面下的勝率評估出現了錯誤。它低估了李世乭那步棋的威力，導致後續應對失誤。

**結果：李世乭 中盤勝**

這是 AlphaGo 正式比賽中唯一的一場敗北。李世乭激動地說：

> 「這場勝利無價。它證明了人類棋手仍然能夠戰勝 AI——至少在某些局面下可以。」

Google DeepMind 執行長 Demis Hassabis 發推特：

> 「李世乭是真正的傳奇。他找到了 AlphaGo 的弱點，並精確地利用了它。」

### 第五盤：最終的結局

**2016 年 3 月 15 日**

在獲得一場寶貴的勝利後，李世乭帶著更輕鬆的心態進入第五盤。他採用了更為激進的策略，試圖再次找到 AlphaGo 的弱點。

但 DeepMind 團隊在第四盤後進行了緊急調整。這一版本的 AlphaGo 似乎更加穩健，不再出現之前的評估錯誤。

**結果：AlphaGo 中盤勝**

**最終比分：AlphaGo 4:1 李世乭**

### 對局的歷史意義

這場比賽的影響遠超圍棋界：

#### 對人工智慧

- **證明深度學習的威力**：AI 可以在複雜決策任務上超越人類
- **強化學習的里程碑**：自我對弈訓練被證明有效
- **激發後續研究**：引發了 AI 領域的投資熱潮

#### 對圍棋界

- **傳統理論被挑戰**：很多「定式」被證明次優
- **訓練方式改變**：職業棋手開始使用 AI 輔助訓練
- **新下法的誕生**：AI 引入了許多創新手法

#### 對公眾

- **AI 意識覺醒**：普通人開始關注人工智慧
- **科技報導增加**：主流媒體大量報導 AI 進展
- **電影與紀錄片**：催生了《AlphaGo》紀錄片

🎬 E11：這場比賽標誌著 AI 能力的「相變」時刻

---

## Master 60 連勝（2017.01）：線上快棋的震撼

### 神秘的「Master」帳號

2016 年 12 月 29 日，一個名為「**Master**」的帳號出現在中國弈城圍棋和騰訊野狐圍棋網站上。

這個帳號的表現令人難以置信：
- **連勝所有對手**：無一敗績
- **對手全是頂尖棋手**：包括世界冠軍和九段高手
- **用時極短**：每步棋幾乎都是秒下

很快，整個圍棋界都在討論：「Master」到底是誰？

### 60 連勝的壯舉

從 12 月 29 日到 2017 年 1 月 4 日，「Master」進行了 60 盤快棋，**全部獲勝**。

被擊敗的棋手名單猶如世界圍棋名人堂：

| 排名 | 棋手 | 戰績 |
|------|------|------|
| 世界第 1 | 柯潔（中國） | 0-3 |
| 世界第 2 | 朴廷桓（韓國） | 0-2 |
| 世界第 3 | 井山裕太（日本） | 0-1 |
| 傳奇棋手 | 聶衛平（中國） | 0-1 |
| 傳奇棋手 | 古力（中國） | 0-2 |
| ... | ... | ... |

總計包括超過 **50 位職業九段**，涵蓋中日韓三國頂尖棋手。

🎬 E13：快棋展示了 Policy Network 即時決策的能力

### 身份揭曉

2017 年 1 月 4 日，在完成第 60 勝後，「Master」在聊天室透露了身份：

> 「我是 AlphaGo 的黃博士。」

黃博士就是 Aja Huang（黃士傑），AlphaGo 團隊的核心成員。

DeepMind 隨後正式確認：「Master」是 AlphaGo 的新版本，這次測試的目的是驗證系統在線上環境中的穩定性。

### 職業棋手的反應

60 連勝的衝擊，比李世乭對局更加深刻。因為這次的對手更多、範圍更廣。

**柯潔**（三次敗給 Master）：

> 「人類與 AI 的差距比我們想像的還要大。我們一直以為自己理解圍棋，但 Master 讓我覺得我們連入門都談不上。」

**聶衛平**（中國棋聖）：

> 「我下了 60 年的棋，第一次感覺如此無力。這不是技術的差距，是維度的差距。」

**古力**（八個世界冠軍）：

> 「輸給 Master 後，我開始思考人類棋手的價值在哪裡。我們還需要職業比賽嗎？」

### 技術分析

這一版本的 AlphaGo（後來被稱為 **AlphaGo Master**）相比李世乭對局版本有顯著提升：

| 指標 | Lee 版本 | Master 版本 | 提升 |
|------|----------|-------------|------|
| Elo 評分 | ~3,600 | ~4,800 | +1,200 |
| 自我對弈勝率 | - | 99%+ | - |
| Policy 準確度 | ~57% | ~62% | +5% |
| 訓練時間 | 數月 | 額外數月 | - |

🎬 E15：Elo 的提升展示了自我對弈的指數級進步

---

## 柯潔對局（2017.05）：王者的謝幕

### 最後的挑戰者

在 Master 60 連勝後，很少有人還認為人類有機會戰勝 AlphaGo。但有一個人依然渴望一戰——**柯潔**。

當時 19 歲的柯潔，是世界排名第一的棋手。他曾多次公開表示：

> 「我不認為 AlphaGo 能擊敗我。即使 Master 贏了我三盤快棋，正式比賽是不同的。」

Google 接受了挑戰。

### 烏鎮圍棋峰會

2017 年 5 月，「**未來圍棋峰會**」在中國浙江烏鎮舉行。這是一場圍繞 AlphaGo 的盛大活動，包括：

1. **柯潔三番棋**：人類最強對 AI 最強
2. **配對賽**：人類 + AlphaGo vs 人類 + AlphaGo
3. **團隊賽**：五位中國頂尖棋手聯手對抗 AlphaGo

### 三番棋：3:0 的結局

**第一盤（5 月 23 日）**

柯潔執黑先行，開局採用了較為穩健的「中國流」布局。這是經過深思熟慮的選擇——柯潔希望避免被 AlphaGo 的大局觀擊敗，轉而在細節處爭取機會。

但 AlphaGo 的應對完美無瑕。它在每個關鍵時刻都找到了最準確的下法，逐漸累積優勢。

**結果：AlphaGo 以 1/4 子（0.5 目）獲勝**

這是圍棋中可能的最小勝利差距。柯潔賽後落淚：

> 「我已經用盡全力，但還是差了一點點。」

🎬 E17：1/4 子的差距展示了 AI 的精確控制能力

**第二盤（5 月 25 日）**

柯潔改變策略，採用了模仿 AlphaGo 的開局方式。他使用了「點三三」直接進角的新手法——這正是 AlphaGo 帶給圍棋界的創新。

> 「既然你的下法更好，我就學你的下法。」

但 AlphaGo 不為所動。它依然按照自己的節奏進行，在中盤戰鬥中展現了驚人的計算能力。

**結果：AlphaGo 中盤勝**

**第三盤（5 月 27 日）**

最後一盤，柯潔孤注一擲。他採用了極為激進的戰鬥風格，試圖將 AlphaGo 拖入混戰。

開局階段，柯潔確實製造了一些複雜局面。但 AlphaGo 的應對依然精準，它沒有給柯潔任何翻盤的機會。

**結果：AlphaGo 中盤勝**

**最終比分：AlphaGo 3:0 柯潔**

🎬 E19：三番棋展示了 AlphaGo 的絕對統治力

### 配對賽與團隊賽

除了柯潔三番棋，峰會還進行了兩種創新賽制：

**配對賽**（5 月 26 日）

連笑 + AlphaGo vs 古力 + AlphaGo

這場比賽的有趣之處在於：當人類棋手與 AlphaGo 意見不同時，會發生什麼？

結果顯示：**完全遵從 AlphaGo 建議的一方表現更好**。當人類棋手試圖「修正」AlphaGo 的下法時，往往會導致局面惡化。

**結果：連笑 + AlphaGo 勝**

**團隊賽**（5 月 26 日）

中國隊（周睿羊、時越、唐韋星、陳耀燁、芈昱廷） vs AlphaGo

五位中國頂尖棋手合作對抗一台 AI。他們可以充分討論，共同決定每一步棋。

但結果沒有懸念：**AlphaGo 中盤勝**。

這場比賽證明：即使人類頂尖棋手聯手，也無法戰勝 AlphaGo。

### AlphaGo 的退役宣言

2017 年 5 月 27 日，在柯潔三番棋結束後，DeepMind 發表了一份重要聲明：

> 「這是 AlphaGo 最後一次公開對弈。我們相信 AlphaGo 已經完成了它的使命——證明 AI 可以在圍棋這個人類智慧的巔峰領域達到超越人類的水平。
>
> 接下來，我們將把從 AlphaGo 學到的技術應用到更重要的問題上：醫療、能源、材料科學。這才是人工智慧的真正價值所在。」

同時宣布：

1. **AlphaGo 教學工具**：將發布 AlphaGo 的對局分析供棋手學習
2. **50 盤自我對弈棋譜**：公開 AlphaGo vs AlphaGo 的棋譜
3. **技術論文**：將在《Nature》發表 AlphaGo Zero 的研究成果

🎬 E21：AlphaGo 的退役標誌著一個時代的結束

---

## 對局的歷史定位

### 技術里程碑

AlphaGo 的對局在人工智慧史上具有里程碑意義：

| 年份 | 事件 | 意義 |
|------|------|------|
| 1997 | 深藍擊敗卡斯帕洛夫 | 暴力搜索的勝利 |
| 2011 | Watson 贏得 Jeopardy! | 自然語言處理的突破 |
| **2016** | **AlphaGo 擊敗李世乭** | **深度學習 + 強化學習的勝利** |
| 2017 | AlphaGo Zero 100:0 | 純粹自我學習的勝利 |

🎬 E23：每個里程碑都代表了 AI 方法論的演進

### 對圍棋界的影響

**棋譜研究的改變**

傳統上，職業棋手主要研究人類棋譜。但 AlphaGo 之後，AI 棋譜成為必修課。

- **點三三開局**：AlphaGo 證明直接點角是有效策略
- **肩衝的妙用**：第 37 手改變了對「肩衝」這個手筋的認知
- **厚勢的價值**：AI 展示了厚勢轉化的新方式

**訓練方式的變革**

職業棋手的訓練方式發生根本改變：

| 傳統方式 | AI 時代方式 |
|----------|-------------|
| 研究人類棋譜 | 研究 AI 棋譜 |
| 依靠師父指導 | 使用 AI 分析工具 |
| 記憶定式 | 理解 AI 的評估邏輯 |
| 實戰練習 | AI 覆盤分析 |

**新一代棋手的崛起**

2016 年後成長起來的棋手，被稱為「AI 原住民」。他們的棋風明顯受到 AI 影響：

- 更注重效率而非傳統美學
- 更願意嘗試非傳統下法
- 更依賴精確計算而非直覺

### 哲學反思

AlphaGo 的勝利引發了深刻的哲學討論：

**智慧的本質是什麼？**

AlphaGo 「理解」圍棋嗎？還是它只是在進行精確的計算？這個問題至今沒有定論。

**人類的價值在哪裡？**

當 AI 在圍棋上超越人類，圍棋比賽還有意義嗎？很多棋手重新思考自己的職業意義。

有趣的是，AlphaGo 之後，圍棋的全球關注度反而提高了。人們意識到：圍棋不只是競技，也是藝術和哲學。

**AI 的發展方向**

AlphaGo 的成功讓人們對 AI 既期待又擔憂。DeepMind 選擇讓 AlphaGo 退役，轉向解決「真正重要的問題」，這本身就是一個倫理選擇。

🎬 E25：AlphaGo 引發了關於 AI 倫理的廣泛討論

---

## 遺珠：其他重要對局

### 與其他 AI 的對決

在公開賽之外，AlphaGo 還與其他圍棋 AI 進行了大量對局：

| 對手 | 版本 | 結果 |
|------|------|------|
| Crazy Stone | 2015 年最強圍棋程式 | 全勝 |
| Zen | 日本最強圍棋 AI | 全勝 |
| 舊版 AlphaGo | 各版本自我對弈 | - |

### 內部測試

DeepMind 團隊進行了大量內部測試：

- **AlphaGo Lee vs AlphaGo Master**：Master 版本勝率超過 99%
- **AlphaGo Master vs AlphaGo Zero**：Zero 版本勝率超過 89%
- **不同訓練時間的版本對弈**：觀察學習曲線

這些測試數據後來都在論文中公開，成為研究 AI 學習的重要資料。

---

## 動畫對應

本文涉及的核心概念與動畫編號：

| 編號 | 概念 | 物理/數學對應 |
|------|------|--------------|
| 🎬 E1 | Policy Network 引導搜索 | 機率分布 |
| 🎬 E3 | 測試 MCTS 的極限 | 樹搜索深度 |
| 🎬 E5 | Value Network 全局評估 | 價值函數 |
| 🎬 E7 | 發現未知策略 | 探索 vs 利用 |
| 🎬 E9 | MCTS 的弱點 | 邊界條件 |
| 🎬 E11 | 能力的「相變」 | 臨界現象 |
| 🎬 E13 | 即時決策能力 | 推理速度 |
| 🎬 E15 | 自我對弈的指數進步 | 迭代優化 |
| 🎬 E17 | 精確控制能力 | 數值穩定性 |
| 🎬 E19 | 絕對統治力 | 收斂到最優 |
| 🎬 E21 | 時代的結束 | 任務完成 |
| 🎬 E23 | 方法論演進 | 典範轉移 |
| 🎬 E25 | AI 倫理討論 | 社會影響 |

---

## 延伸閱讀

- **上一篇**：[AlphaGo 的誕生](../birth-of-alphago) — DeepMind 創立、團隊組成
- **下一篇**：[「神之一手」深度分析](../move-37) — 第 37 手的完整解讀
- **技術細節**：[MCTS 與神經網路的結合](../mcts-neural-combo) — 理解對局背後的技術
- **後續發展**：[AlphaGo 的遺產](../legacy-and-impact) — 對圍棋與 AI 的長期影響

---

## 參考資料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 550, 354-359.
3. 《AlphaGo》紀錄片 (2017)，導演 Greg Kohs。
4. DeepMind 官方 Blog：AlphaGo 系列文章
5. 李世乭對局官方棋譜與評論（韓國棋院）
6. 烏鎮圍棋峰會官方紀錄
