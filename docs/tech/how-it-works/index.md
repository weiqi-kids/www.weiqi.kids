---
sidebar_position: 1
title: ä¸€ç¯‡æ–‡ç« ææ‡‚åœæ£‹ AI
description: å¾ AlphaGo åˆ° KataGoï¼Œå®Œæ•´ç†è§£åœæ£‹ AI çš„é‹ä½œåŸç†
---

# ä¸€ç¯‡æ–‡ç« ææ‡‚åœæ£‹ AI

è®€å®Œé€™ç¯‡æ–‡ç« ï¼Œä½ å°‡èƒ½å¤ ï¼š
- ç†è§£ç‚ºä»€éº¼åœæ£‹å° AI ä¾†èªªç‰¹åˆ¥å›°é›£
- è§£é‡‹ AlphaGo å¦‚ä½•çµåˆç¥ç¶“ç¶²è·¯èˆ‡æ¨¹æœç´¢
- èªªæ˜è‡ªæˆ‘å°å¼ˆè¨“ç·´çš„é‹ä½œåŸç†
- äº†è§£ KataGo ç›¸å°æ–¼ AlphaGo çš„æ”¹é€²

---

## ä¸€ã€åœæ£‹ç‚ºä»€éº¼é›£ï¼Ÿ

### æœç´¢ç©ºé–“çš„è©›å’’

åœæ£‹çš„åˆæ³•å±€é¢æ•¸ç´„ç‚º **10^170**ã€‚é€™æ˜¯ä»€éº¼æ¦‚å¿µï¼Ÿ

| æ¯”è¼ƒå°è±¡ | æ•¸é‡ç´š |
|---------|--------|
| å®‡å®™ä¸­çš„åŸå­æ•¸ | 10^80 |
| åœæ£‹åˆæ³•å±€é¢æ•¸ | 10^170 |
| è¥¿æ´‹æ£‹åˆæ³•å±€é¢æ•¸ | 10^47 |

æ¯ä¸€æ­¥å¹³å‡æœ‰ç´„ 250 å€‹åˆæ³•é¸æ“‡ï¼Œä¸€ç›¤æ£‹ç´„ 150 æ‰‹ã€‚å‚³çµ±çš„çª®èˆ‰æœç´¢æ ¹æœ¬ä¸å¯èƒ½ã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ B2ï¼šçµ„åˆçˆ†ç‚¸ â†” æŒ‡æ•¸çˆ†ç‚¸ â€” æ£‹æ­¥çµ„åˆæ•¸å¦‚ä½•çˆ†ç‚¸æ€§æˆé•·
- ğŸ¬ B8ï¼šåˆ†æ”¯å› å­çˆ†ç‚¸ â†” æŒ‡æ•¸çˆ†ç‚¸ â€” 250^150 çš„ä¸å¯èƒ½æ€§
- ğŸ¬ F1ï¼šè¤‡é›œåº¦ç¸®æ”¾ â†” ç‹€æ…‹ç©ºé–“çˆ†ç‚¸ â€” NÃ—N æ£‹ç›¤çš„åˆ†æ”¯å› å­

### è©•ä¼°çš„å›°é›£

è¥¿æ´‹æ£‹å¯ä»¥ç°¡å–®è¨ˆç®—æ£‹å­åƒ¹å€¼ï¼ˆçš‡å=9ã€è»Š=5...ï¼‰ï¼Œä½†åœæ£‹ä¸è¡Œï¼š
- ä¸€é¡†æ£‹å­çš„åƒ¹å€¼å–æ±ºæ–¼å‘¨åœçš„é…ç½®
- é ˜åœ°æ˜¯ã€Œåœã€å‡ºä¾†çš„ï¼Œé‚Šç•Œæ¨¡ç³Š
- åšå‹¢ã€å¤–å‹¢ç­‰æŠ½è±¡æ¦‚å¿µé›£ä»¥é‡åŒ–

é€™å°±æ˜¯ç‚ºä»€éº¼åœæ£‹è¢«ç¨±ç‚ºã€ŒAI çš„è–æ¯ã€â€”â€”åœ¨ 2016 å¹´ä¹‹å‰ï¼Œæ²’æœ‰äººèªç‚º AI èƒ½åœ¨ 10 å¹´å…§æ“Šæ•—äººé¡å† è»ã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ A1ï¼šç¶²æ ¼ç‹€æ…‹ â†” é›¢æ•£ç¶²æ ¼ â€” æ£‹ç›¤å¦‚ä½•è¡¨ç¤º
- ğŸ¬ A8ï¼šç‹€æ…‹ç·¨ç¢¼ â†” ä¸‰æ…‹ç³»çµ± â€” `{ç©º,é»‘,ç™½}` çš„ç·¨ç¢¼

---

## äºŒã€å‚³çµ±æ–¹æ³•çš„æ¥µé™

### Minimax + Alpha-Beta å‰ªæ

å‚³çµ±æ£‹é¡ AI çš„æ ¸å¿ƒæ¼”ç®—æ³•ï¼š

```
Minimax æ€è·¯ï¼š
- æˆ‘æ–¹ï¼šé¸æ“‡å°è‡ªå·±æœ€æœ‰åˆ©çš„æ£‹æ­¥ï¼ˆmaxï¼‰
- å°æ–¹ï¼šå‡è¨­å°æ‰‹ä¹Ÿæœƒé¸æœ€æœ‰åˆ©çš„æ£‹æ­¥ï¼ˆminï¼‰
- äº¤æ›¿é€²è¡Œï¼Œå»ºç«‹éŠæˆ²æ¨¹
```

**å•é¡Œ**ï¼šæœç´¢æ·±åº¦å—é™ã€‚å³ä½¿ç”¨ Alpha-Beta å‰ªææ¸›å°‘è¨ˆç®—é‡ï¼Œåœæ£‹çš„åˆ†æ”¯å› å­ï¼ˆ~250ï¼‰ä»ç„¶å¤ªå¤§ã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ B3ï¼šMinimax â†” éé» â€” æ¥µå¤§æ¥µå°çš„æ•¸å­¸æ„ç¾©
- ğŸ¬ B7ï¼šAlpha-Beta å‰ªæ â†” ç›¸æ¶ˆå¹²æ¶‰ â€” å¦‚ä½•æ¸›å°‘ç„¡æ•ˆæœç´¢

### ç´”è’™åœ°å¡ç¾…æ¨¹æœç´¢ï¼ˆMCTSï¼‰

2006 å¹´çš„çªç ´â€”â€”ä¸éœ€è¦è©•ä¼°å‡½æ•¸ï¼š

```
MCTS å››æ­¥é©Ÿï¼š
1. Selectionï¼šé¸æ“‡æœ‰å¸Œæœ›çš„ç¯€é»
2. Expansionï¼šæ“´å±•æ–°çš„å­ç¯€é»
3. Simulationï¼šéš¨æ©Ÿæ¨¡æ“¬åˆ°çµ‚å±€
4. Backpropagationï¼šå›å‚³å‹è² çµæœ
```

**é€²æ­¥**ï¼šé¦–æ¬¡è®“ AI é”åˆ°æ¥­é¤˜æ®µä½æ°´å¹³ã€‚

**å•é¡Œ**ï¼šéš¨æ©Ÿæ¨¡æ“¬å¤ªä¸æº–ç¢ºã€‚éœ€è¦å¤§é‡æ¨¡æ“¬æ‰èƒ½å¾—åˆ°å¯é çš„å‹ç‡ä¼°è¨ˆã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ C5ï¼šMCTS å››æ­¥é©Ÿ â†” æ¨¹çš„éæ­· â€” Selectâ†’Expandâ†’Simulateâ†’Backprop
- ğŸ¬ C1ï¼šéš¨æ©Ÿå–æ¨£ â†” è’™åœ°å¡ç¾…ç©åˆ† â€” random playout çš„åŸç†
- ğŸ¬ C3ï¼šæ¢ç´¢ vs åˆ©ç”¨ â†” è‡ªç”±èƒ½æ¬Šè¡¡ â€” UCB å…¬å¼çš„æ„ç¾©

---

## ä¸‰ã€AlphaGo çš„çªç ´

### æ ¸å¿ƒæ´è¦‹

**ç”¨ç¥ç¶“ç¶²è·¯å–ä»£ MCTS ä¸­çš„éš¨æ©Ÿæ¨¡æ“¬**ã€‚

AlphaGo è¨“ç·´äº†å…©å€‹ç¥ç¶“ç¶²è·¯ï¼š

| ç¶²è·¯ | è¼¸å…¥ | è¼¸å‡º | åŠŸèƒ½ |
|------|------|------|------|
| **Policy Network** | æ£‹ç›¤ç‹€æ…‹ | æ¯å€‹ä½ç½®çš„è½å­æ©Ÿç‡ | ã€Œä¸‹ä¸€æ­¥è©²ä¸‹å“ªè£¡ï¼Ÿã€ |
| **Value Network** | æ£‹ç›¤ç‹€æ…‹ | å–®ä¸€æ•¸å€¼ï¼ˆ-1 åˆ° +1ï¼‰ | ã€Œé€™å€‹å±€é¢èª°è´ï¼Ÿã€ |

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ E1ï¼šç­–ç•¥ç¶²è·¯ â†” ç­–ç•¥åˆ†å¸ƒ â€” Policy Network è¼¸å‡ºä»€éº¼
- ğŸ¬ E2ï¼šåƒ¹å€¼ç¶²è·¯ â†” åƒ¹å€¼å‡½æ•¸ â€” Value Network è¼¸å‡ºä»€éº¼
- ğŸ¬ D9ï¼šå·ç©é‹ç®— â†” ç©ºé–“æ¿¾æ³¢ â€” CNN å¦‚ä½•è™•ç†æ£‹ç›¤

### Policy Networkï¼ˆç­–ç•¥ç¶²è·¯ï¼‰

è¼¸å…¥ï¼š19Ã—19 æ£‹ç›¤ï¼Œç·¨ç¢¼ç‚ºå¤šå€‹ç‰¹å¾µå¹³é¢ï¼ˆé»‘å­ä½ç½®ã€ç™½å­ä½ç½®ã€æ°£ã€æ­·å²...ï¼‰

è¼¸å‡ºï¼š361 å€‹æ©Ÿç‡å€¼ï¼Œä»£è¡¨æ¯å€‹ä½ç½®çš„è½å­å¯èƒ½æ€§

```
æ£‹ç›¤ç‹€æ…‹ â†’ CNN â†’ Softmax â†’ [0.01, 0.02, ..., 0.15, ..., 0.01]
                              â†‘ ç¬¬ 42 ä½ç½®æ©Ÿç‡ 15%
```

**ä½œç”¨**ï¼šå‘Šè¨´ MCTSã€Œå“ªäº›ä½ç½®å€¼å¾—æ¢ç´¢ã€ï¼Œå¤§å¹…æ¸›å°‘æœç´¢ç¯„åœã€‚

### Value Networkï¼ˆåƒ¹å€¼ç¶²è·¯ï¼‰

è¼¸å…¥ï¼šåŒæ¨£çš„æ£‹ç›¤ç‹€æ…‹

è¼¸å‡ºï¼šå–®ä¸€æ•¸å€¼ï¼Œä»£è¡¨ç•¶å‰å±€é¢çš„å‹ç‡

```
æ£‹ç›¤ç‹€æ…‹ â†’ CNN â†’ Tanh â†’ 0.72ï¼ˆé»‘æ–¹å‹ç‡ 72%ï¼‰
```

**ä½œç”¨**ï¼šç›´æ¥è©•ä¼°å±€é¢å¥½å£ï¼Œä¸éœ€è¦æ¨¡æ“¬åˆ°çµ‚å±€ã€‚

### ç¥ç¶“ç¶²è·¯ + MCTS çš„çµåˆ

AlphaGo ä½¿ç”¨ **PUCT**ï¼ˆPredictor Upper Confidence Bounds applied to Treesï¼‰å…¬å¼ä¾†é¸æ“‡ç¯€é»ï¼š

```
é¸æ“‡åˆ†æ•¸ = Q(s,a) + c Ã— P(s,a) Ã— âˆš(N(s)) / (1 + N(s,a))

å…¶ä¸­ï¼š
- Q(s,a)ï¼šè©²å‹•ä½œçš„å¹³å‡åƒ¹å€¼ï¼ˆä¾†è‡ª Value Networkï¼‰
- P(s,a)ï¼šè©²å‹•ä½œçš„å…ˆé©—æ©Ÿç‡ï¼ˆä¾†è‡ª Policy Networkï¼‰
- N(s)ï¼šçˆ¶ç¯€é»è¨ªå•æ¬¡æ•¸
- N(s,a)ï¼šè©²å‹•ä½œè¨ªå•æ¬¡æ•¸
- cï¼šæ¢ç´¢å¸¸æ•¸
```

**ç›´è§€ç†è§£**ï¼š
- Policy Network èªªé€™æ­¥æ£‹å¥½ â†’ P(s,a) é«˜ â†’ å„ªå…ˆæ¢ç´¢
- æ¢ç´¢è¶Šå°‘çš„ç¯€é» â†’ N(s,a) å° â†’ åˆ†æ•¸è¶Šé«˜ â†’ é¼“å‹µæ¢ç´¢
- Value Network è©•ä¼°å¥½ â†’ Q(s,a) é«˜ â†’ å„ªå…ˆé¸æ“‡

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ E4ï¼šPUCT å…¬å¼ â†” æœ‰åæ“´æ•£ â€” ç­–ç•¥å¼•å°æœå°‹çš„æ•¸å­¸
- ğŸ¬ C3ï¼šæ¢ç´¢ vs åˆ©ç”¨ â†” è‡ªç”±èƒ½æ¬Šè¡¡ â€” å…¬å¼ä¸­çš„å¹³è¡¡

### æœç´¢éç¨‹åœ–è§£

```mermaid
flowchart TB
    Root["æ ¹ç¯€é»ï¼ˆç•¶å‰å±€é¢ï¼‰"] --> A["ç¯€é» A<br/>P=0.3, Q=0.6<br/>N=100"]
    Root --> B["ç¯€é» B<br/>P=0.5, Q=0.4<br/>N=20"]
    Root --> C["ç¯€é» C<br/>P=0.1, Q=0.7<br/>N=5"]
    A --> A1["ç¯€é» A1"]
    A --> A2["ç¯€é» A2"]
```

**æœç´¢æ­¥é©Ÿ**ï¼š
1. å¾æ ¹ç¯€é»é–‹å§‹ï¼Œç”¨ PUCT é¸æ“‡å­ç¯€é»
2. æ²¿è‘—æ¨¹å‘ä¸‹ï¼Œç›´åˆ°åˆ°é”è‘‰ç¯€é»
3. ç”¨ Value Network è©•ä¼°è‘‰ç¯€é»
4. å°‡è©•ä¼°çµæœå›å‚³æ›´æ–°è·¯å¾‘ä¸Šæ‰€æœ‰ç¯€é»çš„ Q å€¼
5. é‡è¤‡æ•¸åƒæ¬¡
6. é¸æ“‡è¨ªå•æ¬¡æ•¸æœ€å¤šçš„å‹•ä½œ

---

## å››ã€è¨“ç·´ï¼šå¾äººé¡æ£‹è­œåˆ°è¶…è¶Šäººé¡

### éšæ®µä¸€ï¼šç›£ç£å­¸ç¿’

**ç›®æ¨™**ï¼šå­¸ç¿’äººé¡å°ˆå®¶çš„ä¸‹æ³•

```
è¨“ç·´è³‡æ–™ï¼š3000 è¬å±€äººé¡è·æ¥­æ£‹è­œ
è¼¸å…¥ï¼šæ£‹ç›¤ç‹€æ…‹
æ¨™ç±¤ï¼šäººé¡ä¸‹ä¸€æ­¥çš„ä½ç½®

æå¤±å‡½æ•¸ï¼šäº¤å‰ç†µ
Loss = -log(P(äººé¡å¯¦éš›ä¸‹çš„ä½ç½®))
```

çµæœï¼šPolicy Network èƒ½ä»¥ 57% çš„æº–ç¢ºç‡é æ¸¬äººé¡æ£‹æ‰‹çš„ä¸‹ä¸€æ­¥ã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ D3ï¼šå‰å‘å‚³æ’­ â†” å‰é¥‹ç¶²è·¯
- ğŸ¬ D5ï¼šæ¢¯åº¦ä¸‹é™ â†” çƒæ»¾ä¸‹å±±

### éšæ®µäºŒï¼šå¼·åŒ–å­¸ç¿’

**ç›®æ¨™**ï¼šè¶…è¶Šäººé¡æ°´å¹³

ç›£ç£å­¸ç¿’åªèƒ½å­¸åˆ°äººé¡çš„ä¸Šé™ã€‚è¦è¶…è¶Šäººé¡ï¼Œéœ€è¦**è‡ªæˆ‘å°å¼ˆ**ï¼š

```
è‡ªæˆ‘å°å¼ˆè¨“ç·´å¾ªç’°ï¼š

1. ç”¨ç•¶å‰ Policy Network æ§åˆ¶é»‘ç™½é›™æ–¹
2. é€²è¡Œå®Œæ•´å°å±€ï¼Œè¨˜éŒ„æ¯æ­¥æ£‹
3. æ ¹æ“šæœ€çµ‚å‹è² ï¼Œæ›´æ–° Policy Network
   - è´æ£‹çš„ä¸€æ–¹ï¼šå¢åŠ é‚£äº›å‹•ä½œçš„æ©Ÿç‡
   - è¼¸æ£‹çš„ä¸€æ–¹ï¼šæ¸›å°‘é‚£äº›å‹•ä½œçš„æ©Ÿç‡
4. é‡è¤‡æ•¸ç™¾è¬å±€
```

é€™å°±æ˜¯**å¼·åŒ–å­¸ç¿’**çš„æ ¸å¿ƒï¼šå¾çµæœï¼ˆå‹è² ï¼‰åæ¨éç¨‹ï¼ˆæ¯æ­¥æ£‹çš„å¥½å£ï¼‰ã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ H4ï¼šç­–ç•¥æ¢¯åº¦ â†” ç­–ç•¥æ¢¯åº¦æ³•
- ğŸ¬ H5ï¼šç¶“é©—å›æ”¾ â†” ç¶“é©—ç·©è¡å€

### éšæ®µä¸‰ï¼šè¨“ç·´ Value Network

```
è¨“ç·´è³‡æ–™ï¼šè‡ªæˆ‘å°å¼ˆç”¢ç”Ÿçš„æ£‹å±€
è¼¸å…¥ï¼šæ£‹ç›¤ç‹€æ…‹
æ¨™ç±¤ï¼šæœ€çµ‚å‹è² ï¼ˆ+1 æˆ– -1ï¼‰

æå¤±å‡½æ•¸ï¼šå‡æ–¹èª¤å·®
Loss = (V(s) - å¯¦éš›çµæœ)Â²
```

### è‡ªæˆ‘å°å¼ˆå¾ªç’°

```
åˆå§‹æ¨¡å‹ â†’ è‡ªæˆ‘å°å¼ˆ â†’ æ”¶é›†æ£‹è­œ â†’ è¨“ç·´æ–°æ¨¡å‹ â†’ æ›´å¼·æ¨¡å‹ â†’ é‡è¤‡
```

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ E5ï¼šè‡ªæˆ‘å°å¼ˆ â†” ä¸å‹•é»æ”¶æ–‚ â€” ç³»çµ±å¦‚ä½•è¶¨å‘ç©©å®š
- ğŸ¬ H1ï¼šMDP â†” é¦¬å¯å¤«éˆ â€” ç‹€æ…‹è½‰ç§»çš„æ•¸å­¸æ¨¡å‹
- ğŸ¬ E6ï¼šæ£‹åŠ›æ›²ç·š â†” S æ›²ç·šæˆé•· â€” Elo å¦‚ä½•æˆé•·

---

## äº”ã€AlphaGo Zeroï¼šå¾é›¶é–‹å§‹

2017 å¹´ï¼ŒDeepMind ç™¼å¸ƒäº† AlphaGo Zeroï¼Œè­‰æ˜**å®Œå…¨ä¸éœ€è¦äººé¡æ£‹è­œ**ã€‚

### èˆ‡åŸç‰ˆ AlphaGo çš„å·®ç•°

| é¢å‘ | AlphaGo | AlphaGo Zero |
|------|---------|--------------|
| äººé¡æ£‹è­œ | éœ€è¦ | **ä¸éœ€è¦** |
| ç¶²è·¯æ¶æ§‹ | åˆ†é›¢çš„ Policy + Value | **å–®ä¸€ç¶²è·¯ï¼Œé›™é ­è¼¸å‡º** |
| è¼¸å…¥ç‰¹å¾µ | 48 å€‹ç‰¹å¾µå¹³é¢ | **17 å€‹ç‰¹å¾µå¹³é¢** |
| è¨“ç·´æ™‚é–“ | æ•¸æœˆ | **3 å¤©** |
| æ£‹åŠ› | æ“Šæ•—æä¸–ä¹­ | **100:0 æ“Šæ•—åŸç‰ˆ AlphaGo** |

### ç‚ºä»€éº¼å¾é›¶é–‹å§‹åè€Œæ›´å¼·ï¼Ÿ

1. **äººé¡æ£‹è­œæ˜¯åè¦‹**ï¼šäººé¡æœ‰ç›²é»ï¼ŒAI å­¸ç¿’äººé¡ä¹Ÿæœƒç¹¼æ‰¿é€™äº›ç›²é»
2. **è‡ªæˆ‘ç™¼ç¾**ï¼šå¾é›¶é–‹å§‹ï¼ŒAI èƒ½ç™¼ç¾äººé¡å¾æœªæƒ³éçš„ä¸‹æ³•
3. **æ›´ç°¡æ½”çš„æ¶æ§‹**ï¼šå–®ä¸€ç¶²è·¯ã€æ›´å°‘ç‰¹å¾µï¼Œè¨“ç·´æ›´é«˜æ•ˆ

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ E7ï¼šå¾é›¶é–‹å§‹ â†” è‡ªçµ„ç¹”
- ğŸ¬ E3ï¼šé›™é ­ç¶²è·¯ â†” å¤šä»»å‹™å­¸ç¿’

### è¨“ç·´æ›²ç·šçš„é©šäººä¹‹è™•

```
Day 0: éš¨æ©Ÿäº‚ä¸‹
Day 1: ç™¼ç¾åŸºæœ¬è¦å‰‡ï¼ˆåƒå­ã€åšçœ¼ï¼‰
Day 2: ç™¼ç¾å®šå¼ï¼ˆè§’éƒ¨ä¸‹æ³•ï¼‰
Day 3: è¶…è¶Šæ‰€æœ‰äººé¡
```

AlphaGo Zero åœ¨ 3 å¤©å…§ã€Œé‡æ–°ç™¼ç¾ã€äº†äººé¡æ•¸åƒå¹´ç´¯ç©çš„æ£‹ç†ï¼Œç„¶å¾Œè¶…è¶Šäº†å®ƒã€‚

---

## å…­ã€KataGoï¼šæ›´å¿«ã€æ›´å¼·ã€æ›´å¯¦ç”¨

### ç‚ºä»€éº¼éœ€è¦ KataGoï¼Ÿ

AlphaGo æ˜¯é–‰æºçš„ï¼Œéœ€è¦æ•¸åƒå€‹ TPU è¨“ç·´ã€‚æ™®é€šé–‹ç™¼è€…ç„¡æ³•ä½¿ç”¨ã€‚

KataGo æ˜¯ **David Wu** æ–¼ 2019 å¹´ç™¼å¸ƒçš„é–‹æºå°ˆæ¡ˆï¼Œé”åˆ°åŒç­‰æ£‹åŠ›åªéœ€è¦ï¼š

| è³‡æº | AlphaGo | KataGo |
|------|---------|--------|
| ç¡¬é«” | æ•¸åƒ TPU | **30 GPU** |
| æ™‚é–“ | æ•¸æœˆ | **19 å¤©** |
| æ•ˆç‡ | åŸºæº– | **æå‡ 50 å€** |

### AlphaGo vs KataGo å°æ¯”

| æ¯”è¼ƒé …ç›® | AlphaGo | KataGo |
|---------|---------|--------|
| ç¥ç¶“ç¶²è·¯æ¶æ§‹ | åˆ†é›¢å¼ | **æ•´åˆå¼å¤šé ­** |
| è¨“ç·´è³‡æº | æ•¸åƒ TPU | **30 GPU** |
| æ•ˆç‡ | åŸºæº– | **50 å€æå‡** |
| é–‹æºç‹€æ…‹ | é–‰æº | **å®Œå…¨é–‹æº** |
| è¼¸å‡ºåŠŸèƒ½ | ç­–ç•¥+å‹ç‡ | ç­–ç•¥+å‹ç‡+**ç›®æ•¸+é ˜åœ°** |

### KataGo çš„é—œéµå‰µæ–°

#### 1. æ•´åˆå¼å¤šé ­ç¶²è·¯

AlphaGo ç”¨å…©å€‹åˆ†é›¢çš„ç¶²è·¯ï¼ˆPolicy + Valueï¼‰ï¼ŒKataGo ç”¨**å–®ä¸€ç¶²è·¯ï¼Œå¤šå€‹è¼¸å‡ºé ­**ï¼š

```mermaid
flowchart TB
    A["æ£‹ç›¤è¼¸å…¥"] --> B["å…±äº«ä¸»å¹¹<br/>ï¼ˆæ·±åº¦æ®˜å·®ç¶²è·¯ï¼‰"]
    B --> P["Policy<br/>(ä¸‹å“ª)"]
    B --> V["Value<br/>(èª°è´)"]
    B --> S["Score<br/>(è´å¹¾ç›®)"]
    B --> O["Ownership<br/>(é ˜åœ°)"]
```

**å¥½è™•**ï¼šå…±äº«ç‰¹å¾µæå–ï¼Œæ¸›å°‘è¨ˆç®—é‡ï¼ŒåŒæ™‚ç²å¾—æ›´å¤šè³‡è¨Šã€‚

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ E3ï¼šé›™é ­ç¶²è·¯ â†” å¤šä»»å‹™å­¸ç¿’
- ğŸ¬ D12ï¼šæ®˜å·®é€£æ¥ â†” é›»è·¯ä¸¦è¯

#### 2. è¼”åŠ©è¨“ç·´ç›®æ¨™

KataGo ä¸åªé æ¸¬ã€Œèª°è´ã€ï¼Œé‚„é æ¸¬ï¼š
- **Score**ï¼šè´å¤šå°‘ç›®
- **Ownership**ï¼šæ¯å€‹ä½ç½®æœ€çµ‚æ­¸èª°

é€™äº›è¼”åŠ©ç›®æ¨™è®“ç¥ç¶“ç¶²è·¯æ›´æ·±åˆ»ç†è§£å±€é¢ï¼Œè€Œä¸åªæ˜¯é æ¸¬å‹è² ã€‚

#### 3. Playout Cap éš¨æ©ŸåŒ–

å‚³çµ±è¨“ç·´ï¼šæ¯å±€éƒ½ç”¨å›ºå®šçš„æœç´¢æ·±åº¦

KataGoï¼š**éš¨æ©Ÿæ”¹è®Šæ¯å±€çš„æœç´¢æ·±åº¦**

```
- æœ‰æ™‚ç”¨ 600 æ¬¡ MCTSï¼ˆæ·±åº¦æœç´¢ï¼‰
- æœ‰æ™‚ç”¨ 100 æ¬¡ MCTSï¼ˆå¿«é€Ÿæœç´¢ï¼‰
- æœ‰æ™‚ç”¨ 20 æ¬¡ MCTSï¼ˆå¹¾ä¹ç´”ç¥ç¶“ç¶²è·¯ï¼‰
```

**å¥½è™•**ï¼šç¥ç¶“ç¶²è·¯å­¸æœƒåœ¨å„ç¨®æœç´¢æ·±åº¦ä¸‹éƒ½è¡¨ç¾è‰¯å¥½ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

#### 4. å…¨å±€æ± åŒ–ï¼ˆGlobal Poolingï¼‰

å‚³çµ± CNN åªçœ‹å±€éƒ¨ç‰¹å¾µã€‚KataGo åŠ å…¥å…¨å±€æ± åŒ–å±¤ï¼Œè®“ç¶²è·¯èƒ½ã€Œç¶œè§€å…¨å±€ã€ï¼š

```
å±€éƒ¨å·ç©ç‰¹å¾µ â†’ å…¨å±€å¹³å‡æ± åŒ– â†’ èˆ‡å±€éƒ¨ç‰¹å¾µçµåˆ â†’ æ›´å¥½çš„å…¨å±€åˆ¤æ–·
```

**å‹•ç•«å°æ‡‰**ï¼š
- ğŸ¬ G1ï¼šé«˜ç¶­è¡¨ç¤º â†” å‘é‡ç©ºé–“
- ğŸ¬ D11ï¼šæ± åŒ– â†” é™æ¡æ¨£

---

## ä¸ƒã€ç¸½çµï¼šä¸€å¼µåœ–çœ‹æ‡‚æ•´å€‹ç³»çµ±

```mermaid
flowchart TB
    subgraph Training["è¨“ç·´éšæ®µ"]
        NN1["ç¥ç¶“ç¶²è·¯"] -->|è‡ªæˆ‘å°å¼ˆ| GameData["æ£‹å±€è³‡æ–™"]
        GameData -->|æ¢¯åº¦ä¸‹é™æ›´æ–°| NN1
    end

    Training -->|è¨“ç·´å®Œæˆçš„æ¨¡å‹| Inference

    subgraph Inference["æ¨ç†éšæ®µ"]
        Input["ç•¶å‰å±€é¢"] --> NN2["ç¥ç¶“ç¶²è·¯"]
        NN2 --> Policy["Policyï¼ˆå¼•å°æœç´¢ï¼‰"]
        NN2 --> Value["Valueï¼ˆè©•ä¼°å±€é¢ï¼‰"]
        Policy --> MCTS["MCTS æ¨¹æœç´¢"]
        Value --> MCTS
        MCTS --> BestMove["æœ€ä½³ä¸‹æ³•"]
    end
```

### é—œéµè¦é»

1. **ç¥ç¶“ç¶²è·¯è§£æ±ºè©•ä¼°å•é¡Œ**ï¼šä¸éœ€è¦æ‰‹å·¥è¨­è¨ˆè©•ä¼°å‡½æ•¸
2. **MCTS è§£æ±ºæœç´¢å•é¡Œ**ï¼šåœ¨ç¥ç¶“ç¶²è·¯çš„å¼•å°ä¸‹é«˜æ•ˆæœç´¢
3. **è‡ªæˆ‘å°å¼ˆç”¢ç”Ÿè³‡æ–™**ï¼šä¸éœ€è¦äººé¡æ£‹è­œï¼Œå¾é›¶é–‹å§‹å­¸ç¿’
4. **å¼·åŒ–å­¸ç¿’æŒçºŒæ”¹é€²**ï¼šå¾å‹è² çµæœåæ¨ï¼Œä¸æ–·æå‡

---

## å»¶ä¼¸é–±è®€

- **æƒ³æ›´æ·±å…¥ AlphaGo**ï¼Ÿâ†’ [AlphaGo å®Œæ•´è§£æ](/docs/alphago/)
- **æƒ³äº†è§£ KataGo ç´°ç¯€**ï¼Ÿâ†’ [KataGo çš„é—œéµå‰µæ–°](./katago-innovations)
- **æƒ³æŸ¥ç‰¹å®šæ¦‚å¿µ**ï¼Ÿâ†’ [æ¦‚å¿µé€ŸæŸ¥è¡¨](/docs/animations/)
- **æƒ³å‹•æ‰‹å¯¦ä½œ**ï¼Ÿâ†’ [30 åˆ†é˜è·‘èµ·ç¬¬ä¸€å€‹åœæ£‹ AI](../hands-on/)

---

## åƒè€ƒè³‡æ–™

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*.
3. Wu, D. (2019). "Accelerating Self-Play Learning in Go." *arXiv*.
4. [KataGo GitHub](https://github.com/lightvector/KataGo)
