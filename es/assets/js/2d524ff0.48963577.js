"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[9160],{75253(e,a,n){n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"alphago/dual-head-resnet","title":"Red de Doble Cabeza y Redes Residuales","description":"An\xe1lisis profundo de la arquitectura de red neuronal de AlphaGo Zero - Backbone compartido, Policy Head, Value Head y ResNet de 40 capas","source":"@site/i18n/es/docusaurus-plugin-content-docs/current/alphago/17-dual-head-resnet.mdx","sourceDirName":"alphago","slug":"/alphago/dual-head-resnet","permalink":"/es/docs/alphago/dual-head-resnet","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/17-dual-head-resnet.mdx","tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"sidebar_position":18,"title":"Red de Doble Cabeza y Redes Residuales","description":"An\xe1lisis profundo de la arquitectura de red neuronal de AlphaGo Zero - Backbone compartido, Policy Head, Value Head y ResNet de 40 capas","keywords":["red de doble cabeza","red residual","ResNet","Policy Head","Value Head","deep learning","arquitectura de red neuronal"]},"sidebar":"tutorialSidebar","previous":{"title":"Visi\xf3n General de AlphaGo Zero","permalink":"/es/docs/alphago/alphago-zero"},"next":{"title":"El proceso de entrenamiento desde cero","permalink":"/es/docs/alphago/training-from-scratch"}}');var d=n(62615),s=n(30416);const r={sidebar_position:18,title:"Red de Doble Cabeza y Redes Residuales",description:"An\xe1lisis profundo de la arquitectura de red neuronal de AlphaGo Zero - Backbone compartido, Policy Head, Value Head y ResNet de 40 capas",keywords:["red de doble cabeza","red residual","ResNet","Policy Head","Value Head","deep learning","arquitectura de red neuronal"]},l="Red de Doble Cabeza y Redes Residuales",c={},o=[{value:"Dise\xf1o de la Red de Doble Cabeza",id:"dise\xf1o-de-la-red-de-doble-cabeza",level:2},{value:"Arquitectura General",id:"arquitectura-general",level:3},{value:"Backbone Compartido (Shared Backbone)",id:"backbone-compartido-shared-backbone",level:3},{value:"Detalles de Arquitectura",id:"detalles-de-arquitectura",level:4},{value:"Representaci\xf3n Matem\xe1tica",id:"representaci\xf3n-matem\xe1tica",level:4},{value:"Policy Head (Cabeza de Pol\xedtica)",id:"policy-head-cabeza-de-pol\xedtica",level:3},{value:"Detalles de Arquitectura",id:"detalles-de-arquitectura-1",level:4},{value:"Representaci\xf3n Matem\xe1tica",id:"representaci\xf3n-matem\xe1tica-1",level:4},{value:"Value Head (Cabeza de Valor)",id:"value-head-cabeza-de-valor",level:3},{value:"Detalles de Arquitectura",id:"detalles-de-arquitectura-2",level:4},{value:"Representaci\xf3n Matem\xe1tica",id:"representaci\xf3n-matem\xe1tica-2",level:4},{value:"\xbfPor Qu\xe9 Compartir el Backbone?",id:"por-qu\xe9-compartir-el-backbone",level:2},{value:"Comprensi\xf3n Intuitiva",id:"comprensi\xf3n-intuitiva",level:3},{value:"Perspectiva del Aprendizaje Multi-tarea",id:"perspectiva-del-aprendizaje-multi-tarea",level:3},{value:"1. Efecto de Regularizaci\xf3n",id:"1-efecto-de-regularizaci\xf3n",level:4},{value:"2. Eficiencia de Datos",id:"2-eficiencia-de-datos",level:4},{value:"3. Se\xf1ales de Gradiente Enriquecidas",id:"3-se\xf1ales-de-gradiente-enriquecidas",level:4},{value:"Evidencia Experimental",id:"evidencia-experimental",level:3},{value:"Principios de las Redes Residuales",id:"principios-de-las-redes-residuales",level:2},{value:"El Dilema de las Redes Profundas",id:"el-dilema-de-las-redes-profundas",level:3},{value:"Dise\xf1o del Bloque Residual",id:"dise\xf1o-del-bloque-residual",level:3},{value:"Representaci\xf3n Matem\xe1tica",id:"representaci\xf3n-matem\xe1tica-3",level:4},{value:"\xbfPor Qu\xe9 Funcionan las Conexiones Residuales?",id:"por-qu\xe9-funcionan-las-conexiones-residuales",level:3},{value:"1. Autopista de Gradientes",id:"1-autopista-de-gradientes",level:4},{value:"2. El Mapeo Identidad Es M\xe1s F\xe1cil de Aprender",id:"2-el-mapeo-identidad-es-m\xe1s-f\xe1cil-de-aprender",level:4},{value:"3. Efecto de Ensamble",id:"3-efecto-de-ensamble",level:4},{value:"El Avance de ResNet en ImageNet",id:"el-avance-de-resnet-en-imagenet",level:3},{value:"La ResNet de 40 Capas de AlphaGo Zero",id:"la-resnet-de-40-capas-de-alphago-zero",level:2},{value:"\xbfPor Qu\xe9 40 Capas?",id:"por-qu\xe9-40-capas",level:3},{value:"Configuraci\xf3n Espec\xedfica",id:"configuraci\xf3n-espec\xedfica",level:3},{value:"Estimaci\xf3n de Par\xe1metros",id:"estimaci\xf3n-de-par\xe1metros",level:4},{value:"El Rol de Batch Normalization",id:"el-rol-de-batch-normalization",level:3},{value:"1. Normalizar Valores de Activaci\xf3n",id:"1-normalizar-valores-de-activaci\xf3n",level:4},{value:"2. Mitigar el Desplazamiento de Covarianza Interna",id:"2-mitigar-el-desplazamiento-de-covarianza-interna",level:4},{value:"3. Efecto de Regularizaci\xf3n",id:"3-efecto-de-regularizaci\xf3n",level:4},{value:"Comparaci\xf3n con Otras Arquitecturas",id:"comparaci\xf3n-con-otras-arquitecturas",level:2},{value:"vs. CNN del AlphaGo Original",id:"vs-cnn-del-alphago-original",level:3},{value:"vs. Red Estilo VGG",id:"vs-red-estilo-vgg",level:3},{value:"vs. Inception / GoogLeNet",id:"vs-inception--googlenet",level:3},{value:"vs. Transformer",id:"vs-transformer",level:3},{value:"An\xe1lisis Profundo de Decisiones de Dise\xf1o",id:"an\xe1lisis-profundo-de-decisiones-de-dise\xf1o",level:2},{value:"\xbfPor Qu\xe9 Usar Convoluciones 3\xd73?",id:"por-qu\xe9-usar-convoluciones-33",level:3},{value:"\xbfPor Qu\xe9 256 Canales?",id:"por-qu\xe9-256-canales",level:3},{value:"\xbfPor Qu\xe9 Policy Head Usa Softmax y Value Head Usa Tanh?",id:"por-qu\xe9-policy-head-usa-softmax-y-value-head-usa-tanh",level:3},{value:"Policy Head: Softmax",id:"policy-head-softmax",level:4},{value:"Value Head: Tanh",id:"value-head-tanh",level:4},{value:"Detalles de Entrenamiento",id:"detalles-de-entrenamiento",level:2},{value:"Funci\xf3n de P\xe9rdida",id:"funci\xf3n-de-p\xe9rdida",level:3},{value:"Policy Loss",id:"policy-loss",level:4},{value:"Value Loss",id:"value-loss",level:4},{value:"Regularization Loss",id:"regularization-loss",level:4},{value:"Configuraci\xf3n del Optimizador",id:"configuraci\xf3n-del-optimizador",level:3},{value:"Aumento de Datos",id:"aumento-de-datos",level:3},{value:"Consideraciones de Implementaci\xf3n",id:"consideraciones-de-implementaci\xf3n",level:2},{value:"Optimizaci\xf3n de Memoria",id:"optimizaci\xf3n-de-memoria",level:3},{value:"Optimizaci\xf3n de Inferencia",id:"optimizaci\xf3n-de-inferencia",level:3},{value:"Cuantizaci\xf3n y Compresi\xf3n",id:"cuantizaci\xf3n-y-compresi\xf3n",level:3},{value:"Correspondencia con Animaciones",id:"correspondencia-con-animaciones",level:2},{value:"Lecturas Adicionales",id:"lecturas-adicionales",level:2},{value:"Referencias",id:"referencias",level:2}];function t(e){const a={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(a.header,{children:(0,d.jsx)(a.h1,{id:"red-de-doble-cabeza-y-redes-residuales",children:"Red de Doble Cabeza y Redes Residuales"})}),"\n",(0,d.jsxs)(a.p,{children:["Una de las innovaciones arquitect\xf3nicas m\xe1s importantes de AlphaGo Zero es el uso de una ",(0,d.jsx)(a.strong,{children:"Red de Doble Cabeza (Dual-Head Network)"})," para reemplazar el dise\xf1o de doble red del AlphaGo original. Este cambio aparentemente simple trajo mejoras significativas de rendimiento y un proceso de aprendizaje m\xe1s elegante."]}),"\n",(0,d.jsx)(a.p,{children:"Este art\xedculo analizar\xe1 en profundidad los principios de dise\xf1o de esta arquitectura, sus fundamentos matem\xe1ticos, y por qu\xe9 es tan efectiva."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"dise\xf1o-de-la-red-de-doble-cabeza",children:"Dise\xf1o de la Red de Doble Cabeza"}),"\n",(0,d.jsx)(a.h3,{id:"arquitectura-general",children:"Arquitectura General"}),"\n",(0,d.jsx)(a.p,{children:"La red neuronal de AlphaGo Zero se puede dividir en tres partes:"}),"\n",(0,d.jsx)(a.mermaid,{value:'flowchart TB\n    Input["Entrada (17 x 19 x 19)"]\n\n    Backbone["Backbone Compartido (ResNet)<br/>40 bloques residuales, 256 canales"]\n\n    PolicyHead["Policy Head<br/>(Cabeza de Politica)"]\n    ValueHead["Value Head<br/>(Cabeza de Valor)"]\n\n    PolicyOut["Distribucion de prob.<br/>19x19 + prob. de Pass"]\n    ValueOut["Tasa de victoria<br/>[-1, 1]"]\n\n    Input --\x3e Backbone\n    Backbone --\x3e PolicyHead\n    Backbone --\x3e ValueHead\n    PolicyHead --\x3e PolicyOut\n    ValueHead --\x3e ValueOut'}),"\n",(0,d.jsx)(a.p,{children:"Analicemos cada parte."}),"\n",(0,d.jsx)(a.h3,{id:"backbone-compartido-shared-backbone",children:"Backbone Compartido (Shared Backbone)"}),"\n",(0,d.jsxs)(a.p,{children:["El backbone compartido es una ",(0,d.jsx)(a.strong,{children:"Red Residual (ResNet)"})," profunda, responsable de extraer caracter\xedsticas del estado del tablero."]}),"\n",(0,d.jsx)(a.h4,{id:"detalles-de-arquitectura",children:"Detalles de Arquitectura"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Componente"}),(0,d.jsx)(a.th,{children:"Especificaci\xf3n"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Capa de entrada"}),(0,d.jsx)(a.td,{children:"Convoluci\xf3n 3\xd73, 256 canales"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Bloques residuales"}),(0,d.jsx)(a.td,{children:"40 (o 20 versi\xf3n simplificada)"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Cada bloque residual"}),(0,d.jsx)(a.td,{children:"2 capas conv 3\xd73, 256 canales"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Funci\xf3n de activaci\xf3n"}),(0,d.jsx)(a.td,{children:"ReLU"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Normalizaci\xf3n"}),(0,d.jsx)(a.td,{children:"Batch Normalization"})]})]})]}),"\n",(0,d.jsx)(a.h4,{id:"representaci\xf3n-matem\xe1tica",children:"Representaci\xf3n Matem\xe1tica"}),"\n",(0,d.jsx)(a.p,{children:"Sea la entrada x (dimensi\xf3n 17 x 19 x 19), la salida del backbone compartido es:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"f(x) = ResNet_40(Conv_3x3(x))\n"})}),"\n",(0,d.jsx)(a.p,{children:"Donde f(x) (dimensi\xf3n 256 x 19 x 19) es la representaci\xf3n de caracter\xedsticas de alta dimensi\xf3n."}),"\n",(0,d.jsx)(a.h3,{id:"policy-head-cabeza-de-pol\xedtica",children:"Policy Head (Cabeza de Pol\xedtica)"}),"\n",(0,d.jsx)(a.p,{children:"Policy Head es responsable de predecir la probabilidad de jugar en cada posici\xf3n."}),"\n",(0,d.jsx)(a.h4,{id:"detalles-de-arquitectura-1",children:"Detalles de Arquitectura"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"Salida del Backbone (256 \xd7 19 \xd7 19)\n       \u2193\nConvoluci\xf3n 1\xd71 (2 canales)\n       \u2193\nBatch Normalization\n       \u2193\nReLU\n       \u2193\nAplanar (2 \xd7 19 \xd7 19 = 722)\n       \u2193\nCapa Totalmente Conectada (362)\n       \u2193\nSoftmax\n       \u2193\nSalida: 362 probabilidades (361 posiciones + Pass)\n"})}),"\n",(0,d.jsx)(a.h4,{id:"representaci\xf3n-matem\xe1tica-1",children:"Representaci\xf3n Matem\xe1tica"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"\u03c0 = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))\n"})}),"\n",(0,d.jsx)(a.p,{children:"La salida \u03c0 es un vector de 362 dimensiones, donde todos los elementos son no negativos y suman 1."}),"\n",(0,d.jsx)(a.h3,{id:"value-head-cabeza-de-valor",children:"Value Head (Cabeza de Valor)"}),"\n",(0,d.jsx)(a.p,{children:"Value Head es responsable de predecir la tasa de victoria de la posici\xf3n actual."}),"\n",(0,d.jsx)(a.h4,{id:"detalles-de-arquitectura-2",children:"Detalles de Arquitectura"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"Salida del Backbone (256 \xd7 19 \xd7 19)\n       \u2193\nConvoluci\xf3n 1\xd71 (1 canal)\n       \u2193\nBatch Normalization\n       \u2193\nReLU\n       \u2193\nAplanar (1 \xd7 19 \xd7 19 = 361)\n       \u2193\nCapa Totalmente Conectada (256)\n       \u2193\nReLU\n       \u2193\nCapa Totalmente Conectada (1)\n       \u2193\nTanh\n       \u2193\nSalida: Tasa de victoria [-1, 1]\n"})}),"\n",(0,d.jsx)(a.h4,{id:"representaci\xf3n-matem\xe1tica-2",children:"Representaci\xf3n Matem\xe1tica"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))\n"})}),"\n",(0,d.jsx)(a.p,{children:"La salida v est\xe1 en el rango [-1, 1]:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"v = 1: El jugador actual gana seguro"}),"\n",(0,d.jsx)(a.li,{children:"v = -1: El jugador actual pierde seguro"}),"\n",(0,d.jsx)(a.li,{children:"v = 0: Posici\xf3n equilibrada"}),"\n"]}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"por-qu\xe9-compartir-el-backbone",children:"\xbfPor Qu\xe9 Compartir el Backbone?"}),"\n",(0,d.jsx)(a.h3,{id:"comprensi\xf3n-intuitiva",children:"Comprensi\xf3n Intuitiva"}),"\n",(0,d.jsx)(a.p,{children:'"D\xf3nde deber\xeda jugar el siguiente movimiento" (Policy) y "Qui\xe9n ganar\xe1" (Value) -- estas dos preguntas en realidad necesitan entender los mismos patrones del tablero:'}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Forma de las piedras"}),": Qu\xe9 formas son buenas, cu\xe1les son malas"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Influencia"}),": Qu\xe9 lado tiene m\xe1s, d\xf3nde queda espacio"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Vida y muerte"}),": Qu\xe9 grupos est\xe1n vivos, cu\xe1les est\xe1n en ko"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Combate"}),": D\xf3nde hay ataques, cu\xe1l es el resultado local"]}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Si se usan dos redes independientes, estas caracter\xedsticas necesitan aprenderse dos veces. El backbone compartido permite que estas caracter\xedsticas de bajo nivel se aprendan solo una vez, siendo usadas por ambas tareas."}),"\n",(0,d.jsx)(a.h3,{id:"perspectiva-del-aprendizaje-multi-tarea",children:"Perspectiva del Aprendizaje Multi-tarea"}),"\n",(0,d.jsxs)(a.p,{children:["Desde la perspectiva del machine learning, esto es ",(0,d.jsx)(a.strong,{children:"Aprendizaje Multi-tarea (Multi-task Learning)"}),":"]}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"L = L_policy + L_value\n"})}),"\n",(0,d.jsx)(a.p,{children:"Las dos tareas comparten representaci\xf3n de bajo nivel, lo que trae varios beneficios:"}),"\n",(0,d.jsx)(a.h4,{id:"1-efecto-de-regularizaci\xf3n",children:"1. Efecto de Regularizaci\xf3n"}),"\n",(0,d.jsx)(a.p,{children:"Compartir par\xe1metros equivale a regularizaci\xf3n impl\xedcita. Si una caracter\xedstica solo es \xfatil para Policy y no para Value (o viceversa), es m\xe1s dif\xedcil que se amplifique excesivamente."}),"\n",(0,d.jsx)(a.p,{children:"La cantidad efectiva de par\xe1metros es menor que la suma de dos redes independientes."}),"\n",(0,d.jsx)(a.h4,{id:"2-eficiencia-de-datos",children:"2. Eficiencia de Datos"}),"\n",(0,d.jsx)(a.p,{children:"Cada partida produce simult\xe1neamente etiquetas de Policy (probabilidades de b\xfasqueda MCTS) y etiquetas de Value (resultado final). El backbone compartido permite que ambas etiquetas se usen para entrenar caracter\xedsticas compartidas, mejorando la eficiencia de utilizaci\xf3n de datos."}),"\n",(0,d.jsx)(a.h4,{id:"3-se\xf1ales-de-gradiente-enriquecidas",children:"3. Se\xf1ales de Gradiente Enriquecidas"}),"\n",(0,d.jsx)(a.p,{children:"Los gradientes de ambas tareas fluyen hacia el backbone compartido:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"\u2202L/\u2202\u03b8_shared = \u2202L_policy/\u2202\u03b8_shared + \u2202L_value/\u2202\u03b8_shared\n"})}),"\n",(0,d.jsx)(a.p,{children:"Esto proporciona se\xf1ales de supervisi\xf3n m\xe1s ricas, haciendo las caracter\xedsticas compartidas m\xe1s robustas."}),"\n",(0,d.jsx)(a.h3,{id:"evidencia-experimental",children:"Evidencia Experimental"}),"\n",(0,d.jsx)(a.p,{children:"Los experimentos de ablaci\xf3n de DeepMind mostraron que la red de doble cabeza supera significativamente las dobles redes separadas:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Configuraci\xf3n"}),(0,d.jsx)(a.th,{children:"Puntuaci\xf3n ELO"}),(0,d.jsx)(a.th,{children:"Diferencia Relativa"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Redes Policy + Value separadas"}),(0,d.jsx)(a.td,{children:"L\xednea base"}),(0,d.jsx)(a.td,{children:"-"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Red de doble cabeza (backbone compartido)"}),(0,d.jsx)(a.td,{children:"+300 ELO"}),(0,d.jsx)(a.td,{children:"~65% diferencia en tasa de victoria"})]})]})]}),"\n",(0,d.jsx)(a.p,{children:"Una diferencia de 300 ELO significa que la red de doble cabeza tiene aproximadamente 65% de tasa de victoria contra redes separadas. Esta es una mejora significativa."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"principios-de-las-redes-residuales",children:"Principios de las Redes Residuales"}),"\n",(0,d.jsx)(a.h3,{id:"el-dilema-de-las-redes-profundas",children:"El Dilema de las Redes Profundas"}),"\n",(0,d.jsx)(a.p,{children:"Antes de la invenci\xf3n de ResNet, las redes neuronales profundas enfrentaban una paradoja:"}),"\n",(0,d.jsxs)(a.blockquote,{children:["\n",(0,d.jsx)(a.p,{children:"Te\xf3ricamente, las redes m\xe1s profundas deber\xedan ser al menos tan buenas como las m\xe1s superficiales (en el peor caso, las capas extra pueden aprender el mapeo identidad). Pero en la pr\xe1ctica, las redes m\xe1s profundas a menudo rend\xedan peor."}),"\n"]}),"\n",(0,d.jsxs)(a.p,{children:["Este es el ",(0,d.jsx)(a.strong,{children:"Problema de Degradaci\xf3n (Degradation Problem)"}),":"]}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"El error de entrenamiento aumenta con la profundidad (no es sobreajuste, es dificultad de optimizaci\xf3n)"}),"\n",(0,d.jsx)(a.li,{children:"Los gradientes se desvanecen gradualmente durante la retropropagaci\xf3n (Vanishing Gradient)"}),"\n",(0,d.jsx)(a.li,{children:"Los par\xe1metros de capas profundas casi no pueden actualizarse efectivamente"}),"\n"]}),"\n",(0,d.jsx)(a.h3,{id:"dise\xf1o-del-bloque-residual",children:"Dise\xf1o del Bloque Residual"}),"\n",(0,d.jsxs)(a.p,{children:["He Kaiming et al. propusieron en 2015 una soluci\xf3n simple y elegante: ",(0,d.jsx)(a.strong,{children:"Conexiones Residuales (Skip Connection)"}),"."]}),"\n",(0,d.jsx)(a.mermaid,{value:'flowchart TB\n    Input["Entrada x"]\n    Conv1["Capa Conv"]\n    BN1["BN + ReLU"]\n    Conv2["Capa Conv"]\n    BN2["BN"]\n    Add((" + "))\n    ReLU["ReLU"]\n    Output["Salida x + F(x)"]\n\n    Input --\x3e Conv1\n    Conv1 --\x3e BN1\n    BN1 --\x3e Conv2\n    Conv2 --\x3e BN2\n    BN2 --\x3e Add\n    Input -- "x (conexion de salto)" --\x3e Add\n    Add --\x3e ReLU\n    ReLU --\x3e Output'}),"\n",(0,d.jsx)(a.h4,{id:"representaci\xf3n-matem\xe1tica-3",children:"Representaci\xf3n Matem\xe1tica"}),"\n",(0,d.jsx)(a.p,{children:"Red tradicional: Aprender mapeo objetivo H(x)"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"y = H(x)\n"})}),"\n",(0,d.jsxs)(a.p,{children:["Red residual: Aprender ",(0,d.jsx)(a.strong,{children:"mapeo residual"})," F(x) = H(x) - x"]}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"y = F(x) + x\n"})}),"\n",(0,d.jsx)(a.h3,{id:"por-qu\xe9-funcionan-las-conexiones-residuales",children:"\xbfPor Qu\xe9 Funcionan las Conexiones Residuales?"}),"\n",(0,d.jsx)(a.h4,{id:"1-autopista-de-gradientes",children:"1. Autopista de Gradientes"}),"\n",(0,d.jsx)(a.p,{children:"Considera el gradiente de retropropagaci\xf3n:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"\u2202L/\u2202x = \u2202L/\u2202y \xd7 \u2202y/\u2202x = \u2202L/\u2202y \xd7 (1 + \u2202F(x)/\u2202x)\n"})}),"\n",(0,d.jsxs)(a.p,{children:["La clave es ese ",(0,d.jsx)(a.strong,{children:"+1"}),". Incluso si \u2202F(x)/\u2202x es muy peque\xf1o o cero, el gradiente a\xfan puede pasar directamente a trav\xe9s del +1."]}),"\n",(0,d.jsx)(a.p,{children:'Es como construir una "autopista de gradientes", permitiendo que los gradientes fluyan sin obst\xe1culos desde la capa de salida hasta la capa de entrada.'}),"\n",(0,d.jsx)(a.h4,{id:"2-el-mapeo-identidad-es-m\xe1s-f\xe1cil-de-aprender",children:"2. El Mapeo Identidad Es M\xe1s F\xe1cil de Aprender"}),"\n",(0,d.jsx)(a.p,{children:"Si la soluci\xf3n \xf3ptima est\xe1 cerca del mapeo identidad (H(x) \u2248 x), entonces:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"Red tradicional: Necesita aprender H(x) = x, puede ser dif\xedcil"}),"\n",(0,d.jsx)(a.li,{children:"Red residual: Solo necesita aprender F(x) \u2248 0, relativamente f\xe1cil"}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Inicializando pesos a cero o cerca de cero, el bloque residual naturalmente tiende hacia el mapeo identidad."}),"\n",(0,d.jsx)(a.h4,{id:"3-efecto-de-ensamble",children:"3. Efecto de Ensamble"}),"\n",(0,d.jsxs)(a.p,{children:["Una ResNet profunda puede verse como un ",(0,d.jsx)(a.strong,{children:"ensamble impl\xedcito"})," de muchas redes poco profundas. Si hay n bloques residuales, la informaci\xf3n puede fluir a trav\xe9s de 2^n diferentes caminos."]}),"\n",(0,d.jsx)(a.p,{children:"Este efecto de ensamble aumenta la robustez del modelo."}),"\n",(0,d.jsx)(a.h3,{id:"el-avance-de-resnet-en-imagenet",children:"El Avance de ResNet en ImageNet"}),"\n",(0,d.jsx)(a.p,{children:"ResNet logr\xf3 resultados asombrosos en la competencia ImageNet 2015:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Profundidad"}),(0,d.jsx)(a.th,{children:"Error Top-5"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"VGG-19 (sin residual)"}),(0,d.jsx)(a.td,{children:"7.3%"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"ResNet-34"}),(0,d.jsx)(a.td,{children:"5.7%"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"ResNet-152"}),(0,d.jsx)(a.td,{children:"4.5%"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Nivel humano"}),(0,d.jsx)(a.td,{children:"~5.1%"})]})]})]}),"\n",(0,d.jsxs)(a.p,{children:["Una ResNet de ",(0,d.jsx)(a.strong,{children:"152 capas"})," no solo es entrenable, sino que es mucho mejor que VGG de 19 capas. Esto prob\xf3 que las conexiones residuales realmente resuelven el problema de entrenamiento de redes profundas."]}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"la-resnet-de-40-capas-de-alphago-zero",children:"La ResNet de 40 Capas de AlphaGo Zero"}),"\n",(0,d.jsx)(a.h3,{id:"por-qu\xe9-40-capas",children:"\xbfPor Qu\xe9 40 Capas?"}),"\n",(0,d.jsx)(a.p,{children:"DeepMind prob\xf3 ResNets de diferentes profundidades:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"N\xfamero de bloques residuales"}),(0,d.jsx)(a.th,{children:"Total de capas"}),(0,d.jsx)(a.th,{children:"Puntuaci\xf3n ELO"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"5"}),(0,d.jsx)(a.td,{children:"11"}),(0,d.jsx)(a.td,{children:"L\xednea base"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"10"}),(0,d.jsx)(a.td,{children:"21"}),(0,d.jsx)(a.td,{children:"+200"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"20"}),(0,d.jsx)(a.td,{children:"41"}),(0,d.jsx)(a.td,{children:"+400"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"40"}),(0,d.jsx)(a.td,{children:"81"}),(0,d.jsx)(a.td,{children:"+500"})]})]})]}),"\n",(0,d.jsx)(a.p,{children:"Las redes m\xe1s profundas son ciertamente m\xe1s fuertes, pero con retornos decrecientes. AlphaGo Zero usa 20 o 40 bloques residuales:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"AlphaGo Zero (versi\xf3n del paper)"}),": 40 bloques residuales, 256 canales"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Versi\xf3n simplificada"}),": 20 bloques residuales, 256 canales"]}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"La configuraci\xf3n de 40 capas logra un buen equilibrio entre fuerza de juego y costo de entrenamiento."}),"\n",(0,d.jsx)(a.h3,{id:"configuraci\xf3n-espec\xedfica",children:"Configuraci\xf3n Espec\xedfica"}),"\n",(0,d.jsx)(a.p,{children:"La configuraci\xf3n de ResNet de AlphaGo Zero:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"Entrada: 17 \xd7 19 \xd7 19\n\u2193\nCapa conv: 3\xd73, 256 canales, BN, ReLU\n\u2193\nBloque residual \xd740:\n  \u251c\u2500 Capa conv: 3\xd73, 256 canales, BN, ReLU\n  \u251c\u2500 Capa conv: 3\xd73, 256 canales, BN\n  \u2514\u2500 Conexi\xf3n de salto + ReLU\n\u2193\nPolicy Head / Value Head\n"})}),"\n",(0,d.jsx)(a.h4,{id:"estimaci\xf3n-de-par\xe1metros",children:"Estimaci\xf3n de Par\xe1metros"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Componente"}),(0,d.jsx)(a.th,{children:"Par\xe1metros (aprox.)"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Conv de entrada"}),(0,d.jsx)(a.td,{children:"17 \xd7 3 \xd7 3 \xd7 256 \u2248 39K"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Cada bloque residual"}),(0,d.jsx)(a.td,{children:"2 \xd7 256 \xd7 3 \xd7 3 \xd7 256 \u2248 1.2M"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"40 bloques residuales"}),(0,d.jsx)(a.td,{children:"40 \xd7 1.2M \u2248 47M"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Policy Head"}),(0,d.jsx)(a.td,{children:"~1M"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Value Head"}),(0,d.jsx)(a.td,{children:"~0.2M"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:(0,d.jsx)(a.strong,{children:"Total"})}),(0,d.jsx)(a.td,{children:(0,d.jsx)(a.strong,{children:"~48M"})})]})]})]}),"\n",(0,d.jsx)(a.p,{children:"Aproximadamente 48 millones de par\xe1metros, una red neuronal de escala media seg\xfan est\xe1ndares modernos."}),"\n",(0,d.jsx)(a.h3,{id:"el-rol-de-batch-normalization",children:"El Rol de Batch Normalization"}),"\n",(0,d.jsxs)(a.p,{children:["Cada capa convolucional es seguida por ",(0,d.jsx)(a.strong,{children:"Batch Normalization (BN)"}),", crucial para la estabilidad del entrenamiento:"]}),"\n",(0,d.jsx)(a.h4,{id:"1-normalizar-valores-de-activaci\xf3n",children:"1. Normalizar Valores de Activaci\xf3n"}),"\n",(0,d.jsx)(a.p,{children:"BN normaliza los valores de activaci\xf3n de cada capa a media 0, varianza 1:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"x_hat = (x - \u03bc_B) / sqrt(\u03c3_B\xb2 + \u03b5)\ny = \u03b3 \xd7 x_hat + \u03b2\n"})}),"\n",(0,d.jsx)(a.p,{children:"Donde \u03b3 y \u03b2 son par\xe1metros aprendibles."}),"\n",(0,d.jsx)(a.h4,{id:"2-mitigar-el-desplazamiento-de-covarianza-interna",children:"2. Mitigar el Desplazamiento de Covarianza Interna"}),"\n",(0,d.jsx)(a.p,{children:"En redes profundas, la distribuci\xf3n de entrada de cada capa cambia a medida que se actualizan los par\xe1metros de capas anteriores. BN mantiene la distribuci\xf3n de entrada de cada capa estable, acelerando la convergencia del entrenamiento."}),"\n",(0,d.jsx)(a.h4,{id:"3-efecto-de-regularizaci\xf3n",children:"3. Efecto de Regularizaci\xf3n"}),"\n",(0,d.jsx)(a.p,{children:"BN usa estad\xedsticas del mini-batch durante el entrenamiento, introduciendo aleatoriedad, con un ligero efecto de regularizaci\xf3n."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"comparaci\xf3n-con-otras-arquitecturas",children:"Comparaci\xf3n con Otras Arquitecturas"}),"\n",(0,d.jsx)(a.h3,{id:"vs-cnn-del-alphago-original",children:"vs. CNN del AlphaGo Original"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Caracter\xedstica"}),(0,d.jsx)(a.th,{children:"AlphaGo original"}),(0,d.jsx)(a.th,{children:"AlphaGo Zero"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Tipo de arquitectura"}),(0,d.jsx)(a.td,{children:"CNN est\xe1ndar"}),(0,d.jsx)(a.td,{children:"ResNet"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Profundidad"}),(0,d.jsx)(a.td,{children:"13 capas"}),(0,d.jsx)(a.td,{children:"41-81 capas"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Conexiones residuales"}),(0,d.jsx)(a.td,{children:"No"}),(0,d.jsx)(a.td,{children:"S\xed"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"N\xfamero de redes"}),(0,d.jsx)(a.td,{children:"2 (separadas)"}),(0,d.jsx)(a.td,{children:"1 (compartida)"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"BN"}),(0,d.jsx)(a.td,{children:"No"}),(0,d.jsx)(a.td,{children:"S\xed"})]})]})]}),"\n",(0,d.jsx)(a.h3,{id:"vs-red-estilo-vgg",children:"vs. Red Estilo VGG"}),"\n",(0,d.jsx)(a.p,{children:"VGG fue la arquitectura subcampeona de ImageNet 2014, usando convoluciones 3\xd73 apiladas:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Caracter\xedstica"}),(0,d.jsx)(a.th,{children:"VGG"}),(0,d.jsx)(a.th,{children:"ResNet"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"M\xe1x. profundidad entrenable"}),(0,d.jsx)(a.td,{children:"~19 capas"}),(0,d.jsx)(a.td,{children:"152+ capas"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Flujo de gradiente"}),(0,d.jsx)(a.td,{children:"Decrece por capa"}),(0,d.jsx)(a.td,{children:"Tiene autopista"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Dificultad de entrenamiento"}),(0,d.jsx)(a.td,{children:"Dif\xedcil para capas profundas"}),(0,d.jsx)(a.td,{children:"Capas profundas entrenables"})]})]})]}),"\n",(0,d.jsx)(a.h3,{id:"vs-inception--googlenet",children:"vs. Inception / GoogLeNet"}),"\n",(0,d.jsx)(a.p,{children:"Inception usa convoluciones multi-escala en paralelo:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Caracter\xedstica"}),(0,d.jsx)(a.th,{children:"Inception"}),(0,d.jsx)(a.th,{children:"ResNet"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Enfoque"}),(0,d.jsx)(a.td,{children:"Caracter\xedsticas multi-escala"}),(0,d.jsx)(a.td,{children:"Apilamiento profundo"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Complejidad"}),(0,d.jsx)(a.td,{children:"Mayor"}),(0,d.jsx)(a.td,{children:"Simple"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Aplicabilidad para Go"}),(0,d.jsx)(a.td,{children:"General"}),(0,d.jsx)(a.td,{children:"Excelente"})]})]})]}),"\n",(0,d.jsx)(a.p,{children:"El dise\xf1o simple de ResNet es m\xe1s adecuado para tareas que requieren razonamiento profundo como Go."}),"\n",(0,d.jsx)(a.h3,{id:"vs-transformer",children:"vs. Transformer"}),"\n",(0,d.jsx)(a.p,{children:"La arquitectura Transformer propuesta en 2017 logr\xf3 gran \xe9xito en NLP. Algunos intentaron aplicar Transformer a Go:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Caracter\xedstica"}),(0,d.jsx)(a.th,{children:"ResNet"}),(0,d.jsx)(a.th,{children:"Transformer"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Sesgo inductivo"}),(0,d.jsx)(a.td,{children:"Localidad (convoluci\xf3n)"}),(0,d.jsx)(a.td,{children:"Atenci\xf3n global"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Codificaci\xf3n de posici\xf3n"}),(0,d.jsx)(a.td,{children:"Impl\xedcita (convoluci\xf3n)"}),(0,d.jsx)(a.td,{children:"Expl\xedcita"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Rendimiento en Go"}),(0,d.jsx)(a.td,{children:"Excelente"}),(0,d.jsx)(a.td,{children:"Viable pero no superior a ResNet"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Eficiencia computacional"}),(0,d.jsx)(a.td,{children:"Mayor"}),(0,d.jsx)(a.td,{children:"Menor (O(n\xb2))"})]})]})]}),"\n",(0,d.jsx)(a.p,{children:"Para problemas con estructura espacial obvia como Go, el sesgo inductivo de CNN/ResNet es m\xe1s apropiado."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"an\xe1lisis-profundo-de-decisiones-de-dise\xf1o",children:"An\xe1lisis Profundo de Decisiones de Dise\xf1o"}),"\n",(0,d.jsx)(a.h3,{id:"por-qu\xe9-usar-convoluciones-33",children:"\xbfPor Qu\xe9 Usar Convoluciones 3\xd73?"}),"\n",(0,d.jsx)(a.p,{children:"AlphaGo Zero usa convoluciones 3\xd73 en todo el proceso, en lugar de kernels m\xe1s grandes:"}),"\n",(0,d.jsxs)(a.ol,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Eficiencia de par\xe1metros"}),": Dos convoluciones 3\xd73 tienen el mismo campo receptivo que una 5\xd75, pero menos par\xe1metros (18 vs 25)"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Redes m\xe1s profundas"}),": Con la misma cantidad de par\xe1metros, se pueden apilar m\xe1s capas"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"M\xe1s no-linealidad"}),": ReLU entre cada capa, aumentando la capacidad expresiva"]}),"\n"]}),"\n",(0,d.jsx)(a.h3,{id:"por-qu\xe9-256-canales",children:"\xbfPor Qu\xe9 256 Canales?"}),"\n",(0,d.jsx)(a.p,{children:"256 canales es una elecci\xf3n emp\xedrica:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Muy pocos"})," (como 64): Capacidad expresiva insuficiente, no puede capturar patrones complejos"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Demasiados"})," (como 512): Par\xe1metros se duplican, costo de entrenamiento aumenta mucho, pero mejora de fuerza limitada"]}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Los experimentos posteriores de KataGo mostraron que los canales pueden ajustarse seg\xfan recursos de entrenamiento:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"Bajos recursos: 128 canales, 20 bloques"}),"\n",(0,d.jsx)(a.li,{children:"Altos recursos: 256 canales, 40 bloques"}),"\n",(0,d.jsx)(a.li,{children:"M\xe1s recursos: 384 canales, 60 bloques"}),"\n"]}),"\n",(0,d.jsx)(a.h3,{id:"por-qu\xe9-policy-head-usa-softmax-y-value-head-usa-tanh",children:"\xbfPor Qu\xe9 Policy Head Usa Softmax y Value Head Usa Tanh?"}),"\n",(0,d.jsx)(a.h4,{id:"policy-head-softmax",children:"Policy Head: Softmax"}),"\n",(0,d.jsxs)(a.p,{children:["Jugar es un ",(0,d.jsx)(a.strong,{children:"problema de clasificaci\xf3n"})," -- elegir una entre 361 posiciones (m\xe1s Pass). La salida Softmax satisface:"]}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"Todas las probabilidades son no negativas: \u03c0_i >= 0"}),"\n",(0,d.jsx)(a.li,{children:"Las probabilidades suman 1: \u03a3\u03c0_i = 1"}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Esto es consistente con la definici\xf3n de distribuci\xf3n de probabilidad."}),"\n",(0,d.jsx)(a.h4,{id:"value-head-tanh",children:"Value Head: Tanh"}),"\n",(0,d.jsxs)(a.p,{children:["La tasa de victoria es un ",(0,d.jsx)(a.strong,{children:"problema de regresi\xf3n"})," -- predecir un valor continuo. El rango de salida de Tanh es [-1, 1]:"]}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"Acotado: No producir\xe1 valores extremos"}),"\n",(0,d.jsx)(a.li,{children:"Sim\xe9trico: Victoria y derrota tratadas sim\xe9tricamente"}),"\n",(0,d.jsx)(a.li,{children:"Diferenciable: Conveniente para c\xe1lculo de gradientes"}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Usar Tanh en lugar de salida no acotada (como capa lineal) puede prevenir inestabilidad en el entrenamiento."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"detalles-de-entrenamiento",children:"Detalles de Entrenamiento"}),"\n",(0,d.jsx)(a.h3,{id:"funci\xf3n-de-p\xe9rdida",children:"Funci\xf3n de P\xe9rdida"}),"\n",(0,d.jsx)(a.p,{children:"La p\xe9rdida total de AlphaGo Zero es la suma de tres t\xe9rminos:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"L = L_policy + L_value + L_reg\n"})}),"\n",(0,d.jsx)(a.h4,{id:"policy-loss",children:"Policy Loss"}),"\n",(0,d.jsxs)(a.p,{children:["Usa ",(0,d.jsx)(a.strong,{children:"p\xe9rdida de entrop\xeda cruzada"}),", haciendo que la salida de la red se aproxime a las probabilidades de b\xfasqueda MCTS:"]}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"L_policy = -\u03a3 \u03c0_MCTS(a) \xd7 log(\u03c0_net(a))\n"})}),"\n",(0,d.jsx)(a.p,{children:"Donde:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"\u03c0_MCTS(a) es la probabilidad de b\xfasqueda MCTS para acci\xf3n a"}),"\n",(0,d.jsx)(a.li,{children:"\u03c0_net(a) es la probabilidad de salida de la red"}),"\n"]}),"\n",(0,d.jsx)(a.h4,{id:"value-loss",children:"Value Loss"}),"\n",(0,d.jsxs)(a.p,{children:["Usa ",(0,d.jsx)(a.strong,{children:"Error Cuadr\xe1tico Medio (MSE)"}),", haciendo que la salida de la red se aproxime al resultado real:"]}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"L_value = (v_net - z)\xb2\n"})}),"\n",(0,d.jsx)(a.p,{children:"Donde:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsx)(a.li,{children:"v_net es la tasa de victoria predicha por la red"}),"\n",(0,d.jsx)(a.li,{children:"z es el resultado real de la partida (+1 o -1)"}),"\n"]}),"\n",(0,d.jsx)(a.h4,{id:"regularization-loss",children:"Regularization Loss"}),"\n",(0,d.jsxs)(a.p,{children:["Usa ",(0,d.jsx)(a.strong,{children:"regularizaci\xf3n L2"})," para prevenir sobreajuste:"]}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"L_reg = c \xd7 ||\u03b8||\xb2\n"})}),"\n",(0,d.jsx)(a.p,{children:"Donde c es el coeficiente de regularizaci\xf3n, \u03b8 son los par\xe1metros de la red."}),"\n",(0,d.jsx)(a.h3,{id:"configuraci\xf3n-del-optimizador",children:"Configuraci\xf3n del Optimizador"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"Par\xe1metro"}),(0,d.jsx)(a.th,{children:"Valor"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Optimizador"}),(0,d.jsx)(a.td,{children:"SGD + Momentum"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Momentum"}),(0,d.jsx)(a.td,{children:"0.9"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Tasa de aprendizaje inicial"}),(0,d.jsx)(a.td,{children:"0.01"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Decaimiento de tasa de aprendizaje"}),(0,d.jsx)(a.td,{children:"Reducir a mitad cada X pasos"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Tama\xf1o de batch"}),(0,d.jsx)(a.td,{children:"32 \xd7 2048 = 64K (distribuido)"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"Coeficiente de regularizaci\xf3n L2"}),(0,d.jsx)(a.td,{children:"1e-4"})]})]})]}),"\n",(0,d.jsx)(a.h3,{id:"aumento-de-datos",children:"Aumento de Datos"}),"\n",(0,d.jsx)(a.p,{children:"El tablero de Go tiene 8 simetr\xedas (4 rotaciones \xd7 2 reflexiones). Durante el entrenamiento, cada posici\xf3n puede producir 8 muestras de entrenamiento equivalentes."}),"\n",(0,d.jsx)(a.p,{children:"Esto aumenta los datos de entrenamiento efectivos 8 veces, sin necesitar auto-juego adicional."}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"consideraciones-de-implementaci\xf3n",children:"Consideraciones de Implementaci\xf3n"}),"\n",(0,d.jsx)(a.h3,{id:"optimizaci\xf3n-de-memoria",children:"Optimizaci\xf3n de Memoria"}),"\n",(0,d.jsx)(a.p,{children:"Entrenar una ResNet de 40 capas requiere mucha memoria:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Forward pass"}),": Necesita almacenar activaciones de cada capa (para backpropagation)"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Backward pass"}),": Necesita almacenar gradientes"]}),"\n"]}),"\n",(0,d.jsx)(a.p,{children:"Estrategias de optimizaci\xf3n:"}),"\n",(0,d.jsxs)(a.ol,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Gradient Checkpointing"}),": Solo almacenar algunas activaciones, recalcular cuando sea necesario"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Entrenamiento de precisi\xf3n mixta"}),": Usar FP16 para reducir uso de memoria"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Entrenamiento distribuido"}),": Distribuir batch entre m\xfaltiples GPU/TPU"]}),"\n"]}),"\n",(0,d.jsx)(a.h3,{id:"optimizaci\xf3n-de-inferencia",children:"Optimizaci\xf3n de Inferencia"}),"\n",(0,d.jsx)(a.p,{children:"Durante inferencia no se necesitan estad\xedsticas de mini-batch de BN, se puede usar media m\xf3vil acumulada durante entrenamiento:"}),"\n",(0,d.jsx)(a.pre,{children:(0,d.jsx)(a.code,{children:"x_hat = (x - \u03bc_moving) / sqrt(\u03c3_moving\xb2 + \u03b5)\n"})}),"\n",(0,d.jsx)(a.p,{children:"Esto hace la inferencia m\xe1s r\xe1pida y determinista."}),"\n",(0,d.jsx)(a.h3,{id:"cuantizaci\xf3n-y-compresi\xf3n",children:"Cuantizaci\xf3n y Compresi\xf3n"}),"\n",(0,d.jsx)(a.p,{children:"Se puede comprimir m\xe1s la red para despliegue:"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Cuantizaci\xf3n de pesos"}),": FP32 \u2192 INT8, memoria reducida 4x"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Poda"}),": Eliminar conexiones de pesos peque\xf1os"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Destilaci\xf3n de conocimiento"}),": Usar red grande para entrenar red peque\xf1a"]}),"\n"]}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"correspondencia-con-animaciones",children:"Correspondencia con Animaciones"}),"\n",(0,d.jsx)(a.p,{children:"Conceptos centrales cubiertos en este art\xedculo y sus n\xfameros de animaci\xf3n:"}),"\n",(0,d.jsxs)(a.table,{children:[(0,d.jsx)(a.thead,{children:(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.th,{children:"N\xfamero"}),(0,d.jsx)(a.th,{children:"Concepto"}),(0,d.jsx)(a.th,{children:"Correspondencia F\xedsica/Matem\xe1tica"})]})}),(0,d.jsxs)(a.tbody,{children:[(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"E3"}),(0,d.jsx)(a.td,{children:"Red de doble cabeza"}),(0,d.jsx)(a.td,{children:"Aprendizaje multi-tarea"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"D12"}),(0,d.jsx)(a.td,{children:"Conexi\xf3n residual"}),(0,d.jsx)(a.td,{children:"Autopista de gradientes"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"D8"}),(0,d.jsx)(a.td,{children:"Red neuronal convolucional"}),(0,d.jsx)(a.td,{children:"Campo receptivo local"})]}),(0,d.jsxs)(a.tr,{children:[(0,d.jsx)(a.td,{children:"D10"}),(0,d.jsx)(a.td,{children:"Batch Normalization"}),(0,d.jsx)(a.td,{children:"Normalizaci\xf3n de distribuci\xf3n"})]})]})]}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"lecturas-adicionales",children:"Lecturas Adicionales"}),"\n",(0,d.jsxs)(a.ul,{children:["\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Art\xedculo anterior"}),": ",(0,d.jsx)(a.a,{href:"../alphago-zero",children:"Visi\xf3n General de AlphaGo Zero"})," \u2014 Por qu\xe9 no se necesitan partidas humanas"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Siguiente art\xedculo"}),": ",(0,d.jsx)(a.a,{href:"../training-from-scratch",children:"Proceso de Entrenamiento desde Cero"})," \u2014 Evoluci\xf3n detallada del D\xeda 0-3"]}),"\n",(0,d.jsxs)(a.li,{children:[(0,d.jsx)(a.strong,{children:"Profundizaci\xf3n t\xe9cnica"}),": ",(0,d.jsx)(a.a,{href:"../cnn-and-go",children:"CNN y Go"})," \u2014 Por qu\xe9 CNN es adecuada para tableros"]}),"\n"]}),"\n",(0,d.jsx)(a.hr,{}),"\n",(0,d.jsx)(a.h2,{id:"referencias",children:"Referencias"}),"\n",(0,d.jsxs)(a.ol,{children:["\n",(0,d.jsxs)(a.li,{children:['Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." ',(0,d.jsx)(a.em,{children:"Nature"}),", 550, 354-359."]}),"\n",(0,d.jsxs)(a.li,{children:['He, K., et al. (2016). "Deep Residual Learning for Image Recognition." ',(0,d.jsx)(a.em,{children:"CVPR 2016"}),"."]}),"\n",(0,d.jsxs)(a.li,{children:['Ioffe, S., & Szegedy, C. (2015). "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift." ',(0,d.jsx)(a.em,{children:"ICML 2015"}),"."]}),"\n",(0,d.jsxs)(a.li,{children:['Caruana, R. (1997). "Multitask Learning." ',(0,d.jsx)(a.em,{children:"Machine Learning"}),", 28(1), 41-75."]}),"\n",(0,d.jsxs)(a.li,{children:['Veit, A., et al. (2016). "Residual Networks Behave Like Ensembles of Relatively Shallow Networks." ',(0,d.jsx)(a.em,{children:"NeurIPS 2016"}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,d.jsx)(a,{...e,children:(0,d.jsx)(t,{...e})}):t(e)}},30416(e,a,n){n.d(a,{R:()=>r,x:()=>l});var i=n(59471);const d={},s=i.createContext(d);function r(e){const a=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:r(e.components),i.createElement(s.Provider,{value:a},e.children)}}}]);