"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[879],{46020(e,a,n){n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"alphago/traditional-limits","title":"Los Limites de los Metodos Tradicionales","description":"Desde Minimax hasta MCTS, una comprension profunda de por que los metodos tradicionales de IA fracasaron en el Go","source":"@site/i18n/es/docusaurus-plugin-content-docs/current/alphago/05-traditional-limits.mdx","sourceDirName":"alphago","slug":"/alphago/traditional-limits","permalink":"/es/docs/alphago/traditional-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/05-traditional-limits.mdx","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Los Limites de los Metodos Tradicionales","description":"Desde Minimax hasta MCTS, una comprension profunda de por que los metodos tradicionales de IA fracasaron en el Go","keywords":["Minimax","Poda Alpha-Beta","MCTS","Busqueda de Arbol Monte Carlo","Historia de Go por computadora"]},"sidebar":"tutorialSidebar","previous":{"title":"\xbfPor Qu\xe9 es Dif\xedcil el Go?","permalink":"/es/docs/alphago/why-go-is-hard"},"next":{"title":"Representacion del Estado del Tablero","permalink":"/es/docs/alphago/board-representation"}}');var s=n(62615),t=n(30416),l=n(45695);const o={sidebar_position:6,title:"Los Limites de los Metodos Tradicionales",description:"Desde Minimax hasta MCTS, una comprension profunda de por que los metodos tradicionales de IA fracasaron en el Go",keywords:["Minimax","Poda Alpha-Beta","MCTS","Busqueda de Arbol Monte Carlo","Historia de Go por computadora"]},r="Los Limites de los Metodos Tradicionales",d={},c=[{value:"Algoritmo Minimax: La Base de la Teoria de Juegos",id:"algoritmo-minimax-la-base-de-la-teoria-de-juegos",level:2},{value:"Principio Basico",id:"principio-basico",level:3},{value:"Formalizacion Matematica",id:"formalizacion-matematica",level:3},{value:"Diagrama del Arbol de Busqueda",id:"diagrama-del-arbol-de-busqueda",level:3},{value:"Implementacion del Codigo",id:"implementacion-del-codigo",level:3},{value:"Problemas de Minimax en el Go",id:"problemas-de-minimax-en-el-go",level:3},{value:"1. Explosion del Espacio de Busqueda",id:"1-explosion-del-espacio-de-busqueda",level:4},{value:"2. Dificultad de la Funcion de Evaluacion",id:"2-dificultad-de-la-funcion-de-evaluacion",level:4},{value:"Poda Alpha-Beta: Reduciendo Busquedas Inutiles",id:"poda-alpha-beta-reduciendo-busquedas-inutiles",level:2},{value:"Idea Central",id:"idea-central",level:3},{value:"Principio de Poda",id:"principio-de-poda",level:3},{value:"Formalizacion Matematica",id:"formalizacion-matematica-1",level:3},{value:"Implementacion del Codigo",id:"implementacion-del-codigo-1",level:3},{value:"Eficiencia de la Poda",id:"eficiencia-de-la-poda",level:3},{value:"Por que Sigue Siendo Insuficiente",id:"por-que-sigue-siendo-insuficiente",level:3},{value:"1. La Poda Ideal Requiere Ordenamiento Perfecto",id:"1-la-poda-ideal-requiere-ordenamiento-perfecto",level:4},{value:"2. La Profundidad Sigue Siendo Insuficiente",id:"2-la-profundidad-sigue-siendo-insuficiente",level:4},{value:"3. El Cuello de Botella de la Funcion de Evaluacion",id:"3-el-cuello-de-botella-de-la-funcion-de-evaluacion",level:4},{value:"Metodo de Monte Carlo Puro: El Poder de la Aleatoriedad",id:"metodo-de-monte-carlo-puro-el-poder-de-la-aleatoriedad",level:2},{value:"Abandonando la Funcion de Evaluacion",id:"abandonando-la-funcion-de-evaluacion",level:3},{value:"Principio de Estimacion Estadistica",id:"principio-de-estimacion-estadistica",level:3},{value:"Implementacion del Codigo",id:"implementacion-del-codigo-2",level:3},{value:"Ventajas y Limitaciones",id:"ventajas-y-limitaciones",level:3},{value:"Ventajas",id:"ventajas",level:4},{value:"Limitaciones",id:"limitaciones",level:4},{value:"Rendimiento de Monte Carlo Puro en Go",id:"rendimiento-de-monte-carlo-puro-en-go",level:3},{value:"El Avance del MCTS (2006)",id:"el-avance-del-mcts-2006",level:2},{value:"El Nacimiento del Algoritmo UCT",id:"el-nacimiento-del-algoritmo-uct",level:3},{value:"Formula UCB1",id:"formula-ucb1",level:3},{value:"Las Cuatro Fases del MCTS",id:"las-cuatro-fases-del-mcts",level:3},{value:"1. Selection (Seleccion)",id:"1-selection-seleccion",level:4},{value:"2. Expansion (Expansion)",id:"2-expansion-expansion",level:4},{value:"3. Simulation (Simulacion)",id:"3-simulation-simulacion",level:4},{value:"4. Backpropagation (Retropropagacion)",id:"4-backpropagation-retropropagacion",level:4},{value:"Implementacion Completa de MCTS",id:"implementacion-completa-de-mcts",level:3},{value:"\xbfPor Que Funciona MCTS?",id:"por-que-funciona-mcts",level:3},{value:"1. Enfoque Progresivo",id:"1-enfoque-progresivo",level:4},{value:"2. Algoritmo de Cualquier Momento",id:"2-algoritmo-de-cualquier-momento",level:4},{value:"3. No Necesita Funcion de Evaluacion",id:"3-no-necesita-funcion-de-evaluacion",level:4},{value:"2006-2015: La Era del MCTS",id:"2006-2015-la-era-del-mcts",level:3},{value:"El Cuello de Botella de la Funcion de Evaluacion",id:"el-cuello-de-botella-de-la-funcion-de-evaluacion",level:2},{value:"Limitaciones de las Caracteristicas Manuales",id:"limitaciones-de-las-caracteristicas-manuales",level:3},{value:"Caracteristicas Comunes",id:"caracteristicas-comunes",level:4},{value:"Problemas",id:"problemas",level:4},{value:"Problemas de Simulacion en MCTS",id:"problemas-de-simulacion-en-mcts",level:3},{value:"Problemas de la Simulacion Aleatoria",id:"problemas-de-la-simulacion-aleatoria",level:4},{value:"Intentos de Mejora",id:"intentos-de-mejora",level:4},{value:"Por Que Se Necesitan las Redes Neuronales",id:"por-que-se-necesitan-las-redes-neuronales",level:3},{value:"Resumen de los Limites de los Metodos Tradicionales",id:"resumen-de-los-limites-de-los-metodos-tradicionales",level:2},{value:"Cuellos de Botella Fundamentales",id:"cuellos-de-botella-fundamentales",level:3},{value:"1. Problema de Evaluacion",id:"1-problema-de-evaluacion",level:4},{value:"2. Problema de Busqueda",id:"2-problema-de-busqueda",level:4},{value:"La Solucion de AlphaGo",id:"la-solucion-de-alphago",level:3},{value:"Correspondencia con Animaciones",id:"correspondencia-con-animaciones",level:2},{value:"Lecturas Adicionales",id:"lecturas-adicionales",level:2},{value:"Referencias",id:"referencias",level:2}];function u(e){const a={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.header,{children:(0,s.jsx)(a.h1,{id:"los-limites-de-los-metodos-tradicionales",children:"Los Limites de los Metodos Tradicionales"})}),"\n",(0,s.jsx)(a.p,{children:'Antes de la aparicion del aprendizaje profundo, los investigadores pasaron decadas intentando resolver el problema del Go con metodos "tradicionales". Desde el algoritmo Minimax hasta la Busqueda de Arbol Monte Carlo (MCTS), cada avance hizo que el Go por computadora fuera un poco mas fuerte, pero nunca pudo alcanzar el nivel profesional humano.'}),"\n",(0,s.jsx)(a.p,{children:"Este articulo explorara en profundidad los principios, ventajas y desventajas de estos metodos, y por que encontraron un cuello de botella en el Go."}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"algoritmo-minimax-la-base-de-la-teoria-de-juegos",children:"Algoritmo Minimax: La Base de la Teoria de Juegos"}),"\n",(0,s.jsx)(a.h3,{id:"principio-basico",children:"Principio Basico"}),"\n",(0,s.jsxs)(a.p,{children:["El ",(0,s.jsx)(a.strong,{children:"algoritmo Minimax"})," es un concepto central de la teoria de juegos, propuesto por John von Neumann en 1928. Su idea basica es:"]}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsx)(a.p,{children:'En un juego de suma cero, deberia elegir la opcion que siga siendo la mejor para mi incluso despues de la "mejor respuesta" de mi oponente.'}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"En otras palabras:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Yo (Max)"})," quiero maximizar la puntuacion"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Oponente (Min)"})," quiere minimizar mi puntuacion"]}),"\n",(0,s.jsx)(a.li,{children:"Debo asumir que el oponente siempre hace la mejor jugada"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"formalizacion-matematica",children:"Formalizacion Matematica"}),"\n",(0,s.jsx)(a.p,{children:"Sea V(s) el valor de la posicion s, definido recursivamente como:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{children:"V(s) = eval(s)                        // si s es una posicion final\nV(s) = max{ V(result(s, a)) | a \u2208 A(s) }  // si es el turno de Max\nV(s) = min{ V(result(s, a)) | a \u2208 A(s) }  // si es el turno de Min\n"})}),"\n",(0,s.jsx)(a.p,{children:"Donde:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"A(s)"}),": Todas las jugadas legales en la posicion s"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"result(s, a)"}),": El resultado de ejecutar la accion a en la posicion s"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"eval(s)"}),": La evaluacion de una posicion final"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"diagrama-del-arbol-de-busqueda",children:"Diagrama del Arbol de Busqueda"}),"\n",(0,s.jsx)(a.mermaid,{value:'flowchart TB\n    subgraph Max["Capa Max (Yo)"]\n        A["-3"]\n        B["+5"]\n        C["+2"]\n    end\n\n    subgraph MinA["Capa Min"]\n        A1["-3"]\n        A2["+7"]\n        A3["+5"]\n    end\n\n    subgraph MinB["Capa Min"]\n        B1["+5"]\n        B2["-2"]\n        B3["+9"]\n    end\n\n    subgraph MinC["Capa Min"]\n        C1["+2"]\n        C2["+1"]\n        C3["+4"]\n    end\n\n    A --\x3e A1\n    A --\x3e A2\n    A --\x3e A3\n    B --\x3e B1\n    B --\x3e B2\n    B --\x3e B3\n    C --\x3e C1\n    C --\x3e C2\n    C --\x3e C3'}),"\n",(0,s.jsx)(a.p,{children:"En este ejemplo:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"La capa Min elegira el valor menos favorable para mi (el minimo)"}),"\n",(0,s.jsx)(a.li,{children:"La capa Max elegira el valor mas favorable para mi (el maximo)"}),"\n",(0,s.jsx)(a.li,{children:"Finalmente, Max deberia elegir la rama del medio (+5)"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"implementacion-del-codigo",children:"Implementacion del Codigo"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def minimax(state, depth, is_max_turn):\n    """\n    Implementacion basica del algoritmo Minimax\n\n    Args:\n        state: Posicion actual\n        depth: Profundidad de busqueda\n        is_max_turn: Si es el turno de Max\n\n    Returns:\n        (mejor valor, mejor jugada)\n    """\n    # Condicion de terminacion: alcanzar limite de profundidad o fin del juego\n    if depth == 0 or is_terminal(state):\n        return evaluate(state), None\n\n    legal_moves = get_legal_moves(state)\n    best_move = None\n\n    if is_max_turn:\n        best_value = float(\'-inf\')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            value, _ = minimax(next_state, depth - 1, False)\n            if value > best_value:\n                best_value = value\n                best_move = move\n    else:\n        best_value = float(\'inf\')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            value, _ = minimax(next_state, depth - 1, True)\n            if value < best_value:\n                best_value = value\n                best_move = move\n\n    return best_value, best_move\n'})}),"\n",(0,s.jsx)(a.h3,{id:"problemas-de-minimax-en-el-go",children:"Problemas de Minimax en el Go"}),"\n",(0,s.jsx)(a.h4,{id:"1-explosion-del-espacio-de-busqueda",children:"1. Explosion del Espacio de Busqueda"}),"\n",(0,s.jsxs)(a.p,{children:["Como se menciono en el ",(0,s.jsx)(a.a,{href:"../why-go-is-hard",children:"articulo anterior"}),", el factor de ramificacion del Go es aproximadamente 250. Para ver N movimientos:"]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"Numero de nodos \u2248 250^N"})}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Profundidad"}),(0,s.jsx)(a.th,{children:"Numero de nodos"}),(0,s.jsx)(a.th,{children:"Calculando 1 millon de nodos por segundo"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"2"}),(0,s.jsx)(a.td,{children:"62,500"}),(0,s.jsx)(a.td,{children:"0.06 segundos"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"4"}),(0,s.jsx)(a.td,{children:"3.9 mil millones"}),(0,s.jsx)(a.td,{children:"65 minutos"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"6"}),(0,s.jsx)(a.td,{children:"2.4\xd710^14"}),(0,s.jsx)(a.td,{children:"7,600 anos"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"8"}),(0,s.jsx)(a.td,{children:"1.5\xd710^19"}),(0,s.jsx)(a.td,{children:"480 millones de anos"})]})]})]}),"\n",(0,s.jsx)(a.p,{children:"Ver solo 6 movimientos requiere 7,600 anos, sin mencionar una partida completa."}),"\n",(0,s.jsx)(a.h4,{id:"2-dificultad-de-la-funcion-de-evaluacion",children:"2. Dificultad de la Funcion de Evaluacion"}),"\n",(0,s.jsxs)(a.p,{children:["Incluso si solo vemos 4 movimientos, necesitamos una ",(0,s.jsx)(a.strong,{children:"funcion de evaluacion"})," precisa para juzgar el valor de posiciones no finales. Pero como se menciono en el articulo anterior, la evaluacion de posiciones en Go es extremadamente dificil."]}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"Conclusion: El Minimax puro es completamente inviable en el Go."})}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"poda-alpha-beta-reduciendo-busquedas-inutiles",children:"Poda Alpha-Beta: Reduciendo Busquedas Inutiles"}),"\n",(0,s.jsx)(a.h3,{id:"idea-central",children:"Idea Central"}),"\n",(0,s.jsxs)(a.p,{children:["La idea central de la poda Alpha-Beta es: ",(0,s.jsx)(a.strong,{children:"no necesitamos buscar cada rama"}),"."]}),"\n",(0,s.jsx)(a.p,{children:'Si ya sabemos que una rama es "definitivamente mala", podemos saltarla directamente.'}),"\n",(0,s.jsx)(a.h3,{id:"principio-de-poda",children:"Principio de Poda"}),"\n",(0,s.jsx)(a.mermaid,{value:'flowchart TB\n    A["Nodo Max A<br/>(mejor actual \u03b1 = +5)"]\n    B1["Rama 1<br/>Ya evaluada, valor = +5"]\n    B["Rama 2: Nodo Min B"]\n    C1["Sub-rama B1: valor = +3"]\n    C2["Sub-rama B2: ???<br/>(se puede saltar!)"]\n\n    A --\x3e B1\n    A --\x3e B\n    B --\x3e C1\n    B --\x3e C2'}),"\n",(0,s.jsx)(a.p,{children:"En este ejemplo:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"A ya tiene una opcion con valor +5"}),"\n",(0,s.jsx)(a.li,{children:"La primera sub-rama de B es +3, por lo que el valor final de B \u2264 +3"}),"\n",(0,s.jsx)(a.li,{children:"Dado que B \u2264 +3 < +5, A no elegira B"}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.strong,{children:"B2 no necesita ser evaluado"})}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["Esta es la ",(0,s.jsx)(a.strong,{children:"poda Beta"}),". De manera similar, existe la ",(0,s.jsx)(a.strong,{children:"poda Alpha"}),"."]}),"\n",(0,s.jsx)(a.h3,{id:"formalizacion-matematica-1",children:"Formalizacion Matematica"}),"\n",(0,s.jsx)(a.p,{children:"Se introducen dos parametros:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"\u03b1 (alpha)"}),": El valor minimo que Max puede garantizar (limite inferior)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"\u03b2 (beta)"}),": El valor maximo que Min puede garantizar (limite superior)"]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"Condiciones de poda:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"En un nodo Max, si valor \u2265 \u03b2, podar (poda Beta)"}),"\n",(0,s.jsx)(a.li,{children:"En un nodo Min, si valor \u2264 \u03b1, podar (poda Alpha)"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"implementacion-del-codigo-1",children:"Implementacion del Codigo"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:"def alpha_beta(state, depth, alpha, beta, is_max_turn):\n    \"\"\"\n    Algoritmo de poda Alpha-Beta\n\n    Args:\n        state: Posicion actual\n        depth: Profundidad de busqueda\n        alpha: Limite inferior de Max\n        beta: Limite superior de Min\n        is_max_turn: Si es el turno de Max\n\n    Returns:\n        (valor, mejor jugada)\n    \"\"\"\n    if depth == 0 or is_terminal(state):\n        return evaluate(state), None\n\n    legal_moves = get_legal_moves(state)\n    best_move = None\n\n    if is_max_turn:\n        value = float('-inf')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            child_value, _ = alpha_beta(next_state, depth - 1,\n                                        alpha, beta, False)\n            if child_value > value:\n                value = child_value\n                best_move = move\n            alpha = max(alpha, value)\n            if value >= beta:\n                break  # Poda Beta\n        return value, best_move\n    else:\n        value = float('inf')\n        for move in legal_moves:\n            next_state = apply_move(state, move)\n            child_value, _ = alpha_beta(next_state, depth - 1,\n                                        alpha, beta, True)\n            if child_value < value:\n                value = child_value\n                best_move = move\n            beta = min(beta, value)\n            if value <= alpha:\n                break  # Poda Alpha\n        return value, best_move\n\n# Forma de llamada\nvalue, best_move = alpha_beta(state, depth=4,\n                               alpha=float('-inf'),\n                               beta=float('inf'),\n                               is_max_turn=True)\n"})}),"\n",(0,s.jsx)(a.h3,{id:"eficiencia-de-la-poda",children:"Eficiencia de la Poda"}),"\n",(0,s.jsx)(a.p,{children:"En el caso ideal (ordenamiento perfecto de movimientos), Alpha-Beta puede reducir el factor de ramificacion efectivo de b a \u221ab:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"Factor de ramificacion efectivo = b^0.5"})}),"\n",(0,s.jsx)(a.p,{children:"Esto significa:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Ajedrez: de 35 se reduce a ~6"}),"\n",(0,s.jsx)(a.li,{children:"Go: de 250 se reduce a ~16"}),"\n"]}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Profundidad"}),(0,s.jsx)(a.th,{children:"Nodos originales"}),(0,s.jsx)(a.th,{children:"Alpha-Beta (ideal)"}),(0,s.jsx)(a.th,{children:"Aceleracion"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"4"}),(0,s.jsx)(a.td,{children:"3.9 mil millones"}),(0,s.jsx)(a.td,{children:"65,000"}),(0,s.jsx)(a.td,{children:"60,000\xd7"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"6"}),(0,s.jsx)(a.td,{children:"2.4\xd710^14"}),(0,s.jsx)(a.td,{children:"16 millones"}),(0,s.jsx)(a.td,{children:"1.5\xd710^7 \xd7"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"8"}),(0,s.jsx)(a.td,{children:"1.5\xd710^19"}),(0,s.jsx)(a.td,{children:"4.2 mil millones"}),(0,s.jsx)(a.td,{children:"3.6\xd710^9 \xd7"})]})]})]}),"\n",(0,s.jsx)(a.h3,{id:"por-que-sigue-siendo-insuficiente",children:"Por que Sigue Siendo Insuficiente"}),"\n",(0,s.jsx)(a.p,{children:"Incluso con la poda Alpha-Beta, el Go sigue siendo dificil de manejar:"}),"\n",(0,s.jsx)(a.h4,{id:"1-la-poda-ideal-requiere-ordenamiento-perfecto",children:"1. La Poda Ideal Requiere Ordenamiento Perfecto"}),"\n",(0,s.jsx)(a.p,{children:'Para lograr una eficiencia de poda ideal, necesitas buscar primero la "mejor" rama. Pero para saber cual rama es mejor, necesitas buscar... es un problema del huevo y la gallina.'}),"\n",(0,s.jsx)(a.p,{children:"En la practica, la eficiencia de poda del Go esta muy por debajo del ideal, con un factor de ramificacion efectivo que puede seguir siendo 50-100."}),"\n",(0,s.jsx)(a.h4,{id:"2-la-profundidad-sigue-siendo-insuficiente",children:"2. La Profundidad Sigue Siendo Insuficiente"}),"\n",(0,s.jsx)(a.p,{children:"Incluso si el factor de ramificacion efectivo se reduce a 50, ver 10 movimientos todavia requiere 50^10 \u2248 10^17 nodos. Esto sigue siendo demasiado para las computadoras."}),"\n",(0,s.jsx)(a.h4,{id:"3-el-cuello-de-botella-de-la-funcion-de-evaluacion",children:"3. El Cuello de Botella de la Funcion de Evaluacion"}),"\n",(0,s.jsx)(a.p,{children:'Alpha-Beta solo resuelve el problema de "eficiencia de busqueda", no el problema de "precision de evaluacion". Una funcion de evaluacion pobre, con cualquier busqueda rapida, sigue dando resultados pobres.'}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"Conclusion: Alpha-Beta mejoro enormemente la IA de ajedrez, pero ayudo de manera limitada al Go."})}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"metodo-de-monte-carlo-puro-el-poder-de-la-aleatoriedad",children:"Metodo de Monte Carlo Puro: El Poder de la Aleatoriedad"}),"\n",(0,s.jsx)(a.h3,{id:"abandonando-la-funcion-de-evaluacion",children:"Abandonando la Funcion de Evaluacion"}),"\n",(0,s.jsxs)(a.p,{children:["En la decada de 1990, los investigadores comenzaron a probar una idea radical: ",(0,s.jsx)(a.strong,{children:"no usar funcion de evaluacion"}),"."]}),"\n",(0,s.jsxs)(a.p,{children:["En su lugar, utilizaron ",(0,s.jsx)(a.strong,{children:"simulacion aleatoria"})," (Random Playout):"]}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsx)(a.li,{children:"Comenzar desde la posicion actual"}),"\n",(0,s.jsx)(a.li,{children:"Ambos lados juegan aleatoriamente hasta que el juego termina"}),"\n",(0,s.jsx)(a.li,{children:"Registrar el resultado (victoria/derrota)"}),"\n",(0,s.jsx)(a.li,{children:"Repetir N veces, calcular la tasa de victorias"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"principio-de-estimacion-estadistica",children:"Principio de Estimacion Estadistica"}),"\n",(0,s.jsx)(a.p,{children:"Segun la ley de los grandes numeros, cuando el numero de simulaciones N es lo suficientemente grande:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"V\u0302(s) = Numero de victorias simuladas / N \u2248 V(s)"})}),"\n",(0,s.jsx)(a.p,{children:"El error estandar de esta estimacion es:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.strong,{children:"SE = \u221a(V(s)(1-V(s))/N) \u2248 1/(2\u221aN)"})}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Numero de simulaciones"}),(0,s.jsx)(a.th,{children:"Error estandar"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"100"}),(0,s.jsx)(a.td,{children:"5%"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"1,000"}),(0,s.jsx)(a.td,{children:"1.6%"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"10,000"}),(0,s.jsx)(a.td,{children:"0.5%"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"100,000"}),(0,s.jsx)(a.td,{children:"0.16%"})]})]})]}),"\n",(0,s.jsx)(a.h3,{id:"implementacion-del-codigo-2",children:"Implementacion del Codigo"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'import random\n\ndef random_playout(state, player):\n    """\n    Desde la posicion actual, ambos lados juegan aleatoriamente hasta el final\n\n    Returns:\n        1 si player gana, 0 si pierde\n    """\n    current = state.copy()\n    current_player = player\n\n    while not is_terminal(current):\n        legal_moves = get_legal_moves(current)\n        if not legal_moves:\n            current_player = opponent(current_player)\n            continue\n\n        # Elegir un movimiento aleatorio\n        move = random.choice(legal_moves)\n        current = apply_move(current, move)\n        current_player = opponent(current_player)\n\n    return 1 if get_winner(current) == player else 0\n\n\ndef monte_carlo_move_selection(state, player, num_simulations=10000):\n    """\n    Usar el metodo Monte Carlo para seleccionar la mejor jugada\n    """\n    legal_moves = get_legal_moves(state)\n\n    if len(legal_moves) == 0:\n        return None\n\n    # Asignar simulaciones a cada movimiento legal\n    sims_per_move = num_simulations // len(legal_moves)\n\n    best_move = None\n    best_win_rate = -1\n\n    for move in legal_moves:\n        next_state = apply_move(state, move)\n\n        wins = 0\n        for _ in range(sims_per_move):\n            wins += random_playout(next_state, opponent(player))\n\n        # Baja tasa de victorias del oponente = alta tasa de victorias mia\n        my_win_rate = 1 - (wins / sims_per_move)\n\n        if my_win_rate > best_win_rate:\n            best_win_rate = my_win_rate\n            best_move = move\n\n    return best_move, best_win_rate\n'})}),"\n",(0,s.jsx)(a.h3,{id:"ventajas-y-limitaciones",children:"Ventajas y Limitaciones"}),"\n",(0,s.jsx)(a.h4,{id:"ventajas",children:"Ventajas"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"No necesita funcion de evaluacion"}),": Depende completamente de simulaciones"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Aplicable a cualquier juego"}),": Solo necesita conocer las reglas"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Proporciona estimaciones de probabilidad"}),': Sabe "cuan seguro"']}),"\n"]}),"\n",(0,s.jsx)(a.h4,{id:"limitaciones",children:"Limitaciones"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Demasiada aleatoriedad"}),": El juego aleatorio difiere mucho del juego profesional"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Requiere muchas simulaciones"}),": Cada movimiento necesita decenas de miles de simulaciones"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Puntos ciegos tacticos"}),": Las tacticas clave pueden ser omitidas aleatoriamente"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"rendimiento-de-monte-carlo-puro-en-go",children:"Rendimiento de Monte Carlo Puro en Go"}),"\n",(0,s.jsx)(a.p,{children:"Los programas de Go que usan el metodo de Monte Carlo puro pueden alcanzar aproximadamente:"}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsxs)(a.p,{children:["Nivel de ",(0,s.jsx)(a.strong,{children:"amateur 5-10 kyu"})]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"Esto es mejor que los programas anteriores que solo usaban Minimax + funcion de evaluacion, pero todavia hay una brecha enorme con el nivel profesional."}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"el-avance-del-mcts-2006",children:"El Avance del MCTS (2006)"}),"\n",(0,s.jsx)(a.h3,{id:"el-nacimiento-del-algoritmo-uct",children:"El Nacimiento del Algoritmo UCT"}),"\n",(0,s.jsxs)(a.p,{children:["En 2006, Remi Coulom propuso el algoritmo ",(0,s.jsx)(a.strong,{children:"MCTS (Monte Carlo Tree Search)"}),", combinando las ventajas de la busqueda de arbol y la simulacion de Monte Carlo. El mismo ano, Levente Kocsis y Csaba Szepesvari propusieron el algoritmo ",(0,s.jsx)(a.strong,{children:"UCT (Upper Confidence Bounds for Trees)"}),", proporcionando una base teorica para MCTS."]}),"\n",(0,s.jsxs)(a.p,{children:["Este fue un ",(0,s.jsx)(a.strong,{children:"avance historico"})," en el Go por computadora."]}),"\n",(0,s.jsx)(a.h3,{id:"formula-ucb1",children:"Formula UCB1"}),"\n",(0,s.jsxs)(a.p,{children:["El nucleo de MCTS es la formula ",(0,s.jsx)(a.strong,{children:"UCB1 (Upper Confidence Bound)"}),":"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{children:"UCB1(s, a) = X\u0304(s,a) + C \xd7 \u221a(ln(Ns) / n(s,a))\n"})}),"\n",(0,s.jsx)(a.p,{children:"Donde:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"X\u0304(s,a)"}),": Valor promedio (tasa de victorias) de tomar la accion a en el estado s"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Ns"}),": Numero total de veces que el estado s ha sido visitado"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"n(s,a)"}),": Numero de veces que se ha tomado la accion a en el estado s"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"C"}),": Constante de exploracion (normalmente C = \u221a2)"]}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["Esta formula equilibra ingeniosamente ",(0,s.jsx)(a.strong,{children:"explotacion"})," (elegir lo que se sabe que es bueno) y ",(0,s.jsx)(a.strong,{children:"exploracion"})," (probar lo desconocido)."]}),"\n",(0,s.jsx)(a.h3,{id:"las-cuatro-fases-del-mcts",children:"Las Cuatro Fases del MCTS"}),"\n",(0,s.jsx)(l.u8,{showPUCT:!0,width:700,height:450}),"\n",(0,s.jsx)(a.p,{children:"Cada iteracion de MCTS incluye cuatro fases:"}),"\n",(0,s.jsx)(a.h4,{id:"1-selection-seleccion",children:"1. Selection (Seleccion)"}),"\n",(0,s.jsx)(a.p,{children:"Comenzando desde el nodo raiz, usar la formula UCB1 para seleccionar nodos hijos hasta llegar a un nodo hoja."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def select(node):\n    """Usar UCB1 para seleccionar el mejor nodo hijo"""\n    while node.is_fully_expanded():\n        node = max(node.children,\n                   key=lambda c: ucb1(c, node.visits))\n    return node\n\ndef ucb1(child, parent_visits, C=1.414):\n    """Formula UCB1"""\n    if child.visits == 0:\n        return float(\'inf\')  # Prioridad a nodos no visitados\n\n    exploitation = child.wins / child.visits\n    exploration = C * math.sqrt(math.log(parent_visits) / child.visits)\n\n    return exploitation + exploration\n'})}),"\n",(0,s.jsx)(a.h4,{id:"2-expansion-expansion",children:"2. Expansion (Expansion)"}),"\n",(0,s.jsx)(a.p,{children:"Agregar uno o mas nodos hijos al nodo hoja."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def expand(node, state):\n    """Expandir el nodo"""\n    legal_moves = get_legal_moves(state)\n    untried = [m for m in legal_moves if m not in node.tried_moves]\n\n    if untried:\n        move = random.choice(untried)\n        new_state = apply_move(state, move)\n        child = Node(move=move, parent=node)\n        node.children.append(child)\n        node.tried_moves.add(move)\n        return child, new_state\n\n    return node, state\n'})}),"\n",(0,s.jsx)(a.h4,{id:"3-simulation-simulacion",children:"3. Simulation (Simulacion)"}),"\n",(0,s.jsx)(a.p,{children:"Desde el nuevo nodo, realizar simulacion aleatoria hasta que el juego termine."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def simulate(state, player):\n    """Simulacion aleatoria hasta el final del juego"""\n    return random_playout(state, player)\n'})}),"\n",(0,s.jsx)(a.h4,{id:"4-backpropagation-retropropagacion",children:"4. Backpropagation (Retropropagacion)"}),"\n",(0,s.jsx)(a.p,{children:"Propagar el resultado de la simulacion a todos los nodos ancestros."}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def backpropagate(node, result):\n    """Propagar el resultado a todos los ancestros"""\n    while node is not None:\n        node.visits += 1\n        node.wins += result\n        result = 1 - result  # Cambiar perspectiva\n        node = node.parent\n'})}),"\n",(0,s.jsx)(a.h3,{id:"implementacion-completa-de-mcts",children:"Implementacion Completa de MCTS"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'class MCTSNode:\n    def __init__(self, move=None, parent=None):\n        self.move = move\n        self.parent = parent\n        self.children = []\n        self.wins = 0\n        self.visits = 0\n        self.tried_moves = set()\n\n    def is_fully_expanded(self, legal_moves):\n        return len(self.tried_moves) == len(legal_moves)\n\n\ndef mcts(root_state, player, num_iterations=10000):\n    """\n    Funcion principal de MCTS\n\n    Args:\n        root_state: Posicion inicial\n        player: Jugador actual\n        num_iterations: Numero de iteraciones\n\n    Returns:\n        Mejor jugada\n    """\n    root = MCTSNode()\n\n    for _ in range(num_iterations):\n        node = root\n        state = root_state.copy()\n        current_player = player\n\n        # 1. Selection\n        while node.children and node.is_fully_expanded(get_legal_moves(state)):\n            node = max(node.children,\n                      key=lambda c: ucb1(c, node.visits))\n            state = apply_move(state, node.move)\n            current_player = opponent(current_player)\n\n        # 2. Expansion\n        legal_moves = get_legal_moves(state)\n        if not node.is_fully_expanded(legal_moves) and not is_terminal(state):\n            move = random.choice([m for m in legal_moves\n                                  if m not in node.tried_moves])\n            state = apply_move(state, move)\n            child = MCTSNode(move=move, parent=node)\n            node.children.append(child)\n            node.tried_moves.add(move)\n            node = child\n            current_player = opponent(current_player)\n\n        # 3. Simulation\n        result = simulate(state, current_player)\n\n        # 4. Backpropagation\n        backpropagate(node, result)\n\n    # Seleccionar el nodo hijo con mas visitas\n    return max(root.children, key=lambda c: c.visits).move\n'})}),"\n",(0,s.jsx)(a.h3,{id:"por-que-funciona-mcts",children:"\xbfPor Que Funciona MCTS?"}),"\n",(0,s.jsx)(a.p,{children:"El exito de MCTS tiene varios factores clave:"}),"\n",(0,s.jsx)(a.h4,{id:"1-enfoque-progresivo",children:"1. Enfoque Progresivo"}),"\n",(0,s.jsx)(a.p,{children:'MCTS no busca todas las ramas uniformemente, sino que invierte mas recursos en ramas que parecen mas prometedoras. Esto le permite "ignorar" movimientos obviamente malos.'}),"\n",(0,s.jsx)(a.h4,{id:"2-algoritmo-de-cualquier-momento",children:"2. Algoritmo de Cualquier Momento"}),"\n",(0,s.jsx)(a.p,{children:"MCTS puede detenerse en cualquier momento y dar la mejor respuesta actual. Cuanto mas tiempo, mejor la respuesta."}),"\n",(0,s.jsx)(a.h4,{id:"3-no-necesita-funcion-de-evaluacion",children:"3. No Necesita Funcion de Evaluacion"}),"\n",(0,s.jsx)(a.p,{children:"MCTS estima el valor a traves de simulaciones, no necesita disenar funciones de evaluacion manualmente."}),"\n",(0,s.jsx)(a.h3,{id:"2006-2015-la-era-del-mcts",children:"2006-2015: La Era del MCTS"}),"\n",(0,s.jsx)(a.p,{children:"La aparicion de MCTS llevo al Go por computadora a una nueva era:"}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Programa"}),(0,s.jsx)(a.th,{children:"Ano"}),(0,s.jsx)(a.th,{children:"Caracteristicas"}),(0,s.jsx)(a.th,{children:"Fuerza"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Crazy Stone"})}),(0,s.jsx)(a.td,{children:"2006"}),(0,s.jsx)(a.td,{children:"Primer programa de Go con MCTS"}),(0,s.jsx)(a.td,{children:"Amateur dan alto"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"MoGo"})}),(0,s.jsx)(a.td,{children:"2007"}),(0,s.jsx)(a.td,{children:"MCTS optimizado"}),(0,s.jsx)(a.td,{children:"Amateur 5 dan"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Zen"})}),(0,s.jsx)(a.td,{children:"2009"}),(0,s.jsx)(a.td,{children:"Agrego reconocimiento de patrones"}),(0,s.jsx)(a.td,{children:"Amateur 6 dan"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Crazy Stone"})}),(0,s.jsx)(a.td,{children:"2013"}),(0,s.jsx)(a.td,{children:"Vencio a un profesional 9 dan con 4 piedras de ventaja"}),(0,s.jsx)(a.td,{children:"1 dan profesional (con ventaja)"})]})]})]}),"\n",(0,s.jsx)(a.p,{children:"Este fue un progreso historico, pero todavia habia una brecha enorme:"}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsxs)(a.p,{children:["Los programas MCTS mas fuertes, ",(0,s.jsx)(a.strong,{children:"sin piedras de ventaja"}),", todavia no podian vencer a jugadores profesionales."]}),"\n"]}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"el-cuello-de-botella-de-la-funcion-de-evaluacion",children:"El Cuello de Botella de la Funcion de Evaluacion"}),"\n",(0,s.jsx)(a.h3,{id:"limitaciones-de-las-caracteristicas-manuales",children:"Limitaciones de las Caracteristicas Manuales"}),"\n",(0,s.jsxs)(a.p,{children:["Antes de MCTS, los investigadores intentaron disenar varias ",(0,s.jsx)(a.strong,{children:"caracteristicas manuales"})," para evaluar posiciones:"]}),"\n",(0,s.jsx)(a.h4,{id:"caracteristicas-comunes",children:"Caracteristicas Comunes"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def evaluate_position(state):\n    """Funcion de evaluacion disenada manualmente"""\n    score = 0\n\n    # 1. Estimacion del territorio\n    score += count_territory(state, BLACK) - count_territory(state, WHITE)\n\n    # 2. Libertades de las piedras (numero de liberties)\n    score += sum(liberties(group) for group in groups(state, BLACK))\n    score -= sum(liberties(group) for group in groups(state, WHITE))\n\n    # 3. Numero de ojos\n    score += count_eyes(state, BLACK) * 10\n    score -= count_eyes(state, WHITE) * 10\n\n    # 4. Fuerza de conexion\n    score += connectivity_score(state, BLACK)\n    score -= connectivity_score(state, WHITE)\n\n    # ... mas caracteristicas\n\n    return score\n'})}),"\n",(0,s.jsx)(a.h4,{id:"problemas",children:"Problemas"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Caracteristicas incompletas"}),": Muchos factores de la intuicion humana son dificiles de describir en codigo"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Dificil ajustar pesos"}),": \xbfComo determinar la importancia relativa de cada caracteristica?"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Local vs Global"}),": El calculo local es facil, el juicio global es dificil"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Interacciones"}),": Las interacciones entre caracteristicas son dificiles de modelar"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"problemas-de-simulacion-en-mcts",children:"Problemas de Simulacion en MCTS"}),"\n",(0,s.jsxs)(a.p,{children:["Incluso sin usar directamente una funcion de evaluacion en MCTS, ",(0,s.jsx)(a.strong,{children:"la calidad de la simulacion"})," sigue siendo un cuello de botella clave."]}),"\n",(0,s.jsx)(a.h4,{id:"problemas-de-la-simulacion-aleatoria",children:"Problemas de la Simulacion Aleatoria"}),"\n",(0,s.jsx)(a.p,{children:'Jugar aleatoriamente produce muchas posiciones "irrazonables", llevando a estimaciones inexactas:'}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Grandes grupos mueren en vano"}),"\n",(0,s.jsx)(a.li,{children:"Se puede capturar pero no se captura"}),"\n",(0,s.jsx)(a.li,{children:"Se pierden muertes simples"}),"\n"]}),"\n",(0,s.jsx)(a.h4,{id:"intentos-de-mejora",children:"Intentos de Mejora"}),"\n",(0,s.jsxs)(a.p,{children:["Los investigadores intentaron agregar ",(0,s.jsx)(a.strong,{children:"conocimiento previo"})," a las simulaciones:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-python",children:'def simulation_policy(state, legal_moves):\n    """\n    Politica de simulacion con conocimiento previo\n    """\n    # Priorizar:\n    # 1. Capturas\n    # 2. Escapar\n    # 3. Conectar\n    # 4. Ocupar puntos grandes\n    # ...\n\n    for move in legal_moves:\n        if is_capture(state, move):\n            return move\n        if saves_group(state, move):\n            return move\n\n    # El resto aleatorio\n    return random.choice(legal_moves)\n'})}),"\n",(0,s.jsx)(a.p,{children:"Pero estas reglas heuristicas:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Aumentaron el costo computacional"}),"\n",(0,s.jsx)(a.li,{children:"Pueden introducir sesgos"}),"\n",(0,s.jsx)(a.li,{children:"Todavia no son lo suficientemente precisas"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"por-que-se-necesitan-las-redes-neuronales",children:"Por Que Se Necesitan las Redes Neuronales"}),"\n",(0,s.jsxs)(a.p,{children:["El cuello de botella de los metodos tradicionales es esencialmente un problema de ",(0,s.jsx)(a.strong,{children:"aprendizaje de representaciones"}),":"]}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsx)(a.p,{children:'\xbfComo aprender caracteristicas de "buenas jugadas" a partir de los pixeles del tablero (el estado de 361 puntos)?'}),"\n"]}),"\n",(0,s.jsxs)(a.p,{children:["Esta es precisamente la fortaleza del ",(0,s.jsx)(a.strong,{children:"aprendizaje profundo"}),":"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Aprendizaje automatico de caracteristicas"}),": No necesita diseno manual"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Mapeo no lineal"}),": Puede capturar relaciones complejas"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Entrenamiento de extremo a extremo"}),": Directamente de la entrada a la salida"]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"El avance del aprendizaje profundo en ImageNet en 2012 hizo que los investigadores comenzaran a pensar:"}),"\n",(0,s.jsxs)(a.blockquote,{children:["\n",(0,s.jsx)(a.p,{children:'Si las redes neuronales pueden "entender" fotos, \xbfpueden tambien "entender" tableros de Go?'}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"La respuesta a esta pregunta es AlphaGo."}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"resumen-de-los-limites-de-los-metodos-tradicionales",children:"Resumen de los Limites de los Metodos Tradicionales"}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Metodo"}),(0,s.jsx)(a.th,{children:"Ventajas"}),(0,s.jsx)(a.th,{children:"Problemas en Go"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Minimax"})}),(0,s.jsx)(a.td,{children:"Teoricamente completo, solucion optima"}),(0,s.jsx)(a.td,{children:"Factor de ramificacion demasiado grande, no puede buscar profundo"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Alpha-Beta"})}),(0,s.jsx)(a.td,{children:"Reduce enormemente el volumen de busqueda"}),(0,s.jsx)(a.td,{children:"El factor de ramificacion efectivo sigue siendo demasiado alto"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"Monte Carlo puro"})}),(0,s.jsx)(a.td,{children:"No necesita funcion de evaluacion"}),(0,s.jsx)(a.td,{children:"Calidad de simulacion aleatoria demasiado pobre"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:(0,s.jsx)(a.strong,{children:"MCTS"})}),(0,s.jsx)(a.td,{children:"Busqueda enfocada inteligente"}),(0,s.jsx)(a.td,{children:"Las simulaciones todavia no son lo suficientemente buenas, alcanza amateur dan alto"})]})]})]}),"\n",(0,s.jsx)(a.h3,{id:"cuellos-de-botella-fundamentales",children:"Cuellos de Botella Fundamentales"}),"\n",(0,s.jsx)(a.p,{children:"En ultima instancia, los metodos tradicionales enfrentan dos cuellos de botella principales:"}),"\n",(0,s.jsx)(a.h4,{id:"1-problema-de-evaluacion",children:"1. Problema de Evaluacion"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"No hay una buena funcion de evaluacion"}),"\n",(0,s.jsx)(a.li,{children:'No se pueden cuantificar conceptos abstractos como "grosor" e "influencia"'}),"\n",(0,s.jsx)(a.li,{children:"Las caracteristicas manuales no son lo suficientemente expresivas"}),"\n"]}),"\n",(0,s.jsx)(a.h4,{id:"2-problema-de-busqueda",children:"2. Problema de Busqueda"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Incluso con poda, el espacio de busqueda sigue siendo demasiado grande"}),"\n",(0,s.jsx)(a.li,{children:"No se pueden ver variaciones lo suficientemente profundas"}),"\n",(0,s.jsx)(a.li,{children:"La calidad de simulacion afecta la precision de la estimacion"}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"la-solucion-de-alphago",children:"La Solucion de AlphaGo"}),"\n",(0,s.jsx)(a.p,{children:"AlphaGo uso el aprendizaje profundo para resolver ambos problemas:"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Policy Network"}),': Aprende "donde podria ser una buena jugada", reduciendo el factor de ramificacion efectivo']}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Value Network"}),': Aprende "quien tiene mas probabilidad de ganar", reemplazando la funcion de evaluacion manual']}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Integracion MCTS"}),": Usa redes neuronales para guiar la busqueda, usa la busqueda para mejorar las decisiones"]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:'Esto no es simplemente "usar una red neuronal para reemplazar la funcion de evaluacion", sino una arquitectura completamente nueva.'}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"correspondencia-con-animaciones",children:"Correspondencia con Animaciones"}),"\n",(0,s.jsx)(a.p,{children:"Conceptos centrales cubiertos en este articulo y numeros de animacion:"}),"\n",(0,s.jsxs)(a.table,{children:[(0,s.jsx)(a.thead,{children:(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.th,{children:"Numero"}),(0,s.jsx)(a.th,{children:"Concepto"}),(0,s.jsx)(a.th,{children:"Correspondencia Fisica/Matematica"})]})}),(0,s.jsxs)(a.tbody,{children:[(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"\ud83c\udfac B3"}),(0,s.jsx)(a.td,{children:"Busqueda Minimax"}),(0,s.jsx)(a.td,{children:"Teoria de juegos, juegos de suma cero"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"\ud83c\udfac C5"}),(0,s.jsx)(a.td,{children:"Cuatro fases de MCTS"}),(0,s.jsx)(a.td,{children:"Metodos de Monte Carlo, UCB"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"\ud83c\udfac C2"}),(0,s.jsx)(a.td,{children:"Formula UCB1"}),(0,s.jsx)(a.td,{children:"Bandidos multibrazo, equilibrio exploracion-explotacion"})]}),(0,s.jsxs)(a.tr,{children:[(0,s.jsx)(a.td,{children:"\ud83c\udfac C4"}),(0,s.jsx)(a.td,{children:"Crecimiento del arbol de busqueda"}),(0,s.jsx)(a.td,{children:"Expansion progresiva"})]})]})]}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"lecturas-adicionales",children:"Lecturas Adicionales"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Articulo anterior"}),": ",(0,s.jsx)(a.a,{href:"../why-go-is-hard",children:"\xbfPor que es dificil el Go?"})," - Espacio de estados y dificultad de evaluacion"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Articulo siguiente"}),": ",(0,s.jsx)(a.a,{href:"../board-representation",children:"Representacion del Estado del Tablero"})," - Zobrist Hashing, codificacion de caracteristicas"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.strong,{children:"Profundizacion tecnica"}),": ",(0,s.jsx)(a.a,{href:"../mcts-neural-combo",children:"La combinacion de MCTS y redes neuronales"})," - La arquitectura central de AlphaGo"]}),"\n"]}),"\n",(0,s.jsx)(a.hr,{}),"\n",(0,s.jsx)(a.h2,{id:"referencias",children:"Referencias"}),"\n",(0,s.jsxs)(a.ol,{children:["\n",(0,s.jsxs)(a.li,{children:['Coulom, R. (2006). "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search." ',(0,s.jsx)(a.em,{children:"Computers and Games"}),", 72-83. - El articulo original de MCTS"]}),"\n",(0,s.jsxs)(a.li,{children:['Kocsis, L., & Szepesvari, C. (2006). "Bandit based Monte-Carlo Planning." ',(0,s.jsx)(a.em,{children:"ECML"}),", 282-293. - Algoritmo UCT"]}),"\n",(0,s.jsxs)(a.li,{children:['Browne, C., et al. (2012). "A Survey of Monte Carlo Tree Search Methods." ',(0,s.jsx)(a.em,{children:"IEEE TCIAIG"}),", 4(1), 1-43. - Revision de MCTS"]}),"\n",(0,s.jsxs)(a.li,{children:['Gelly, S., & Silver, D. (2011). "Monte-Carlo tree search and rapid action value estimation in computer Go." ',(0,s.jsx)(a.em,{children:"Artificial Intelligence"}),", 175(11), 1856-1875. - Aplicacion de MCTS en Go"]}),"\n"]})]})}function m(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},42948(e,a,n){n.d(a,{A:()=>t});n(59471);var i=n(61785),s=n(62615);function t({children:e,fallback:a}){return(0,i.A)()?(0,s.jsx)(s.Fragment,{children:e?.()}):a??null}},45695(e,a,n){n.d(a,{$W:()=>_,tO:()=>r,u8:()=>v,dW:()=>p});var i=n(59471),s=n(90989),t=n(62615);const l=19,o=[[3,3],[3,9],[3,15],[9,3],[9,9],[9,15],[15,3],[15,9],[15,15]];function r({size:e=400,stones:a=[],highlights:n=[],labels:r=[],onCellClick:d=null,showCoordinates:c=!0}){const u=(0,i.useRef)(null),m=c?30:15,h=e-2*m,p=h/18;return(0,i.useEffect)(()=>{if(!u.current)return;const e=s.Ltv(u.current);e.selectAll("*").remove();const i=e.append("g").attr("transform",`translate(${m}, ${m})`);i.append("rect").attr("x",-p/2).attr("y",-p/2).attr("width",h+p).attr("height",h+p).attr("fill","#dcb35c").attr("rx",4);const t=i.append("g").attr("class","grid");for(let a=0;a<l;a++)t.append("line").attr("class","grid-line").attr("x1",0).attr("y1",a*p).attr("x2",18*p).attr("y2",a*p);for(let a=0;a<l;a++)t.append("line").attr("class","grid-line").attr("x1",a*p).attr("y1",0).attr("x2",a*p).attr("y2",18*p);const x=i.append("g").attr("class","star-points");if(o.forEach(([e,a])=>{x.append("circle").attr("class","star-point").attr("cx",e*p).attr("cy",a*p).attr("r",p/8)}),n.length>0){const e=i.append("g").attr("class","highlights");n.forEach(({x:a,y:n,intensity:i})=>{e.append("rect").attr("class","heatmap-cell").attr("x",a*p-p/2).attr("y",n*p-p/2).attr("width",p).attr("height",p).attr("fill",s.Q3(i)).attr("opacity",.7*i)})}const j=i.append("g").attr("class","stones");if(a.forEach(({x:e,y:a,color:n})=>{const i="black"===n?"stone-black":"stone-white";j.append("circle").attr("cx",e*p+2).attr("cy",a*p+2).attr("r",.45*p).attr("fill","rgba(0,0,0,0.2)"),j.append("circle").attr("class",i).attr("cx",e*p).attr("cy",a*p).attr("r",.45*p)}),r.length>0){const e=i.append("g").attr("class","labels");r.forEach(({x:n,y:i,text:s})=>{const t=a.find(e=>e.x===n&&e.y===i),l="black"===t?.color?"#fff":"#000";e.append("text").attr("x",n*p).attr("y",i*p).attr("dy","0.35em").attr("text-anchor","middle").attr("fill",l).attr("font-size",.5*p).attr("font-weight","bold").text(s)})}if(c){const a=e.append("g").attr("class","coordinates"),n="ABCDEFGHJKLMNOPQRST";for(let e=0;e<l;e++)a.append("text").attr("x",m+e*p).attr("y",m/2).attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(n[e]);for(let e=0;e<l;e++)a.append("text").attr("x",m/2).attr("y",m+e*p).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(l-e)}d&&i.append("g").attr("class","click-targets").selectAll("rect").data(s.y17(361)).enter().append("rect").attr("x",e=>e%l*p-p/2).attr("y",e=>Math.floor(e/l)*p-p/2).attr("width",p).attr("height",p).attr("fill","transparent").attr("cursor","pointer").on("click",(e,a)=>{const n=a%l,i=Math.floor(a/l);d({x:n,y:i})})},[e,a,n,r,c,d,p,m,h]),(0,t.jsx)("div",{className:"go-board-container",children:(0,t.jsx)("svg",{ref:u,width:e,height:e,className:"go-board"})})}var d=n(42948);const c=19,u={empty:function(){const e=[];for(let a=0;a<c;a++)for(let n=0;n<c;n++)e.push({x:n,y:a,prob:1/361});return e}(),corner:function(){const e=[],a=[[3,3],[3,15],[15,3],[15,15]],n=[[2,4],[4,2],[2,14],[4,16],[14,2],[16,4],[14,16],[16,14]];for(let i=0;i<c;i++)for(let s=0;s<c;s++){let t=.001;a.some(([e,a])=>e===s&&a===i)?t=.15:n.some(([e,a])=>e===s&&a===i)?t=.05:0!==s&&18!==s&&0!==i&&18!==i||(t=5e-4),e.push({x:s,y:i,prob:t})}return m(e)}(),move37:function(){const e=[],a={x:9,y:4},n=[[3,2],[15,2],[10,10],[8,6]];for(let i=0;i<c;i++)for(let s=0;s<c;s++){let t=.001;s===a.x&&i===a.y?t=.08:n.some(([e,a])=>e===s&&a===i)?t=.12:s>=5&&s<=13&&i>=5&&i<=13&&(t=.005+.01*Math.random()),e.push({x:s,y:i,prob:t})}return m(e)}()};function m(e){const a=e.reduce((e,a)=>e+a.prob,0);return e.map(e=>({...e,prob:e.prob/a}))}function h({initialPosition:e="corner",stones:a=[],highlightMoves:n=[],size:l=450,showTopN:o=5,interactive:r=!0}){const d=(0,i.useRef)(null),m=(0,i.useRef)(null),[h,p]=(0,i.useState)(u[e]||u.corner),[x,j]=(0,i.useState)(null),v=35,g=l-70,f=g/18;(0,i.useEffect)(()=>{if(!d.current)return;const e=s.Ltv(d.current);e.selectAll("*").remove();const n=e.append("g").attr("transform","translate(35, 35)");n.append("rect").attr("x",-f/2).attr("y",-f/2).attr("width",g+f).attr("height",g+f).attr("fill","#dcb35c").attr("rx",4);const i=Math.max(...h.map(e=>e.prob)),t=s.exT(s.oKI).domain([0,i]);n.append("g").attr("class","heatmap").selectAll("rect").data(h).enter().append("rect").attr("class","heatmap-cell").attr("x",e=>e.x*f-f/2).attr("y",e=>e.y*f-f/2).attr("width",f).attr("height",f).attr("fill",e=>t(e.prob)).attr("opacity",e=>.3+e.prob/i*.6).attr("cursor",r?"pointer":"default").on("mouseover",function(e,a){if(!r)return;s.Ltv(this).attr("stroke","#333").attr("stroke-width",2);s.Ltv(m.current).style("display","block").style("left",`${e.pageX+10}px`).style("top",e.pageY-10+"px").html(`\u4f4d\u7f6e: ${String.fromCharCode(65+a.x)}${19-a.y}<br>\u6a5f\u7387: ${(100*a.prob).toFixed(2)}%`)}).on("mouseout",function(){s.Ltv(this).attr("stroke","none"),s.Ltv(m.current).style("display","none")}).on("click",function(e,a){r&&j(a)});const l=n.append("g").attr("class","grid");for(let a=0;a<c;a++)l.append("line").attr("class","grid-line").attr("x1",0).attr("y1",a*f).attr("x2",18*f).attr("y2",a*f).attr("stroke","#333").attr("stroke-width",.5).attr("opacity",.5),l.append("line").attr("class","grid-line").attr("x1",a*f).attr("y1",0).attr("x2",a*f).attr("y2",18*f).attr("stroke","#333").attr("stroke-width",.5).attr("opacity",.5);const u=n.append("g").attr("class","stones");a.forEach(({x:e,y:a,color:n})=>{u.append("circle").attr("cx",e*f).attr("cy",a*f).attr("r",.45*f).attr("fill","black"===n?"#1a1a1a":"#f5f5f5").attr("stroke","black"===n?"#000":"#333").attr("stroke-width",1)});const p=[...h].sort((e,a)=>a.prob-e.prob).slice(0,o),x=n.append("g").attr("class","top-labels");p.forEach((e,n)=>{a.some(a=>a.x===e.x&&a.y===e.y)||(x.append("circle").attr("cx",e.x*f).attr("cy",e.y*f).attr("r",.3*f).attr("fill","rgba(255,255,255,0.8)").attr("stroke","#e74c3c").attr("stroke-width",2),x.append("text").attr("x",e.x*f).attr("y",e.y*f).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#e74c3c").attr("font-size",.4*f).attr("font-weight","bold").text(n+1))});const b=e.append("g").attr("class","coordinates");for(let a=0;a<c;a++)b.append("text").attr("x",v+a*f).attr("y",17.5).attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text("ABCDEFGHJKLMNOPQRST"[a]),b.append("text").attr("x",17.5).attr("y",v+a*f).attr("dy","0.35em").attr("text-anchor","middle").attr("fill","#666").attr("font-size",10).text(c-a)},[h,a,o,r,f,v,g]);const b=e=>{p(u[e]||u.corner)};return(0,t.jsxs)("div",{children:[r&&(0,t.jsxs)("div",{className:"d3-controls",children:[(0,t.jsx)("button",{className:"empty"===e?"active":"",onClick:()=>b("empty"),children:"\u5747\u52fb\u5206\u5e03"}),(0,t.jsx)("button",{className:"corner"===e?"active":"",onClick:()=>b("corner"),children:"\u958b\u5c40\u661f\u4f4d"}),(0,t.jsx)("button",{className:"move37"===e?"active":"",onClick:()=>b("move37"),children:"\u7b2c 37 \u624b"})]}),(0,t.jsx)("div",{className:"go-board-container",children:(0,t.jsx)("svg",{ref:d,width:l,height:l,className:"go-board"})}),(0,t.jsx)("div",{ref:m,className:"d3-tooltip",style:{display:"none",position:"fixed"}}),x&&(0,t.jsx)("div",{className:"d3-legend",children:(0,t.jsxs)("div",{className:"d3-legend-item",children:["\u5df2\u9078\u64c7: ",String.fromCharCode(65+x.x),19-x.y,"\u2014 \u6a5f\u7387: ",(100*x.prob).toFixed(2),"%"]})}),(0,t.jsxs)("div",{className:"d3-legend",children:[(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#ffffb2"}}),"\u4f4e\u6a5f\u7387"]}),(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#fd8d3c"}}),"\u4e2d\u6a5f\u7387"]}),(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#bd0026"}}),"\u9ad8\u6a5f\u7387"]})]})]})}function p(e){return(0,t.jsx)(d.A,{fallback:(0,t.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,t.jsx)(h,{...e})})}const x={name:"Root",visits:1600,value:.55,prior:1,children:[{name:"D4",visits:800,value:.62,prior:.35,selected:!0,children:[{name:"Q16",visits:400,value:.58,prior:.3},{name:"R4",visits:300,value:.65,prior:.25,selected:!0},{name:"C16",visits:100,value:.55,prior:.2}]},{name:"Q4",visits:500,value:.52,prior:.3,children:[{name:"D16",visits:300,value:.5,prior:.28},{name:"Q16",visits:200,value:.54,prior:.22}]},{name:"D16",visits:200,value:.48,prior:.2},{name:"Q16",visits:100,value:.45,prior:.15}]};function j({data:e=x,width:a=700,height:n=450,showPUCT:l=!0,cPuct:o=1.5,interactive:r=!0}){const d=(0,i.useRef)(null),c=(0,i.useRef)(null),[u,m]=(0,i.useState)(null),[h,p]=(0,i.useState)(o),j=40,v=40,g=a-v-40,f=n-j-40;return(0,i.useEffect)(()=>{if(!d.current)return;const i=s.Ltv(d.current);i.selectAll("*").remove();const t=s.B22().size([g,f-50]),o=s.Sk5(e);t(o);const u=i.append("g").attr("transform",`translate(${v}, ${j})`);u.append("g").attr("class","links").selectAll("path").data(o.links()).enter().append("path").attr("class",e=>"link "+(e.target.data.selected?"selected":"")).attr("fill","none").attr("stroke",e=>e.target.data.selected?"#4a90d9":"#999").attr("stroke-width",e=>e.target.data.selected?3:1.5).attr("d",s.vu().x(e=>e.x).y(e=>e.y));const p=u.append("g").attr("class","nodes").selectAll("g").data(o.descendants()).enter().append("g").attr("class","node").attr("transform",e=>`translate(${e.x}, ${e.y})`).attr("cursor",r?"pointer":"default").on("mouseover",function(e,a){if(!r)return;s.Ltv(this).select("circle").transition().duration(200).attr("r",30);const n=a.parent?a.parent.data.visits:a.data.visits,i=((e,a)=>{if(!a)return 0;const n=e.value,i=e.prior,s=e.visits;return n+h*i*Math.sqrt(a)/(1+s)})(a.data,n);s.Ltv(c.current).style("display","block").style("left",`${e.pageX+15}px`).style("top",e.pageY-10+"px").html(`\n            <strong>${a.data.name}</strong><br>\n            \u8a2a\u554f\u6b21\u6578 (N): ${a.data.visits}<br>\n            \u5e73\u5747\u50f9\u503c (Q): ${a.data.value.toFixed(3)}<br>\n            \u5148\u9a57\u6a5f\u7387 (P): ${(100*a.data.prior).toFixed(1)}%<br>\n            ${l?`PUCT \u5206\u6578: ${i.toFixed(3)}`:""}\n          `)}).on("mouseout",function(){s.Ltv(this).select("circle").transition().duration(200).attr("r",25),s.Ltv(c.current).style("display","none")}).on("click",function(e,a){r&&m(a.data)});p.append("circle").attr("r",25).attr("fill",e=>e.data.selected?"#4a90d9":"#fff").attr("stroke",a=>{if(a.data.selected)return"#2c5282";const n=a.data.visits/e.visits;return s.dM(.3+.5*n)}).attr("stroke-width",e=>e.data.selected?3:2),p.append("text").attr("dy",-5).attr("text-anchor","middle").attr("fill",e=>e.data.selected?"#fff":"#333").attr("font-size",11).attr("font-weight","bold").text(e=>e.data.name),p.append("text").attr("dy",10).attr("text-anchor","middle").attr("fill",e=>e.data.selected?"#fff":"#666").attr("font-size",9).text(e=>`N=${e.data.visits}`),i.append("text").attr("x",a/2).attr("y",20).attr("text-anchor","middle").attr("font-size",14).attr("font-weight","bold").attr("fill","#333").text("MCTS \u641c\u7d22\u6a39"),l&&i.append("text").attr("x",a/2).attr("y",n-10).attr("text-anchor","middle").attr("font-size",11).attr("fill","#666").text("\u85cd\u8272\u8def\u5f91\uff1aPUCT \u9078\u64c7\u7684\u6700\u4f73\u8def\u5f91")},[e,a,n,l,h,r,g,f]),(0,t.jsxs)("div",{children:[l&&r&&(0,t.jsx)("div",{className:"d3-controls",children:(0,t.jsxs)("div",{className:"d3-slider",children:[(0,t.jsxs)("label",{children:["c_puct: ",h.toFixed(1)]}),(0,t.jsx)("input",{type:"range",min:"0.5",max:"3",step:"0.1",value:h,onChange:e=>p(parseFloat(e.target.value))})]})}),(0,t.jsx)("div",{className:"mcts-tree-container",children:(0,t.jsx)("svg",{ref:d,width:a,height:n,className:"mcts-tree"})}),(0,t.jsx)("div",{ref:c,className:"d3-tooltip",style:{display:"none",position:"fixed"}}),u&&(0,t.jsxs)("div",{className:"d3-legend",style:{background:"#f5f5f5",padding:"1rem",borderRadius:"4px"},children:[(0,t.jsxs)("strong",{children:["\u5df2\u9078\u64c7\u7bc0\u9ede: ",u.name]}),(0,t.jsxs)("div",{children:["\u8a2a\u554f\u6b21\u6578: ",u.visits]}),(0,t.jsxs)("div",{children:["\u5e73\u5747\u50f9\u503c: ",u.value.toFixed(3)]}),(0,t.jsxs)("div",{children:["\u5148\u9a57\u6a5f\u7387: ",(100*u.prior).toFixed(1),"%"]})]}),(0,t.jsxs)("div",{className:"d3-legend",children:[(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#4a90d9"}}),"\u9078\u4e2d\u8def\u5f91"]}),(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#fff",border:"2px solid #999"}}),"\u5176\u4ed6\u7bc0\u9ede"]}),(0,t.jsx)("div",{className:"d3-legend-item",children:(0,t.jsx)("span",{style:{fontSize:"12px"},children:"\u7bc0\u9ede\u5927\u5c0f \u221d \u8a2a\u554f\u6b21\u6578"})})]})]})}function v(e){return(0,t.jsx)(d.A,{fallback:(0,t.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,t.jsx)(j,{...e})})}const g=[{hours:0,elo:0,label:"\u96a8\u6a5f"},{hours:3,elo:1e3,label:"\u767c\u73fe\u898f\u5247"},{hours:6,elo:2e3},{hours:12,elo:3e3,label:"\u767c\u73fe\u5b9a\u5f0f"},{hours:24,elo:4e3},{hours:36,elo:4500,label:"\u8d85\u8d8a Fan Hui"},{hours:48,elo:5e3},{hours:60,elo:5200,label:"\u8d85\u8d8a Lee Sedol"},{hours:72,elo:5400,label:"\u8d85\u8d8a\u539f\u7248 AlphaGo"}],f=[{elo:2700,label:"\u696d\u9918\u5f37\u8c6a"},{elo:3500,label:"Fan Hui (\u8077\u696d\u4e8c\u6bb5)"},{elo:4500,label:"Lee Sedol (\u4e16\u754c\u51a0\u8ecd)"},{elo:5e3,label:"\u539f\u7248 AlphaGo"}],b=[{epochs:0,elo:0},{epochs:10,elo:1500},{epochs:20,elo:2500},{epochs:30,elo:3e3},{epochs:40,elo:3200},{epochs:50,elo:3300}],y=[{games:0,elo:3300},{games:1e3,elo:3800},{games:5e3,elo:4200},{games:1e4,elo:4500},{games:5e4,elo:4800},{games:1e5,elo:5e3}];function C({mode:e="zero",width:a=600,height:n=400,animated:l=!0,showMilestones:o=!0}){const r=(0,i.useRef)(null),[d,c]=(0,i.useState)(e),u=40,m=70,h=a-m-100,p=n-u-60;return(0,i.useEffect)(()=>{if(!r.current)return;const e=s.Ltv(r.current);let n,i,t;e.selectAll("*").remove(),"zero"===d?(n=g,i="\u8a13\u7df4\u6642\u9593\uff08\u5c0f\u6642\uff09",t=[0,80]):"sl"===d?(n=b,i="\u8a13\u7df4\u8f2a\u6578\uff08Epochs\uff09",t=[0,60]):(n=y,i="\u81ea\u6211\u5c0d\u5f08\u5c40\u6578",t=[0,12e4]);const c="selfplay"===d?s.ZEH().domain([1,t[1]]).range([0,h]):s.m4Y().domain(t).range([0,h]),x=s.m4Y().domain([0,6e3]).range([p,0]),j=e.append("g").attr("transform",`translate(${m}, ${u})`);if(j.append("g").attr("class","grid").selectAll(".grid-line-y").data(x.ticks(6)).enter().append("line").attr("class","grid-line-y").attr("x1",0).attr("x2",h).attr("y1",e=>x(e)).attr("y2",e=>x(e)).attr("stroke","#ddd").attr("stroke-dasharray","3,3"),o&&"zero"===d){const e=j.append("g").attr("class","human-levels");f.forEach(a=>{e.append("line").attr("x1",0).attr("x2",h).attr("y1",x(a.elo)).attr("y2",x(a.elo)).attr("stroke","#e74c3c").attr("stroke-dasharray","5,5").attr("opacity",.6),e.append("text").attr("x",h+5).attr("y",x(a.elo)).attr("dy","0.35em").attr("fill","#e74c3c").attr("font-size",10).text(a.label)})}const v=s.n8j().x(e=>c("zero"===d?e.hours:"sl"===d?e.epochs:Math.max(1,e.games))).y(e=>x(e.elo)).curve(s.nVG),C=s.Wcw().x(e=>c("zero"===d?e.hours:"sl"===d?e.epochs:Math.max(1,e.games))).y0(p).y1(e=>x(e.elo)).curve(s.nVG);j.append("path").datum(n).attr("class","area").attr("fill","#4a90d9").attr("opacity",.1).attr("d",C);const _=j.append("path").datum(n).attr("class","line").attr("fill","none").attr("stroke","#4a90d9").attr("stroke-width",3).attr("d",v);if(l){const e=_.node().getTotalLength();_.attr("stroke-dasharray",`${e} ${e}`).attr("stroke-dashoffset",e).transition().duration(2e3).ease(s.yfw).attr("stroke-dashoffset",0)}if(o&&"zero"===d){const e=n.filter(e=>e.label),a=j.append("g").attr("class","milestones");a.selectAll("circle").data(e).enter().append("circle").attr("cx",e=>c(e.hours)).attr("cy",e=>x(e.elo)).attr("r",6).attr("fill","#e74c3c").attr("stroke","#fff").attr("stroke-width",2),a.selectAll("text").data(e).enter().append("text").attr("x",e=>c(e.hours)).attr("y",e=>x(e.elo)-15).attr("text-anchor","middle").attr("fill","#333").attr("font-size",10).text(e=>e.label)}const M="selfplay"===d?s.l78(c).ticks(5,"~s"):s.l78(c);j.append("g").attr("class","x-axis").attr("transform",`translate(0, ${p})`).call(M),j.append("text").attr("class","axis-label").attr("x",h/2).attr("y",p+45).attr("text-anchor","middle").attr("fill","#666").text(i),j.append("g").attr("class","y-axis").call(s.V4s(x).ticks(6)),j.append("text").attr("class","axis-label").attr("transform","rotate(-90)").attr("x",-p/2).attr("y",-50).attr("text-anchor","middle").attr("fill","#666").text("ELO \u8a55\u5206"),e.append("text").attr("x",a/2).attr("y",20).attr("text-anchor","middle").attr("font-size",14).attr("font-weight","bold").attr("fill","#333").text("zero"===d?"AlphaGo Zero \u8a13\u7df4\u66f2\u7dda":"sl"===d?"\u76e3\u7763\u5b78\u7fd2\u68cb\u529b\u6210\u9577":"\u81ea\u6211\u5c0d\u5f08\u68cb\u529b\u6210\u9577")},[d,a,n,l,o,h,p]),(0,t.jsxs)("div",{children:[(0,t.jsxs)("div",{className:"d3-controls",children:[(0,t.jsx)("button",{className:"zero"===d?"active":"",onClick:()=>c("zero"),children:"AlphaGo Zero"}),(0,t.jsx)("button",{className:"sl"===d?"active":"",onClick:()=>c("sl"),children:"\u76e3\u7763\u5b78\u7fd2"}),(0,t.jsx)("button",{className:"selfplay"===d?"active":"",onClick:()=>c("selfplay"),children:"\u81ea\u6211\u5c0d\u5f08"})]}),(0,t.jsx)("div",{className:"elo-chart-container",children:(0,t.jsx)("svg",{ref:r,width:a,height:n,className:"elo-chart"})}),(0,t.jsxs)("div",{className:"d3-legend",children:[(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#4a90d9"}}),"ELO \u8a55\u5206"]}),o&&"zero"===d&&(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#e74c3c"}}),"\u91cc\u7a0b\u7891"]}),(0,t.jsxs)("div",{className:"d3-legend-item",children:[(0,t.jsx)("div",{className:"d3-legend-color",style:{background:"#e74c3c",opacity:.3}}),"\u4eba\u985e\u6c34\u5e73\u53c3\u8003\u7dda"]})]})]})]})}function _(e){return(0,t.jsx)(d.A,{fallback:(0,t.jsx)("div",{children:"\u8f09\u5165\u4e2d..."}),children:()=>(0,t.jsx)(C,{...e})})}},30416(e,a,n){n.d(a,{R:()=>l,x:()=>o});var i=n(59471);const s={},t=i.createContext(s);function l(e){const a=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(t.Provider,{value:a},e.children)}}}]);