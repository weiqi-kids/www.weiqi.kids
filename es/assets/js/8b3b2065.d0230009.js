"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[5039],{28271(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>p,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"for-engineers/deep-dive/quantization-deploy","title":"Cuantizaci\xf3n y despliegue de modelos","description":"T\xe9cnicas de cuantizaci\xf3n de modelos KataGo, formatos de exportaci\xf3n y soluciones de despliegue multiplataforma","source":"@site/i18n/es/docusaurus-plugin-content-docs/current/for-engineers/deep-dive/quantization-deploy.md","sourceDirName":"for-engineers/deep-dive","slug":"/for-engineers/deep-dive/quantization-deploy","permalink":"/es/docs/for-engineers/deep-dive/quantization-deploy","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/deep-dive/quantization-deploy.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Cuantizaci\xf3n y despliegue de modelos","description":"T\xe9cnicas de cuantizaci\xf3n de modelos KataGo, formatos de exportaci\xf3n y soluciones de despliegue multiplataforma"},"sidebar":"tutorialSidebar","previous":{"title":"Arquitectura de entrenamiento distribuido","permalink":"/es/docs/for-engineers/deep-dive/distributed-training"},"next":{"title":"Evaluaci\xf3n y benchmarking","permalink":"/es/docs/for-engineers/deep-dive/evaluation"}}');var a=i(62615),r=i(30416);const t={sidebar_position:8,title:"Cuantizaci\xf3n y despliegue de modelos",description:"T\xe9cnicas de cuantizaci\xf3n de modelos KataGo, formatos de exportaci\xf3n y soluciones de despliegue multiplataforma"},d="Cuantizaci\xf3n y despliegue de modelos",o={},l=[{value:"Visi\xf3n general de t\xe9cnicas de cuantizaci\xf3n",id:"visi\xf3n-general-de-t\xe9cnicas-de-cuantizaci\xf3n",level:2},{value:"\xbfPor qu\xe9 se necesita cuantizaci\xf3n?",id:"por-qu\xe9-se-necesita-cuantizaci\xf3n",level:3},{value:"Tipos de cuantizaci\xf3n",id:"tipos-de-cuantizaci\xf3n",level:3},{value:"FP16 Media precisi\xf3n",id:"fp16-media-precisi\xf3n",level:2},{value:"Concepto",id:"concepto",level:3},{value:"Configuraci\xf3n KataGo",id:"configuraci\xf3n-katago",level:3},{value:"Impacto en el rendimiento",id:"impacto-en-el-rendimiento",level:3},{value:"Cuantizaci\xf3n INT8",id:"cuantizaci\xf3n-int8",level:2},{value:"Proceso de cuantizaci\xf3n",id:"proceso-de-cuantizaci\xf3n",level:3},{value:"Datos de calibraci\xf3n",id:"datos-de-calibraci\xf3n",level:3},{value:"Notas",id:"notas",level:3},{value:"Despliegue TensorRT",id:"despliegue-tensorrt",level:2},{value:"Proceso de conversi\xf3n",id:"proceso-de-conversi\xf3n",level:3},{value:"Usar motor TensorRT",id:"usar-motor-tensorrt",level:3},{value:"Exportaci\xf3n ONNX",id:"exportaci\xf3n-onnx",level:2},{value:"PyTorch \u2192 ONNX",id:"pytorch--onnx",level:3},{value:"Validar modelo ONNX",id:"validar-modelo-onnx",level:3},{value:"Despliegue multiplataforma",id:"despliegue-multiplataforma",level:2},{value:"Despliegue en servidor",id:"despliegue-en-servidor",level:3},{value:"Integraci\xf3n en aplicaci\xf3n de escritorio",id:"integraci\xf3n-en-aplicaci\xf3n-de-escritorio",level:3},{value:"Despliegue en dispositivos m\xf3viles",id:"despliegue-en-dispositivos-m\xf3viles",level:3},{value:"iOS (Core ML)",id:"ios-core-ml",level:4},{value:"Android (TensorFlow Lite)",id:"android-tensorflow-lite",level:4},{value:"Sistemas embebidos",id:"sistemas-embebidos",level:3},{value:"Raspberry Pi",id:"raspberry-pi",level:4},{value:"NVIDIA Jetson",id:"nvidia-jetson",level:4},{value:"Comparaci\xf3n de rendimiento",id:"comparaci\xf3n-de-rendimiento",level:2},{value:"Rendimiento de diferentes m\xe9todos de despliegue",id:"rendimiento-de-diferentes-m\xe9todos-de-despliegue",level:3},{value:"Comparaci\xf3n de tama\xf1o de modelo",id:"comparaci\xf3n-de-tama\xf1o-de-modelo",level:3},{value:"Lista de verificaci\xf3n de despliegue",id:"lista-de-verificaci\xf3n-de-despliegue",level:2},{value:"Lectura adicional",id:"lectura-adicional",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",input:"input",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"cuantizaci\xf3n-y-despliegue-de-modelos",children:"Cuantizaci\xf3n y despliegue de modelos"})}),"\n",(0,a.jsx)(n.p,{children:"Este art\xedculo presenta c\xf3mo cuantizar modelos KataGo para reducir los requisitos de recursos, as\xed como soluciones de despliegue en diversas plataformas."}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"visi\xf3n-general-de-t\xe9cnicas-de-cuantizaci\xf3n",children:"Visi\xf3n general de t\xe9cnicas de cuantizaci\xf3n"}),"\n",(0,a.jsx)(n.h3,{id:"por-qu\xe9-se-necesita-cuantizaci\xf3n",children:"\xbfPor qu\xe9 se necesita cuantizaci\xf3n?"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Precisi\xf3n"}),(0,a.jsx)(n.th,{children:"Tama\xf1o"}),(0,a.jsx)(n.th,{children:"Velocidad"}),(0,a.jsx)(n.th,{children:"P\xe9rdida de precisi\xf3n"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"FP32"}),(0,a.jsx)(n.td,{children:"100%"}),(0,a.jsx)(n.td,{children:"Base"}),(0,a.jsx)(n.td,{children:"0%"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"FP16"}),(0,a.jsx)(n.td,{children:"50%"}),(0,a.jsx)(n.td,{children:"+50%"}),(0,a.jsx)(n.td,{children:"~0%"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"INT8"}),(0,a.jsx)(n.td,{children:"25%"}),(0,a.jsx)(n.td,{children:"+100%"}),(0,a.jsx)(n.td,{children:"<1%"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"tipos-de-cuantizaci\xf3n",children:"Tipos de cuantizaci\xf3n"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Cuantizaci\xf3n post-entrenamiento (PTQ)\n\u251c\u2500\u2500 Simple y r\xe1pido\n\u251c\u2500\u2500 No requiere re-entrenamiento\n\u2514\u2500\u2500 Puede haber p\xe9rdida de precisi\xf3n\n\nEntrenamiento consciente de cuantizaci\xf3n (QAT)\n\u251c\u2500\u2500 Mayor precisi\xf3n\n\u251c\u2500\u2500 Requiere re-entrenamiento\n\u2514\u2500\u2500 M\xe1s complejo\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"fp16-media-precisi\xf3n",children:"FP16 Media precisi\xf3n"}),"\n",(0,a.jsx)(n.h3,{id:"concepto",children:"Concepto"}),"\n",(0,a.jsx)(n.p,{children:"Convertir n\xfameros de punto flotante de 32 bits a 16 bits:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Conversi\xf3n FP32 \u2192 FP16\nmodel_fp16 = model.half()\n\n# Inferencia\nwith torch.cuda.amp.autocast():\n    output = model_fp16(input.half())\n"})}),"\n",(0,a.jsx)(n.h3,{id:"configuraci\xf3n-katago",children:"Configuraci\xf3n KataGo"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ini",children:"# config.cfg\nuseFP16 = true           # Habilitar inferencia FP16\nuseFP16Storage = true    # Almacenamiento de resultados intermedios en FP16\n"})}),"\n",(0,a.jsx)(n.h3,{id:"impacto-en-el-rendimiento",children:"Impacto en el rendimiento"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Serie GPU"}),(0,a.jsx)(n.th,{children:"Aceleraci\xf3n FP16"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"GTX 10xx"}),(0,a.jsx)(n.td,{children:"Ninguna (sin Tensor Core)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"RTX 20xx"}),(0,a.jsx)(n.td,{children:"+30-50%"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"RTX 30xx"}),(0,a.jsx)(n.td,{children:"+50-80%"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"RTX 40xx"}),(0,a.jsx)(n.td,{children:"+80-100%"})]})]})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"cuantizaci\xf3n-int8",children:"Cuantizaci\xf3n INT8"}),"\n",(0,a.jsx)(n.h3,{id:"proceso-de-cuantizaci\xf3n",children:"Proceso de cuantizaci\xf3n"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import torch.quantization as quant\n\n# 1. Preparar modelo\nmodel.eval()\nmodel.qconfig = quant.get_default_qconfig('fbgemm')\n\n# 2. Preparar cuantizaci\xf3n\nmodel_prepared = quant.prepare(model)\n\n# 3. Calibrar (usar datos representativos)\nwith torch.no_grad():\n    for data in calibration_loader:\n        model_prepared(data)\n\n# 4. Convertir a modelo cuantizado\nmodel_quantized = quant.convert(model_prepared)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"datos-de-calibraci\xf3n",children:"Datos de calibraci\xf3n"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'def create_calibration_dataset(num_samples=1000):\n    """Crear dataset de calibraci\xf3n"""\n    samples = []\n\n    # Muestrear de partidas reales\n    for game in random_games(num_samples):\n        position = random_position(game)\n        features = encode_state(position)\n        samples.append(features)\n\n    return samples\n'})}),"\n",(0,a.jsx)(n.h3,{id:"notas",children:"Notas"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"La cuantizaci\xf3n INT8 requiere datos de calibraci\xf3n"}),"\n",(0,a.jsx)(n.li,{children:"Algunas capas pueden no ser adecuadas para cuantizaci\xf3n"}),"\n",(0,a.jsx)(n.li,{children:"Es necesario probar la p\xe9rdida de precisi\xf3n"}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"despliegue-tensorrt",children:"Despliegue TensorRT"}),"\n",(0,a.jsx)(n.h3,{id:"proceso-de-conversi\xf3n",children:"Proceso de conversi\xf3n"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import tensorrt as trt\n\ndef convert_to_tensorrt(onnx_path, engine_path):\n    logger = trt.Logger(trt.Logger.WARNING)\n    builder = trt.Builder(logger)\n    network = builder.create_network(\n        1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n    )\n    parser = trt.OnnxParser(network, logger)\n\n    # Parsear modelo ONNX\n    with open(onnx_path, 'rb') as f:\n        parser.parse(f.read())\n\n    # Configurar opciones de optimizaci\xf3n\n    config = builder.create_builder_config()\n    config.max_workspace_size = 1 << 30  # 1GB\n\n    # Habilitar FP16\n    config.set_flag(trt.BuilderFlag.FP16)\n\n    # Construir motor\n    engine = builder.build_engine(network, config)\n\n    # Guardar\n    with open(engine_path, 'wb') as f:\n        f.write(engine.serialize())\n"})}),"\n",(0,a.jsx)(n.h3,{id:"usar-motor-tensorrt",children:"Usar motor TensorRT"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def inference_with_tensorrt(engine_path, input_data):\n    # Cargar motor\n    with open(engine_path, 'rb') as f:\n        engine = trt.Runtime(logger).deserialize_cuda_engine(f.read())\n\n    context = engine.create_execution_context()\n\n    # Asignar memoria\n    d_input = cuda.mem_alloc(input_data.nbytes)\n    d_output = cuda.mem_alloc(output_size)\n\n    # Copiar entrada\n    cuda.memcpy_htod(d_input, input_data)\n\n    # Ejecutar inferencia\n    context.execute_v2([int(d_input), int(d_output)])\n\n    # Obtener salida\n    output = np.empty(output_shape, dtype=np.float32)\n    cuda.memcpy_dtoh(output, d_output)\n\n    return output\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"exportaci\xf3n-onnx",children:"Exportaci\xf3n ONNX"}),"\n",(0,a.jsx)(n.h3,{id:"pytorch--onnx",children:"PyTorch \u2192 ONNX"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import torch.onnx\n\ndef export_to_onnx(model, output_path):\n    model.eval()\n\n    # Crear entrada de ejemplo\n    dummy_input = torch.randn(1, 22, 19, 19)\n\n    # Exportar\n    torch.onnx.export(\n        model,\n        dummy_input,\n        output_path,\n        input_names=['input'],\n        output_names=['policy', 'value', 'ownership'],\n        dynamic_axes={\n            'input': {0: 'batch_size'},\n            'policy': {0: 'batch_size'},\n            'value': {0: 'batch_size'},\n            'ownership': {0: 'batch_size'}\n        },\n        opset_version=13\n    )\n"})}),"\n",(0,a.jsx)(n.h3,{id:"validar-modelo-onnx",children:"Validar modelo ONNX"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import onnx\nimport onnxruntime as ort\n\n# Validar estructura del modelo\nmodel = onnx.load("model.onnx")\nonnx.checker.check_model(model)\n\n# Probar inferencia\nsession = ort.InferenceSession("model.onnx")\noutput = session.run(None, {\'input\': input_data})\n'})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"despliegue-multiplataforma",children:"Despliegue multiplataforma"}),"\n",(0,a.jsx)(n.h3,{id:"despliegue-en-servidor",children:"Despliegue en servidor"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# docker-compose.yml\nversion: '3'\nservices:\n  katago:\n    image: katago/katago:latest\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n    volumes:\n      - ./models:/models\n      - ./config:/config\n    command: >\n      katago analysis\n      -model /models/kata-b18c384.bin.gz\n      -config /config/analysis.cfg\n"})}),"\n",(0,a.jsx)(n.h3,{id:"integraci\xf3n-en-aplicaci\xf3n-de-escritorio",children:"Integraci\xf3n en aplicaci\xf3n de escritorio"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Integrar KataGo en aplicaci\xf3n Python\nimport subprocess\nimport json\n\nclass KataGoProcess:\n    def __init__(self, katago_path, model_path):\n        self.process = subprocess.Popen(\n            [katago_path, 'analysis', '-model', model_path],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            text=True\n        )\n\n    def analyze(self, moves):\n        query = {\n            'id': 'query1',\n            'moves': moves,\n            'rules': 'chinese',\n            'komi': 7.5,\n            'boardXSize': 19,\n            'boardYSize': 19\n        }\n        self.process.stdin.write(json.dumps(query) + '\\n')\n        self.process.stdin.flush()\n\n        response = self.process.stdout.readline()\n        return json.loads(response)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"despliegue-en-dispositivos-m\xf3viles",children:"Despliegue en dispositivos m\xf3viles"}),"\n",(0,a.jsx)(n.h4,{id:"ios-core-ml",children:"iOS (Core ML)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import coremltools as ct\n\n# Convertir a Core ML\nmlmodel = ct.convert(\n    model,\n    inputs=[ct.TensorType(shape=(1, 22, 19, 19))],\n    minimum_deployment_target=ct.target.iOS15\n)\n\nmlmodel.save("KataGo.mlmodel")\n'})}),"\n",(0,a.jsx)(n.h4,{id:"android-tensorflow-lite",children:"Android (TensorFlow Lite)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import tensorflow as tf\n\n# Convertir a TFLite\nconverter = tf.lite.TFLiteConverter.from_saved_model(model_path)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.target_spec.supported_types = [tf.float16]\n\ntflite_model = converter.convert()\n\nwith open('katago.tflite', 'wb') as f:\n    f.write(tflite_model)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"sistemas-embebidos",children:"Sistemas embebidos"}),"\n",(0,a.jsx)(n.h4,{id:"raspberry-pi",children:"Raspberry Pi"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Usar backend Eigen (solo CPU)\n./katago gtp -model kata-b10c128.bin.gz -config rpi.cfg\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ini",children:"# rpi.cfg - Configuraci\xf3n optimizada para Raspberry Pi\nnumSearchThreads = 4\nmaxVisits = 100\nnnMaxBatchSize = 1\n"})}),"\n",(0,a.jsx)(n.h4,{id:"nvidia-jetson",children:"NVIDIA Jetson"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Usar backend CUDA\n./katago gtp -model kata-b18c384.bin.gz -config jetson.cfg\n"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"comparaci\xf3n-de-rendimiento",children:"Comparaci\xf3n de rendimiento"}),"\n",(0,a.jsx)(n.h3,{id:"rendimiento-de-diferentes-m\xe9todos-de-despliegue",children:"Rendimiento de diferentes m\xe9todos de despliegue"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"M\xe9todo de despliegue"}),(0,a.jsx)(n.th,{children:"Hardware"}),(0,a.jsx)(n.th,{children:"Playouts/seg"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"CUDA FP32"}),(0,a.jsx)(n.td,{children:"RTX 3080"}),(0,a.jsx)(n.td,{children:"~3000"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"CUDA FP16"}),(0,a.jsx)(n.td,{children:"RTX 3080"}),(0,a.jsx)(n.td,{children:"~5000"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"TensorRT FP16"}),(0,a.jsx)(n.td,{children:"RTX 3080"}),(0,a.jsx)(n.td,{children:"~6500"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"OpenCL"}),(0,a.jsx)(n.td,{children:"M1 Pro"}),(0,a.jsx)(n.td,{children:"~1500"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Core ML"}),(0,a.jsx)(n.td,{children:"M1 Pro"}),(0,a.jsx)(n.td,{children:"~1800"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"TFLite"}),(0,a.jsx)(n.td,{children:"Pixel 7"}),(0,a.jsx)(n.td,{children:"~50"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Eigen"}),(0,a.jsx)(n.td,{children:"RPi 4"}),(0,a.jsx)(n.td,{children:"~15"})]})]})]}),"\n",(0,a.jsx)(n.h3,{id:"comparaci\xf3n-de-tama\xf1o-de-modelo",children:"Comparaci\xf3n de tama\xf1o de modelo"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Formato"}),(0,a.jsx)(n.th,{children:"Tama\xf1o b18c384"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Original (.bin.gz)"}),(0,a.jsx)(n.td,{children:"~140 MB"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"ONNX FP32"}),(0,a.jsx)(n.td,{children:"~280 MB"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"ONNX FP16"}),(0,a.jsx)(n.td,{children:"~140 MB"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"TensorRT FP16"}),(0,a.jsx)(n.td,{children:"~100 MB"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"TFLite FP16"}),(0,a.jsx)(n.td,{children:"~140 MB"})]})]})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"lista-de-verificaci\xf3n-de-despliegue",children:"Lista de verificaci\xf3n de despliegue"}),"\n",(0,a.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Elegir la precisi\xf3n de cuantizaci\xf3n adecuada"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Preparar datos de calibraci\xf3n (INT8)"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Exportar al formato objetivo"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Verificar que la p\xe9rdida de precisi\xf3n es aceptable"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Probar el rendimiento en la plataforma objetivo"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Optimizar el uso de memoria"]}),"\n",(0,a.jsxs)(n.li,{className:"task-list-item",children:[(0,a.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Establecer flujo de despliegue automatizado"]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"lectura-adicional",children:"Lectura adicional"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"../gpu-optimization",children:"Backend GPU y optimizaci\xf3n"})," \u2014 Optimizaci\xf3n b\xe1sica de rendimiento"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"../evaluation",children:"Evaluaci\xf3n y benchmarking"})," \u2014 Verificar rendimiento post-despliegue"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"../../hands-on/integration",children:"Integraci\xf3n en tu proyecto"})," \u2014 Ejemplos de integraci\xf3n de API"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},30416(e,n,i){i.d(n,{R:()=>t,x:()=>d});var s=i(59471);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);