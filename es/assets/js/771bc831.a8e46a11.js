"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[3421],{36431(e,n,s){s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"alphago/distributed-systems","title":"Sistemas distribuidos y TPU","description":"An\xe1lisis profundo de la arquitectura de entrenamiento distribuido de AlphaGo, aceleraci\xf3n con TPU y MCTS paralelo a gran escala","source":"@site/i18n/es/docusaurus-plugin-content-docs/current/alphago/19-distributed-systems.mdx","sourceDirName":"alphago","slug":"/alphago/distributed-systems","permalink":"/es/docs/alphago/distributed-systems","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/19-distributed-systems.mdx","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20,"title":"Sistemas distribuidos y TPU","description":"An\xe1lisis profundo de la arquitectura de entrenamiento distribuido de AlphaGo, aceleraci\xf3n con TPU y MCTS paralelo a gran escala","keywords":["sistemas distribuidos","TPU","computaci\xf3n paralela","MCTS","virtual loss","deep learning","aceleraci\xf3n de hardware"]},"sidebar":"tutorialSidebar","previous":{"title":"El proceso de entrenamiento desde cero","permalink":"/es/docs/alphago/training-from-scratch"},"next":{"title":"El legado de AlphaGo","permalink":"/es/docs/alphago/legacy-and-impact"}}');var r=s(62615),i=s(30416);const l={sidebar_position:20,title:"Sistemas distribuidos y TPU",description:"An\xe1lisis profundo de la arquitectura de entrenamiento distribuido de AlphaGo, aceleraci\xf3n con TPU y MCTS paralelo a gran escala",keywords:["sistemas distribuidos","TPU","computaci\xf3n paralela","MCTS","virtual loss","deep learning","aceleraci\xf3n de hardware"]},d="Sistemas distribuidos y TPU",t={},c=[{value:"Visi\xf3n general de la arquitectura de entrenamiento",id:"visi\xf3n-general-de-la-arquitectura-de-entrenamiento",level:2},{value:"Arquitectura de entrenamiento del AlphaGo original",id:"arquitectura-de-entrenamiento-del-alphago-original",level:3},{value:"Arquitectura de entrenamiento de AlphaGo Zero",id:"arquitectura-de-entrenamiento-de-alphago-zero",level:3},{value:"Estaciones de auto-juego (Self-play Workers)",id:"estaciones-de-auto-juego-self-play-workers",level:2},{value:"Asignaci\xf3n de tareas",id:"asignaci\xf3n-de-tareas",level:3},{value:"Flujo de trabajo",id:"flujo-de-trabajo",level:3},{value:"Balanceo de carga",id:"balanceo-de-carga",level:3},{value:"Estaciones de entrenamiento (Training Workers)",id:"estaciones-de-entrenamiento-training-workers",level:2},{value:"Asignaci\xf3n de tareas",id:"asignaci\xf3n-de-tareas-1",level:3},{value:"Entrenamiento distribuido",id:"entrenamiento-distribuido",level:3},{value:"Actualizaci\xf3n s\xedncrona vs. as\xedncrona",id:"actualizaci\xf3n-s\xedncrona-vs-as\xedncrona",level:3},{value:"El papel de las TPU",id:"el-papel-de-las-tpu",level:2},{value:"\xbfQu\xe9 es una TPU?",id:"qu\xe9-es-una-tpu",level:3},{value:"Arquitectura de las TPU",id:"arquitectura-de-las-tpu",level:3},{value:"\xbfPor qu\xe9 AlphaGo necesita TPU?",id:"por-qu\xe9-alphago-necesita-tpu",level:3},{value:"Evoluci\xf3n del uso de TPU",id:"evoluci\xf3n-del-uso-de-tpu",level:3},{value:"MCTS paralelo y Virtual Loss",id:"mcts-paralelo-y-virtual-loss",level:2},{value:"El desaf\xedo de la paralelizaci\xf3n",id:"el-desaf\xedo-de-la-paralelizaci\xf3n",level:3},{value:"Paralelizaci\xf3n de hojas (Leaf Parallelization)",id:"paralelizaci\xf3n-de-hojas-leaf-parallelization",level:3},{value:"Virtual Loss",id:"virtual-loss",level:3},{value:"Concepto b\xe1sico",id:"concepto-b\xe1sico",level:4},{value:"Flujo de operaci\xf3n",id:"flujo-de-operaci\xf3n",level:4},{value:"Efecto del virtual loss",id:"efecto-del-virtual-loss",level:4},{value:"Evaluaci\xf3n de red neuronal por lotes",id:"evaluaci\xf3n-de-red-neuronal-por-lotes",level:3},{value:"Arquitectura de inferencia",id:"arquitectura-de-inferencia",level:2},{value:"Configuraci\xf3n durante competencias",id:"configuraci\xf3n-durante-competencias",level:3},{value:"Flujo de inferencia distribuida",id:"flujo-de-inferencia-distribuida",level:3},{value:"Gesti\xf3n del tiempo de pensamiento",id:"gesti\xf3n-del-tiempo-de-pensamiento",level:3},{value:"Comunicaci\xf3n y sincronizaci\xf3n",id:"comunicaci\xf3n-y-sincronizaci\xf3n",level:2},{value:"Formato de datos",id:"formato-de-datos",level:3},{value:"Requisitos de ancho de banda",id:"requisitos-de-ancho-de-banda",level:3},{value:"Manejo de fallos",id:"manejo-de-fallos",level:3},{value:"An\xe1lisis de costos",id:"an\xe1lisis-de-costos",level:2},{value:"Estimaci\xf3n de costo de hardware",id:"estimaci\xf3n-de-costo-de-hardware",level:3},{value:"Comparaci\xf3n con entrenamiento humano",id:"comparaci\xf3n-con-entrenamiento-humano",level:3},{value:"Costo de inferencia",id:"costo-de-inferencia",level:3},{value:"Evoluci\xf3n tecnol\xf3gica",id:"evoluci\xf3n-tecnol\xf3gica",level:2},{value:"De AlphaGo a AlphaZero",id:"de-alphago-a-alphazero",level:3},{value:"Impacto en la comunidad de c\xf3digo abierto",id:"impacto-en-la-comunidad-de-c\xf3digo-abierto",level:3},{value:"Correspondencia con animaciones",id:"correspondencia-con-animaciones",level:2},{value:"Lecturas adicionales",id:"lecturas-adicionales",level:2},{value:"Referencias",id:"referencias",level:2}];function o(e){const n={a:"a",annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mn:"mn",mo:"mo",mover:"mover",mrow:"mrow",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sistemas-distribuidos-y-tpu",children:"Sistemas distribuidos y TPU"})}),"\n",(0,r.jsx)(n.p,{children:"El \xe9xito de AlphaGo no es solo una victoria algor\xedtmica, sino tambi\xe9n una victoria de ingenier\xeda. Para entrenar una IA de Go que supere a los humanos en un tiempo razonable, se necesita un sistema distribuido cuidadosamente dise\xf1ado y el soporte de hardware especializado."}),"\n",(0,r.jsx)(n.p,{children:"Este art\xedculo analizar\xe1 en profundidad la arquitectura del sistema detr\xe1s de AlphaGo, incluyendo el proceso de entrenamiento, la arquitectura de inferencia, MCTS paralelo y el papel crucial de las TPU."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"visi\xf3n-general-de-la-arquitectura-de-entrenamiento",children:"Visi\xf3n general de la arquitectura de entrenamiento"}),"\n",(0,r.jsx)(n.h3,{id:"arquitectura-de-entrenamiento-del-alphago-original",children:"Arquitectura de entrenamiento del AlphaGo original"}),"\n",(0,r.jsx)(n.p,{children:"El entrenamiento del AlphaGo original (la versi\xf3n que derrot\xf3 a Lee Sedol) se dividi\xf3 en m\xfaltiples etapas, cada una usando diferentes configuraciones de recursos:"}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph E1["Etapa 1: Aprendizaje supervisado"]\n        H1["Partidas humanas<br/>(30M)"] --\x3e G1["Cluster GPU<br/>(50 GPUs)"] --\x3e P1["Policy Net<br/>(version SL)"]\n    end\n\n    subgraph E2["Etapa 2: Aprendizaje por refuerzo"]\n        S2["Auto-juego<br/>(millones partidas)"] --\x3e G2["Cluster GPU<br/>(50 GPUs)"] --\x3e P2["Policy Net<br/>(version RL)"]\n    end\n\n    subgraph E3["Etapa 3: Entrenamiento de Value Net"]\n        D3["Datos de auto-juego<br/>(30M pos.)"] --\x3e G3["Cluster GPU<br/>(50 GPUs)"] --\x3e V3["Value Net"]\n    end\n\n    E1 --\x3e E2\n    E2 --\x3e E3'}),"\n",(0,r.jsx)(n.h3,{id:"arquitectura-de-entrenamiento-de-alphago-zero",children:"Arquitectura de entrenamiento de AlphaGo Zero"}),"\n",(0,r.jsx)(n.p,{children:"AlphaGo Zero simplific\xf3 enormemente el proceso de entrenamiento, usando un \xfanico ciclo de entrenamiento de extremo a extremo:"}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Ciclo["Ciclo de entrenamiento AlphaGo Zero"]\n        SP["Self-play Workers<br/>(TPU x N)<br/>\u2190 Red mas reciente"]\n        RB["Replay Buffer<br/>(RAM/SSD)<br/>(ultimas 500K partidas)"]\n        TW["Training Workers<br/>(TPU x M)"]\n        NC["Network Checkpoint<br/>\u2192 Actualiza red usada en Self-play"]\n\n        SP --\x3e RB\n        RB --\x3e TW\n        TW --\x3e NC\n        NC -.->|"actualizar"| SP\n    end'}),"\n",(0,r.jsx)(n.p,{children:"Las ventajas de esta arquitectura:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Aprendizaje continuo"}),": Self-play y Training ocurren simult\xe1neamente, sin necesidad de esperar"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Eficiencia de recursos"}),": Todos los recursos hacen trabajo \xfatil"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Iteraci\xf3n r\xe1pida"}),": La red se usa inmediatamente para generar nuevos datos despu\xe9s de actualizarse"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"estaciones-de-auto-juego-self-play-workers",children:"Estaciones de auto-juego (Self-play Workers)"}),"\n",(0,r.jsx)(n.h3,{id:"asignaci\xf3n-de-tareas",children:"Asignaci\xf3n de tareas"}),"\n",(0,r.jsx)(n.p,{children:"Los Self-play Workers son responsables de realizar auto-juego con la red m\xe1s fuerte actual, produciendo datos de entrenamiento."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Configuraci\xf3n"}),(0,r.jsx)(n.th,{children:"AlphaGo Zero"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"N\xfamero de Workers"}),(0,r.jsx)(n.td,{children:"Decenas"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Por Worker"}),(0,r.jsx)(n.td,{children:"1-4 TPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"MCTS por partida"}),(0,r.jsx)(n.td,{children:"1600 simulaciones"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Producci\xf3n diaria"}),(0,r.jsx)(n.td,{children:"~100,000 partidas"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"flujo-de-trabajo",children:"Flujo de trabajo"}),"\n",(0,r.jsx)(n.p,{children:"El flujo de trabajo de cada Self-play Worker:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"while True:\n    # 1. Descargar los pesos de red m\xe1s recientes\n    network = download_latest_checkpoint()\n\n    # 2. Realizar m\xfaltiples auto-juegos\n    for game in range(batch_size):\n        positions = []\n        board = EmptyBoard()\n\n        while not board.is_terminal():\n            # Ejecutar MCTS\n            mcts = MCTS(network, board)\n            policy = mcts.search(num_simulations=1600)\n\n            # Elegir movimiento\n            action = sample(policy)\n\n            # Registrar\n            positions.append((board.state, policy))\n\n            # Jugar\n            board = board.play(action)\n\n        # 3. Obtener resultado del juego\n        result = board.get_result()\n\n        # 4. Subir datos\n        upload_to_replay_buffer(positions, result)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"balanceo-de-carga",children:"Balanceo de carga"}),"\n",(0,r.jsx)(n.p,{children:"M\xfaltiples Workers necesitan balanceo de carga:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sincronizaci\xf3n de red"}),": Todos los Workers usan la misma versi\xf3n de la red"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Balance de datos"}),": Asegurar que los datos de diferentes Workers sean usados"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Manejo de errores"}),": El fallo de un Worker no afecta el entrenamiento general"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"estaciones-de-entrenamiento-training-workers",children:"Estaciones de entrenamiento (Training Workers)"}),"\n",(0,r.jsx)(n.h3,{id:"asignaci\xf3n-de-tareas-1",children:"Asignaci\xf3n de tareas"}),"\n",(0,r.jsx)(n.p,{children:"Los Training Workers son responsables de muestrear datos del Replay Buffer y entrenar la red neuronal."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Configuraci\xf3n"}),(0,r.jsx)(n.th,{children:"AlphaGo Zero"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"N\xfamero de Workers"}),(0,r.jsx)(n.td,{children:"1-4"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Por Worker"}),(0,r.jsx)(n.td,{children:"4 TPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Batch Size"}),(0,r.jsx)(n.td,{children:"2048 (512 por TPU)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Pasos de entrenamiento"}),(0,r.jsx)(n.td,{children:"Decenas de miles por d\xeda"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"entrenamiento-distribuido",children:"Entrenamiento distribuido"}),"\n",(0,r.jsxs)(n.p,{children:["El entrenamiento a gran escala usa ",(0,r.jsx)(n.strong,{children:"paralelismo de datos (Data Parallelism)"}),":"]}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart TB\n    PS["Parameter Server"]\n\n    TPU0["TPU 0<br/>Batch 0"]\n    TPU1["TPU 1<br/>Batch 1"]\n    TPU2["TPU 2<br/>Batch 2"]\n\n    GA["Gradient Aggregation"]\n\n    PS --\x3e TPU0\n    PS --\x3e TPU1\n    PS --\x3e TPU2\n\n    TPU0 --\x3e GA\n    TPU1 --\x3e GA\n    TPU2 --\x3e GA\n\n    GA --\x3e PS'}),"\n",(0,r.jsx)(n.p,{children:"Cada TPU procesa diferentes mini-batches, calcula gradientes locales, luego los agrega para actualizar par\xe1metros globales."}),"\n",(0,r.jsx)(n.h3,{id:"actualizaci\xf3n-s\xedncrona-vs-as\xedncrona",children:"Actualizaci\xf3n s\xedncrona vs. as\xedncrona"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Tipo de actualizaci\xf3n"}),(0,r.jsx)(n.th,{children:"Ventajas"}),(0,r.jsx)(n.th,{children:"Desventajas"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"S\xedncrona"}),(0,r.jsx)(n.td,{children:"Estable, reproducible"}),(0,r.jsx)(n.td,{children:"Workers deben esperar al m\xe1s lento"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"As\xedncrona"}),(0,r.jsx)(n.td,{children:"Alto throughput"}),(0,r.jsx)(n.td,{children:"Los gradientes pueden estar obsoletos"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["AlphaGo Zero usa ",(0,r.jsx)(n.strong,{children:"actualizaci\xf3n s\xedncrona"})," para asegurar la estabilidad del entrenamiento."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"el-papel-de-las-tpu",children:"El papel de las TPU"}),"\n",(0,r.jsx)(n.h3,{id:"qu\xe9-es-una-tpu",children:"\xbfQu\xe9 es una TPU?"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"TPU (Tensor Processing Unit)"})," es un acelerador dise\xf1ado por Google espec\xedficamente para deep learning:"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Caracter\xedstica"}),(0,r.jsx)(n.th,{children:"TPU"}),(0,r.jsx)(n.th,{children:"GPU"}),(0,r.jsx)(n.th,{children:"CPU"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Objetivo de dise\xf1o"}),(0,r.jsx)(n.td,{children:"Operaciones matriciales"}),(0,r.jsx)(n.td,{children:"Paralelismo general"}),(0,r.jsx)(n.td,{children:"Computaci\xf3n general"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Precisi\xf3n"}),(0,r.jsx)(n.td,{children:"Optimizado FP16/BF16"}),(0,r.jsx)(n.td,{children:"FP32/FP16"}),(0,r.jsx)(n.td,{children:"FP64/FP32"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Consumo"}),(0,r.jsx)(n.td,{children:"Relativamente bajo"}),(0,r.jsx)(n.td,{children:"M\xe1s alto"}),(0,r.jsx)(n.td,{children:"El m\xe1s alto"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Latencia"}),(0,r.jsx)(n.td,{children:"Baja"}),(0,r.jsx)(n.td,{children:"Media"}),(0,r.jsx)(n.td,{children:"Alta"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"arquitectura-de-las-tpu",children:"Arquitectura de las TPU"}),"\n",(0,r.jsxs)(n.p,{children:["El n\xfacleo de las TPU es la ",(0,r.jsx)(n.strong,{children:"MXU (Matrix Multiply Unit)"}),":"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Arquitectura TPU v2/v3:"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"Componente"}),(0,r.jsx)(n.th,{style:{textAlign:"center"},children:"Especificacion"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"MXU (Matrix Multiply Unit)"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"128 x 128 = 16K MACs/ciclo"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Vector Unit"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"Operaciones vectoriales"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"HBM (High Bandwidth Memory)"}),(0,r.jsx)(n.td,{style:{textAlign:"center"},children:"16-32 GB"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"La MXU puede ejecutar 16K operaciones de multiplicaci\xf3n-acumulaci\xf3n por ciclo, crucial para la multiplicaci\xf3n de matrices de redes neuronales."}),"\n",(0,r.jsx)(n.h3,{id:"por-qu\xe9-alphago-necesita-tpu",children:"\xbfPor qu\xe9 AlphaGo necesita TPU?"}),"\n",(0,r.jsxs)(n.p,{children:["El cuello de botella computacional de la IA de Go est\xe1 en la ",(0,r.jsx)(n.strong,{children:"inferencia de red neuronal"}),":"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Operaci\xf3n"}),(0,r.jsx)(n.th,{children:"Proporci\xf3n"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Forward pass de red neuronal"}),(0,r.jsx)(n.td,{children:"~95%"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Operaciones del \xe1rbol MCTS"}),(0,r.jsx)(n.td,{children:"~4%"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Otros"}),(0,r.jsx)(n.td,{children:"~1%"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Cada paso de MCTS requiere 1600 inferencias de red neuronal. El alto throughput de las TPU hace esto posible."}),"\n",(0,r.jsx)(n.h3,{id:"evoluci\xf3n-del-uso-de-tpu",children:"Evoluci\xf3n del uso de TPU"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Versi\xf3n"}),(0,r.jsx)(n.th,{children:"TPU de entrenamiento"}),(0,r.jsx)(n.th,{children:"TPU de inferencia"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Lee"}),(0,r.jsx)(n.td,{children:"50 GPU"}),(0,r.jsx)(n.td,{children:"48 TPU (v1)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Master"}),(0,r.jsx)(n.td,{children:"4 TPU (v2)"}),(0,r.jsx)(n.td,{children:"4 TPU (v2)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Zero"}),(0,r.jsx)(n.td,{children:"4 TPU (v2)"}),(0,r.jsx)(n.td,{children:"4 TPU (v2) (escalable)"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"El n\xfamero de TPU usadas por AlphaGo Zero se redujo significativamente, gracias a arquitecturas m\xe1s eficientes y versiones m\xe1s nuevas de TPU."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"mcts-paralelo-y-virtual-loss",children:"MCTS paralelo y Virtual Loss"}),"\n",(0,r.jsx)(n.h3,{id:"el-desaf\xedo-de-la-paralelizaci\xf3n",children:"El desaf\xedo de la paralelizaci\xf3n"}),"\n",(0,r.jsxs)(n.p,{children:["La implementaci\xf3n est\xe1ndar de MCTS es ",(0,r.jsx)(n.strong,{children:"serial"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"for i in range(num_simulations):\n    1. Selection: Seleccionar hacia abajo desde la ra\xedz\n    2. Expansion: Expandir nodo hoja\n    3. Evaluation: Evaluaci\xf3n con red neuronal\n    4. Backup: Retropropagar actualizaciones\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Pero la evaluaci\xf3n de red neuronal es una ",(0,r.jsx)(n.strong,{children:"operaci\xf3n por lotes"})," amigable para GPU/TPU. \xbfC\xf3mo hacer que m\xfaltiples simulaciones ocurran simult\xe1neamente?"]}),"\n",(0,r.jsx)(n.h3,{id:"paralelizaci\xf3n-de-hojas-leaf-parallelization",children:"Paralelizaci\xf3n de hojas (Leaf Parallelization)"}),"\n",(0,r.jsx)(n.p,{children:"El m\xe9todo de paralelizaci\xf3n m\xe1s simple: ejecutar m\xfaltiples simulaciones completas simult\xe1neamente, luego fusionar resultados."}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart TB\n    Root["Root"]\n\n    Sim1["Sim 1<br/>(indep.)"]\n    Sim2["Sim 2<br/>(indep.)"]\n    Sim3["Sim 3<br/>(indep.)"]\n    Sim4["Sim 4<br/>(indep.)"]\n\n    Merge["Merge Trees"]\n\n    Root --\x3e Sim1\n    Root --\x3e Sim2\n    Root --\x3e Sim3\n    Root --\x3e Sim4\n\n    Sim1 --\x3e Merge\n    Sim2 --\x3e Merge\n    Sim3 --\x3e Merge\n    Sim4 --\x3e Merge'}),"\n",(0,r.jsx)(n.p,{children:"Problema: Cada simulaci\xf3n comienza desde la ra\xedz, explorando repetidamente los mismos caminos."}),"\n",(0,r.jsx)(n.h3,{id:"virtual-loss",children:"Virtual Loss"}),"\n",(0,r.jsxs)(n.p,{children:["DeepMind adopt\xf3 la t\xe9cnica de ",(0,r.jsx)(n.strong,{children:"Virtual Loss"})," para implementar paralelismo de \xe1rbol (Tree Parallelization)."]}),"\n",(0,r.jsx)(n.h4,{id:"concepto-b\xe1sico",children:"Concepto b\xe1sico"}),"\n",(0,r.jsx)(n.p,{children:"Cuando un hilo est\xe1 explorando un nodo, reduce temporalmente el valor de ese nodo, haciendo que otros hilos elijan otros caminos."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"UCB normal: Q(s,a) + c * P(s,a) * sqrt(N(s)) / (1 + N(s,a))\n\nCon virtual loss:\n(Q(s,a) * N(s,a) - v * n_virtual) / (N(s,a) + n_virtual) + c * P(s,a) * sqrt(N(s)) / (1 + N(s,a) + n_virtual)\n"})}),"\n",(0,r.jsx)(n.p,{children:"Donde:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"n_virtual"})," es el n\xfamero de hilos actualmente explorando ese nodo"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"v"})," es el valor del virtual loss (usualmente 1 o valor correspondiente a tasa de victoria)"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"flujo-de-operaci\xf3n",children:"Flujo de operaci\xf3n"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'Tiempo T1:\n  Thread 1 elige camino A \u2192 B \u2192 C\n  Nodo C recibe virtual loss -1\n\nTiempo T2:\n  Thread 2 elige camino A \u2192 B \u2192 D (porque C fue "penalizado")\n  Nodo D recibe virtual loss -1\n\nTiempo T3:\n  Thread 1 completa evaluaci\xf3n, actualiza valor real de C, remueve virtual loss\n  Thread 3 ahora puede elegir C (si el valor real es suficientemente bueno)\n'})}),"\n",(0,r.jsx)(n.h4,{id:"efecto-del-virtual-loss",children:"Efecto del virtual loss"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspecto"}),(0,r.jsx)(n.th,{children:"Efecto"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Diversidad de exploraci\xf3n"}),(0,r.jsx)(n.td,{children:"Fuerza exploraci\xf3n de diferentes caminos"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Eficiencia de lotes"}),(0,r.jsx)(n.td,{children:"Puede evaluar m\xfaltiples hojas simult\xe1neamente"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Convergencia"}),(0,r.jsx)(n.td,{children:"El virtual loss es finalmente cubierto por valores reales, no afecta convergencia"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"evaluaci\xf3n-de-red-neuronal-por-lotes",children:"Evaluaci\xf3n de red neuronal por lotes"}),"\n",(0,r.jsxs)(n.p,{children:["A trav\xe9s del virtual loss, se pueden recoger m\xfaltiples nodos hoja pendientes de evaluaci\xf3n para ",(0,r.jsx)(n.strong,{children:"inferencia por lotes"}),":"]}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph Parallel["MCTS Paralelo"]\n        T1["Thread 1 \u2192 nodo hoja L1"]\n        T2["Thread 2 \u2192 nodo hoja L2"]\n        T3["Thread 3 \u2192 nodo hoja L3"]\n        T4["Thread 4 \u2192 nodo hoja L4"]\n    end\n\n    Batch["Batch"]\n    TPU["TPU"]\n    Results["Obtiene (P1,V1), (P2,V2), ...<br/>simultaneamente"]\n\n    T1 --\x3e Batch\n    T2 --\x3e Batch\n    T3 --\x3e Batch\n    T4 --\x3e Batch\n\n    Batch --\x3e TPU\n    TPU --\x3e Results'}),"\n",(0,r.jsx)(n.p,{children:"La eficiencia de inferencia por lotes de TPU es mucho mayor que inferencia uno por uno, haciendo posible el MCTS paralelo."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"arquitectura-de-inferencia",children:"Arquitectura de inferencia"}),"\n",(0,r.jsx)(n.h3,{id:"configuraci\xf3n-durante-competencias",children:"Configuraci\xf3n durante competencias"}),"\n",(0,r.jsx)(n.p,{children:"Arquitectura de inferencia de AlphaGo en competencias oficiales:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Versi\xf3n"}),(0,r.jsx)(n.th,{children:"Configuraci\xf3n de hardware"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Fan"}),(0,r.jsx)(n.td,{children:"176 GPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Lee"}),(0,r.jsx)(n.td,{children:"48 TPU + m\xfaltiples servidores"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Master"}),(0,r.jsx)(n.td,{children:"4 TPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"AlphaGo Zero"}),(0,r.jsx)(n.td,{children:"4 TPU (escalable)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"flujo-de-inferencia-distribuida",children:"Flujo de inferencia distribuida"}),"\n",(0,r.jsx)(n.p,{children:"Flujo de inferencia durante competencias (ejemplo de AlphaGo Lee):"}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Arch["Arquitectura de inferencia distribuida"]\n        Master["Nodo maestro<br/>\u2190 Recibe movimiento del oponente<br/>\u2192 Envia movimiento de AlphaGo"]\n\n        MCTS["Controlador MCTS<br/>Gestiona arbol de busqueda,<br/>asigna tareas, recopila resultados"]\n\n        subgraph Cluster["Cluster TPU (48 TPUs)"]\n            TPU1["TPU 1"]\n            TPU2["TPU 2"]\n            TPU3["TPU 3"]\n            TPU4["TPU 4"]\n            TPU5["TPU 5"]\n            TPUN["... TPU 48"]\n        end\n\n        Master --\x3e MCTS\n        MCTS --\x3e Cluster\n    end'}),"\n",(0,r.jsx)(n.h3,{id:"gesti\xf3n-del-tiempo-de-pensamiento",children:"Gesti\xf3n del tiempo de pensamiento"}),"\n",(0,r.jsx)(n.p,{children:"Estrategia de gesti\xf3n de tiempo de AlphaGo:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Posici\xf3n"}),(0,r.jsx)(n.th,{children:"Tiempo de pensamiento"}),(0,r.jsx)(n.th,{children:"Simulaciones MCTS"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Apertura (con joseki)"}),(0,r.jsx)(n.td,{children:"M\xe1s corto"}),(0,r.jsx)(n.td,{children:"~10,000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Medio juego (complejo)"}),(0,r.jsx)(n.td,{children:"M\xe1s largo"}),(0,r.jsx)(n.td,{children:"~100,000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Posici\xf3n simple"}),(0,r.jsx)(n.td,{children:"M\xe1s corto"}),(0,r.jsx)(n.td,{children:"~5,000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Byoyomi"}),(0,r.jsx)(n.td,{children:"Fijo"}),(0,r.jsx)(n.td,{children:"~1,600"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"M\xe1s simulaciones MCTS generalmente significan mejor calidad de movimiento."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"comunicaci\xf3n-y-sincronizaci\xf3n",children:"Comunicaci\xf3n y sincronizaci\xf3n"}),"\n",(0,r.jsx)(n.h3,{id:"formato-de-datos",children:"Formato de datos"}),"\n",(0,r.jsx)(n.p,{children:"Formato de transmisi\xf3n de datos de entrenamiento:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-protobuf",children:"message TrainingExample {\n    // Estado del tablero (17 \xd7 19 \xd7 19)\n    repeated float board_planes = 1;\n\n    // Resultado de b\xfasqueda MCTS (362)\n    repeated float mcts_policy = 2;\n\n    // Resultado del juego (1 = actual gana, -1 = actual pierde)\n    float game_result = 3;\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requisitos-de-ancho-de-banda",children:"Requisitos de ancho de banda"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Flujo de datos"}),(0,r.jsx)(n.th,{children:"Tama\xf1o"}),(0,r.jsx)(n.th,{children:"Frecuencia"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Muestra de entrenamiento"}),(0,r.jsx)(n.td,{children:"~10 KB/muestra"}),(0,r.jsx)(n.td,{children:"Miles de muestras/segundo"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Pesos de red"}),(0,r.jsx)(n.td,{children:"~200 MB"}),(0,r.jsx)(n.td,{children:"Varias veces/hora"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Mensajes de control"}),(0,r.jsx)(n.td,{children:"< 1 KB"}),(0,r.jsx)(n.td,{children:"Continuo"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Requisito total de ancho de banda: ~100 Mbps (red interna suficiente)"}),"\n",(0,r.jsx)(n.h3,{id:"manejo-de-fallos",children:"Manejo de fallos"}),"\n",(0,r.jsx)(n.p,{children:"Manejo de fallos en sistemas distribuidos:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Tipo de fallo"}),(0,r.jsx)(n.th,{children:"Manejo"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Worker cae"}),(0,r.jsx)(n.td,{children:"Reiniciar, continuar usando \xfaltimo checkpoint"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Desconexi\xf3n de red"}),(0,r.jsx)(n.td,{children:"Almacenar en b\xfafer, retransmitir tras reconexi\xf3n"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fallo de TPU"}),(0,r.jsx)(n.td,{children:"Cambio autom\xe1tico a TPU de respaldo"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Corrupci\xf3n de datos"}),(0,r.jsx)(n.td,{children:"Descartar tras verificaci\xf3n, regenerar"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"an\xe1lisis-de-costos",children:"An\xe1lisis de costos"}),"\n",(0,r.jsx)(n.h3,{id:"estimaci\xf3n-de-costo-de-hardware",children:"Estimaci\xf3n de costo de hardware"}),"\n",(0,r.jsx)(n.p,{children:"Estimaci\xf3n de costo de entrenamiento de AlphaGo Zero basada en precios de TPU de Google Cloud:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Recurso"}),(0,r.jsx)(n.th,{children:"Cantidad"}),(0,r.jsx)(n.th,{children:"Precio/hora"}),(0,r.jsx)(n.th,{children:"Precio total/d\xeda"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TPU v2 Pod"}),(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"~$32"}),(0,r.jsx)(n.td,{children:"~$3,000"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"VM alta memoria"}),(0,r.jsx)(n.td,{children:"Varios"}),(0,r.jsx)(n.td,{children:"~$5"}),(0,r.jsx)(n.td,{children:"~$500"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Almacenamiento"}),(0,r.jsx)(n.td,{children:"10 TB"}),(0,r.jsx)(n.td,{children:"~$0.02/GB"}),(0,r.jsx)(n.td,{children:"~$200"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Red"}),(0,r.jsx)(n.td,{children:"-"}),(0,r.jsx)(n.td,{children:"Incluido"}),(0,r.jsx)(n.td,{children:"-"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsxs)(n.strong,{children:["Aproximadamente ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsx)(n.mn,{children:"3"}),(0,r.jsx)(n.mo,{separator:"true",children:","}),(0,r.jsx)(n.mn,{children:"700"}),(0,r.jsx)(n.mi,{mathvariant:"normal",children:"/"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsxs)(n.mover,{accent:"true",children:[(0,r.jsx)(n.mi,{mathvariant:"normal",children:"\u0131"}),(0,r.jsx)(n.mo,{children:"\u02ca"})]}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mo,{children:"\u2217"}),(0,r.jsx)(n.mo,{children:"\u2217"}),(0,r.jsx)(n.mo,{separator:"true",children:","}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"t"}),(0,r.jsx)(n.mi,{children:"r"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"t"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mi,{children:"c"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"p"}),(0,r.jsx)(n.mi,{children:"l"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"t"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsx)(n.mn,{children:"40"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsxs)(n.mover,{accent:"true",children:[(0,r.jsx)(n.mi,{mathvariant:"normal",children:"\u0131"}),(0,r.jsx)(n.mo,{children:"\u02ca"})]}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mi,{children:"s"}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mi,{children:"p"}),(0,r.jsx)(n.mi,{children:"r"}),(0,r.jsx)(n.mi,{children:"o"}),(0,r.jsx)(n.mi,{children:"x"}),(0,r.jsx)(n.mi,{children:"i"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mi,{children:"d"}),(0,r.jsx)(n.mi,{children:"a"}),(0,r.jsx)(n.mi,{children:"m"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mi,{children:"n"}),(0,r.jsx)(n.mi,{children:"t"}),(0,r.jsx)(n.mi,{children:"e"}),(0,r.jsx)(n.mo,{children:"\u2217"}),(0,r.jsx)(n.mo,{children:"\u2217"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"3,700/d\xeda**, entrenamiento completo (40 d\xedas) aproximadamente **"})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"3"}),(0,r.jsx)(n.span,{className:"mpunct",children:","}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,r.jsx)(n.span,{className:"mord",children:"700/"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"d"}),(0,r.jsx)(n.span,{className:"mord accent",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsxs)(n.span,{className:"vlist",style:{height:"0.6944em"},children:[(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"mord latin_fallback",children:"\u0131"})]}),(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"accent-body",style:{left:"-0.25em"},children:(0,r.jsx)(n.span,{className:"mord",children:"\u02ca"})})]})]})})})}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"a"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2217"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"\u2217"}),(0,r.jsx)(n.span,{className:"mpunct",children:","}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"n"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"nami"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"n"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"oco"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"m"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"pl"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"o"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsx)(n.span,{className:"mord",children:"40"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"d"}),(0,r.jsx)(n.span,{className:"mord accent",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsxs)(n.span,{className:"vlist",style:{height:"0.6944em"},children:[(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"mord latin_fallback",children:"\u0131"})]}),(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"accent-body",style:{left:"-0.25em"},children:(0,r.jsx)(n.span,{className:"mord",children:"\u02ca"})})]})]})})})}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"a"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"s"}),(0,r.jsx)(n.span,{className:"mclose",children:")"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"a"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"p"}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"o"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"x"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"ima"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"d"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"am"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"n"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2217"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"0.4653em"}}),(0,r.jsx)(n.span,{className:"mord",children:"\u2217"})]})]})]}),"150,000"]}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Nota: Esta es una estimaci\xf3n de 2017, DeepMind como subsidiaria de Google puede tener descuentos internos."}),"\n",(0,r.jsx)(n.h3,{id:"comparaci\xf3n-con-entrenamiento-humano",children:"Comparaci\xf3n con entrenamiento humano"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspecto"}),(0,r.jsx)(n.th,{children:"AlphaGo Zero"}),(0,r.jsx)(n.th,{children:"Jugador profesional humano"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Alcanzar nivel profesional"}),(0,r.jsx)(n.td,{children:"2 d\xedas"}),(0,r.jsx)(n.td,{children:"10-15 a\xf1os"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Costo de entrenamiento"}),(0,r.jsx)(n.td,{children:"~$7,500"}),(0,r.jsx)(n.td,{children:"Millones (matr\xedcula, gastos, costo de oportunidad)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Costo continuo"}),(0,r.jsx)(n.td,{children:"Electricidad"}),(0,r.jsx)(n.td,{children:"Gastos de vida"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Replicabilidad"}),(0,r.jsx)(n.td,{children:"Perfecta"}),(0,r.jsx)(n.td,{children:"No replicable"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Por supuesto, esta comparaci\xf3n no es completamente justa: los humanos aprenden m\xe1s que solo Go durante el proceso."}),"\n",(0,r.jsx)(n.h3,{id:"costo-de-inferencia",children:"Costo de inferencia"}),"\n",(0,r.jsx)(n.p,{children:"Costo de inferencia en competencias oficiales:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Configuraci\xf3n"}),(0,r.jsx)(n.th,{children:"Costo por partida"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"48 TPU (AlphaGo Lee)"}),(0,r.jsx)(n.td,{children:"~$500"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4 TPU (AlphaGo Zero)"}),(0,r.jsx)(n.td,{children:"~$50"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"GPU \xfanica (KataGo)"}),(0,r.jsx)(n.td,{children:"~$1"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"El costo de inferencia ha disminuido dr\xe1sticamente con el progreso tecnol\xf3gico."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"evoluci\xf3n-tecnol\xf3gica",children:"Evoluci\xf3n tecnol\xf3gica"}),"\n",(0,r.jsx)(n.h3,{id:"de-alphago-a-alphazero",children:"De AlphaGo a AlphaZero"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspecto"}),(0,r.jsx)(n.th,{children:"AlphaGo Lee"}),(0,r.jsx)(n.th,{children:"AlphaGo Zero"}),(0,r.jsx)(n.th,{children:"AlphaZero"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TPU entrenamiento"}),(0,r.jsx)(n.td,{children:"50+ GPU \u2192 TPU"}),(0,r.jsx)(n.td,{children:"4 TPU"}),(0,r.jsx)(n.td,{children:"4 TPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TPU inferencia"}),(0,r.jsx)(n.td,{children:"48 TPU"}),(0,r.jsx)(n.td,{children:"4 TPU"}),(0,r.jsx)(n.td,{children:"4 TPU"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"MCTS/movimiento"}),(0,r.jsx)(n.td,{children:"~100,000"}),(0,r.jsx)(n.td,{children:"~1,600"}),(0,r.jsx)(n.td,{children:"~800"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Tiempo de entrenamiento"}),(0,r.jsx)(n.td,{children:"Meses"}),(0,r.jsx)(n.td,{children:"40 d\xedas"}),(0,r.jsx)(n.td,{children:"Horas-d\xedas"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Mejora de eficiencia de aproximadamente 100 veces."}),"\n",(0,r.jsx)(n.h3,{id:"impacto-en-la-comunidad-de-c\xf3digo-abierto",children:"Impacto en la comunidad de c\xf3digo abierto"}),"\n",(0,r.jsx)(n.p,{children:"La arquitectura de AlphaGo inspir\xf3 m\xfaltiples proyectos de c\xf3digo abierto:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Proyecto"}),(0,r.jsx)(n.th,{children:"Caracter\xedsticas"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Leela Zero"}),(0,r.jsx)(n.td,{children:"Entrenamiento distribuido comunitario, replica AlphaGo Zero"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"KataGo"}),(0,r.jsx)(n.td,{children:"Entrenamiento eficiente en una sola GPU, supera AlphaGo Zero"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ELF OpenGo"}),(0,r.jsx)(n.td,{children:"C\xf3digo abierto de Facebook, usa PyTorch"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Minigo"}),(0,r.jsx)(n.td,{children:"C\xf3digo abierto de Google, usa TensorFlow"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:"Estos proyectos permiten a investigadores ordinarios entrenar IA de Go potentes."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"correspondencia-con-animaciones",children:"Correspondencia con animaciones"}),"\n",(0,r.jsx)(n.p,{children:"Conceptos centrales de este art\xedculo y n\xfameros de animaci\xf3n:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"N\xfamero"}),(0,r.jsx)(n.th,{children:"Concepto"}),(0,r.jsx)(n.th,{children:"Correspondencia f\xedsica/matem\xe1tica"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83c\udfac C9"}),(0,r.jsx)(n.td,{children:"MCTS paralelo"}),(0,r.jsx)(n.td,{children:"Problema de muchos cuerpos"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83c\udfac E9"}),(0,r.jsx)(n.td,{children:"Entrenamiento distribuido"}),(0,r.jsx)(n.td,{children:"Computaci\xf3n distribuida"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83c\udfac C5"}),(0,r.jsx)(n.td,{children:"Virtual loss"}),(0,r.jsx)(n.td,{children:"Potencial de repulsi\xf3n"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\ud83c\udfac D15"}),(0,r.jsx)(n.td,{children:"Inferencia por lotes"}),(0,r.jsx)(n.td,{children:"C\xe1lculo vectorizado"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"lecturas-adicionales",children:"Lecturas adicionales"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Art\xedculo anterior"}),": ",(0,r.jsx)(n.a,{href:"../training-from-scratch",children:"El proceso de entrenamiento desde cero"})," \u2014 An\xe1lisis detallado de la curva de entrenamiento"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Art\xedculo siguiente"}),": ",(0,r.jsx)(n.a,{href:"../legacy-and-impact",children:"El legado de AlphaGo"})," \u2014 El profundo impacto de AlphaGo en el campo de IA"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Art\xedculo relacionado"}),": ",(0,r.jsx)(n.a,{href:"../mcts-neural-combo",children:"Combinaci\xf3n de MCTS y redes neuronales"})," \u2014 Conocimientos b\xe1sicos de MCTS"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"referencias",children:"Referencias"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:['Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." ',(0,r.jsx)(n.em,{children:"Nature"}),", 550, 354-359."]}),"\n",(0,r.jsxs)(n.li,{children:['Jouppi, N., et al. (2017). "In-Datacenter Performance Analysis of a Tensor Processing Unit." ',(0,r.jsx)(n.em,{children:"ISCA 2017"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:['Dean, J., et al. (2012). "Large Scale Distributed Deep Networks." ',(0,r.jsx)(n.em,{children:"NeurIPS 2012"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:['Chaslot, G., et al. (2008). "Parallel Monte-Carlo Tree Search." ',(0,r.jsx)(n.em,{children:"CIG 2008"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:['Segal, R. (2010). "On the Scalability of Parallel UCT." ',(0,r.jsx)(n.em,{children:"CIG 2010"}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},30416(e,n,s){s.d(n,{R:()=>l,x:()=>d});var a=s(59471);const r={},i=a.createContext(r);function l(e){const n=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);