<!doctype html>
<html lang="es" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/explained/dual-head-resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Red de Doble Cabeza y Redes Residuales | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/es/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/es/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/es/docs/alphago/explained/dual-head-resnet/"><meta data-rh="true" property="og:locale" content="es"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="es"><meta data-rh="true" name="docsearch:language" content="es"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Red de Doble Cabeza y Redes Residuales | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="Análisis profundo de la arquitectura de red neuronal de AlphaGo Zero - Backbone compartido, Policy Head, Value Head y ResNet de 40 capas"><meta data-rh="true" property="og:description" content="Análisis profundo de la arquitectura de red neuronal de AlphaGo Zero - Backbone compartido, Policy Head, Value Head y ResNet de 40 capas"><meta data-rh="true" name="keywords" content="red de doble cabeza,red residual,ResNet,Policy Head,Value Head,deep learning,arquitectura de red neuronal"><link data-rh="true" rel="icon" href="/es/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/es/docs/alphago/explained/dual-head-resnet/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/dual-head-resnet/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/dual-head-resnet/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/explained/dual-head-resnet/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/explained/dual-head-resnet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/explained/dual-head-resnet/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/explained/dual-head-resnet/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/explained/dual-head-resnet/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/explained/dual-head-resnet/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/explained/dual-head-resnet/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/explained/dual-head-resnet/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/explained/dual-head-resnet/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/dual-head-resnet/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/es/docs/alphago/"},{"@type":"ListItem","position":2,"name":"完整解析","item":"https://www.weiqi.kids/es/docs/alphago/explained/"},{"@type":"ListItem","position":3,"name":"Red de Doble Cabeza y Redes Residuales","item":"https://www.weiqi.kids/es/docs/alphago/explained/dual-head-resnet"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/es/assets/css/styles.f23bf74b.css">
<script src="/es/assets/js/runtime~main.95f0457a.js" defer="defer"></script>
<script src="/es/assets/js/main.998fa461.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/es/img/logo.svg"><div role="region" aria-label="Saltar al contenido principal"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Saltar al contenido principal</a></div><nav aria-label="Principal" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar barra lateral" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/es/"><div class="navbar__logo"><img src="/es/img/logo.svg" alt="Logo de la Asociación Weiqi Kids" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/es/img/logo.svg" alt="Logo de la Asociación Weiqi Kids" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/es/docs/learn/">Aprender Go</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/es/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/es/docs/animations/">Estudio de Animación</a><a class="navbar__item navbar__link" href="/es/docs/tech/">Documentación Técnica</a><a class="navbar__item navbar__link" href="/es/docs/about/">Sobre Nosotros</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>Español</a><ul class="dropdown__menu"><li><a href="/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="es">Español</a></li><li><a href="/pt/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Volver al principio" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Barra lateral de Documentos" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/intro/"><span title="Guia de uso" class="linkLabel_REp1">Guia de uso</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/es/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="Ampliar la categoría &#x27;學圍棋&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/es/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="Colapsar categoría &#x27;AlphaGo&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/es/docs/alphago/explained/"><span title="完整解析" class="categoryLinkLabel_ezQx">完整解析</span></a><button aria-label="Colapsar categoría &#x27;完整解析&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/birth-of-alphago/"><span title="El Nacimiento de AlphaGo" class="linkLabel_REp1">El Nacimiento de AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/key-matches/"><span title="Revisiones de partidas clave" class="linkLabel_REp1">Revisiones de partidas clave</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/move-37/"><span title="Análisis Profundo del &quot;Movimiento Divino&quot;" class="linkLabel_REp1">Análisis Profundo del &quot;Movimiento Divino&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/why-go-is-hard/"><span title="¿Por Qué es Difícil el Go?" class="linkLabel_REp1">¿Por Qué es Difícil el Go?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/traditional-limits/"><span title="Los Limites de los Metodos Tradicionales" class="linkLabel_REp1">Los Limites de los Metodos Tradicionales</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/board-representation/"><span title="Representacion del Estado del Tablero" class="linkLabel_REp1">Representacion del Estado del Tablero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/policy-network/"><span title="Policy Network en detalle" class="linkLabel_REp1">Policy Network en detalle</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/value-network/"><span title="Value Network en detalle" class="linkLabel_REp1">Value Network en detalle</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/input-features/"><span title="Diseno de Caracteristicas de Entrada" class="linkLabel_REp1">Diseno de Caracteristicas de Entrada</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/cnn-and-go/"><span title="CNN y Go" class="linkLabel_REp1">CNN y Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/supervised-learning/"><span title="Fase de aprendizaje supervisado" class="linkLabel_REp1">Fase de aprendizaje supervisado</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/reinforcement-intro/"><span title="Introducción al aprendizaje por refuerzo" class="linkLabel_REp1">Introducción al aprendizaje por refuerzo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/self-play/"><span title="Auto-juego" class="linkLabel_REp1">Auto-juego</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/mcts-neural-combo/"><span title="La Combinación de MCTS y Redes Neuronales" class="linkLabel_REp1">La Combinación de MCTS y Redes Neuronales</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/puct-formula/"><span title="Explicación Detallada de la Fórmula PUCT" class="linkLabel_REp1">Explicación Detallada de la Fórmula PUCT</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/alphago-zero/"><span title="Visión General de AlphaGo Zero" class="linkLabel_REp1">Visión General de AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/es/docs/alphago/explained/dual-head-resnet/"><span title="Red de Doble Cabeza y Redes Residuales" class="linkLabel_REp1">Red de Doble Cabeza y Redes Residuales</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/training-from-scratch/"><span title="El proceso de entrenamiento desde cero" class="linkLabel_REp1">El proceso de entrenamiento desde cero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/distributed-systems/"><span title="Sistemas distribuidos y TPU" class="linkLabel_REp1">Sistemas distribuidos y TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/es/docs/alphago/explained/legacy-and-impact/"><span title="El legado de AlphaGo" class="linkLabel_REp1">El legado de AlphaGo</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/es/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/es/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="Ampliar la categoría &#x27;技術文件&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/es/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="Ampliar la categoría &#x27;關於我們&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Rastro de navegación"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página de Inicio" class="breadcrumbs__link" href="/es/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/es/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/es/docs/alphago/explained/"><span>完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Red de Doble Cabeza y Redes Residuales</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">En esta página</button></div><div class="theme-doc-markdown markdown"><header><h1>Red de Doble Cabeza y Redes Residuales</h1></header>
<p>Una de las innovaciones arquitectónicas más importantes de AlphaGo Zero es el uso de una <strong>Red de Doble Cabeza (Dual-Head Network)</strong> para reemplazar el diseño de doble red del AlphaGo original. Este cambio aparentemente simple trajo mejoras significativas de rendimiento y un proceso de aprendizaje más elegante.</p>
<p>Este artículo analizará en profundidad los principios de diseño de esta arquitectura, sus fundamentos matemáticos, y por qué es tan efectiva.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="diseño-de-la-red-de-doble-cabeza">Diseño de la Red de Doble Cabeza<a href="#diseño-de-la-red-de-doble-cabeza" class="hash-link" aria-label="Enlace directo al Diseño de la Red de Doble Cabeza" title="Enlace directo al Diseño de la Red de Doble Cabeza" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="arquitectura-general">Arquitectura General<a href="#arquitectura-general" class="hash-link" aria-label="Enlace directo al Arquitectura General" title="Enlace directo al Arquitectura General" translate="no">​</a></h3>
<p>La red neuronal de AlphaGo Zero se puede dividir en tres partes:</p>
<!-- -->
<p>Analicemos cada parte.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="backbone-compartido-shared-backbone">Backbone Compartido (Shared Backbone)<a href="#backbone-compartido-shared-backbone" class="hash-link" aria-label="Enlace directo al Backbone Compartido (Shared Backbone)" title="Enlace directo al Backbone Compartido (Shared Backbone)" translate="no">​</a></h3>
<p>El backbone compartido es una <strong>Red Residual (ResNet)</strong> profunda, responsable de extraer características del estado del tablero.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalles-de-arquitectura">Detalles de Arquitectura<a href="#detalles-de-arquitectura" class="hash-link" aria-label="Enlace directo al Detalles de Arquitectura" title="Enlace directo al Detalles de Arquitectura" translate="no">​</a></h4>
<table><thead><tr><th>Componente</th><th>Especificación</th></tr></thead><tbody><tr><td>Capa de entrada</td><td>Convolución 3×3, 256 canales</td></tr><tr><td>Bloques residuales</td><td>40 (o 20 versión simplificada)</td></tr><tr><td>Cada bloque residual</td><td>2 capas conv 3×3, 256 canales</td></tr><tr><td>Función de activación</td><td>ReLU</td></tr><tr><td>Normalización</td><td>Batch Normalization</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representación-matemática">Representación Matemática<a href="#representación-matemática" class="hash-link" aria-label="Enlace directo al Representación Matemática" title="Enlace directo al Representación Matemática" translate="no">​</a></h4>
<p>Sea la entrada x (dimensión 17 x 19 x 19), la salida del backbone compartido es:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">f(x) = ResNet_40(Conv_3x3(x))</span><br></span></code></pre></div></div>
<p>Donde f(x) (dimensión 256 x 19 x 19) es la representación de características de alta dimensión.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head-cabeza-de-política">Policy Head (Cabeza de Política)<a href="#policy-head-cabeza-de-política" class="hash-link" aria-label="Enlace directo al Policy Head (Cabeza de Política)" title="Enlace directo al Policy Head (Cabeza de Política)" translate="no">​</a></h3>
<p>Policy Head es responsable de predecir la probabilidad de jugar en cada posición.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalles-de-arquitectura-1">Detalles de Arquitectura<a href="#detalles-de-arquitectura-1" class="hash-link" aria-label="Enlace directo al Detalles de Arquitectura" title="Enlace directo al Detalles de Arquitectura" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Salida del Backbone (256 × 19 × 19)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Convolución 1×1 (2 canales)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Aplanar (2 × 19 × 19 = 722)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Capa Totalmente Conectada (362)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Softmax</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Salida: 362 probabilidades (361 posiciones + Pass)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representación-matemática-1">Representación Matemática<a href="#representación-matemática-1" class="hash-link" aria-label="Enlace directo al Representación Matemática" title="Enlace directo al Representación Matemática" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">π = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))</span><br></span></code></pre></div></div>
<p>La salida π es un vector de 362 dimensiones, donde todos los elementos son no negativos y suman 1.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head-cabeza-de-valor">Value Head (Cabeza de Valor)<a href="#value-head-cabeza-de-valor" class="hash-link" aria-label="Enlace directo al Value Head (Cabeza de Valor)" title="Enlace directo al Value Head (Cabeza de Valor)" translate="no">​</a></h3>
<p>Value Head es responsable de predecir la tasa de victoria de la posición actual.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="detalles-de-arquitectura-2">Detalles de Arquitectura<a href="#detalles-de-arquitectura-2" class="hash-link" aria-label="Enlace directo al Detalles de Arquitectura" title="Enlace directo al Detalles de Arquitectura" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Salida del Backbone (256 × 19 × 19)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Convolución 1×1 (1 canal)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Batch Normalization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Aplanar (1 × 19 × 19 = 361)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Capa Totalmente Conectada (256)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Capa Totalmente Conectada (1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Tanh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Salida: Tasa de victoria [-1, 1]</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representación-matemática-2">Representación Matemática<a href="#representación-matemática-2" class="hash-link" aria-label="Enlace directo al Representación Matemática" title="Enlace directo al Representación Matemática" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))</span><br></span></code></pre></div></div>
<p>La salida v está en el rango [-1, 1]:</p>
<ul>
<li class="">v = 1: El jugador actual gana seguro</li>
<li class="">v = -1: El jugador actual pierde seguro</li>
<li class="">v = 0: Posición equilibrada</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-compartir-el-backbone">¿Por Qué Compartir el Backbone?<a href="#por-qué-compartir-el-backbone" class="hash-link" aria-label="Enlace directo al ¿Por Qué Compartir el Backbone?" title="Enlace directo al ¿Por Qué Compartir el Backbone?" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="comprensión-intuitiva">Comprensión Intuitiva<a href="#comprensión-intuitiva" class="hash-link" aria-label="Enlace directo al Comprensión Intuitiva" title="Enlace directo al Comprensión Intuitiva" translate="no">​</a></h3>
<p>&quot;Dónde debería jugar el siguiente movimiento&quot; (Policy) y &quot;Quién ganará&quot; (Value) -- estas dos preguntas en realidad necesitan entender los mismos patrones del tablero:</p>
<ul>
<li class=""><strong>Forma de las piedras</strong>: Qué formas son buenas, cuáles son malas</li>
<li class=""><strong>Influencia</strong>: Qué lado tiene más, dónde queda espacio</li>
<li class=""><strong>Vida y muerte</strong>: Qué grupos están vivos, cuáles están en ko</li>
<li class=""><strong>Combate</strong>: Dónde hay ataques, cuál es el resultado local</li>
</ul>
<p>Si se usan dos redes independientes, estas características necesitan aprenderse dos veces. El backbone compartido permite que estas características de bajo nivel se aprendan solo una vez, siendo usadas por ambas tareas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="perspectiva-del-aprendizaje-multi-tarea">Perspectiva del Aprendizaje Multi-tarea<a href="#perspectiva-del-aprendizaje-multi-tarea" class="hash-link" aria-label="Enlace directo al Perspectiva del Aprendizaje Multi-tarea" title="Enlace directo al Perspectiva del Aprendizaje Multi-tarea" translate="no">​</a></h3>
<p>Desde la perspectiva del machine learning, esto es <strong>Aprendizaje Multi-tarea (Multi-task Learning)</strong>:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value</span><br></span></code></pre></div></div>
<p>Las dos tareas comparten representación de bajo nivel, lo que trae varios beneficios:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-efecto-de-regularización">1. Efecto de Regularización<a href="#1-efecto-de-regularización" class="hash-link" aria-label="Enlace directo al 1. Efecto de Regularización" title="Enlace directo al 1. Efecto de Regularización" translate="no">​</a></h4>
<p>Compartir parámetros equivale a regularización implícita. Si una característica solo es útil para Policy y no para Value (o viceversa), es más difícil que se amplifique excesivamente.</p>
<p>La cantidad efectiva de parámetros es menor que la suma de dos redes independientes.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-eficiencia-de-datos">2. Eficiencia de Datos<a href="#2-eficiencia-de-datos" class="hash-link" aria-label="Enlace directo al 2. Eficiencia de Datos" title="Enlace directo al 2. Eficiencia de Datos" translate="no">​</a></h4>
<p>Cada partida produce simultáneamente etiquetas de Policy (probabilidades de búsqueda MCTS) y etiquetas de Value (resultado final). El backbone compartido permite que ambas etiquetas se usen para entrenar características compartidas, mejorando la eficiencia de utilización de datos.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-señales-de-gradiente-enriquecidas">3. Señales de Gradiente Enriquecidas<a href="#3-señales-de-gradiente-enriquecidas" class="hash-link" aria-label="Enlace directo al 3. Señales de Gradiente Enriquecidas" title="Enlace directo al 3. Señales de Gradiente Enriquecidas" translate="no">​</a></h4>
<p>Los gradientes de ambas tareas fluyen hacia el backbone compartido:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂θ_shared = ∂L_policy/∂θ_shared + ∂L_value/∂θ_shared</span><br></span></code></pre></div></div>
<p>Esto proporciona señales de supervisión más ricas, haciendo las características compartidas más robustas.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="evidencia-experimental">Evidencia Experimental<a href="#evidencia-experimental" class="hash-link" aria-label="Enlace directo al Evidencia Experimental" title="Enlace directo al Evidencia Experimental" translate="no">​</a></h3>
<p>Los experimentos de ablación de DeepMind mostraron que la red de doble cabeza supera significativamente las dobles redes separadas:</p>
<table><thead><tr><th>Configuración</th><th>Puntuación ELO</th><th>Diferencia Relativa</th></tr></thead><tbody><tr><td>Redes Policy + Value separadas</td><td>Línea base</td><td>-</td></tr><tr><td>Red de doble cabeza (backbone compartido)</td><td>+300 ELO</td><td>~65% diferencia en tasa de victoria</td></tr></tbody></table>
<p>Una diferencia de 300 ELO significa que la red de doble cabeza tiene aproximadamente 65% de tasa de victoria contra redes separadas. Esta es una mejora significativa.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="principios-de-las-redes-residuales">Principios de las Redes Residuales<a href="#principios-de-las-redes-residuales" class="hash-link" aria-label="Enlace directo al Principios de las Redes Residuales" title="Enlace directo al Principios de las Redes Residuales" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="el-dilema-de-las-redes-profundas">El Dilema de las Redes Profundas<a href="#el-dilema-de-las-redes-profundas" class="hash-link" aria-label="Enlace directo al El Dilema de las Redes Profundas" title="Enlace directo al El Dilema de las Redes Profundas" translate="no">​</a></h3>
<p>Antes de la invención de ResNet, las redes neuronales profundas enfrentaban una paradoja:</p>
<blockquote>
<p>Teóricamente, las redes más profundas deberían ser al menos tan buenas como las más superficiales (en el peor caso, las capas extra pueden aprender el mapeo identidad). Pero en la práctica, las redes más profundas a menudo rendían peor.</p>
</blockquote>
<p>Este es el <strong>Problema de Degradación (Degradation Problem)</strong>:</p>
<ul>
<li class="">El error de entrenamiento aumenta con la profundidad (no es sobreajuste, es dificultad de optimización)</li>
<li class="">Los gradientes se desvanecen gradualmente durante la retropropagación (Vanishing Gradient)</li>
<li class="">Los parámetros de capas profundas casi no pueden actualizarse efectivamente</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="diseño-del-bloque-residual">Diseño del Bloque Residual<a href="#diseño-del-bloque-residual" class="hash-link" aria-label="Enlace directo al Diseño del Bloque Residual" title="Enlace directo al Diseño del Bloque Residual" translate="no">​</a></h3>
<p>He Kaiming et al. propusieron en 2015 una solución simple y elegante: <strong>Conexiones Residuales (Skip Connection)</strong>.</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="representación-matemática-3">Representación Matemática<a href="#representación-matemática-3" class="hash-link" aria-label="Enlace directo al Representación Matemática" title="Enlace directo al Representación Matemática" translate="no">​</a></h4>
<p>Red tradicional: Aprender mapeo objetivo H(x)</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = H(x)</span><br></span></code></pre></div></div>
<p>Red residual: Aprender <strong>mapeo residual</strong> F(x) = H(x) - x</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = F(x) + x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-funcionan-las-conexiones-residuales">¿Por Qué Funcionan las Conexiones Residuales?<a href="#por-qué-funcionan-las-conexiones-residuales" class="hash-link" aria-label="Enlace directo al ¿Por Qué Funcionan las Conexiones Residuales?" title="Enlace directo al ¿Por Qué Funcionan las Conexiones Residuales?" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-autopista-de-gradientes">1. Autopista de Gradientes<a href="#1-autopista-de-gradientes" class="hash-link" aria-label="Enlace directo al 1. Autopista de Gradientes" title="Enlace directo al 1. Autopista de Gradientes" translate="no">​</a></h4>
<p>Considera el gradiente de retropropagación:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂x = ∂L/∂y × ∂y/∂x = ∂L/∂y × (1 + ∂F(x)/∂x)</span><br></span></code></pre></div></div>
<p>La clave es ese <strong>+1</strong>. Incluso si ∂F(x)/∂x es muy pequeño o cero, el gradiente aún puede pasar directamente a través del +1.</p>
<p>Es como construir una &quot;autopista de gradientes&quot;, permitiendo que los gradientes fluyan sin obstáculos desde la capa de salida hasta la capa de entrada.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-el-mapeo-identidad-es-más-fácil-de-aprender">2. El Mapeo Identidad Es Más Fácil de Aprender<a href="#2-el-mapeo-identidad-es-más-fácil-de-aprender" class="hash-link" aria-label="Enlace directo al 2. El Mapeo Identidad Es Más Fácil de Aprender" title="Enlace directo al 2. El Mapeo Identidad Es Más Fácil de Aprender" translate="no">​</a></h4>
<p>Si la solución óptima está cerca del mapeo identidad (H(x) ≈ x), entonces:</p>
<ul>
<li class="">Red tradicional: Necesita aprender H(x) = x, puede ser difícil</li>
<li class="">Red residual: Solo necesita aprender F(x) ≈ 0, relativamente fácil</li>
</ul>
<p>Inicializando pesos a cero o cerca de cero, el bloque residual naturalmente tiende hacia el mapeo identidad.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-efecto-de-ensamble">3. Efecto de Ensamble<a href="#3-efecto-de-ensamble" class="hash-link" aria-label="Enlace directo al 3. Efecto de Ensamble" title="Enlace directo al 3. Efecto de Ensamble" translate="no">​</a></h4>
<p>Una ResNet profunda puede verse como un <strong>ensamble implícito</strong> de muchas redes poco profundas. Si hay n bloques residuales, la información puede fluir a través de 2^n diferentes caminos.</p>
<p>Este efecto de ensamble aumenta la robustez del modelo.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="el-avance-de-resnet-en-imagenet">El Avance de ResNet en ImageNet<a href="#el-avance-de-resnet-en-imagenet" class="hash-link" aria-label="Enlace directo al El Avance de ResNet en ImageNet" title="Enlace directo al El Avance de ResNet en ImageNet" translate="no">​</a></h3>
<p>ResNet logró resultados asombrosos en la competencia ImageNet 2015:</p>
<table><thead><tr><th>Profundidad</th><th>Error Top-5</th></tr></thead><tbody><tr><td>VGG-19 (sin residual)</td><td>7.3%</td></tr><tr><td>ResNet-34</td><td>5.7%</td></tr><tr><td>ResNet-152</td><td>4.5%</td></tr><tr><td>Nivel humano</td><td>~5.1%</td></tr></tbody></table>
<p>Una ResNet de <strong>152 capas</strong> no solo es entrenable, sino que es mucho mejor que VGG de 19 capas. Esto probó que las conexiones residuales realmente resuelven el problema de entrenamiento de redes profundas.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="la-resnet-de-40-capas-de-alphago-zero">La ResNet de 40 Capas de AlphaGo Zero<a href="#la-resnet-de-40-capas-de-alphago-zero" class="hash-link" aria-label="Enlace directo al La ResNet de 40 Capas de AlphaGo Zero" title="Enlace directo al La ResNet de 40 Capas de AlphaGo Zero" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-40-capas">¿Por Qué 40 Capas?<a href="#por-qué-40-capas" class="hash-link" aria-label="Enlace directo al ¿Por Qué 40 Capas?" title="Enlace directo al ¿Por Qué 40 Capas?" translate="no">​</a></h3>
<p>DeepMind probó ResNets de diferentes profundidades:</p>
<table><thead><tr><th>Número de bloques residuales</th><th>Total de capas</th><th>Puntuación ELO</th></tr></thead><tbody><tr><td>5</td><td>11</td><td>Línea base</td></tr><tr><td>10</td><td>21</td><td>+200</td></tr><tr><td>20</td><td>41</td><td>+400</td></tr><tr><td>40</td><td>81</td><td>+500</td></tr></tbody></table>
<p>Las redes más profundas son ciertamente más fuertes, pero con retornos decrecientes. AlphaGo Zero usa 20 o 40 bloques residuales:</p>
<ul>
<li class=""><strong>AlphaGo Zero (versión del paper)</strong>: 40 bloques residuales, 256 canales</li>
<li class=""><strong>Versión simplificada</strong>: 20 bloques residuales, 256 canales</li>
</ul>
<p>La configuración de 40 capas logra un buen equilibrio entre fuerza de juego y costo de entrenamiento.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="configuración-específica">Configuración Específica<a href="#configuración-específica" class="hash-link" aria-label="Enlace directo al Configuración Específica" title="Enlace directo al Configuración Específica" translate="no">​</a></h3>
<p>La configuración de ResNet de AlphaGo Zero:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Entrada: 17 × 19 × 19</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Capa conv: 3×3, 256 canales, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bloque residual ×40:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ Capa conv: 3×3, 256 canales, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ Capa conv: 3×3, 256 canales, BN</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └─ Conexión de salto + ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Policy Head / Value Head</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="estimación-de-parámetros">Estimación de Parámetros<a href="#estimación-de-parámetros" class="hash-link" aria-label="Enlace directo al Estimación de Parámetros" title="Enlace directo al Estimación de Parámetros" translate="no">​</a></h4>
<table><thead><tr><th>Componente</th><th>Parámetros (aprox.)</th></tr></thead><tbody><tr><td>Conv de entrada</td><td>17 × 3 × 3 × 256 ≈ 39K</td></tr><tr><td>Cada bloque residual</td><td>2 × 256 × 3 × 3 × 256 ≈ 1.2M</td></tr><tr><td>40 bloques residuales</td><td>40 × 1.2M ≈ 47M</td></tr><tr><td>Policy Head</td><td>~1M</td></tr><tr><td>Value Head</td><td>~0.2M</td></tr><tr><td><strong>Total</strong></td><td><strong>~48M</strong></td></tr></tbody></table>
<p>Aproximadamente 48 millones de parámetros, una red neuronal de escala media según estándares modernos.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="el-rol-de-batch-normalization">El Rol de Batch Normalization<a href="#el-rol-de-batch-normalization" class="hash-link" aria-label="Enlace directo al El Rol de Batch Normalization" title="Enlace directo al El Rol de Batch Normalization" translate="no">​</a></h3>
<p>Cada capa convolucional es seguida por <strong>Batch Normalization (BN)</strong>, crucial para la estabilidad del entrenamiento:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-normalizar-valores-de-activación">1. Normalizar Valores de Activación<a href="#1-normalizar-valores-de-activación" class="hash-link" aria-label="Enlace directo al 1. Normalizar Valores de Activación" title="Enlace directo al 1. Normalizar Valores de Activación" translate="no">​</a></h4>
<p>BN normaliza los valores de activación de cada capa a media 0, varianza 1:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_B) / sqrt(σ_B² + ε)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y = γ × x_hat + β</span><br></span></code></pre></div></div>
<p>Donde γ y β son parámetros aprendibles.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-mitigar-el-desplazamiento-de-covarianza-interna">2. Mitigar el Desplazamiento de Covarianza Interna<a href="#2-mitigar-el-desplazamiento-de-covarianza-interna" class="hash-link" aria-label="Enlace directo al 2. Mitigar el Desplazamiento de Covarianza Interna" title="Enlace directo al 2. Mitigar el Desplazamiento de Covarianza Interna" translate="no">​</a></h4>
<p>En redes profundas, la distribución de entrada de cada capa cambia a medida que se actualizan los parámetros de capas anteriores. BN mantiene la distribución de entrada de cada capa estable, acelerando la convergencia del entrenamiento.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-efecto-de-regularización">3. Efecto de Regularización<a href="#3-efecto-de-regularización" class="hash-link" aria-label="Enlace directo al 3. Efecto de Regularización" title="Enlace directo al 3. Efecto de Regularización" translate="no">​</a></h4>
<p>BN usa estadísticas del mini-batch durante el entrenamiento, introduciendo aleatoriedad, con un ligero efecto de regularización.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="comparación-con-otras-arquitecturas">Comparación con Otras Arquitecturas<a href="#comparación-con-otras-arquitecturas" class="hash-link" aria-label="Enlace directo al Comparación con Otras Arquitecturas" title="Enlace directo al Comparación con Otras Arquitecturas" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-cnn-del-alphago-original">vs. CNN del AlphaGo Original<a href="#vs-cnn-del-alphago-original" class="hash-link" aria-label="Enlace directo al vs. CNN del AlphaGo Original" title="Enlace directo al vs. CNN del AlphaGo Original" translate="no">​</a></h3>
<table><thead><tr><th>Característica</th><th>AlphaGo original</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>Tipo de arquitectura</td><td>CNN estándar</td><td>ResNet</td></tr><tr><td>Profundidad</td><td>13 capas</td><td>41-81 capas</td></tr><tr><td>Conexiones residuales</td><td>No</td><td>Sí</td></tr><tr><td>Número de redes</td><td>2 (separadas)</td><td>1 (compartida)</td></tr><tr><td>BN</td><td>No</td><td>Sí</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-red-estilo-vgg">vs. Red Estilo VGG<a href="#vs-red-estilo-vgg" class="hash-link" aria-label="Enlace directo al vs. Red Estilo VGG" title="Enlace directo al vs. Red Estilo VGG" translate="no">​</a></h3>
<p>VGG fue la arquitectura subcampeona de ImageNet 2014, usando convoluciones 3×3 apiladas:</p>
<table><thead><tr><th>Característica</th><th>VGG</th><th>ResNet</th></tr></thead><tbody><tr><td>Máx. profundidad entrenable</td><td>~19 capas</td><td>152+ capas</td></tr><tr><td>Flujo de gradiente</td><td>Decrece por capa</td><td>Tiene autopista</td></tr><tr><td>Dificultad de entrenamiento</td><td>Difícil para capas profundas</td><td>Capas profundas entrenables</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-inception--googlenet">vs. Inception / GoogLeNet<a href="#vs-inception--googlenet" class="hash-link" aria-label="Enlace directo al vs. Inception / GoogLeNet" title="Enlace directo al vs. Inception / GoogLeNet" translate="no">​</a></h3>
<p>Inception usa convoluciones multi-escala en paralelo:</p>
<table><thead><tr><th>Característica</th><th>Inception</th><th>ResNet</th></tr></thead><tbody><tr><td>Enfoque</td><td>Características multi-escala</td><td>Apilamiento profundo</td></tr><tr><td>Complejidad</td><td>Mayor</td><td>Simple</td></tr><tr><td>Aplicabilidad para Go</td><td>General</td><td>Excelente</td></tr></tbody></table>
<p>El diseño simple de ResNet es más adecuado para tareas que requieren razonamiento profundo como Go.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-transformer">vs. Transformer<a href="#vs-transformer" class="hash-link" aria-label="Enlace directo al vs. Transformer" title="Enlace directo al vs. Transformer" translate="no">​</a></h3>
<p>La arquitectura Transformer propuesta en 2017 logró gran éxito en NLP. Algunos intentaron aplicar Transformer a Go:</p>
<table><thead><tr><th>Característica</th><th>ResNet</th><th>Transformer</th></tr></thead><tbody><tr><td>Sesgo inductivo</td><td>Localidad (convolución)</td><td>Atención global</td></tr><tr><td>Codificación de posición</td><td>Implícita (convolución)</td><td>Explícita</td></tr><tr><td>Rendimiento en Go</td><td>Excelente</td><td>Viable pero no superior a ResNet</td></tr><tr><td>Eficiencia computacional</td><td>Mayor</td><td>Menor (O(n²))</td></tr></tbody></table>
<p>Para problemas con estructura espacial obvia como Go, el sesgo inductivo de CNN/ResNet es más apropiado.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="análisis-profundo-de-decisiones-de-diseño">Análisis Profundo de Decisiones de Diseño<a href="#análisis-profundo-de-decisiones-de-diseño" class="hash-link" aria-label="Enlace directo al Análisis Profundo de Decisiones de Diseño" title="Enlace directo al Análisis Profundo de Decisiones de Diseño" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-usar-convoluciones-33">¿Por Qué Usar Convoluciones 3×3?<a href="#por-qué-usar-convoluciones-33" class="hash-link" aria-label="Enlace directo al ¿Por Qué Usar Convoluciones 3×3?" title="Enlace directo al ¿Por Qué Usar Convoluciones 3×3?" translate="no">​</a></h3>
<p>AlphaGo Zero usa convoluciones 3×3 en todo el proceso, en lugar de kernels más grandes:</p>
<ol>
<li class=""><strong>Eficiencia de parámetros</strong>: Dos convoluciones 3×3 tienen el mismo campo receptivo que una 5×5, pero menos parámetros (18 vs 25)</li>
<li class=""><strong>Redes más profundas</strong>: Con la misma cantidad de parámetros, se pueden apilar más capas</li>
<li class=""><strong>Más no-linealidad</strong>: ReLU entre cada capa, aumentando la capacidad expresiva</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-256-canales">¿Por Qué 256 Canales?<a href="#por-qué-256-canales" class="hash-link" aria-label="Enlace directo al ¿Por Qué 256 Canales?" title="Enlace directo al ¿Por Qué 256 Canales?" translate="no">​</a></h3>
<p>256 canales es una elección empírica:</p>
<ul>
<li class=""><strong>Muy pocos</strong> (como 64): Capacidad expresiva insuficiente, no puede capturar patrones complejos</li>
<li class=""><strong>Demasiados</strong> (como 512): Parámetros se duplican, costo de entrenamiento aumenta mucho, pero mejora de fuerza limitada</li>
</ul>
<p>Los experimentos posteriores de KataGo mostraron que los canales pueden ajustarse según recursos de entrenamiento:</p>
<ul>
<li class="">Bajos recursos: 128 canales, 20 bloques</li>
<li class="">Altos recursos: 256 canales, 40 bloques</li>
<li class="">Más recursos: 384 canales, 60 bloques</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="por-qué-policy-head-usa-softmax-y-value-head-usa-tanh">¿Por Qué Policy Head Usa Softmax y Value Head Usa Tanh?<a href="#por-qué-policy-head-usa-softmax-y-value-head-usa-tanh" class="hash-link" aria-label="Enlace directo al ¿Por Qué Policy Head Usa Softmax y Value Head Usa Tanh?" title="Enlace directo al ¿Por Qué Policy Head Usa Softmax y Value Head Usa Tanh?" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head-softmax">Policy Head: Softmax<a href="#policy-head-softmax" class="hash-link" aria-label="Enlace directo al Policy Head: Softmax" title="Enlace directo al Policy Head: Softmax" translate="no">​</a></h4>
<p>Jugar es un <strong>problema de clasificación</strong> -- elegir una entre 361 posiciones (más Pass). La salida Softmax satisface:</p>
<ul>
<li class="">Todas las probabilidades son no negativas: π_i &gt;= 0</li>
<li class="">Las probabilidades suman 1: Σπ_i = 1</li>
</ul>
<p>Esto es consistente con la definición de distribución de probabilidad.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head-tanh">Value Head: Tanh<a href="#value-head-tanh" class="hash-link" aria-label="Enlace directo al Value Head: Tanh" title="Enlace directo al Value Head: Tanh" translate="no">​</a></h4>
<p>La tasa de victoria es un <strong>problema de regresión</strong> -- predecir un valor continuo. El rango de salida de Tanh es [-1, 1]:</p>
<ul>
<li class="">Acotado: No producirá valores extremos</li>
<li class="">Simétrico: Victoria y derrota tratadas simétricamente</li>
<li class="">Diferenciable: Conveniente para cálculo de gradientes</li>
</ul>
<p>Usar Tanh en lugar de salida no acotada (como capa lineal) puede prevenir inestabilidad en el entrenamiento.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="detalles-de-entrenamiento">Detalles de Entrenamiento<a href="#detalles-de-entrenamiento" class="hash-link" aria-label="Enlace directo al Detalles de Entrenamiento" title="Enlace directo al Detalles de Entrenamiento" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="función-de-pérdida">Función de Pérdida<a href="#función-de-pérdida" class="hash-link" aria-label="Enlace directo al Función de Pérdida" title="Enlace directo al Función de Pérdida" translate="no">​</a></h3>
<p>La pérdida total de AlphaGo Zero es la suma de tres términos:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value + L_reg</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-loss">Policy Loss<a href="#policy-loss" class="hash-link" aria-label="Enlace directo al Policy Loss" title="Enlace directo al Policy Loss" translate="no">​</a></h4>
<p>Usa <strong>pérdida de entropía cruzada</strong>, haciendo que la salida de la red se aproxime a las probabilidades de búsqueda MCTS:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_policy = -Σ π_MCTS(a) × log(π_net(a))</span><br></span></code></pre></div></div>
<p>Donde:</p>
<ul>
<li class="">π_MCTS(a) es la probabilidad de búsqueda MCTS para acción a</li>
<li class="">π_net(a) es la probabilidad de salida de la red</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-loss">Value Loss<a href="#value-loss" class="hash-link" aria-label="Enlace directo al Value Loss" title="Enlace directo al Value Loss" translate="no">​</a></h4>
<p>Usa <strong>Error Cuadrático Medio (MSE)</strong>, haciendo que la salida de la red se aproxime al resultado real:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_value = (v_net - z)²</span><br></span></code></pre></div></div>
<p>Donde:</p>
<ul>
<li class="">v_net es la tasa de victoria predicha por la red</li>
<li class="">z es el resultado real de la partida (+1 o -1)</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="regularization-loss">Regularization Loss<a href="#regularization-loss" class="hash-link" aria-label="Enlace directo al Regularization Loss" title="Enlace directo al Regularization Loss" translate="no">​</a></h4>
<p>Usa <strong>regularización L2</strong> para prevenir sobreajuste:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_reg = c × ||θ||²</span><br></span></code></pre></div></div>
<p>Donde c es el coeficiente de regularización, θ son los parámetros de la red.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="configuración-del-optimizador">Configuración del Optimizador<a href="#configuración-del-optimizador" class="hash-link" aria-label="Enlace directo al Configuración del Optimizador" title="Enlace directo al Configuración del Optimizador" translate="no">​</a></h3>
<table><thead><tr><th>Parámetro</th><th>Valor</th></tr></thead><tbody><tr><td>Optimizador</td><td>SGD + Momentum</td></tr><tr><td>Momentum</td><td>0.9</td></tr><tr><td>Tasa de aprendizaje inicial</td><td>0.01</td></tr><tr><td>Decaimiento de tasa de aprendizaje</td><td>Reducir a mitad cada X pasos</td></tr><tr><td>Tamaño de batch</td><td>32 × 2048 = 64K (distribuido)</td></tr><tr><td>Coeficiente de regularización L2</td><td>1e-4</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="aumento-de-datos">Aumento de Datos<a href="#aumento-de-datos" class="hash-link" aria-label="Enlace directo al Aumento de Datos" title="Enlace directo al Aumento de Datos" translate="no">​</a></h3>
<p>El tablero de Go tiene 8 simetrías (4 rotaciones × 2 reflexiones). Durante el entrenamiento, cada posición puede producir 8 muestras de entrenamiento equivalentes.</p>
<p>Esto aumenta los datos de entrenamiento efectivos 8 veces, sin necesitar auto-juego adicional.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="consideraciones-de-implementación">Consideraciones de Implementación<a href="#consideraciones-de-implementación" class="hash-link" aria-label="Enlace directo al Consideraciones de Implementación" title="Enlace directo al Consideraciones de Implementación" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="optimización-de-memoria">Optimización de Memoria<a href="#optimización-de-memoria" class="hash-link" aria-label="Enlace directo al Optimización de Memoria" title="Enlace directo al Optimización de Memoria" translate="no">​</a></h3>
<p>Entrenar una ResNet de 40 capas requiere mucha memoria:</p>
<ul>
<li class=""><strong>Forward pass</strong>: Necesita almacenar activaciones de cada capa (para backpropagation)</li>
<li class=""><strong>Backward pass</strong>: Necesita almacenar gradientes</li>
</ul>
<p>Estrategias de optimización:</p>
<ol>
<li class=""><strong>Gradient Checkpointing</strong>: Solo almacenar algunas activaciones, recalcular cuando sea necesario</li>
<li class=""><strong>Entrenamiento de precisión mixta</strong>: Usar FP16 para reducir uso de memoria</li>
<li class=""><strong>Entrenamiento distribuido</strong>: Distribuir batch entre múltiples GPU/TPU</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="optimización-de-inferencia">Optimización de Inferencia<a href="#optimización-de-inferencia" class="hash-link" aria-label="Enlace directo al Optimización de Inferencia" title="Enlace directo al Optimización de Inferencia" translate="no">​</a></h3>
<p>Durante inferencia no se necesitan estadísticas de mini-batch de BN, se puede usar media móvil acumulada durante entrenamiento:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_moving) / sqrt(σ_moving² + ε)</span><br></span></code></pre></div></div>
<p>Esto hace la inferencia más rápida y determinista.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="cuantización-y-compresión">Cuantización y Compresión<a href="#cuantización-y-compresión" class="hash-link" aria-label="Enlace directo al Cuantización y Compresión" title="Enlace directo al Cuantización y Compresión" translate="no">​</a></h3>
<p>Se puede comprimir más la red para despliegue:</p>
<ul>
<li class=""><strong>Cuantización de pesos</strong>: FP32 → INT8, memoria reducida 4x</li>
<li class=""><strong>Poda</strong>: Eliminar conexiones de pesos pequeños</li>
<li class=""><strong>Destilación de conocimiento</strong>: Usar red grande para entrenar red pequeña</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="correspondencia-con-animaciones">Correspondencia con Animaciones<a href="#correspondencia-con-animaciones" class="hash-link" aria-label="Enlace directo al Correspondencia con Animaciones" title="Enlace directo al Correspondencia con Animaciones" translate="no">​</a></h2>
<p>Conceptos centrales cubiertos en este artículo y sus números de animación:</p>
<table><thead><tr><th>Número</th><th>Concepto</th><th>Correspondencia Física/Matemática</th></tr></thead><tbody><tr><td>E3</td><td>Red de doble cabeza</td><td>Aprendizaje multi-tarea</td></tr><tr><td>D12</td><td>Conexión residual</td><td>Autopista de gradientes</td></tr><tr><td>D8</td><td>Red neuronal convolucional</td><td>Campo receptivo local</td></tr><tr><td>D10</td><td>Batch Normalization</td><td>Normalización de distribución</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="lecturas-adicionales">Lecturas Adicionales<a href="#lecturas-adicionales" class="hash-link" aria-label="Enlace directo al Lecturas Adicionales" title="Enlace directo al Lecturas Adicionales" translate="no">​</a></h2>
<ul>
<li class=""><strong>Artículo anterior</strong>: <a class="" href="/es/docs/alphago/explained/alphago-zero/">Visión General de AlphaGo Zero</a> — Por qué no se necesitan partidas humanas</li>
<li class=""><strong>Siguiente artículo</strong>: <a class="" href="/es/docs/alphago/explained/training-from-scratch/">Proceso de Entrenamiento desde Cero</a> — Evolución detallada del Día 0-3</li>
<li class=""><strong>Profundización técnica</strong>: <a class="" href="/es/docs/alphago/explained/cnn-and-go/">CNN y Go</a> — Por qué CNN es adecuada para tableros</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="referencias">Referencias<a href="#referencias" class="hash-link" aria-label="Enlace directo al Referencias" title="Enlace directo al Referencias" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">He, K., et al. (2016). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR 2016</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&quot; <em>ICML 2015</em>.</li>
<li class="">Caruana, R. (1997). &quot;Multitask Learning.&quot; <em>Machine Learning</em>, 28(1), 41-75.</li>
<li class="">Veit, A., et al. (2016). &quot;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&quot; <em>NeurIPS 2016</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/explained/17-dual-head-resnet.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Editar esta página</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Página del documento"><a class="pagination-nav__link pagination-nav__link--prev" href="/es/docs/alphago/explained/alphago-zero/"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Visión General de AlphaGo Zero</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/es/docs/alphago/explained/training-from-scratch/"><div class="pagination-nav__sublabel">Siguiente</div><div class="pagination-nav__label">El proceso de entrenamiento desde cero</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#diseño-de-la-red-de-doble-cabeza" class="table-of-contents__link toc-highlight">Diseño de la Red de Doble Cabeza</a><ul><li><a href="#arquitectura-general" class="table-of-contents__link toc-highlight">Arquitectura General</a></li><li><a href="#backbone-compartido-shared-backbone" class="table-of-contents__link toc-highlight">Backbone Compartido (Shared Backbone)</a></li><li><a href="#policy-head-cabeza-de-política" class="table-of-contents__link toc-highlight">Policy Head (Cabeza de Política)</a></li><li><a href="#value-head-cabeza-de-valor" class="table-of-contents__link toc-highlight">Value Head (Cabeza de Valor)</a></li></ul></li><li><a href="#por-qué-compartir-el-backbone" class="table-of-contents__link toc-highlight">¿Por Qué Compartir el Backbone?</a><ul><li><a href="#comprensión-intuitiva" class="table-of-contents__link toc-highlight">Comprensión Intuitiva</a></li><li><a href="#perspectiva-del-aprendizaje-multi-tarea" class="table-of-contents__link toc-highlight">Perspectiva del Aprendizaje Multi-tarea</a></li><li><a href="#evidencia-experimental" class="table-of-contents__link toc-highlight">Evidencia Experimental</a></li></ul></li><li><a href="#principios-de-las-redes-residuales" class="table-of-contents__link toc-highlight">Principios de las Redes Residuales</a><ul><li><a href="#el-dilema-de-las-redes-profundas" class="table-of-contents__link toc-highlight">El Dilema de las Redes Profundas</a></li><li><a href="#diseño-del-bloque-residual" class="table-of-contents__link toc-highlight">Diseño del Bloque Residual</a></li><li><a href="#por-qué-funcionan-las-conexiones-residuales" class="table-of-contents__link toc-highlight">¿Por Qué Funcionan las Conexiones Residuales?</a></li><li><a href="#el-avance-de-resnet-en-imagenet" class="table-of-contents__link toc-highlight">El Avance de ResNet en ImageNet</a></li></ul></li><li><a href="#la-resnet-de-40-capas-de-alphago-zero" class="table-of-contents__link toc-highlight">La ResNet de 40 Capas de AlphaGo Zero</a><ul><li><a href="#por-qué-40-capas" class="table-of-contents__link toc-highlight">¿Por Qué 40 Capas?</a></li><li><a href="#configuración-específica" class="table-of-contents__link toc-highlight">Configuración Específica</a></li><li><a href="#el-rol-de-batch-normalization" class="table-of-contents__link toc-highlight">El Rol de Batch Normalization</a></li></ul></li><li><a href="#comparación-con-otras-arquitecturas" class="table-of-contents__link toc-highlight">Comparación con Otras Arquitecturas</a><ul><li><a href="#vs-cnn-del-alphago-original" class="table-of-contents__link toc-highlight">vs. CNN del AlphaGo Original</a></li><li><a href="#vs-red-estilo-vgg" class="table-of-contents__link toc-highlight">vs. Red Estilo VGG</a></li><li><a href="#vs-inception--googlenet" class="table-of-contents__link toc-highlight">vs. Inception / GoogLeNet</a></li><li><a href="#vs-transformer" class="table-of-contents__link toc-highlight">vs. Transformer</a></li></ul></li><li><a href="#análisis-profundo-de-decisiones-de-diseño" class="table-of-contents__link toc-highlight">Análisis Profundo de Decisiones de Diseño</a><ul><li><a href="#por-qué-usar-convoluciones-33" class="table-of-contents__link toc-highlight">¿Por Qué Usar Convoluciones 3×3?</a></li><li><a href="#por-qué-256-canales" class="table-of-contents__link toc-highlight">¿Por Qué 256 Canales?</a></li><li><a href="#por-qué-policy-head-usa-softmax-y-value-head-usa-tanh" class="table-of-contents__link toc-highlight">¿Por Qué Policy Head Usa Softmax y Value Head Usa Tanh?</a></li></ul></li><li><a href="#detalles-de-entrenamiento" class="table-of-contents__link toc-highlight">Detalles de Entrenamiento</a><ul><li><a href="#función-de-pérdida" class="table-of-contents__link toc-highlight">Función de Pérdida</a></li><li><a href="#configuración-del-optimizador" class="table-of-contents__link toc-highlight">Configuración del Optimizador</a></li><li><a href="#aumento-de-datos" class="table-of-contents__link toc-highlight">Aumento de Datos</a></li></ul></li><li><a href="#consideraciones-de-implementación" class="table-of-contents__link toc-highlight">Consideraciones de Implementación</a><ul><li><a href="#optimización-de-memoria" class="table-of-contents__link toc-highlight">Optimización de Memoria</a></li><li><a href="#optimización-de-inferencia" class="table-of-contents__link toc-highlight">Optimización de Inferencia</a></li><li><a href="#cuantización-y-compresión" class="table-of-contents__link toc-highlight">Cuantización y Compresión</a></li></ul></li><li><a href="#correspondencia-con-animaciones" class="table-of-contents__link toc-highlight">Correspondencia con Animaciones</a></li><li><a href="#lecturas-adicionales" class="table-of-contents__link toc-highlight">Lecturas Adicionales</a></li><li><a href="#referencias" class="table-of-contents__link toc-highlight">Referencias</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>