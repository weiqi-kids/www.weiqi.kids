<!doctype html>
<html lang="zh-cn" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/explained/dual-head-resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">双头网络与残差网络 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/zh-cn/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/zh-cn/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/zh-cn/docs/alphago/explained/dual-head-resnet/"><meta data-rh="true" property="og:locale" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="zh-cn"><meta data-rh="true" name="docsearch:language" content="zh-cn"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="双头网络与残差网络 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="深入解析 AlphaGo Zero 的神经网络架构 - 共享主干、Policy Head、Value Head 与 40 层 ResNet"><meta data-rh="true" property="og:description" content="深入解析 AlphaGo Zero 的神经网络架构 - 共享主干、Policy Head、Value Head 与 40 层 ResNet"><meta data-rh="true" name="keywords" content="双头网络,残差网络,ResNet,Policy Head,Value Head,深度学习,神经网络架构"><link data-rh="true" rel="icon" href="/zh-cn/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/dual-head-resnet/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/dual-head-resnet/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/dual-head-resnet/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/explained/dual-head-resnet/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/explained/dual-head-resnet/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/explained/dual-head-resnet/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/explained/dual-head-resnet/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/explained/dual-head-resnet/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/explained/dual-head-resnet/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/explained/dual-head-resnet/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/explained/dual-head-resnet/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/explained/dual-head-resnet/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/dual-head-resnet/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/zh-cn/docs/alphago/"},{"@type":"ListItem","position":2,"name":"完整解析","item":"https://www.weiqi.kids/zh-cn/docs/alphago/explained/"},{"@type":"ListItem","position":3,"name":"双头网络与残差网络","item":"https://www.weiqi.kids/zh-cn/docs/alphago/explained/dual-head-resnet"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/zh-cn/assets/css/styles.f23bf74b.css">
<script src="/zh-cn/assets/js/runtime~main.e14fb8f3.js" defer="defer"></script>
<script src="/zh-cn/assets/js/main.0c339658.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/zh-cn/img/logo.svg"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-cn/"><div class="navbar__logo"><img src="/zh-cn/img/logo.svg" alt="好棋宝宝协会标志" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/zh-cn/img/logo.svg" alt="好棋宝宝协会标志" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">围棋宝宝</b></a><a class="navbar__item navbar__link" href="/zh-cn/docs/learn/">学围棋</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-cn/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/zh-cn/docs/animations/">动画教室</a><a class="navbar__item navbar__link" href="/zh-cn/docs/tech/">技术文档</a><a class="navbar__item navbar__link" href="/zh-cn/docs/about/">关于我们</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/explained/dual-head-resnet/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-cn/docs/intro/"><span title="使用指南" class="linkLabel_REp1">使用指南</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="展开侧边栏分类 &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/zh-cn/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="折叠侧边栏分类 &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/zh-cn/docs/alphago/explained/"><span title="完整解析" class="categoryLinkLabel_ezQx">完整解析</span></a><button aria-label="折叠侧边栏分类 &#x27;完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/birth-of-alphago/"><span title="AlphaGo 的诞生" class="linkLabel_REp1">AlphaGo 的诞生</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/key-matches/"><span title="关键对局回顾" class="linkLabel_REp1">关键对局回顾</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/move-37/"><span title="「神之一手」深度分析" class="linkLabel_REp1">「神之一手」深度分析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/why-go-is-hard/"><span title="围棋为什么难？" class="linkLabel_REp1">围棋为什么难？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/traditional-limits/"><span title="传统方法的极限" class="linkLabel_REp1">传统方法的极限</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/board-representation/"><span title="棋盘状态表示" class="linkLabel_REp1">棋盘状态表示</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/policy-network/"><span title="Policy Network 详解" class="linkLabel_REp1">Policy Network 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/value-network/"><span title="Value Network 详解" class="linkLabel_REp1">Value Network 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/input-features/"><span title="输入特征设计" class="linkLabel_REp1">输入特征设计</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/cnn-and-go/"><span title="CNN 与围棋的结合" class="linkLabel_REp1">CNN 与围棋的结合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/supervised-learning/"><span title="监督学习阶段" class="linkLabel_REp1">监督学习阶段</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/reinforcement-intro/"><span title="强化学习入门" class="linkLabel_REp1">强化学习入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/self-play/"><span title="自我对弈" class="linkLabel_REp1">自我对弈</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/mcts-neural-combo/"><span title="MCTS 与神经网络的结合" class="linkLabel_REp1">MCTS 与神经网络的结合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/puct-formula/"><span title="PUCT 公式详解" class="linkLabel_REp1">PUCT 公式详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/alphago-zero/"><span title="AlphaGo Zero 概述" class="linkLabel_REp1">AlphaGo Zero 概述</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh-cn/docs/alphago/explained/dual-head-resnet/"><span title="双头网络与残差网络" class="linkLabel_REp1">双头网络与残差网络</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/training-from-scratch/"><span title="从零训练的过程" class="linkLabel_REp1">从零训练的过程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/distributed-systems/"><span title="分布式系统与 TPU" class="linkLabel_REp1">分布式系统与 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/legacy-and-impact/"><span title="AlphaGo 的遗产" class="linkLabel_REp1">AlphaGo 的遗产</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-cn/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="展开侧边栏分类 &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="展开侧边栏分类 &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/zh-cn/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/zh-cn/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/zh-cn/docs/alphago/explained/"><span>完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">双头网络与残差网络</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>双头网络与残差网络</h1></header>
<p>AlphaGo Zero 最重要的架构创新之一，是使用<strong>双头网络</strong>（Dual-Head Network）取代原版 AlphaGo 的双网络设计。这个看似简单的改变，却带来了显著的效能提升和更优雅的学习过程。</p>
<p>本文将深入解析这个架构的设计原理、数学基础，以及为什么它如此有效。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="双头网络设计">双头网络设计<a href="#双头网络设计" class="hash-link" aria-label="双头网络设计的直接链接" title="双头网络设计的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="整体架构">整体架构<a href="#整体架构" class="hash-link" aria-label="整体架构的直接链接" title="整体架构的直接链接" translate="no">​</a></h3>
<p>AlphaGo Zero 的神经网络可以分为三个部分：</p>
<!-- -->
<p>让我们逐一解析每个部分。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="共享主干shared-backbone">共享主干（Shared Backbone）<a href="#共享主干shared-backbone" class="hash-link" aria-label="共享主干（Shared Backbone）的直接链接" title="共享主干（Shared Backbone）的直接链接" translate="no">​</a></h3>
<p>共享主干是一个深层的<strong>残差网络（ResNet）</strong>，负责从棋盘状态中提取特征。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="架构细节">架构细节<a href="#架构细节" class="hash-link" aria-label="架构细节的直接链接" title="架构细节的直接链接" translate="no">​</a></h4>
<table><thead><tr><th>组件</th><th>规格</th></tr></thead><tbody><tr><td>输入层</td><td>3×3 卷积，256 通道</td></tr><tr><td>残差块</td><td>40 个（或 20 个精简版）</td></tr><tr><td>每个残差块</td><td>2 层 3×3 卷积，256 通道</td></tr><tr><td>激活函数</td><td>ReLU</td></tr><tr><td>正规化</td><td>Batch Normalization</td></tr></tbody></table>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学表示">数学表示<a href="#数学表示" class="hash-link" aria-label="数学表示的直接链接" title="数学表示的直接链接" translate="no">​</a></h4>
<p>设输入为 x（维度 17 x 19 x 19），共享主干的输出为：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">f(x) = ResNet_40(Conv_3x3(x))</span><br></span></code></pre></div></div>
<p>其中 f(x)（维度 256 x 19 x 19）是高维特征表示。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-head策略头">Policy Head（策略头）<a href="#policy-head策略头" class="hash-link" aria-label="Policy Head（策略头）的直接链接" title="Policy Head（策略头）的直接链接" translate="no">​</a></h3>
<p>Policy Head 负责预测每个位置的落子概率。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="架构细节-1">架构细节<a href="#架构细节-1" class="hash-link" aria-label="架构细节的直接链接" title="架构细节的直接链接" translate="no">​</a></h4>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学表示-1">数学表示<a href="#数学表示-1" class="hash-link" aria-label="数学表示的直接链接" title="数学表示的直接链接" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">π = Softmax(FC(Flatten(ReLU(BN(Conv_1x1(f(x)))))))</span><br></span></code></pre></div></div>
<p>输出 π 是一个 362 维向量，满足所有元素非负且和为 1。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="value-head价值头">Value Head（价值头）<a href="#value-head价值头" class="hash-link" aria-label="Value Head（价值头）的直接链接" title="Value Head（价值头）的直接链接" translate="no">​</a></h3>
<p>Value Head 负责预测当前局面的胜率。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="架构细节-2">架构细节<a href="#架构细节-2" class="hash-link" aria-label="架构细节的直接链接" title="架构细节的直接链接" translate="no">​</a></h4>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学表示-2">数学表示<a href="#数学表示-2" class="hash-link" aria-label="数学表示的直接链接" title="数学表示的直接链接" translate="no">​</a></h4>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">v = Tanh(FC_1(ReLU(FC_2(Flatten(ReLU(BN(Conv_1x1(f(x)))))))))</span><br></span></code></pre></div></div>
<p>输出 v 在 [-1, 1] 范围内：</p>
<ul>
<li class="">v = 1：当前方必胜</li>
<li class="">v = -1：当前方必败</li>
<li class="">v = 0：势均力敌</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么要共享主干">为什么要共享主干？<a href="#为什么要共享主干" class="hash-link" aria-label="为什么要共享主干？的直接链接" title="为什么要共享主干？的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="直觉理解">直觉理解<a href="#直觉理解" class="hash-link" aria-label="直觉理解的直接链接" title="直觉理解的直接链接" translate="no">​</a></h3>
<p>「下一步应该下哪里」（Policy）和「谁会赢」（Value）这两个问题，其实需要理解相同的棋盘模式：</p>
<ul>
<li class=""><strong>棋形</strong>：哪些形状是好的，哪些是坏的</li>
<li class=""><strong>势力</strong>：哪边更大，哪些地方还有空间</li>
<li class=""><strong>死活</strong>：哪些棋已经活了，哪些还在打劫</li>
<li class=""><strong>战斗</strong>：哪里有攻杀，局部胜负如何</li>
</ul>
<p>如果用两个独立的网络，这些特征需要学习两次。共享主干让这些底层特征只需学习一次，两个任务都能使用。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="多任务学习视角">多任务学习视角<a href="#多任务学习视角" class="hash-link" aria-label="多任务学习视角的直接链接" title="多任务学习视角的直接链接" translate="no">​</a></h3>
<p>从机器学习的角度，这是一种<strong>多任务学习（Multi-task Learning）</strong>：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value</span><br></span></code></pre></div></div>
<p>两个任务共享底层表示，这带来几个好处：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-正则化效果">1. 正则化效果<a href="#1-正则化效果" class="hash-link" aria-label="1. 正则化效果的直接链接" title="1. 正则化效果的直接链接" translate="no">​</a></h4>
<p>共享参数相当于隐式的正则化。如果一个特征只对 Policy 有用而对 Value 无用（或反之），它更难被过度放大。</p>
<p>有效参数量小于两个独立网络的参数量。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-数据效率">2. 数据效率<a href="#2-数据效率" class="hash-link" aria-label="2. 数据效率的直接链接" title="2. 数据效率的直接链接" translate="no">​</a></h4>
<p>每一局棋同时产生 Policy 标签（MCTS 搜索概率）和 Value 标签（最终胜负）。共享主干让两个标签都用于训练共享特征，提高了数据利用效率。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-梯度信号丰富">3. 梯度信号丰富<a href="#3-梯度信号丰富" class="hash-link" aria-label="3. 梯度信号丰富的直接链接" title="3. 梯度信号丰富的直接链接" translate="no">​</a></h4>
<p>两个任务的梯度都会流向共享主干：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂θ_shared = ∂L_policy/∂θ_shared + ∂L_value/∂θ_shared</span><br></span></code></pre></div></div>
<p>这提供了更丰富的监督信号，让共享特征更加稳健。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="实验证据">实验证据<a href="#实验证据" class="hash-link" aria-label="实验证据的直接链接" title="实验证据的直接链接" translate="no">​</a></h3>
<p>DeepMind 的消融实验显示，双头网络的表现显著优于分离的双网络：</p>
<table><thead><tr><th>配置</th><th>ELO 评分</th><th>相对差距</th></tr></thead><tbody><tr><td>分离的 Policy + Value 网络</td><td>基准</td><td>-</td></tr><tr><td>双头网络（共享主干）</td><td>+300 ELO</td><td>~65% 胜率差距</td></tr></tbody></table>
<p>300 ELO 的差距意味着双头网络对分离网络有约 65% 的胜率。这是一个显著的提升。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="残差网络原理">残差网络原理<a href="#残差网络原理" class="hash-link" aria-label="残差网络原理的直接链接" title="残差网络原理的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="深度网络的困境">深度网络的困境<a href="#深度网络的困境" class="hash-link" aria-label="深度网络的困境的直接链接" title="深度网络的困境的直接链接" translate="no">​</a></h3>
<p>在 ResNet 发明之前，深层神经网络面临一个悖论：</p>
<blockquote>
<p>理论上，更深的网络应该至少和浅层网络一样好（最差情况下，额外的层可以学习恒等映射）。但实际上，更深的网络往往表现更差。</p>
</blockquote>
<p>这就是<strong>退化问题（Degradation Problem）</strong>：</p>
<ul>
<li class="">训练误差随深度增加而增加（不是过拟合，是优化困难）</li>
<li class="">梯度在反向传播时逐渐消失（Vanishing Gradient）</li>
<li class="">深层的参数几乎无法被有效更新</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="残差块的设计">残差块的设计<a href="#残差块的设计" class="hash-link" aria-label="残差块的设计的直接链接" title="残差块的设计的直接链接" translate="no">​</a></h3>
<p>何恺明等人在 2015 年提出了一个简洁而优雅的解决方案：<strong>残差连接（Skip Connection）</strong>。</p>
<!-- -->
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="数学表示-3">数学表示<a href="#数学表示-3" class="hash-link" aria-label="数学表示的直接链接" title="数学表示的直接链接" translate="no">​</a></h4>
<p>传统网络：学习目标映射 H(x)</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = H(x)</span><br></span></code></pre></div></div>
<p>残差网络：学习<strong>残差映射</strong> F(x) = H(x) - x</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">y = F(x) + x</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么残差连接有效">为什么残差连接有效？<a href="#为什么残差连接有效" class="hash-link" aria-label="为什么残差连接有效？的直接链接" title="为什么残差连接有效？的直接链接" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-梯度高速公路">1. 梯度高速公路<a href="#1-梯度高速公路" class="hash-link" aria-label="1. 梯度高速公路的直接链接" title="1. 梯度高速公路的直接链接" translate="no">​</a></h4>
<p>考虑反向传播的梯度：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">∂L/∂x = ∂L/∂y × ∂y/∂x = ∂L/∂y × (1 + ∂F(x)/∂x)</span><br></span></code></pre></div></div>
<p>关键在于那个 <strong>+1</strong>。即使 ∂F(x)/∂x 很小或为零，梯度仍然可以通过 +1 直接传回去。</p>
<p>这就像修了一条「梯度高速公路」，让梯度可以畅通无阻地从输出层传回输入层。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-恒等映射更容易学习">2. 恒等映射更容易学习<a href="#2-恒等映射更容易学习" class="hash-link" aria-label="2. 恒等映射更容易学习的直接链接" title="2. 恒等映射更容易学习的直接链接" translate="no">​</a></h4>
<p>如果最优解接近恒等映射（H(x) 约等于 x），那么：</p>
<ul>
<li class="">传统网络：需要学习 H(x) = x，可能很难</li>
<li class="">残差网络：只需学习 F(x) 约等于 0，相对容易</li>
</ul>
<p>将权重初始化为零或接近零，残差块就自然趋向恒等映射。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-集成效应">3. 集成效应<a href="#3-集成效应" class="hash-link" aria-label="3. 集成效应的直接链接" title="3. 集成效应的直接链接" translate="no">​</a></h4>
<p>深层 ResNet 可以视为许多浅层网络的<strong>隐式集成</strong>。如果有 n 个残差块，信息可以通过 2^n 种不同的路径流动。</p>
<p>这种集成效应增加了模型的稳健性。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="resnet-在-imagenet-上的突破">ResNet 在 ImageNet 上的突破<a href="#resnet-在-imagenet-上的突破" class="hash-link" aria-label="ResNet 在 ImageNet 上的突破的直接链接" title="ResNet 在 ImageNet 上的突破的直接链接" translate="no">​</a></h3>
<p>ResNet 在 2015 年 ImageNet 竞赛中取得了惊人的成绩：</p>
<table><thead><tr><th>深度</th><th>Top-5 错误率</th></tr></thead><tbody><tr><td>VGG-19（无残差）</td><td>7.3%</td></tr><tr><td>ResNet-34</td><td>5.7%</td></tr><tr><td>ResNet-152</td><td>4.5%</td></tr><tr><td>人类水平</td><td>~5.1%</td></tr></tbody></table>
<p><strong>152 层</strong>的 ResNet 不仅可以训练，还比 19 层的 VGG 好得多。这证明了残差连接确实解决了深度网络的训练问题。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero-的-40-层-resnet">AlphaGo Zero 的 40 层 ResNet<a href="#alphago-zero-的-40-层-resnet" class="hash-link" aria-label="AlphaGo Zero 的 40 层 ResNet的直接链接" title="AlphaGo Zero 的 40 层 ResNet的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么选择-40-层">为什么选择 40 层？<a href="#为什么选择-40-层" class="hash-link" aria-label="为什么选择 40 层？的直接链接" title="为什么选择 40 层？的直接链接" translate="no">​</a></h3>
<p>DeepMind 测试了不同深度的 ResNet：</p>
<table><thead><tr><th>残差块数量</th><th>总层数</th><th>ELO 评分</th></tr></thead><tbody><tr><td>5</td><td>11</td><td>基准</td></tr><tr><td>10</td><td>21</td><td>+200</td></tr><tr><td>20</td><td>41</td><td>+400</td></tr><tr><td>40</td><td>81</td><td>+500</td></tr></tbody></table>
<p>更深的网络确实更强，但边际效益递减。AlphaGo Zero 使用 20 或 40 个残差块：</p>
<ul>
<li class=""><strong>AlphaGo Zero（论文版）</strong>：40 个残差块，256 通道</li>
<li class=""><strong>精简版</strong>：20 个残差块，256 通道</li>
</ul>
<p>40 层的配置在棋力和训练成本之间取得了良好的平衡。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="具体配置">具体配置<a href="#具体配置" class="hash-link" aria-label="具体配置的直接链接" title="具体配置的直接链接" translate="no">​</a></h3>
<p>AlphaGo Zero 的 ResNet 配置如下：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">输入：17 × 19 × 19</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">卷积层：3×3, 256 通道, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">残差块 ×40：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ 卷积层：3×3, 256 通道, BN, ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ├─ 卷积层：3×3, 256 通道, BN</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  └─ 跳跃连接 + ReLU</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Policy Head / Value Head</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="参数量估计">参数量估计<a href="#参数量估计" class="hash-link" aria-label="参数量估计的直接链接" title="参数量估计的直接链接" translate="no">​</a></h4>
<table><thead><tr><th>组件</th><th>参数量（约）</th></tr></thead><tbody><tr><td>输入卷积</td><td>17 × 3 × 3 × 256 ≈ 39K</td></tr><tr><td>每个残差块</td><td>2 × 256 × 3 × 3 × 256 ≈ 1.2M</td></tr><tr><td>40 个残差块</td><td>40 × 1.2M ≈ 47M</td></tr><tr><td>Policy Head</td><td>~1M</td></tr><tr><td>Value Head</td><td>~0.2M</td></tr><tr><td><strong>总计</strong></td><td><strong>~48M</strong></td></tr></tbody></table>
<p>约 4800 万参数，以现代标准来看是中等规模的神经网络。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="batch-normalization-的作用">Batch Normalization 的作用<a href="#batch-normalization-的作用" class="hash-link" aria-label="Batch Normalization 的作用的直接链接" title="Batch Normalization 的作用的直接链接" translate="no">​</a></h3>
<p>每个卷积层之后都有 <strong>Batch Normalization（BN）</strong>，这对训练稳定性至关重要：</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-正规化激活值">1. 正规化激活值<a href="#1-正规化激活值" class="hash-link" aria-label="1. 正规化激活值的直接链接" title="1. 正规化激活值的直接链接" translate="no">​</a></h4>
<p>BN 将每一层的激活值正规化到均值为 0、方差为 1：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_B) / sqrt(σ_B² + ε)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y = γ × x_hat + β</span><br></span></code></pre></div></div>
<p>其中 γ 和 β 是可学习的参数。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-缓解内部协变量偏移">2. 缓解内部协变量偏移<a href="#2-缓解内部协变量偏移" class="hash-link" aria-label="2. 缓解内部协变量偏移的直接链接" title="2. 缓解内部协变量偏移的直接链接" translate="no">​</a></h4>
<p>深层网络中，每一层的输入分布会随着前面层的参数更新而改变。BN 让每一层的输入分布保持稳定，加速训练收敛。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-正则化效果">3. 正则化效果<a href="#3-正则化效果" class="hash-link" aria-label="3. 正则化效果的直接链接" title="3. 正则化效果的直接链接" translate="no">​</a></h4>
<p>BN 在训练时使用 mini-batch 的统计量，引入了随机性，有轻微的正则化效果。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="与其他架构的比较">与其他架构的比较<a href="#与其他架构的比较" class="hash-link" aria-label="与其他架构的比较的直接链接" title="与其他架构的比较的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-原版-alphago-的-cnn">vs. 原版 AlphaGo 的 CNN<a href="#vs-原版-alphago-的-cnn" class="hash-link" aria-label="vs. 原版 AlphaGo 的 CNN的直接链接" title="vs. 原版 AlphaGo 的 CNN的直接链接" translate="no">​</a></h3>
<table><thead><tr><th>特性</th><th>AlphaGo 原版</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>架构类型</td><td>标准 CNN</td><td>ResNet</td></tr><tr><td>深度</td><td>13 层</td><td>41-81 层</td></tr><tr><td>残差连接</td><td>无</td><td>有</td></tr><tr><td>网络数量</td><td>2（分离）</td><td>1（共享）</td></tr><tr><td>BN</td><td>无</td><td>有</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-vgg-风格网络">vs. VGG 风格网络<a href="#vs-vgg-风格网络" class="hash-link" aria-label="vs. VGG 风格网络的直接链接" title="vs. VGG 风格网络的直接链接" translate="no">​</a></h3>
<p>VGG 是 2014 年 ImageNet 亚军的架构，使用堆叠的 3×3 卷积：</p>
<table><thead><tr><th>特性</th><th>VGG</th><th>ResNet</th></tr></thead><tbody><tr><td>最大可训练深度</td><td>~19 层</td><td>152+ 层</td></tr><tr><td>梯度流动</td><td>逐层递减</td><td>有高速公路</td></tr><tr><td>训练难度</td><td>深层困难</td><td>深层可训练</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-inception--googlenet">vs. Inception / GoogLeNet<a href="#vs-inception--googlenet" class="hash-link" aria-label="vs. Inception / GoogLeNet的直接链接" title="vs. Inception / GoogLeNet的直接链接" translate="no">​</a></h3>
<p>Inception 使用多尺度卷积并行：</p>
<table><thead><tr><th>特性</th><th>Inception</th><th>ResNet</th></tr></thead><tbody><tr><td>特点</td><td>多尺度特征</td><td>深度堆叠</td></tr><tr><td>复杂度</td><td>较高</td><td>简洁</td></tr><tr><td>围棋适用性</td><td>一般</td><td>优秀</td></tr></tbody></table>
<p>ResNet 的简洁设计更适合围棋这种需要深层推理的任务。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="vs-transformer">vs. Transformer<a href="#vs-transformer" class="hash-link" aria-label="vs. Transformer的直接链接" title="vs. Transformer的直接链接" translate="no">​</a></h3>
<p>2017 年提出的 Transformer 架构在 NLP 领域取得了巨大成功。有人尝试将 Transformer 应用于围棋：</p>
<table><thead><tr><th>特性</th><th>ResNet</th><th>Transformer</th></tr></thead><tbody><tr><td>归纳偏置</td><td>局部性（卷积）</td><td>全局注意力</td></tr><tr><td>位置编码</td><td>隐式（卷积）</td><td>显式</td></tr><tr><td>围棋表现</td><td>优秀</td><td>可行但不优于 ResNet</td></tr><tr><td>计算效率</td><td>较高</td><td>较低（O(n²)）</td></tr></tbody></table>
<p>对于围棋这种有明显空间结构的问题，CNN/ResNet 的归纳偏置更加合适。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="设计选择的深入分析">设计选择的深入分析<a href="#设计选择的深入分析" class="hash-link" aria-label="设计选择的深入分析的直接链接" title="设计选择的深入分析的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么用-33-卷积">为什么用 3×3 卷积？<a href="#为什么用-33-卷积" class="hash-link" aria-label="为什么用 3×3 卷积？的直接链接" title="为什么用 3×3 卷积？的直接链接" translate="no">​</a></h3>
<p>AlphaGo Zero 全程使用 3×3 卷积，而非更大的卷积核：</p>
<ol>
<li class=""><strong>参数效率</strong>：两个 3×3 卷积的感受野等于一个 5×5，但参数量更少（18 vs 25）</li>
<li class=""><strong>更深的网络</strong>：相同参数量下，可以堆叠更多层</li>
<li class=""><strong>更多非线性</strong>：每层之间有 ReLU，增加表达能力</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么用-256-通道">为什么用 256 通道？<a href="#为什么用-256-通道" class="hash-link" aria-label="为什么用 256 通道？的直接链接" title="为什么用 256 通道？的直接链接" translate="no">​</a></h3>
<p>256 通道是一个经验性的选择：</p>
<ul>
<li class=""><strong>太少</strong>（如 64）：表达能力不足，无法捕捉复杂模式</li>
<li class=""><strong>太多</strong>（如 512）：参数量翻倍，训练成本大增，但棋力提升有限</li>
</ul>
<p>后来的 KataGo 实验显示，通道数可以根据训练资源调整：</p>
<ul>
<li class="">低资源：128 通道，20 块</li>
<li class="">高资源：256 通道，40 块</li>
<li class="">更高资源：384 通道，60 块</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么-policy-head-用-softmaxvalue-head-用-tanh">为什么 Policy Head 用 Softmax、Value Head 用 Tanh？<a href="#为什么-policy-head-用-softmaxvalue-head-用-tanh" class="hash-link" aria-label="为什么 Policy Head 用 Softmax、Value Head 用 Tanh？的直接链接" title="为什么 Policy Head 用 Softmax、Value Head 用 Tanh？的直接链接" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-headsoftmax">Policy Head：Softmax<a href="#policy-headsoftmax" class="hash-link" aria-label="Policy Head：Softmax的直接链接" title="Policy Head：Softmax的直接链接" translate="no">​</a></h4>
<p>落子是一个<strong>分类问题</strong>——361 个位置（加 Pass）中选择一个。Softmax 输出满足：</p>
<ul>
<li class="">所有概率非负：π_i &gt;= 0</li>
<li class="">概率和为 1：Σπ_i = 1</li>
</ul>
<p>这与概率分布的定义一致。</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-headtanh">Value Head：Tanh<a href="#value-headtanh" class="hash-link" aria-label="Value Head：Tanh的直接链接" title="Value Head：Tanh的直接链接" translate="no">​</a></h4>
<p>胜率是一个<strong>回归问题</strong>——预测一个连续值。Tanh 输出范围是 [-1, 1]：</p>
<ul>
<li class="">有界：不会产生极端值</li>
<li class="">对称：胜和负对称处理</li>
<li class="">可微：方便梯度计算</li>
</ul>
<p>使用 Tanh 而非无界输出（如线性层）可以防止训练不稳定。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="训练细节">训练细节<a href="#训练细节" class="hash-link" aria-label="训练细节的直接链接" title="训练细节的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="损失函数">损失函数<a href="#损失函数" class="hash-link" aria-label="损失函数的直接链接" title="损失函数的直接链接" translate="no">​</a></h3>
<p>AlphaGo Zero 的总损失是三项之和：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L = L_policy + L_value + L_reg</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="policy-loss">Policy Loss<a href="#policy-loss" class="hash-link" aria-label="Policy Loss的直接链接" title="Policy Loss的直接链接" translate="no">​</a></h4>
<p>使用<strong>交叉熵损失</strong>，让网络输出逼近 MCTS 搜索概率：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_policy = -Σ π_MCTS(a) × log(π_net(a))</span><br></span></code></pre></div></div>
<p>其中：</p>
<ul>
<li class="">π_MCTS(a) 是 MCTS 对动作 a 的搜索概率</li>
<li class="">π_net(a) 是网络输出的概率</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="value-loss">Value Loss<a href="#value-loss" class="hash-link" aria-label="Value Loss的直接链接" title="Value Loss的直接链接" translate="no">​</a></h4>
<p>使用<strong>均方误差（MSE）</strong>，让网络输出逼近实际胜负：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_value = (v_net - z)²</span><br></span></code></pre></div></div>
<p>其中：</p>
<ul>
<li class="">v_net 是网络预测的胜率</li>
<li class="">z 是实际比赛结果（+1 或 -1）</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="regularization-loss">Regularization Loss<a href="#regularization-loss" class="hash-link" aria-label="Regularization Loss的直接链接" title="Regularization Loss的直接链接" translate="no">​</a></h4>
<p>使用 <strong>L2 正则化</strong>防止过拟合：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">L_reg = c × ||θ||²</span><br></span></code></pre></div></div>
<p>其中 c 是正则化系数，θ 是网络参数。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="优化器配置">优化器配置<a href="#优化器配置" class="hash-link" aria-label="优化器配置的直接链接" title="优化器配置的直接链接" translate="no">​</a></h3>
<table><thead><tr><th>参数</th><th>值</th></tr></thead><tbody><tr><td>优化器</td><td>SGD + Momentum</td></tr><tr><td>动量</td><td>0.9</td></tr><tr><td>初始学习率</td><td>0.01</td></tr><tr><td>学习率衰减</td><td>每 X 步减半</td></tr><tr><td>Batch Size</td><td>32 × 2048 = 64K（分布式）</td></tr><tr><td>L2 正则化系数</td><td>1e-4</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="数据增强">数据增强<a href="#数据增强" class="hash-link" aria-label="数据增强的直接链接" title="数据增强的直接链接" translate="no">​</a></h3>
<p>围棋棋盘有 8 重对称性（4 次旋转 × 2 次翻转）。训练时，每个局面可以产生 8 个等价的训练样本。</p>
<p>这让有效训练数据增加 8 倍，且不需要额外的自我对弈。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="实现考量">实现考量<a href="#实现考量" class="hash-link" aria-label="实现考量的直接链接" title="实现考量的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="内存优化">内存优化<a href="#内存优化" class="hash-link" aria-label="内存优化的直接链接" title="内存优化的直接链接" translate="no">​</a></h3>
<p>40 层 ResNet 的训练需要大量内存：</p>
<ul>
<li class=""><strong>前向传播</strong>：需要存储每层的激活值（用于反向传播）</li>
<li class=""><strong>反向传播</strong>：需要存储梯度</li>
</ul>
<p>优化策略：</p>
<ol>
<li class=""><strong>梯度检查点（Gradient Checkpointing）</strong>：只存储部分激活值，需要时重新计算</li>
<li class=""><strong>混合精度训练</strong>：使用 FP16 减少内存占用</li>
<li class=""><strong>分布式训练</strong>：将 batch 分散到多个 GPU/TPU</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="推理优化">推理优化<a href="#推理优化" class="hash-link" aria-label="推理优化的直接链接" title="推理优化的直接链接" translate="no">​</a></h3>
<p>推理时不需要 BN 的 mini-batch 统计量，可以使用训练时累积的移动平均：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">x_hat = (x - μ_moving) / sqrt(σ_moving² + ε)</span><br></span></code></pre></div></div>
<p>这让推理速度更快且结果确定性。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="量化与压缩">量化与压缩<a href="#量化与压缩" class="hash-link" aria-label="量化与压缩的直接链接" title="量化与压缩的直接链接" translate="no">​</a></h3>
<p>部署时可以进一步压缩网络：</p>
<ul>
<li class=""><strong>权重量化</strong>：FP32 → INT8，内存减少 4 倍</li>
<li class=""><strong>剪枝</strong>：移除小权重连接</li>
<li class=""><strong>知识蒸馏</strong>：用大网络训练小网络</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="动画对应">动画对应<a href="#动画对应" class="hash-link" aria-label="动画对应的直接链接" title="动画对应的直接链接" translate="no">​</a></h2>
<p>本文涉及的核心概念与动画编号：</p>
<table><thead><tr><th>编号</th><th>概念</th><th>物理/数学对应</th></tr></thead><tbody><tr><td>🎬 E3</td><td>双头网络</td><td>多任务学习</td></tr><tr><td>🎬 D12</td><td>残差连接</td><td>梯度高速公路</td></tr><tr><td>🎬 D8</td><td>卷积神经网络</td><td>局部感受野</td></tr><tr><td>🎬 D10</td><td>Batch Normalization</td><td>分布正规化</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="延伸阅读">延伸阅读<a href="#延伸阅读" class="hash-link" aria-label="延伸阅读的直接链接" title="延伸阅读的直接链接" translate="no">​</a></h2>
<ul>
<li class=""><strong>上一篇</strong>：<a class="" href="/zh-cn/docs/alphago/explained/alphago-zero/">AlphaGo Zero 概述</a> — 为什么不需要人类棋谱</li>
<li class=""><strong>下一篇</strong>：<a class="" href="/zh-cn/docs/alphago/explained/training-from-scratch/">从零训练的过程</a> — Day 0-3 的详细演进</li>
<li class=""><strong>技术深入</strong>：<a class="" href="/zh-cn/docs/alphago/explained/cnn-and-go/">CNN 与围棋的结合</a> — 为什么 CNN 适合棋盘</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="参考资料">参考资料<a href="#参考资料" class="hash-link" aria-label="参考资料的直接链接" title="参考资料的直接链接" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">He, K., et al. (2016). &quot;Deep Residual Learning for Image Recognition.&quot; <em>CVPR 2016</em>.</li>
<li class="">Ioffe, S., &amp; Szegedy, C. (2015). &quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.&quot; <em>ICML 2015</em>.</li>
<li class="">Caruana, R. (1997). &quot;Multitask Learning.&quot; <em>Machine Learning</em>, 28(1), 41-75.</li>
<li class="">Veit, A., et al. (2016). &quot;Residual Networks Behave Like Ensembles of Relatively Shallow Networks.&quot; <em>NeurIPS 2016</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/explained/17-dual-head-resnet.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-cn/docs/alphago/explained/alphago-zero/"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">AlphaGo Zero 概述</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-cn/docs/alphago/explained/training-from-scratch/"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">从零训练的过程</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#双头网络设计" class="table-of-contents__link toc-highlight">双头网络设计</a><ul><li><a href="#整体架构" class="table-of-contents__link toc-highlight">整体架构</a></li><li><a href="#共享主干shared-backbone" class="table-of-contents__link toc-highlight">共享主干（Shared Backbone）</a></li><li><a href="#policy-head策略头" class="table-of-contents__link toc-highlight">Policy Head（策略头）</a></li><li><a href="#value-head价值头" class="table-of-contents__link toc-highlight">Value Head（价值头）</a></li></ul></li><li><a href="#为什么要共享主干" class="table-of-contents__link toc-highlight">为什么要共享主干？</a><ul><li><a href="#直觉理解" class="table-of-contents__link toc-highlight">直觉理解</a></li><li><a href="#多任务学习视角" class="table-of-contents__link toc-highlight">多任务学习视角</a></li><li><a href="#实验证据" class="table-of-contents__link toc-highlight">实验证据</a></li></ul></li><li><a href="#残差网络原理" class="table-of-contents__link toc-highlight">残差网络原理</a><ul><li><a href="#深度网络的困境" class="table-of-contents__link toc-highlight">深度网络的困境</a></li><li><a href="#残差块的设计" class="table-of-contents__link toc-highlight">残差块的设计</a></li><li><a href="#为什么残差连接有效" class="table-of-contents__link toc-highlight">为什么残差连接有效？</a></li><li><a href="#resnet-在-imagenet-上的突破" class="table-of-contents__link toc-highlight">ResNet 在 ImageNet 上的突破</a></li></ul></li><li><a href="#alphago-zero-的-40-层-resnet" class="table-of-contents__link toc-highlight">AlphaGo Zero 的 40 层 ResNet</a><ul><li><a href="#为什么选择-40-层" class="table-of-contents__link toc-highlight">为什么选择 40 层？</a></li><li><a href="#具体配置" class="table-of-contents__link toc-highlight">具体配置</a></li><li><a href="#batch-normalization-的作用" class="table-of-contents__link toc-highlight">Batch Normalization 的作用</a></li></ul></li><li><a href="#与其他架构的比较" class="table-of-contents__link toc-highlight">与其他架构的比较</a><ul><li><a href="#vs-原版-alphago-的-cnn" class="table-of-contents__link toc-highlight">vs. 原版 AlphaGo 的 CNN</a></li><li><a href="#vs-vgg-风格网络" class="table-of-contents__link toc-highlight">vs. VGG 风格网络</a></li><li><a href="#vs-inception--googlenet" class="table-of-contents__link toc-highlight">vs. Inception / GoogLeNet</a></li><li><a href="#vs-transformer" class="table-of-contents__link toc-highlight">vs. Transformer</a></li></ul></li><li><a href="#设计选择的深入分析" class="table-of-contents__link toc-highlight">设计选择的深入分析</a><ul><li><a href="#为什么用-33-卷积" class="table-of-contents__link toc-highlight">为什么用 3×3 卷积？</a></li><li><a href="#为什么用-256-通道" class="table-of-contents__link toc-highlight">为什么用 256 通道？</a></li><li><a href="#为什么-policy-head-用-softmaxvalue-head-用-tanh" class="table-of-contents__link toc-highlight">为什么 Policy Head 用 Softmax、Value Head 用 Tanh？</a></li></ul></li><li><a href="#训练细节" class="table-of-contents__link toc-highlight">训练细节</a><ul><li><a href="#损失函数" class="table-of-contents__link toc-highlight">损失函数</a></li><li><a href="#优化器配置" class="table-of-contents__link toc-highlight">优化器配置</a></li><li><a href="#数据增强" class="table-of-contents__link toc-highlight">数据增强</a></li></ul></li><li><a href="#实现考量" class="table-of-contents__link toc-highlight">实现考量</a><ul><li><a href="#内存优化" class="table-of-contents__link toc-highlight">内存优化</a></li><li><a href="#推理优化" class="table-of-contents__link toc-highlight">推理优化</a></li><li><a href="#量化与压缩" class="table-of-contents__link toc-highlight">量化与压缩</a></li></ul></li><li><a href="#动画对应" class="table-of-contents__link toc-highlight">动画对应</a></li><li><a href="#延伸阅读" class="table-of-contents__link toc-highlight">延伸阅读</a></li><li><a href="#参考资料" class="table-of-contents__link toc-highlight">参考资料</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>