<!doctype html>
<html lang="zh-cn" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-alphago/explained/self-play" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">自我对弈 | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/zh-cn/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/zh-cn/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/zh-cn/docs/alphago/explained/self-play/"><meta data-rh="true" property="og:locale" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="zh-cn"><meta data-rh="true" name="docsearch:language" content="zh-cn"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="自我对弈 | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="深入理解 AlphaGo 如何透过自我对弈突破人类棋力的极限"><meta data-rh="true" property="og:description" content="深入理解 AlphaGo 如何透过自我对弈突破人类棋力的极限"><link data-rh="true" rel="icon" href="/zh-cn/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/self-play/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/self-play/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/alphago/explained/self-play/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/alphago/explained/self-play/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/alphago/explained/self-play/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/alphago/explained/self-play/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/alphago/explained/self-play/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/alphago/explained/self-play/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/alphago/explained/self-play/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/alphago/explained/self-play/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/alphago/explained/self-play/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/alphago/explained/self-play/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/alphago/explained/self-play/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AlphaGo","item":"https://www.weiqi.kids/zh-cn/docs/alphago/"},{"@type":"ListItem","position":2,"name":"完整解析","item":"https://www.weiqi.kids/zh-cn/docs/alphago/explained/"},{"@type":"ListItem","position":3,"name":"自我对弈","item":"https://www.weiqi.kids/zh-cn/docs/alphago/explained/self-play"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/zh-cn/assets/css/styles.f23bf74b.css">
<script src="/zh-cn/assets/js/runtime~main.e14fb8f3.js" defer="defer"></script>
<script src="/zh-cn/assets/js/main.0c339658.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/zh-cn/img/logo.svg"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-cn/"><div class="navbar__logo"><img src="/zh-cn/img/logo.svg" alt="好棋宝宝协会标志" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/zh-cn/img/logo.svg" alt="好棋宝宝协会标志" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">围棋宝宝</b></a><a class="navbar__item navbar__link" href="/zh-cn/docs/learn/">学围棋</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-cn/docs/alphago/">AlphaGo</a><a class="navbar__item navbar__link" href="/zh-cn/docs/animations/">动画教室</a><a class="navbar__item navbar__link" href="/zh-cn/docs/tech/">技术文档</a><a class="navbar__item navbar__link" href="/zh-cn/docs/about/">关于我们</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/alphago/explained/self-play/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-cn/docs/intro/"><span title="使用指南" class="linkLabel_REp1">使用指南</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/learn/"><span title="學圍棋" class="categoryLinkLabel_ezQx">學圍棋</span></a><button aria-label="展开侧边栏分类 &#x27;學圍棋&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/zh-cn/docs/alphago/"><span title="AlphaGo" class="categoryLinkLabel_ezQx">AlphaGo</span></a><button aria-label="折叠侧边栏分类 &#x27;AlphaGo&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/zh-cn/docs/alphago/explained/"><span title="完整解析" class="categoryLinkLabel_ezQx">完整解析</span></a><button aria-label="折叠侧边栏分类 &#x27;完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/birth-of-alphago/"><span title="AlphaGo 的诞生" class="linkLabel_REp1">AlphaGo 的诞生</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/key-matches/"><span title="关键对局回顾" class="linkLabel_REp1">关键对局回顾</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/move-37/"><span title="「神之一手」深度分析" class="linkLabel_REp1">「神之一手」深度分析</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/why-go-is-hard/"><span title="围棋为什么难？" class="linkLabel_REp1">围棋为什么难？</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/traditional-limits/"><span title="传统方法的极限" class="linkLabel_REp1">传统方法的极限</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/board-representation/"><span title="棋盘状态表示" class="linkLabel_REp1">棋盘状态表示</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/policy-network/"><span title="Policy Network 详解" class="linkLabel_REp1">Policy Network 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/value-network/"><span title="Value Network 详解" class="linkLabel_REp1">Value Network 详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/input-features/"><span title="输入特征设计" class="linkLabel_REp1">输入特征设计</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/cnn-and-go/"><span title="CNN 与围棋的结合" class="linkLabel_REp1">CNN 与围棋的结合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/supervised-learning/"><span title="监督学习阶段" class="linkLabel_REp1">监督学习阶段</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/reinforcement-intro/"><span title="强化学习入门" class="linkLabel_REp1">强化学习入门</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh-cn/docs/alphago/explained/self-play/"><span title="自我对弈" class="linkLabel_REp1">自我对弈</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/mcts-neural-combo/"><span title="MCTS 与神经网络的结合" class="linkLabel_REp1">MCTS 与神经网络的结合</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/puct-formula/"><span title="PUCT 公式详解" class="linkLabel_REp1">PUCT 公式详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/alphago-zero/"><span title="AlphaGo Zero 概述" class="linkLabel_REp1">AlphaGo Zero 概述</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/dual-head-resnet/"><span title="双头网络与残差网络" class="linkLabel_REp1">双头网络与残差网络</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/training-from-scratch/"><span title="从零训练的过程" class="linkLabel_REp1">从零训练的过程</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/distributed-systems/"><span title="分布式系统与 TPU" class="linkLabel_REp1">分布式系统与 TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-cn/docs/alphago/explained/legacy-and-impact/"><span title="AlphaGo 的遗产" class="linkLabel_REp1">AlphaGo 的遗产</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-cn/docs/animations/"><span title="動畫教室" class="linkLabel_REp1">動畫教室</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/tech/"><span title="技術文件" class="categoryLinkLabel_ezQx">技術文件</span></a><button aria-label="展开侧边栏分类 &#x27;技術文件&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/zh-cn/docs/about/"><span title="關於我們" class="categoryLinkLabel_ezQx">關於我們</span></a><button aria-label="展开侧边栏分类 &#x27;關於我們&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/zh-cn/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/zh-cn/docs/alphago/"><span>AlphaGo</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/zh-cn/docs/alphago/explained/"><span>完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">自我对弈</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>自我对弈</h1></header>
<p>在前一篇文章中，我们介绍了强化学习的基本概念。现在，让我们探讨 AlphaGo 成功的关键之一——<strong>自我对弈（Self-Play）</strong>。</p>
<p>这是一个看似矛盾的概念：<strong>AI 怎么能透过和自己下棋变得更强？</strong></p>
<p>答案既深刻又优雅，涉及博弈论、演化动力学、以及学习的本质。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="为什么自我对弈有效">为什么自我对弈有效？<a href="#为什么自我对弈有效" class="hash-link" aria-label="为什么自我对弈有效？的直接链接" title="为什么自我对弈有效？的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="直觉解释">直觉解释<a href="#直觉解释" class="hash-link" aria-label="直觉解释的直接链接" title="直觉解释的直接链接" translate="no">​</a></h3>
<p>想象你是一位围棋初学者，在一个荒岛上独自练习：</p>
<ol>
<li class="">你下了一盘棋，自己同时扮演黑白双方</li>
<li class="">对局结束后，你分析哪些棋下得好、哪些下得差</li>
<li class="">下一盘棋时，你尝试避免之前的错误</li>
<li class="">你重复这个过程数百万次</li>
</ol>
<p>直觉上，这似乎有问题：</p>
<ul>
<li class="">如果你的水平很差，黑白双方都下差棋，能学到什么？</li>
<li class="">会不会陷入「错误的平衡」——双方都下错棋但能互相抵消？</li>
</ul>
<p>但实际上，自我对弈能够产生持续的进步。原因如下：</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="渐进式发现弱点">渐进式发现弱点<a href="#渐进式发现弱点" class="hash-link" aria-label="渐进式发现弱点的直接链接" title="渐进式发现弱点的直接链接" translate="no">​</a></h3>
<p>关键洞见是：<strong>即使双方都是同一个 AI，每盘棋的结果仍然包含信息</strong>。</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">局面 A：AI 选择了走法 X，最终获胜</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">局面 A：AI 选择了走法 Y，最终失败</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">→ 结论：在局面 A 中，X 比 Y 好</span><br></span></code></pre></div></div>
<p>透过统计大量对局，AI 能够学习到每个局面下哪些选择更优。这就是<strong>策略梯度</strong>的本质：好的选择会被强化，差的选择会被抑制。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="对抗性学习">对抗性学习<a href="#对抗性学习" class="hash-link" aria-label="对抗性学习的直接链接" title="对抗性学习的直接链接" translate="no">​</a></h3>
<p>自我对弈有一个特殊的性质：<strong>训练对手会自动适应你的水平</strong>。</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">训练周期 1：AI 发现了一个有效的战术 T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">训练周期 2：作为对手的 AI 学会了如何防守 T</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">训练周期 3：原版 AI 被迫寻找更好的战术 T&#x27;</span><br></span></code></pre></div></div>
<p>这形成了一个<strong>军备竞赛（Arms Race）</strong>，双方不断发现并克服彼此的弱点。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="与人类棋谱的比较">与人类棋谱的比较<a href="#与人类棋谱的比较" class="hash-link" aria-label="与人类棋谱的比较的直接链接" title="与人类棋谱的比较的直接链接" translate="no">​</a></h3>
<table><thead><tr><th>训练方式</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong>人类棋谱</strong></td><td>学习人类智慧的结晶</td><td>受限于人类水平</td></tr><tr><td><strong>自我对弈</strong></td><td>无上限的提升潜力</td><td>可能陷入局部最优</td></tr><tr><td><strong>两者结合</strong></td><td>快速起步 + 持续提升</td><td>最佳策略</td></tr></tbody></table>
<p>AlphaGo 原版先用人类棋谱做监督学习，再用自我对弈做强化学习。AlphaGo Zero 则证明了只用自我对弈也能达到超人水平。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="博弈论视角">博弈论视角<a href="#博弈论视角" class="hash-link" aria-label="博弈论视角的直接链接" title="博弈论视角的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="纳什均衡">纳什均衡<a href="#纳什均衡" class="hash-link" aria-label="纳什均衡的直接链接" title="纳什均衡的直接链接" translate="no">​</a></h3>
<p>在博弈论中，<strong>纳什均衡（Nash Equilibrium）</strong> 是一种稳定状态：在这个状态下，没有任何玩家有动机单方面改变策略。</p>
<p>对于围棋这样的<strong>零和、完美信息博弈</strong>，纳什均衡有特殊的意义：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>π</mi></msub><msub><mrow><mi>min</mi><mo>⁡</mo></mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi^* = \arg\max_\pi \min_{\pi&#x27;} V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>π</mi><mo separator="true">,</mo><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(\pi, \pi&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是当策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">π</span></span></span></span> 对上策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>π</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">\pi&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7519em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> 时的预期价值。</p>
<p>这就是著名的 <strong>Minimax 原则</strong>：最佳策略是那个能在最坏情况下表现最好的策略。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="自我对弈与纳什均衡">自我对弈与纳什均衡<a href="#自我对弈与纳什均衡" class="hash-link" aria-label="自我对弈与纳什均衡的直接链接" title="自我对弈与纳什均衡的直接链接" translate="no">​</a></h3>
<p>理论上，如果自我对弈能够收敛，它应该收敛到纳什均衡。对于围棋这样的确定性博弈，纳什均衡就是<strong>完美下法</strong>。</p>
<p>但围棋的状态空间太大了（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mn>170</mn></msup></mrow><annotation encoding="application/x-tex">10^{170}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">170</span></span></span></span></span></span></span></span></span></span></span></span>），我们不可能找到真正的纳什均衡。自我对弈实际上是在<strong>近似</strong>这个均衡。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="虚拟对弈fictitious-play">虚拟对弈（Fictitious Play）<a href="#虚拟对弈fictitious-play" class="hash-link" aria-label="虚拟对弈（Fictitious Play）的直接链接" title="虚拟对弈（Fictitious Play）的直接链接" translate="no">​</a></h3>
<p>自我对弈与博弈论中的<strong>虚拟对弈</strong>概念相关：</p>
<ol>
<li class="">每个玩家观察对手的历史策略</li>
<li class="">计算对手策略的平均分布</li>
<li class="">选择对抗这个平均分布的最佳回应</li>
</ol>
<p>在某些条件下，虚拟对弈可以证明会收敛到纳什均衡。</p>
<p>AlphaGo 的自我对弈可以看作是这个概念的神经网络实现。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="自我对弈的机制">自我对弈的机制<a href="#自我对弈的机制" class="hash-link" aria-label="自我对弈的机制的直接链接" title="自我对弈的机制的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="基本流程">基本流程<a href="#基本流程" class="hash-link" aria-label="基本流程的直接链接" title="基本流程的直接链接" translate="no">​</a></h3>
<p>AlphaGo 的自我对弈流程：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">算法：Self-Play Training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">初始化：Policy Network π_θ（可从监督学习或随机初始化开始）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">重复以下步骤直到收敛：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. 产生对弈数据</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   对于 i = 1 到 N（并行进行）：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. 用当前策略 π_θ 进行一局自我对弈</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 收集轨迹：τ_i = (s_0, a_0, r_1, s_1, a_1, ...)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. 记录最终结果 z_i ∈ {-1, +1}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 更新策略</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 计算策略梯度：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ∇J = (1/N) Σ_i Σ_t ∇_θ log π_θ(a_t|s_t) · z_i</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 更新参数：θ ← θ + α · ∇J</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 更新价值网络</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 用 (s, z) 对训练 Value Network</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 最小化：L = E[(V_φ(s) - z)²]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 可选：评估并保存检查点</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   a. 让新策略对抗旧版本</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   b. 如果胜率 &gt; 55%，更新对手池</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="训练数据的产生">训练数据的产生<a href="#训练数据的产生" class="hash-link" aria-label="训练数据的产生的直接链接" title="训练数据的产生的直接链接" translate="no">​</a></h3>
<p>每局自我对弈产生一个<strong>轨迹（trajectory）</strong>：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau = (s_0, a_0, s_1, a_1, \ldots, s_T, z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose">)</span></span></span></span></p>
<p>其中：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>：时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> 的棋盘状态</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>：时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span> 选择的动作</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span>：最终结果（+1 胜利，-1 失败）</li>
</ul>
<p>一局 200 手的对弈就产生了 200 个训练样本。每天进行数十万局自我对弈，训练数据量是惊人的。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="策略更新">策略更新<a href="#策略更新" class="hash-link" aria-label="策略更新的直接链接" title="策略更新的直接链接" translate="no">​</a></h3>
<p>使用策略梯度更新 Policy Network：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>+</mo><mi>α</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><msub><mo>∑</mo><mi>t</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi>z</mi><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\theta \leftarrow \theta + \alpha \cdot \nabla_\theta \mathbb{E}\left[\sum_t \log \pi_\theta(a_t|s_t) \cdot z\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1308em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">lo<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose delimcenter" style="top:0em">]</span></span></span></span></span></p>
<p>这个更新的效果：</p>
<ul>
<li class="">如果最终获胜（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = +1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">+</span><span class="mord">1</span></span></span></span>），增加所有落子的概率</li>
<li class="">如果最终失败（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">z = -1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span>），减少所有落子的概率</li>
</ul>
<p>这看起来很粗糙——赢棋时可能也有些差棋，输棋时可能也有些好棋。但透过大量对局的统计，这些「杂讯」会被平均掉，真正的好棋会被识别出来。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="价值网络训练">价值网络训练<a href="#价值网络训练" class="hash-link" aria-label="价值网络训练的直接链接" title="价值网络训练的直接链接" translate="no">​</a></h3>
<p>Value Network 使用<strong>回归（regression）</strong> 训练：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>←</mo><mi>ϕ</mi><mo>−</mo><mi>β</mi><mo>⋅</mo><msub><mi mathvariant="normal">∇</mi><mi>ϕ</mi></msub><mi mathvariant="double-struck">E</mi><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><msub><mi>V</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>−</mo><mi>z</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\phi \leftarrow \phi - \beta \cdot \nabla_\phi \mathbb{E}\left[(V_\phi(s) - z)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord mathbb">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>这让 Value Network 学会预测：从当前局面开始，最终获胜的概率是多少？</p>
<p>Value Network 的作用是：</p>
<ol>
<li class="">在 MCTS 中提供叶节点评估</li>
<li class="">作为策略梯度的基准线（baseline）</li>
<li class="">直接用于局面评估</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="随机化的重要性">随机化的重要性<a href="#随机化的重要性" class="hash-link" aria-label="随机化的重要性的直接链接" title="随机化的重要性的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="避免确定性循环">避免确定性循环<a href="#避免确定性循环" class="hash-link" aria-label="避免确定性循环的直接链接" title="避免确定性循环的直接链接" translate="no">​</a></h3>
<p>如果自我对弈是完全确定性的，可能会陷入循环：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">策略 A 总是下固定的开局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">策略 A 对上策略 A 总是产生相同的棋局</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">只有一局棋被反复学习</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">AI 无法探索其他可能性</span><br></span></code></pre></div></div>
<p>这就是为什么<strong>随机性</strong>在自我对弈中至关重要。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="随机化的来源">随机化的来源<a href="#随机化的来源" class="hash-link" aria-label="随机化的来源的直接链接" title="随机化的来源的直接链接" translate="no">​</a></h3>
<p>AlphaGo 在自我对弈中引入随机性的方式：</p>
<p><strong>1. 策略网络本身是随机的</strong></p>
<p>Policy Network 输出的是概率分布，而非确定性选择：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∼</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a \sim \pi_\theta(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></p>
<p>同样的局面，每次可能选择不同的落子。</p>
<p><strong>2. 温度参数</strong></p>
<p>在训练时使用较高的温度（temperature）来增加多样性：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow><mrow><msub><mo>∑</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msub><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mi mathvariant="normal">∣</mi><mi>s</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>τ</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\pi_\tau(a|s) = \frac{\pi_\theta(a|s)^{1/\tau}}{\sum_{a&#x27;} \pi_\theta(a&#x27;|s)^{1/\tau}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.7721em;vertical-align:-0.6104em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1617em"><span style="top:-2.6146em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2854em"><span style="top:-2.2854em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.6068em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8496em"><span style="top:-2.8496em;margin-right:0.1em"><span class="pstrut" style="height:2.5556em"></span><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.822em"><span style="top:-2.822em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.485em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9667em"><span style="top:-2.9667em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1/</span><span class="mord mathnormal mtight" style="margin-right:0.1132em">τ</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6104em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：更随机，更多探索</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：更确定，更多利用</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\tau = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.1132em">τ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>：原始分布</li>
</ul>
<p><strong>3. 狄利克雷噪音（Dirichlet Noise）</strong></p>
<p>AlphaGo Zero 在自我对弈时，在根节点的先验概率上加入狄利克雷噪音：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ε</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ε</mi><mo>⋅</mo><msub><mi>η</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">P(s, a) = (1 - \varepsilon) \cdot \pi_\theta(a|s) + \varepsilon \cdot \eta_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi><mo>∼</mo><mtext>Dir</mtext><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\eta \sim \text{Dir}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mclose">)</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi><mo>=</mo><mn>0.25</mn></mrow><annotation encoding="application/x-tex">\varepsilon = 0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.25</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.03</span></span></span></span>（针对围棋的 361 个动作）。</p>
<p>这确保了即使是非常低概率的走法，也有机会被探索。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="对弈池population方法">对弈池（Population）方法<a href="#对弈池population方法" class="hash-link" aria-label="对弈池（Population）方法的直接链接" title="对弈池（Population）方法的直接链接" translate="no">​</a></h3>
<p>另一种增加多样性的方法是维护一个<strong>对弈池</strong>：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">对弈池 = [π_1, π_2, π_3, ..., π_k]（不同版本的策略）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">每局对弈：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. 从池中随机选择一个对手</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 与该对手进行对弈</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 用结果更新当前策略</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. 定期将改进的策略加入池中</span><br></span></code></pre></div></div>
<p>这种方法的好处：</p>
<ul>
<li class=""><strong>多样性</strong>：不同风格的对手</li>
<li class=""><strong>稳定性</strong>：避免对特定对手过拟合</li>
<li class=""><strong>鲁棒性</strong>：学会应对各种策略</li>
</ul>
<p>AlphaGo 原版和 AlphaGo Zero 都使用了类似的技术。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="棋力成长曲线">棋力成长曲线<a href="#棋力成长曲线" class="hash-link" aria-label="棋力成长曲线的直接链接" title="棋力成长曲线的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="elo-评分系统">Elo 评分系统<a href="#elo-评分系统" class="hash-link" aria-label="Elo 评分系统的直接链接" title="Elo 评分系统的直接链接" translate="no">​</a></h3>
<p>为了追踪 AI 棋力的变化，AlphaGo 使用了 <strong>Elo 评分系统</strong>。</p>
<p>Elo 系统的基本原理：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mtext>A 胜</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mn>10</mn><mrow><mo stretchy="false">(</mo><msub><mi>R</mi><mi>B</mi></msub><mo>−</mo><msub><mi>R</mi><mi>A</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>400</mn></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(\text{A 胜}) = \frac{1}{1 + 10^{(R_B - R_A)/400}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord text"><span class="mord">A </span><span class="mord cjk_fallback">胜</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3331em;vertical-align:-0.488em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.5703em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8853em"><span style="top:-2.8853em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.0077em;margin-right:0.1em"><span class="pstrut" style="height:2.6833em"></span><span class="mord mathnormal mtight">A</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3385em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/400</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.488em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">R_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>B</mi></msub></mrow><annotation encoding="application/x-tex">R_B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 是双方的 Elo 分数。</p>
<ul>
<li class="">分差 200：强者预期赢 75%</li>
<li class="">分差 400：强者预期赢 90%</li>
<li class="">分差 800：强者预期赢 99%</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-的棋力成长">AlphaGo 的棋力成长<a href="#alphago-的棋力成长" class="hash-link" aria-label="AlphaGo 的棋力成长的直接链接" title="AlphaGo 的棋力成长的直接链接" translate="no">​</a></h3>
<p>让我们可视化 AlphaGo 各版本的棋力成长：</p>
<div>載入中...</div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="成长速度分析">成长速度分析<a href="#成长速度分析" class="hash-link" aria-label="成长速度分析的直接链接" title="成长速度分析的直接链接" translate="no">​</a></h3>
<p>从曲线可以观察到几个有趣的现象：</p>
<p><strong>1. 初期快速增长</strong></p>
<p>在训练的最初几个小时，AI 学会了基本规则和简单战术。这是<strong>低垂果实</strong>阶段——有太多明显的错误可以修正。</p>
<p><strong>2. 中期稳定增长</strong></p>
<p>随着基本错误被消除，AI 开始学习更精妙的战术和定式。增长速度变慢，但仍然稳定。</p>
<p><strong>3. 后期增长放缓</strong></p>
<p>当 AI 已经很强时，进一步提升变得困难。可能需要发现全新的策略，而不只是修正错误。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="超越人类的时刻">超越人类的时刻<a href="#超越人类的时刻" class="hash-link" aria-label="超越人类的时刻的直接链接" title="超越人类的时刻的直接链接" translate="no">​</a></h3>
<p>AlphaGo 训练曲线中的关键里程碑：</p>
<table><thead><tr><th>里程碑</th><th>相当于</th><th>达成时间</th></tr></thead><tbody><tr><td>超越业余强豪</td><td>Elo ~2700</td><td>约 3 小时</td></tr><tr><td>超越 Fan Hui</td><td>Elo ~3500</td><td>约 36 小时</td></tr><tr><td>超越 Lee Sedol</td><td>Elo ~4500</td><td>约 60 小时</td></tr><tr><td>超越原版 AlphaGo</td><td>Elo ~5000</td><td>约 72 小时</td></tr></tbody></table>
<p>这些数字（来自 AlphaGo Zero）令人震惊：<strong>AI 在 3 天内从零开始超越了人类数千年的围棋智慧</strong>。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="收敛性分析">收敛性分析<a href="#收敛性分析" class="hash-link" aria-label="收敛性分析的直接链接" title="收敛性分析的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="自我对弈会收敛吗">自我对弈会收敛吗？<a href="#自我对弈会收敛吗" class="hash-link" aria-label="自我对弈会收敛吗？的直接链接" title="自我对弈会收敛吗？的直接链接" translate="no">​</a></h3>
<p>这是一个重要的理论问题。简短的答案是：<strong>在某些条件下会，但围棋太复杂了，我们无法严格证明</strong>。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="理论保证">理论保证<a href="#理论保证" class="hash-link" aria-label="理论保证的直接链接" title="理论保证的直接链接" translate="no">​</a></h3>
<p>对于较简单的游戏（如井字棋），可以证明：</p>
<ol>
<li class=""><strong>存在性</strong>：存在纳什均衡（Minimax 定理）</li>
<li class=""><strong>收敛性</strong>：某些算法（如虚拟对弈）会收敛到纳什均衡</li>
</ol>
<p>对于围棋，我们没有严格的收敛保证，但实验证据显示：</p>
<ul>
<li class="">棋力持续提升</li>
<li class="">没有出现明显的振荡或退化</li>
<li class="">最终棋力超越所有已知人类</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="可能的失败模式">可能的失败模式<a href="#可能的失败模式" class="hash-link" aria-label="可能的失败模式的直接链接" title="可能的失败模式的直接链接" translate="no">​</a></h3>
<p>自我对弈可能遇到的问题：</p>
<p><strong>1. 策略循环（Strategy Cycling）</strong></p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">策略 A 打败策略 B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">策略 B 打败策略 C</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">策略 C 打败策略 A</span><br></span></code></pre></div></div>
<p>这在某些游戏中确实会发生（如剪刀石头布）。但围棋有足够的复杂性，这种纯粹的循环似乎不会发生。</p>
<p><strong>2. 过拟合到自己</strong></p>
<p>AI 可能学会了只针对自己风格的策略，而无法应对其他风格的对手。这是为什么 AlphaGo 会与不同版本的自己对弈，以及最终与人类棋手测试。</p>
<p><strong>3. 局部最优</strong></p>
<p>AI 可能陷入局部最优——一种「还不错但不是最好」的策略。随机化和大量对弈有助于避免这个问题。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="实际观察">实际观察<a href="#实际观察" class="hash-link" aria-label="实际观察的直接链接" title="实际观察的直接链接" translate="no">​</a></h3>
<p>从 AlphaGo 的训练过程观察到：</p>
<ol>
<li class=""><strong>持续进步</strong>：Elo 分数随着训练持续上升</li>
<li class=""><strong>没有退化</strong>：没有出现棋力突然下降的情况</li>
<li class=""><strong>风格演化</strong>：AI 的下棋风格随着训练逐渐变化</li>
<li class=""><strong>发现新定式</strong>：AI 发现了人类从未使用过的开局和战术</li>
</ol>
<p>这些观察表明，虽然我们没有理论保证，但自我对弈在实践中确实有效。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="实作细节">实作细节<a href="#实作细节" class="hash-link" aria-label="实作细节的直接链接" title="实作细节的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="并行自我对弈">并行自我对弈<a href="#并行自我对弈" class="hash-link" aria-label="并行自我对弈的直接链接" title="并行自我对弈的直接链接" translate="no">​</a></h3>
<p>为了加速训练，AlphaGo 使用大规模并行自我对弈：</p>
<!-- -->
<p><strong>关键设计决策</strong>：</p>
<ul>
<li class=""><strong>同步 vs 非同步</strong>：AlphaGo 使用非同步更新，Worker 不需要等待彼此</li>
<li class=""><strong>更新频率</strong>：每完成 N 局对弈就更新一次参数</li>
<li class=""><strong>对手选择</strong>：随机选择最近几个版本中的一个作为对手</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="检查点策略">检查点策略<a href="#检查点策略" class="hash-link" aria-label="检查点策略的直接链接" title="检查点策略的直接链接" translate="no">​</a></h3>
<p>定期保存模型检查点，用于：</p>
<ol>
<li class=""><strong>对弈池</strong>：维护不同版本的对手</li>
<li class=""><strong>评估</strong>：追踪棋力变化</li>
<li class=""><strong>故障恢复</strong>：训练中断时可以恢复</li>
</ol>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 伪代码</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">training_loop</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> iteration </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">num_iterations</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 产生对弈数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        trajectories </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> parallel_self_play</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_games</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 更新策略</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        update_policy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">trajectories</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 定期评估和保存</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> iteration </span><span class="token operator" style="color:#393A34">%</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate_against_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            save_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> elo</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> elo </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> best_elo</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                add_to_pool</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">current_policy</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                best_elo </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> elo</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="训练资源需求">训练资源需求<a href="#训练资源需求" class="hash-link" aria-label="训练资源需求的直接链接" title="训练资源需求的直接链接" translate="no">​</a></h3>
<p>AlphaGo 的训练规模令人印象深刻：</p>
<table><thead><tr><th>版本</th><th>硬件</th><th>训练时间</th><th>自我对弈局数</th></tr></thead><tbody><tr><td>AlphaGo Fan</td><td>176 GPU</td><td>数月</td><td>~30M</td></tr><tr><td>AlphaGo Lee</td><td>48 TPU</td><td>数周</td><td>~30M</td></tr><tr><td>AlphaGo Zero</td><td>4 TPU</td><td>3 天</td><td>~5M</td></tr><tr><td>AlphaGo Zero (40天版)</td><td>4 TPU</td><td>40 天</td><td>~30M</td></tr></tbody></table>
<p>注意 AlphaGo Zero 用更少的硬件和更短的时间达到了更强的棋力——这是算法效率的提升。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="超参数设置">超参数设置<a href="#超参数设置" class="hash-link" aria-label="超参数设置的直接链接" title="超参数设置的直接链接" translate="no">​</a></h3>
<p>一些关键的超参数：</p>
<div class="language-python codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-python codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 自我对弈设置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NUM_PARALLEL_GAMES </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># 同时进行的对弈数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GAMES_PER_ITERATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">25000</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 每次迭代的对弈数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MCTS_SIMULATIONS </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1600</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 每步棋的 MCTS 模拟次数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 训练设置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BATCH_SIZE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 训练批次大小</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LEARNING_RATE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.01</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># 初始学习率</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">L2_REGULARIZATION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1e-4</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># 权重衰减</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 探索设置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TEMPERATURE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1.0</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># 开局 30 手的温度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DIRICHLET_ALPHA </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.03</span><span class="token plain">         </span><span class="token comment" style="color:#999988;font-style:italic"># 狄利克雷噪音参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EXPLORATION_FRACTION </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.25</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 噪音比例</span><br></span></code></pre></div></div>
<p>这些超参数是经过大量实验调整的，对训练效果有显著影响。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="自我对弈的变体">自我对弈的变体<a href="#自我对弈的变体" class="hash-link" aria-label="自我对弈的变体的直接链接" title="自我对弈的变体的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-原版">AlphaGo 原版<a href="#alphago-原版" class="hash-link" aria-label="AlphaGo 原版的直接链接" title="AlphaGo 原版的直接链接" translate="no">​</a></h3>
<p>AlphaGo 原版的训练流程：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 监督学习 (SL)：从人类棋谱学习</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → 产生 SL Policy Network (π_SL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. 强化学习 (RL)：自我对弈</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   初始化 π_RL = π_SL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   对手池 = [π_SL]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   重复：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. π_RL 与池中策略对弈</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 用策略梯度更新 π_RL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. 如果 π_RL 变强，加入池中</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → 产生 RL Policy Network (π_RL)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. 价值网络训练：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   用 π_RL 自我对弈产生局面</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   训练 V(s) 预测胜率</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphago-zero">AlphaGo Zero<a href="#alphago-zero" class="hash-link" aria-label="AlphaGo Zero的直接链接" title="AlphaGo Zero的直接链接" translate="no">​</a></h3>
<p>AlphaGo Zero 简化了这个流程：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. 纯自我对弈（无人类数据）</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   初始化随机网络 f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   重复：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     a. 用 MCTS + f_θ 进行自我对弈</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     b. 同时训练策略头和价值头</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     c. 更新 f_θ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   → 单一网络同时输出策略和价值</span><br></span></code></pre></div></div>
<p>关键改进：</p>
<ul>
<li class=""><strong>无需人类数据</strong>：从零开始</li>
<li class=""><strong>单一网络</strong>：策略和价值共享特征</li>
<li class=""><strong>更简洁的训练</strong>：端到端学习</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="alphazero">AlphaZero<a href="#alphazero" class="hash-link" aria-label="AlphaZero的直接链接" title="AlphaZero的直接链接" translate="no">​</a></h3>
<p>AlphaZero 进一步泛化：</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">同样的算法，不同的游戏：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 围棋：达到超越 AlphaGo Zero 的水平</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 西洋棋：超越 Stockfish</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- 将棋：超越 Elmo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">唯一的游戏特定部分：规则编码</span><br></span></code></pre></div></div>
<p>这证明了自我对弈是一种<strong>通用的学习范式</strong>，不限于围棋。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="人类从中学到什么">人类从中学到什么？<a href="#人类从中学到什么" class="hash-link" aria-label="人类从中学到什么？的直接链接" title="人类从中学到什么？的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ai-发现的新定式">AI 发现的新定式<a href="#ai-发现的新定式" class="hash-link" aria-label="AI 发现的新定式的直接链接" title="AI 发现的新定式的直接链接" translate="no">​</a></h3>
<p>自我对弈产生了许多人类从未使用过的下法：</p>
<p><strong>1. 开局创新</strong></p>
<p>AlphaGo 偏好的一些开局：</p>
<ul>
<li class="">3-3 侵入：在早期就侵入角部</li>
<li class="">高位下法：传统上被认为「不稳定」</li>
<li class="">大雪崩变化：人类认为复杂难以计算</li>
</ul>
<p><strong>2. 新的形势判断</strong></p>
<p>AI 对某些局面的评估与人类大相径庭：</p>
<ul>
<li class="">某些看似「薄弱」的棋形其实很坚实</li>
<li class="">某些「厚势」的价值被高估</li>
<li class="">对「先手」和「后手」的重新评估</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="对人类围棋的影响">对人类围棋的影响<a href="#对人类围棋的影响" class="hash-link" aria-label="对人类围棋的影响的直接链接" title="对人类围棋的影响的直接链接" translate="no">​</a></h3>
<p>AlphaGo 之后，职业围棋发生了显著变化：</p>
<ol>
<li class=""><strong>开局多样化</strong>：职业棋手开始使用 AI 发现的新开局</li>
<li class=""><strong>训练方式改变</strong>：AI 成为职业棋手的主要训练工具</li>
<li class=""><strong>棋理重新思考</strong>：许多传统「棋理」被质疑和修正</li>
<li class=""><strong>新的美学</strong>：开始欣赏 AI 风格的棋</li>
</ol>
<p>柯洁在输给 AlphaGo 后说：</p>
<blockquote>
<p>「AlphaGo 让我重新认识围棋。我以前认为人类理解围棋，现在我知道我们只是触及皮毛。」</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="哲学思考">哲学思考<a href="#哲学思考" class="hash-link" aria-label="哲学思考的直接链接" title="哲学思考的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="学习的本质">学习的本质<a href="#学习的本质" class="hash-link" aria-label="学习的本质的直接链接" title="学习的本质的直接链接" translate="no">​</a></h3>
<p>自我对弈提出了关于学习的深刻问题：</p>
<p><strong>知识从哪里来？</strong></p>
<ul>
<li class="">人类学习依赖于外部信息（老师、书本、经验）</li>
<li class="">自我对弈的 AI 只有规则，没有外部知识</li>
<li class="">但它仍然能「发现」知识——这些知识是从哪里来的？</li>
</ul>
<p>答案可能是：<strong>知识隐含在游戏规则和结构中</strong>。围棋的规则定义了什么是好棋、什么是坏棋，自我对弈只是揭示了这些隐含的结构。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="创造力与发现">创造力与发现<a href="#创造力与发现" class="hash-link" aria-label="创造力与发现的直接链接" title="创造力与发现的直接链接" translate="no">​</a></h3>
<p>当 AI 下出「神之一手」（Move 37），这算是创造还是发现？</p>
<p>一种观点是：那步棋一直「存在」于围棋的规则中，AI 只是「发现」了它。
另一种观点是：AI 「创造」了这步棋，因为没有人（包括 AI 自己）事先知道它。</p>
<p>这个问题没有标准答案，但它挑战了我们对创造力的传统理解。</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="人类智慧的位置">人类智慧的位置<a href="#人类智慧的位置" class="hash-link" aria-label="人类智慧的位置的直接链接" title="人类智慧的位置的直接链接" translate="no">​</a></h3>
<p>如果 AI 可以从零开始，透过自我对弈超越人类数千年的智慧，这对人类意味着什么？</p>
<p>乐观的看法：</p>
<ul>
<li class="">AI 是人类创造的工具</li>
<li class="">AI 的发现可以增强人类的理解</li>
<li class="">人类可以与 AI 合作，达到更高的水平</li>
</ul>
<p>谨慎的看法：</p>
<ul>
<li class="">某些领域，纯粹的计算可能超越人类直觉</li>
<li class="">需要重新思考「专业技能」的价值</li>
<li class="">教育和训练方式可能需要改变</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="动画对应">动画对应<a href="#动画对应" class="hash-link" aria-label="动画对应的直接链接" title="动画对应的直接链接" translate="no">​</a></h2>
<p>本文涉及的核心概念与动画编号：</p>
<table><thead><tr><th>编号</th><th>概念</th><th>物理/数学对应</th></tr></thead><tbody><tr><td>🎬 E5</td><td>自我对弈循环</td><td>不动点迭代</td></tr><tr><td>🎬 E6</td><td>策略演化</td><td>进化动力学</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="总结">总结<a href="#总结" class="hash-link" aria-label="总结的直接链接" title="总结的直接链接" translate="no">​</a></h2>
<p>自我对弈是 AlphaGo 成功的关键技术之一。我们学习了：</p>
<ol>
<li class=""><strong>为什么有效</strong>：对抗性学习、渐进式发现弱点</li>
<li class=""><strong>机制</strong>：轨迹收集、策略梯度、价值网络训练</li>
<li class=""><strong>随机化</strong>：温度参数、狄利克雷噪音、对弈池</li>
<li class=""><strong>棋力成长</strong>：Elo 系统、成长曲线分析</li>
<li class=""><strong>收敛性</strong>：理论保证与实际观察</li>
<li class=""><strong>实作细节</strong>：并行训练、检查点策略、超参数</li>
</ol>
<p>下一篇，我们将探讨 AlphaGo 如何将神经网络与 MCTS 结合，发挥两者的优势。</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="延伸阅读">延伸阅读<a href="#延伸阅读" class="hash-link" aria-label="延伸阅读的直接链接" title="延伸阅读的直接链接" translate="no">​</a></h2>
<ul>
<li class=""><strong>下一篇</strong>：<a class="" href="/zh-cn/docs/alphago/explained/mcts-neural-combo/">MCTS 与神经网络的结合</a> — 直觉与推理的完美结合</li>
<li class=""><strong>上一篇</strong>：<a class="" href="/zh-cn/docs/alphago/explained/reinforcement-intro/">强化学习入门</a> — 强化学习的基本概念</li>
<li class=""><strong>相关</strong>：<a class="" href="/zh-cn/docs/alphago/explained/alphago-zero/">AlphaGo Zero 概述</a> — 从零开始的突破</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="参考资料">参考资料<a href="#参考资料" class="hash-link" aria-label="参考资料的直接链接" title="参考资料的直接链接" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">Heinrich, J., &amp; Silver, D. (2016). &quot;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games.&quot; <em>arXiv preprint</em>.</li>
<li class="">Lanctot, M., et al. (2017). &quot;A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning.&quot; <em>NeurIPS</em>.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/alphago/explained/13-self-play.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-cn/docs/alphago/explained/reinforcement-intro/"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">强化学习入门</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-cn/docs/alphago/explained/mcts-neural-combo/"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">MCTS 与神经网络的结合</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#为什么自我对弈有效" class="table-of-contents__link toc-highlight">为什么自我对弈有效？</a><ul><li><a href="#直觉解释" class="table-of-contents__link toc-highlight">直觉解释</a></li><li><a href="#渐进式发现弱点" class="table-of-contents__link toc-highlight">渐进式发现弱点</a></li><li><a href="#对抗性学习" class="table-of-contents__link toc-highlight">对抗性学习</a></li><li><a href="#与人类棋谱的比较" class="table-of-contents__link toc-highlight">与人类棋谱的比较</a></li></ul></li><li><a href="#博弈论视角" class="table-of-contents__link toc-highlight">博弈论视角</a><ul><li><a href="#纳什均衡" class="table-of-contents__link toc-highlight">纳什均衡</a></li><li><a href="#自我对弈与纳什均衡" class="table-of-contents__link toc-highlight">自我对弈与纳什均衡</a></li><li><a href="#虚拟对弈fictitious-play" class="table-of-contents__link toc-highlight">虚拟对弈（Fictitious Play）</a></li></ul></li><li><a href="#自我对弈的机制" class="table-of-contents__link toc-highlight">自我对弈的机制</a><ul><li><a href="#基本流程" class="table-of-contents__link toc-highlight">基本流程</a></li><li><a href="#训练数据的产生" class="table-of-contents__link toc-highlight">训练数据的产生</a></li><li><a href="#策略更新" class="table-of-contents__link toc-highlight">策略更新</a></li><li><a href="#价值网络训练" class="table-of-contents__link toc-highlight">价值网络训练</a></li></ul></li><li><a href="#随机化的重要性" class="table-of-contents__link toc-highlight">随机化的重要性</a><ul><li><a href="#避免确定性循环" class="table-of-contents__link toc-highlight">避免确定性循环</a></li><li><a href="#随机化的来源" class="table-of-contents__link toc-highlight">随机化的来源</a></li><li><a href="#对弈池population方法" class="table-of-contents__link toc-highlight">对弈池（Population）方法</a></li></ul></li><li><a href="#棋力成长曲线" class="table-of-contents__link toc-highlight">棋力成长曲线</a><ul><li><a href="#elo-评分系统" class="table-of-contents__link toc-highlight">Elo 评分系统</a></li><li><a href="#alphago-的棋力成长" class="table-of-contents__link toc-highlight">AlphaGo 的棋力成长</a></li><li><a href="#成长速度分析" class="table-of-contents__link toc-highlight">成长速度分析</a></li><li><a href="#超越人类的时刻" class="table-of-contents__link toc-highlight">超越人类的时刻</a></li></ul></li><li><a href="#收敛性分析" class="table-of-contents__link toc-highlight">收敛性分析</a><ul><li><a href="#自我对弈会收敛吗" class="table-of-contents__link toc-highlight">自我对弈会收敛吗？</a></li><li><a href="#理论保证" class="table-of-contents__link toc-highlight">理论保证</a></li><li><a href="#可能的失败模式" class="table-of-contents__link toc-highlight">可能的失败模式</a></li><li><a href="#实际观察" class="table-of-contents__link toc-highlight">实际观察</a></li></ul></li><li><a href="#实作细节" class="table-of-contents__link toc-highlight">实作细节</a><ul><li><a href="#并行自我对弈" class="table-of-contents__link toc-highlight">并行自我对弈</a></li><li><a href="#检查点策略" class="table-of-contents__link toc-highlight">检查点策略</a></li><li><a href="#训练资源需求" class="table-of-contents__link toc-highlight">训练资源需求</a></li><li><a href="#超参数设置" class="table-of-contents__link toc-highlight">超参数设置</a></li></ul></li><li><a href="#自我对弈的变体" class="table-of-contents__link toc-highlight">自我对弈的变体</a><ul><li><a href="#alphago-原版" class="table-of-contents__link toc-highlight">AlphaGo 原版</a></li><li><a href="#alphago-zero" class="table-of-contents__link toc-highlight">AlphaGo Zero</a></li><li><a href="#alphazero" class="table-of-contents__link toc-highlight">AlphaZero</a></li></ul></li><li><a href="#人类从中学到什么" class="table-of-contents__link toc-highlight">人类从中学到什么？</a><ul><li><a href="#ai-发现的新定式" class="table-of-contents__link toc-highlight">AI 发现的新定式</a></li><li><a href="#对人类围棋的影响" class="table-of-contents__link toc-highlight">对人类围棋的影响</a></li></ul></li><li><a href="#哲学思考" class="table-of-contents__link toc-highlight">哲学思考</a><ul><li><a href="#学习的本质" class="table-of-contents__link toc-highlight">学习的本质</a></li><li><a href="#创造力与发现" class="table-of-contents__link toc-highlight">创造力与发现</a></li><li><a href="#人类智慧的位置" class="table-of-contents__link toc-highlight">人类智慧的位置</a></li></ul></li><li><a href="#动画对应" class="table-of-contents__link toc-highlight">动画对应</a></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a></li><li><a href="#延伸阅读" class="table-of-contents__link toc-highlight">延伸阅读</a></li><li><a href="#参考资料" class="table-of-contents__link toc-highlight">参考资料</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>