---
sidebar_position: 19
title: O Processo de Treinamento do Zero
description: Testemunhe como o AlphaGo Zero passou de jogadas aleatÃ³rias a superar os humanos em trÃªs dias, redescobrindo e transcendendo milÃªnios de teoria do Go
keywords: [AlphaGo Zero, processo de treinamento, auto-jogo, crescimento de habilidade, Go AI, deep learning]
---

import { EloChart } from '@site/src/components/D3Charts';

# O Processo de Treinamento do Zero

O mais impressionante sobre o AlphaGo Zero nÃ£o Ã© apenas sua forÃ§a final de jogo, mas seu **processo de crescimento** â€” partindo de um estado completamente aleatÃ³rio, em apenas trÃªs dias atravessou o acÃºmulo de conhecimento de Go que os humanos levaram milhares de anos para desenvolver, e entÃ£o superou toda a compreensÃ£o humana.

Este artigo irÃ¡ guiÃ¡-lo passo a passo atravÃ©s deste processo de transformaÃ§Ã£o impressionante.

---

## Curva de Treinamento

Primeiro, vejamos a curva de crescimento de habilidade do AlphaGo Zero:

<EloChart mode="zero" width={700} height={400} />

Esta curva mostra as mudanÃ§as na forÃ§a de jogo do AlphaGo Zero ao longo de 72 horas. Observe alguns marcos importantes:

| Tempo | ClassificaÃ§Ã£o ELO | Equivalente a |
|-------|-------------------|---------------|
| 0 horas | 0 | Jogadas aleatÃ³rias |
| 3 horas | ~1000 | Descobrindo regras bÃ¡sicas |
| 12 horas | ~3000 | Descobrindo joseki e formas |
| 36 horas | ~4500 | Superando o AlphaGo versÃ£o Fan Hui |
| 60 horas | ~5200 | Superando o AlphaGo versÃ£o Lee Sedol |
| 72 horas | ~5400 | Superando todas as versÃµes anteriores |

**TrÃªs dias, do zero ao Ã¡pice alÃ©m dos humanos.**

---

## Dia 0: O InÃ­cio CaÃ³tico

### Estado Inicial Completamente AleatÃ³rio

No inÃ­cio do treinamento, os pesos da rede neural sÃ£o inicializados aleatoriamente. Isso significa:

- **Policy Head**: Produz uma distribuiÃ§Ã£o quase uniforme, com probabilidade de jogada em cada posiÃ§Ã£o de aproximadamente 1/361
- **Value Head**: Produz valores prÃ³ximos de 0, incapaz de distinguir posiÃ§Ãµes boas de ruins

Neste momento, o AlphaGo Zero joga de forma completamente aleatÃ³ria â€” pior do que alguÃ©m que nunca viu um tabuleiro de Go.

### A Primeira Partida de Auto-Jogo

Imagine como era a primeira partida de auto-jogo:

```
Preto 1: Joga aleatoriamente em algum lugar (pode ser tengen, pode ser um canto, pode ser na primeira linha)
Branco 2: Joga aleatoriamente em outro lugar
Preto 3: AleatÃ³rio...
...
Jogada 200: O tabuleiro estÃ¡ cheio de pedras isoladas, sem nenhuma conexÃ£o
Final: O resultado Ã© determinado por fatores aleatÃ³rios
```

A "qualidade" desta partida Ã© extremamente baixa, mas ela contÃ©m informaÃ§Ã£o valiosa: **quem venceu no final**.

### O Primeiro Sinal de Treinamento

Embora ambos os lados estivessem jogando aleatoriamente, o resultado do jogo Ã© determinado. A rede neural comeÃ§a a aprender:

> "Nesta posiÃ§Ã£o, as pretas venceram no final. Embora eu nÃ£o saiba por quÃª, esta posiÃ§Ã£o pode ser melhor para as pretas."

Este Ã© um sinal muito fraco, mas Ã© real. ApÃ³s milhares de partidas de "Go lixo" assim, a rede comeÃ§a a descobrir alguns padrÃµes estatÃ­sticos.

---

## Horas 1-3: Descobrindo as Regras do Jogo

### ConsciÃªncia Emergente das Regras

ApÃ³s dezenas de milhares de partidas de auto-jogo, o AlphaGo Zero comeÃ§a a "descobrir" as regras bÃ¡sicas do Go (embora essas regras jÃ¡ estejam incorporadas no motor do jogo):

#### 1. A ImportÃ¢ncia da ConexÃ£o

```
ObservaÃ§Ã£o: Quando as pedras estÃ£o conectadas, sÃ£o mais difÃ­ceis de capturar
Aprendizado: ComeÃ§a a preferir jogar ao lado de pedras existentes
```

Isso nÃ£o foi ensinado, mas aprendido atravÃ©s dos resultados das partidas. Pedras dispersas sÃ£o facilmente capturadas uma a uma, enquanto pedras conectadas tÃªm mais chances de sobreviver.

#### 2. O Conceito de Liberdades

```
ObservaÃ§Ã£o: Quando todos os pontos adjacentes de uma pedra sÃ£o ocupados, a pedra desaparece
Aprendizado: ComeÃ§a a evitar posiÃ§Ãµes com poucas liberdades, comeÃ§a a atacar pedras do oponente com poucas liberdades
```

A rede aprendeu a rastrear a contagem de liberdades â€” embora nÃ£o haja uma caracterÃ­stica explÃ­cita de "contagem de liberdades" na entrada, isso pode ser inferido dos estados histÃ³ricos do tabuleiro.

#### 3. O EmbriÃ£o dos Olhos

```
ObservaÃ§Ã£o: Certas formas sÃ£o particularmente difÃ­ceis de capturar
Aprendizado: ComeÃ§a a formar formas com espaÃ§o nos cantos e bordas
```

Este Ã© o surgimento do conceito de vida. A rede descobriu que grupos de pedras com espaÃ§o interno sÃ£o mais propensos a sobreviver.

### AvaliaÃ§Ã£o de Habilidade

Neste ponto, o AlphaGo Zero estÃ¡ aproximadamente em:
- **ELO**: ~1000
- **Equivalente a**: Um iniciante que acabou de aprender as regras
- **CaracterÃ­sticas**: Sabe que deve conectar pedras, sabe que deve capturar pedras do oponente

---

## Horas 3-12: Descobrindo Joseki e Formas

### O Despertar dos Cantos

Com mais treinamento, a rede descobriu a importÃ¢ncia dos cantos:

```
ObservaÃ§Ã£o: Pedras nos cantos precisam de apenas 2 olhos para viver
          Nas bordas, 2 olhos sÃ£o mais difÃ­ceis
          No centro, 2 olhos sÃ£o os mais difÃ­ceis
Aprendizado: Prioriza ocupar os cantos na abertura
```

Este Ã© o processo de descoberta do princÃ­pio humano de que "cantos sÃ£o ouro, bordas sÃ£o prata, centro Ã© grama". A rede nÃ£o foi informada deste princÃ­pio, mas o descobriu sozinha atravÃ©s de centenas de milhares de partidas.

### A EmergÃªncia dos Joseki

Ainda mais surpreendente, a rede comeÃ§ou a "inventar" joseki â€” sequÃªncias padrÃ£o de jogadas nos cantos:

#### FenÃ´meno Observado

```
InÃ­cio do treinamento: Jogadas nos cantos sÃ£o extremamente variadas
Meio do treinamento: Certas jogadas aparecem repetidamente
Final do treinamento: Joseki estÃ¡veis de canto se formam
```

Esses joseki sÃ£o **altamente semelhantes** aos joseki acumulados por humanos ao longo de centenas de anos, validando que esses joseki sÃ£o de fato aproximaÃ§Ãµes das soluÃ§Ãµes Ã³timas para ambos os lados.

### Joseki Emergentes TÃ­picos

Tomando o joseki do pequeno ponto (komoku) como exemplo:

```
  A B C D E F G H J
9 . . . . . . . . .
8 . . . . . . . . .
7 . . . . . . . . .
6 . . . â— . . . . .   â— = Preto
5 . . . . . . . . .   â—‹ = Branco
4 . . . â—‹ . â— . . .
3 . . . . . . . . .
2 . . . . . . . . .
1 . . . . . . . . .
```

Preto ocupa o pequeno ponto, Branco faz uma aproximaÃ§Ã£o de canto, Preto faz um pinÃ§amento â€” esta sequÃªncia emergiu naturalmente durante o treinamento.

### Conhecimento de Formas

AlÃ©m de joseki, a rede tambÃ©m aprendeu a diferenÃ§a entre boas e mÃ¡s formas:

| Forma | AvaliaÃ§Ã£o Humana | Aprendizado do Zero |
|-------|------------------|---------------------|
| TriÃ¢ngulo Vazio | Forma ruim | Gradualmente evitada |
| Boca de Tigre | Boa forma | Gradualmente preferida |
| Ataque Duplo de Andorinha | Forma de ataque clÃ¡ssica | Descoberta naturalmente |
| CabeÃ§a Divina de SupressÃ£o | Ataque poderoso | Descoberta naturalmente |

### AvaliaÃ§Ã£o de Habilidade

Neste ponto, o AlphaGo Zero estÃ¡ em:
- **ELO**: ~3000
- **Equivalente a**: Alto dan amador
- **CaracterÃ­sticas**: Tem conhecimento bÃ¡sico de joseki, entende formas bÃ¡sicas

---

## Horas 12-36: Maturidade da Teoria do Go

### FormaÃ§Ã£o da VisÃ£o Global

Entrando no segundo dia, a rede comeÃ§a a exibir **visÃ£o global**:

#### InfluÃªncia e TerritÃ³rio

```
ObservaÃ§Ã£o: Cercar espaÃ§o pode garantir pontos
           Mas influÃªncia tambÃ©m tem valor â€” pode atacar o oponente
Aprendizado: Busca equilÃ­brio entre territÃ³rio e influÃªncia
```

Este Ã© um dos conceitos mais profundos do Go. A rede aprendeu a avaliar o valor do "virtual" e do "real".

#### Julgamento de Espessura e Finura

```
ObservaÃ§Ã£o: Pedras "espessas" podem apoiar batalhas distantes
           Pedras "finas" precisam de reforÃ§o, caso contrÃ¡rio serÃ£o atacadas
Aprendizado: Ativamente constrÃ³i posiÃ§Ãµes espessas, ataca as fraquezas do oponente
```

### TÃ¡ticas do Meio-Jogo

A capacidade de luta no meio-jogo da rede melhorou significativamente:

| TÃ©cnica | DescriÃ§Ã£o |
|---------|-----------|
| Atacar pedras fracas | Identificar os grupos fracos do oponente, lanÃ§ar ataques |
| Utilizar espessura | Usar posiÃ§Ãµes espessas para apoiar ataques, obter benefÃ­cios |
| Troca | Abandonar perdas locais, trocar por vantagem global |
| InvasÃ£o | Reduzir a Ã¡rea de influÃªncia do oponente |

### TÃ©cnicas de Yose

Os cÃ¡lculos precisos na fase de yose (fim de jogo) tambÃ©m estÃ£o melhorando:

```
ObservaÃ§Ã£o: Cada jogada na fase de yose pode ser calculada precisamente
Aprendizado: Faz yose na ordem de maior para menor valor
```

A rede aprendeu conceitos de yose como "sente duplo", "sente unilateral" e "gote".

### AvaliaÃ§Ã£o de Habilidade

Neste ponto, o AlphaGo Zero estÃ¡ em:
- **ELO**: ~4500
- **Equivalente a**: NÃ­vel profissional
- **CaracterÃ­sticas**: Tem compreensÃ£o completa do Go, pode jogar partidas de alta qualidade

---

## Horas 36-72: Superando os Humanos

### Rompendo o NÃ­vel Profissional

Por volta das 36 horas, a forÃ§a de jogo do AlphaGo Zero atingiu o nÃ­vel profissional. Mas o treinamento nÃ£o parou â€” ele continuou o auto-jogo, continuou a melhorar.

O que aconteceu a seguir Ã© ainda mais interessante: **ele comeÃ§ou a descobrir jogadas que os humanos nunca haviam pensado**.

### Aberturas RevolucionÃ¡rias

A abertura tradicional do Go tem muitas "crenÃ§as estabelecidas":

| VisÃ£o Tradicional | Descoberta do AlphaGo Zero |
|-------------------|----------------------------|
| Abertura comeÃ§a ocupando cantos | Em certas situaÃ§Ãµes, ocupar bordas primeiro Ã© melhor |
| Pequeno ponto Ã© mais sÃ³lido | OcupaÃ§Ã£o direta do 3-3 Ã© viÃ¡vel |
| Joseki deve ser memorizado rigorosamente | Pode-se desviar ativamente do joseki |
| Jogar 3-3 cedo Ã© ganancioso | Em certas posiÃ§Ãµes, jogar 3-3 estÃ¡ correto |

Essas "descobertas" foram amplamente estudadas por jogadores profissionais apÃ³s o AlphaGo, e muitas jÃ¡ foram incorporadas Ã  teoria moderna do Go.

### Formas Contra-Intuitivas

O AlphaGo Zero Ã s vezes joga formas que os humanos consideram "feias":

```
Humano: "Esta Ã© uma forma ruim, nÃ£o pode ser uma boa jogada"
Zero: (Joga aquela jogada)
ApÃ³s anÃ¡lise: "Na verdade, isso Ã© mais eficiente"
```

Isso revela as limitaÃ§Ãµes da teoria humana do Go: algumas "formas ruins" sÃ£o na verdade as soluÃ§Ãµes Ã³timas em posiÃ§Ãµes especÃ­ficas.

### SacrifÃ­cios Agressivos

O Zero estÃ¡ mais disposto a sacrificar pedras em troca de outros benefÃ­cios do que os humanos:

```
Perda local de 3 pontos
Ganha iniciativa global
Taxa de vitÃ³ria final aumenta
```

Os jogadores humanos frequentemente se preocupam demais com ganhos e perdas locais, enquanto o Zero sempre mantÃ©m os olhos na taxa de vitÃ³ria final.

### AvaliaÃ§Ã£o de Habilidade

ApÃ³s 72 horas, o AlphaGo Zero estÃ¡ em:
- **ELO**: ~5400
- **Equivalente a**: Superando todos os jogadores humanos
- **CaracterÃ­sticas**: Descobre jogadas desconhecidas pelos humanos, cria nova teoria do Go

---

## Redescobrindo a Teoria Humana do Go

### Milhares de Anos vs. TrÃªs Dias

O Go humano se desenvolveu por milhares de anos:
- Originou-se na China por volta de 2000 a.C.
- Transmitido ao JapÃ£o durante a Dinastia Tang, desenvolvendo teoria sofisticada
- Sistema profissional surgiu no sÃ©culo 20, teoria aprofundada ainda mais
- Em 2016, os humanos acreditavam que jÃ¡ entendiam o Go bastante bem

O AlphaGo Zero completou essa jornada em trÃªs dias. Ainda mais surpreendente, a teoria do Go que ele descobriu Ã© **altamente consistente** com a dos humanos.

### ValidaÃ§Ã£o e TranscendÃªncia

| Conhecimento Humano | Atitude do Zero |
|---------------------|-----------------|
| Cantos sÃ£o ouro, bordas sÃ£o prata, centro Ã© grama | Confirmado (cantos sÃ£o realmente importantes) |
| Joseki bÃ¡sicos | A maioria confirmada, alguns melhorados |
| Boas e mÃ¡s formas | A maioria confirmada, exceÃ§Ãµes existem |
| SacrifÃ­cio e troca | Mais agressivo que os humanos |
| Julgamento de espessura/finura | Geralmente consistente, detalhes diferem |

Isso mostra que a teoria do Go acumulada pelos humanos ao longo de milhares de anos estÃ¡ **na direÃ§Ã£o certa em geral**. Mas hÃ¡ algumas Ã¡reas onde a compreensÃ£o humana precisa de correÃ§Ã£o.

### LiÃ§Ãµes para a Aprendizagem Humana

O processo de treinamento do AlphaGo Zero traz liÃ§Ãµes para a aprendizagem humana:

1. **ComeÃ§ar do bÃ¡sico**: Zero primeiro aprendeu as regras, depois formas, e finalmente desenvolveu visÃ£o global
2. **PrÃ¡tica abundante**: 4,9 milhÃµes de partidas de auto-jogo equivalem a dezenas de milhares de anos de partidas humanas
3. **Foco na vitÃ³ria**: NÃ£o busca "Go bonito", apenas busca vencer
4. **Livre das restriÃ§Ãµes da tradiÃ§Ã£o**: Ousa tentar jogadas "impossÃ­veis"

---

## Detalhes TÃ©cnicos do Processo de Treinamento

### O Mecanismo de Auto-Jogo

O fluxo de cada partida de auto-jogo:

```
InicializaÃ§Ã£o: Tabuleiro vazio
â†“
Cada jogada:
  1. Usar rede neural para avaliar a posiÃ§Ã£o atual
  2. Executar busca MCTS (1600 simulaÃ§Ãµes)
  3. Selecionar jogada baseada nos resultados da busca
  4. Registrar (posiÃ§Ã£o, probabilidade MCTS, -)
â†“
Fim do jogo:
  1. Determinar o resultado z âˆˆ {-1, +1}
  2. Adicionar resultado a todos os registros (posiÃ§Ã£o, probabilidade MCTS, z)
  3. Adicionar dados ao pool de treinamento
```

### O Ritmo do Treinamento

O treinamento do AlphaGo Zero Ã© **contÃ­nuo**:

```
Self-play Workers:       Produzem constantemente dados de auto-jogo
Training Workers:        Amostragem constante do pool de dados para treinamento
Network Updates:         Atualizam periodicamente a rede usada para auto-jogo
```

Esses trÃªs processos acontecem simultaneamente, formando um ciclo de melhoria contÃ­nua.

### Gerenciamento do Pool de Dados

Gerenciamento do pool de dados de treinamento:

| ParÃ¢metro | Valor |
|-----------|-------|
| Tamanho do pool | 500.000 jogos mais recentes |
| Amostras por jogo | ~200 jogadas |
| Total de amostras | ~100 milhÃµes |
| MÃ©todo de amostragem | AleatÃ³rio uniforme |

Dados antigos sÃ£o substituÃ­dos por novos dados, garantindo que os dados de treinamento reflitam o nÃ­vel atual da rede.

### EstratÃ©gia de AtualizaÃ§Ã£o da Rede

A rede de auto-jogo nÃ£o Ã© atualizada apÃ³s cada passo de treinamento. Em vez disso:

1. ApÃ³s treinar por um perÃ­odo, gera uma rede candidata
2. A rede candidata joga contra a rede atual (400 jogos)
3. Se a taxa de vitÃ³ria da rede candidata > 55%, atualiza
4. Caso contrÃ¡rio, continua treinando

Isso garante que o auto-jogo sempre use uma rede **suficientemente forte**.

---

## AnÃ¡lise da Velocidade de Aprendizado

### Por Que TÃ£o RÃ¡pido?

RazÃµes para a velocidade de aprendizado impressionante do AlphaGo Zero:

#### 1. Recursos Computacionais

- 4 TPUs, dezenas de milhares de inferÃªncias por segundo
- Centenas de milhares de jogos de auto-jogo por dia
- Equivalente a milhares de anos de partidas humanas

#### 2. O Oponente Perfeito

Auto-jogo significa:
- O nÃ­vel do oponente Ã© sempre igual ao seu
- NÃ£o muito fraco (nada a aprender) nem muito forte (nÃ£o consegue vencer)
- Estas sÃ£o condiÃ§Ãµes ideais de aprendizado

#### 3. Objetivo Direto

Apenas um objetivo: vencer. Sem:
- PreferÃªncias do professor
- Busca por estilo
- ConsideraÃ§Ãµes estÃ©ticas

#### 4. Aprendizado de RepresentaÃ§Ã£o Eficiente

As redes residuais podem aprender caracterÃ­sticas muito abstratas do tabuleiro, mais eficazes do que caracterÃ­sticas projetadas manualmente.

### ComparaÃ§Ã£o com Humanos

| Aspecto | Humanos | AlphaGo Zero |
|---------|---------|--------------|
| Velocidade de aprendizado | ~10 jogos/dia | ~100.000 jogos/dia |
| RetenÃ§Ã£o de memÃ³ria | Esquecimento ocorre | RetenÃ§Ã£o perfeita |
| LimitaÃ§Ãµes de energia | Precisa descansar | Funciona 24/7 |
| Capacidade de inovaÃ§Ã£o | Influenciado pela tradiÃ§Ã£o | Sem restriÃ§Ãµes prÃ©-estabelecidas |

---

## FenÃ´menos Interessantes Durante o Treinamento

### PlatÃ´s PeriÃ³dicos

A curva de treinamento nÃ£o Ã© perfeitamente suave, Ã s vezes hÃ¡ **perÃ­odos de platÃ´**:

```
ELO: 2000 -----> 2000 -----> 2500 ---->
          (platÃ´)       (avanÃ§o)
```

Isso pode ser porque a rede estÃ¡ aprendendo algum novo conceito e precisa de tempo para "digerir".

### EmergÃªncia e Desaparecimento de EstratÃ©gias

Certas estratÃ©gias emergem durante o treinamento e depois desaparecem:

```
Fase 1: Descobre uma tÃ¡tica de ataque
Fase 2: O oponente aprende a se defender
Fase 3: A frequÃªncia de uso dessa tÃ¡tica diminui
Fase 4: Descobre uma nova tÃ¡tica de ataque
```

Esta Ã© uma miniatura de uma corrida armamentista.

### "Reinventando a Roda"

Durante o treinamento, o Zero "reinventa" conceitos que os humanos jÃ¡ conhecem:

- **Escada (Shicho)**: Descobre que atari contÃ­nuo pode capturar pedras
- **Snapback (Uttegaeshi)**: Descobre que pode sacrificar primeiro e depois contra-capturar
- **Ko**: Descobre formas de utilizar a regra de repetiÃ§Ã£o

A ordem dessas descobertas Ã© semelhante Ã  ordem em que os humanos aprendem Go.

---

## CorrespondÃªncia com AnimaÃ§Ãµes

Os conceitos principais deste artigo e nÃºmeros de animaÃ§Ã£o correspondentes:

| NÃºmero | Conceito | CorrespondÃªncia FÃ­sica/MatemÃ¡tica |
|--------|----------|-----------------------------------|
| ğŸ¬ E12 | Curva de crescimento de habilidade | Crescimento em S (logÃ­stico) |
| ğŸ¬ E7 | Do zero | FenÃ´meno de auto-organizaÃ§Ã£o |
| ğŸ¬ E5 | Auto-jogo | ConvergÃªncia de ponto fixo |
| ğŸ¬ F8 | Capacidades emergentes | TransiÃ§Ã£o de fase |

---

## Leitura Adicional

- **Artigo anterior**: [Rede Dual-Head e Redes Residuais](../dual-head-resnet) â€” A arquitetura de rede neural que sustenta tudo isso
- **PrÃ³ximo artigo**: [Sistemas DistribuÃ­dos e TPU](../distributed-systems) â€” O hardware que tornou tudo isso possÃ­vel
- **Artigo relacionado**: [Auto-Jogo](../self-play) â€” Por que o auto-jogo Ã© tÃ£o eficaz

---

## ReferÃªncias

1. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 550, 354-359.
2. Silver, D., et al. (2017). "AlphaGo Zero: Starting from scratch." *DeepMind Blog*.
3. DeepMind. (2017). "AlphaGo Zero: Learning from scratch." *YouTube*.
4. Wang, F., et al. (2019). "A Survey on the Evolution of AlphaGo." *arXiv:1907.11180*.
