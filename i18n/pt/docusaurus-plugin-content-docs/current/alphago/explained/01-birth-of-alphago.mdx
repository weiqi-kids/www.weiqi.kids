---
sidebar_position: 2
title: O Nascimento do AlphaGo
description: Da fundação da DeepMind à aquisição pelo Google, como o AlphaGo passou de uma ideia louca a uma IA que mudou o mundo
---

# O Nascimento do AlphaGo

Em março de 2016, quando o AlphaGo derrotou Lee Sedol por 4:1, o mundo inteiro perguntou: como nasceu este programa que mudou a história da inteligência artificial?

A resposta começa com o sonho de um prodígio do xadrez.

---

## A Fundação da DeepMind

### Demis Hassabis: De Prodígio a Pioneiro da IA

**Demis Hassabis** é o cofundador e CEO da DeepMind. Sua trajetória de vida parece ter sido preparada para criar o AlphaGo.

#### Prodígio do Xadrez

Nascido em Londres em 1975, Hassabis aprendeu a jogar xadrez aos 4 anos e alcançou o nível de mestre de xadrez (Elo 2300+) aos 13 anos, sendo o segundo mais jovem a alcançar esse nível na história britânica.

Essa experiência lhe deu uma compreensão profunda de:
- **Jogos de tabuleiro são um teste para a inteligência**: Jogar xadrez requer planejamento, intuição e reconhecimento de padrões
- **A natureza da inteligência humana**: Como os jogadores encontram boas jogadas em meio a enormes possibilidades?
- **As limitações dos computadores**: A vitória do Deep Blue sobre Kasparov em 1997 foi baseada em busca por força bruta, não em verdadeira "compreensão"

#### Designer de Jogos

Aos 17 anos, Hassabis juntou-se à Bullfrog Productions (empresa de jogos fundada por Peter Molyneux, criador de "Populous"), participando do desenvolvimento do jogo clássico "Theme Park". Essa experiência ensinou-lhe:

- **Como projetar sistemas complexos**: Jogos são modelos simplificados que simulam o mundo real
- **Previsão de comportamento dos jogadores**: A IA precisa entender o processo de tomada de decisão humana

#### Neurocientista Cognitivo

Após obter seu diploma em Ciência da Computação em Cambridge, Hassabis obteve seu doutorado em Neurociência Cognitiva na University College London (UCL). Seu tema de pesquisa foi: **como o hipocampo permite que os humanos imaginem e planejem**.

Esta pesquisa descobriu:
- A memória humana e a imaginação usam a mesma região cerebral
- Planejamos o futuro através de "viagens mentais no tempo"
- Essa capacidade pode ser o núcleo da inteligência

Esses insights influenciaram diretamente o design posterior do AlphaGo — permitindo que a IA "imagine" jogadas futuras e aprenda com elas.

### Cofundadores

Em 2010, Hassabis cofundou a DeepMind com dois parceiros:

| Fundador | Background | Contribuição |
|----------|------------|--------------|
| **Demis Hassabis** | Neurociência, Design de Jogos | Visão e Estratégia |
| **Shane Legg** | PhD em Machine Learning | Base Teórica da AGI |
| **Mustafa Suleyman** | Empreendedor Social | Negócios e Aplicações |

### "Resolver a Inteligência, Usar a Inteligência para Resolver Tudo"

A declaração de missão da DeepMind é:

> **"Solve intelligence, and then use that to solve everything else."**
>
> "Resolver a inteligência e então usá-la para resolver todo o resto."

Esta não é uma empresa de IA comum. Seu objetivo não é criar produtos, mas criar **Inteligência Artificial Geral (AGI)** — uma IA capaz de pensar, aprender e resolver qualquer problema como os humanos.

Por que "resolver a inteligência" primeiro? Porque uma vez que tenhamos AGI, ela pode nos ajudar a resolver os maiores desafios da humanidade: mudanças climáticas, doenças, energia.

---

## Avanços Iniciais: Jogos de Atari

Antes de desafiar o Go, a DeepMind primeiro provou suas capacidades — usando IA para jogar jogos de Atari.

### DQN: A IA que Aprendeu a Jogar

Em 2013, a DeepMind publicou o algoritmo **DQN (Deep Q-Network)**. Esta IA era capaz de:

1. **Ver apenas pixels da tela** — sem receber nenhuma regra do jogo
2. **Aprender a jogar sozinha** — através de tentativa e erro
3. **Alcançar nível humano** — e até superar humanos em alguns jogos

No Breakout, a DQN aprendeu uma estratégia que os humanos levam horas para descobrir: **cavar um túnel para deixar a bola passar atrás dos tijolos, eliminando muitos de uma vez**.

Isso provou que a combinação de deep learning + aprendizado por reforço pode descobrir estratégias que os humanos nunca imaginaram.

### Por Que Começar com Jogos?

Hassabis escolheu jogos como plataforma de pesquisa por várias razões:

1. **Ambiente controlável**: Jogos têm regras e objetivos claros
2. **Progresso mensurável**: Há pontuações objetivas para avaliar a capacidade da IA
3. **Referência humana**: Pode-se comparar com jogadores humanos
4. **Diversidade**: Diferentes jogos testam diferentes habilidades

Essa metodologia foi posteriormente aplicada ao Go.

---

## Aquisição pelo Google

### A Aposta de 500 Milhões de Dólares

Em janeiro de 2014, o Google adquiriu a DeepMind por aproximadamente **500 milhões de dólares**. Esta foi uma das maiores aquisições no campo da IA na época.

Por que o Google estava disposto a pagar tanto por uma empresa com apenas 75 pessoas e sem produtos?

A resposta está na **teoria dos jogos**:

- **Facebook também estava competindo**: Rumores dizem que o Facebook ofereceu 400 milhões de dólares
- **IA é a tecnologia chave do futuro**: Quem dominar a IA primeiro, dominará o futuro
- **DeepMind é a melhor equipe**: Eles provaram a viabilidade do deep reinforcement learning

O CEO do Google, Larry Page, interveio pessoalmente para convencer Hassabis a escolher o Google em vez do Facebook.

### Condições da Aquisição

Hassabis negociou várias condições importantes:

1. **Operação independente**: A DeepMind manteve sua sede em Londres, P&D independente
2. **Liberdade acadêmica**: Pode publicar artigos, em vez de manter tudo confidencial
3. **Comitê de ética**: Estabelecimento de um mecanismo de revisão ética de IA
4. **Pesquisa de longo prazo**: Sem pressão de comercialização a curto prazo

Essas condições permitiram que a DeepMind perseguisse pesquisas de longo prazo e alto risco — como conquistar o Go com IA.

### Estratégia de IA do Google

A aquisição da DeepMind fez parte da estratégia "IA primeiro" do Google:

| Ano | Evento |
|-----|--------|
| 2011 | Fundação do Google Brain |
| 2013 | Aquisição da DNNresearch (equipe de Hinton) |
| 2014 | Aquisição da DeepMind |
| 2015 | TensorFlow de código aberto |
| 2016 | Lançamento do TPU |

O Google percebeu que busca, publicidade, tradução, voz — todos os negócios principais seriam remodelados pela IA. Quem tiver a melhor IA será o vencedor.

---

## Escolhendo o Go como Objetivo

### Por Que o Go?

Após ser adquirida pelo Google, a DeepMind tinha mais recursos. Hassabis decidiu enfrentar um objetivo aparentemente impossível: **usar IA para derrotar o campeão mundial de Go humano**.

Por que escolher o Go, e não outros problemas?

#### 1. Go é o "Santo Graal da IA"

Antes de 2016, especialistas geralmente acreditavam que a IA precisaria de pelo menos 10-20 anos para derrotar humanos no Go. O Go era chamado de "a última fortaleza da IA".

Razões:
- **Espaço de busca enorme**: 10^170 posições possíveis (o número de átomos no universo é apenas 10^80)
- **Avaliação difícil**: Ao contrário do xadrez, não há valores claros de peças
- **Dependência da intuição**: Jogadores de alto nível frequentemente dizem "esta jogada parece certa", mas não conseguem explicar por quê

#### 2. A Lição do Deep Blue

Em 1997, o Deep Blue da IBM derrotou o campeão mundial de xadrez Kasparov. Mas essa vitória foi controversa:

- O Deep Blue dependia de **busca por força bruta** (avaliando 200 milhões de posições por segundo)
- Usava **funções de avaliação projetadas por especialistas humanos**
- Isso não era verdadeira "inteligência", mas "poder computacional"

Hassabis queria provar: a IA pode resolver problemas através de **aprendizado**, não força bruta.

#### 3. Objetivo Mensurável

O Go tem um sistema de classificação internacional (Elo rating) e jogadores profissionais, fornecendo padrões objetivos de medição. Se a IA pudesse derrotar o campeão mundial, seria um sucesso indiscutível.

#### 4. Conexão com a Neurociência

A intuição dos jogadores humanos — olhar para o tabuleiro e instantaneamente saber quais posições são importantes — é exatamente a capacidade que Hassabis queria replicar com IA. O Go é o cenário perfeito para testar a "intuição da máquina".

---

## Equipe AlphaGo

### Figuras Principais

O sucesso do AlphaGo veio de uma equipe com backgrounds multidisciplinares:

#### David Silver: Pesquisador Principal

**David Silver** é o primeiro autor do artigo do AlphaGo e um especialista de ponta em aprendizado por reforço.

- **Background**: Graduado em Matemática em Cambridge, PhD em RL pela Universidade de Alberta
- **Orientador**: Richard Sutton (pai do aprendizado por reforço)
- **Especialidade**: Monte Carlo Tree Search, aprendizado por diferença temporal

Silver pesquisou Go computacional em sua tese de doutorado, mas a tecnologia na época estava longe de ser madura. Após entrar na DeepMind, ele finalmente teve a chance de realizar esse sonho.

#### Aja Huang: Especialista em Go

**Aja Huang** (Huang Shih-Chieh) é taiwanês, jogador amador de 6 dan, e também um pioneiro no campo do Go computacional.

- **Background**: PhD em Ciência da Computação pela National Taiwan Normal University
- **Especialidade**: Programação de Go computacional
- **Trabalho famoso**: Erica (programa de Go computacional antigo)

Huang desempenhou um papel fundamental na equipe do AlphaGo: ele não só entendia Go, mas também IA. Durante as partidas contra Lee Sedol, ele foi quem operou o AlphaGo.

#### Outros Membros Importantes

| Membro | Função |
|--------|--------|
| Chris J. Maddison | Especialista em Monte Carlo Tree Search |
| Arthur Guez | Pesquisador de Aprendizado por Reforço |
| Laurent Sifre | Engenheiro de Deep Learning |
| George van den Driessche | Engenheiro de Sistemas Distribuídos |

### Colaboração Interdisciplinar

O sucesso do AlphaGo provou o poder da **colaboração interdisciplinar**:

- **Especialistas em Go** forneceram conhecimento de domínio
- **Pesquisadores de machine learning** projetaram algoritmos
- **Engenheiros** implementaram sistemas de treinamento em larga escala
- **Neurocientistas** forneceram inspiração teórica

Essa composição de equipe mais tarde se tornou o padrão da DeepMind.

---

## Publicação no Nature

### A Surpresa Secreta

Em 27 de janeiro de 2016, a DeepMind publicou um artigo na prestigiosa revista acadêmica *Nature*:

> **"Mastering the game of Go with deep neural networks and tree search"**

O artigo anunciou que o AlphaGo tinha:
1. Derrotado todos os outros programas de Go
2. Derrotado o campeão europeu **Fan Hui** (profissional 2 dan) por **5:0**

Esta notícia chocou o mundo. Antes da publicação do artigo, ninguém sabia que a DeepMind estava pesquisando Go.

### Contribuições Principais do Artigo

O artigo da *Nature* descreveu três grandes inovações do AlphaGo:

#### 1. Policy Network (Rede de Políticas)

Usar redes neurais convolucionais profundas para prever o próximo movimento de jogadores humanos. Os dados de treinamento vieram de **30 milhões de partidas** humanas.

```
Precisão: 57% (prever o próximo movimento de especialistas humanos)
```

Isso foi mais de 10 pontos percentuais maior que os melhores programas de Go computacional anteriores.

#### 2. Value Network (Rede de Valor)

Usar outra rede neural para avaliar a taxa de vitória da posição atual. Isso substituiu as simulações aleatórias tradicionais (Monte Carlo rollout).

```
Precisão: Equivalente a 15.000 simulações aleatórias, mas 15.000 vezes mais rápido
```

#### 3. Integração com Monte Carlo Tree Search

Integrar as duas redes neurais no framework MCTS:
- Policy Network guia a direção da busca
- Value Network avalia os nós folha

Isso deu ao AlphaGo tanto "intuição" (redes neurais) quanto "raciocínio" (busca em árvore).

### Reação da Comunidade Acadêmica

Após a publicação do artigo, a comunidade acadêmica reagiu entusiasticamente:

> "Este é o momento de pouso na lua da inteligência artificial."
> — **Stuart Russell**, Professor da UC Berkeley, autor de livro-texto de IA

> "Eu originalmente pensei que levaria mais 10 anos, não esperava que fosse tão rápido."
> — **Martin Müller**, especialista em Go computacional

Mas alguns também eram céticos:

> "Fan Hui é apenas um profissional 2 dan, não um jogador de alto nível real. Deixe o AlphaGo jogar contra Lee Sedol primeiro."

A DeepMind aceitou esse desafio.

---

## Desafiando Lee Sedol

### Por Que Lee Sedol?

**Lee Sedol** é um jogador coreano, considerado um dos jogadores mais fortes da última década:

| Métrica | Dados |
|---------|-------|
| Títulos de Campeão Mundial | 18 |
| Campeonatos Internacionais | 32 |
| Maior Ranking Mundial | #1 |
| Estilo | "Gênio" "Calculista Divino" |

Ao escolher Lee Sedol, a DeepMind estava desafiando o oponente humano mais forte.

### Prêmio de 1 Milhão de Dólares

O Google ofereceu um prêmio de **1 milhão de dólares** para esta partida:

- Se Lee Sedol vencesse: O prêmio iria para Lee Sedol
- Se o AlphaGo vencesse: O prêmio seria doado para UNICEF, educação STEM e outras instituições de caridade

Isso não foi apenas uma demonstração técnica, mas também um evento esportivo de atenção global.

### Previsões Antes da Partida

Antes da partida, a maioria dos jogadores profissionais previa que Lee Sedol venceria facilmente:

> "O AlphaGo pode ganhar um jogo, mas em 5 jogos eu vencerei 5:0."
> — **Lee Sedol**, entrevista pré-partida

> "Computadores jogam de forma rígida, jogadores de alto nível podem facilmente encontrar fraquezas."
> — Um profissional 9 dan

Mas a equipe da DeepMind tinha uma visão diferente. David Silver revelou depois:

> "Em nossos testes internos, já havíamos feito o AlphaGo jogar 500 partidas contra a versão que enfrentou Fan Hui. A nova versão ganhou 499."

---

## Março de 2016: Cinco Jogos que Mudaram o Mundo

### Primeiro Jogo: O Choque Começa

9 de março de 2016, Hotel Four Seasons, Seul.

Lee Sedol jogou de preto primeiro, AlphaGo de branco. Após 3 horas e 28 minutos de jogo, o AlphaGo venceu por resignação no meio do jogo.

Esta foi a primeira vez que um jogador humano de elite perdeu oficialmente para uma IA.

### Segundo Jogo: A Jogada Divina

O segundo jogo produziu o que ficou conhecido como a "**Jogada Divina**" na jogada 37 — AlphaGo fez um shoulder hit na quinta linha que todos os jogadores profissionais pensaram ser um erro, mas que se provou ser a chave para a vitória.

(Veja detalhes no próximo artigo: [Análise Aprofundada da "Jogada Divina"](../move-37))

O AlphaGo venceu novamente.

### Terceiro Jogo: 3:0

No terceiro jogo, Lee Sedol tentou uma abertura não tradicional, mas o AlphaGo respondeu com facilidade. 3:0.

O mundo começou a perceber: isso não foi acidente, a IA realmente superou os humanos.

### Quarto Jogo: O Contra-Ataque Humano

No quarto jogo, Lee Sedol fez o que ficou conhecido como a "**Jogada Divina**" na jogada 78 — um wedge brilhante que causou confusão no AlphaGo.

O AlphaGo fez jogadas claramente ruins nos movimentos seguintes e finalmente resignou.

Esta vitória provou: a IA também tem fraquezas. Lee Sedol a encontrou.

### Quinto Jogo: Placar Final

No quinto jogo, o AlphaGo voltou ao normal e terminou a partida com uma vitória por resignação no meio do jogo.

**Placar final: AlphaGo 4:1 Lee Sedol**

---

## Impacto e Consequências

### Atenção Global

O impacto desta partida foi muito além do mundo do Go:

- **200 milhões de pessoas** ao redor do mundo assistiram à transmissão ao vivo
- *The New York Times*, *The Economist* e outros meios de comunicação mainstream cobriram extensivamente
- O preço das ações do Google subiu durante a partida
- "Inteligência Artificial" tornou-se o tópico de tecnologia mais quente daquele ano

### Impacto no Mundo do Go

Após a partida, a atitude dos jogadores profissionais mudou de "desdém" para "respeito":

> "Nós pensávamos que humanos entendiam Go, agora descobrimos que só sabemos um pouco."
> — **Ke Jie**, jogador chinês, #1 mundial na época

Muitos jogadores profissionais começaram a usar IA para treinar, e a forma de jogar Go também mudou como resultado.

### Impacto no Campo da IA

O AlphaGo provou várias coisas:

1. **Deep learning pode resolver problemas de nível especialista**: Não apenas reconhecer gatos e cachorros, mas também jogar Go
2. **Aprendizado por reforço pode superar humanos**: Através de auto-jogo, a IA pode descobrir estratégias desconhecidas pelos humanos
3. **Redes neurais + busca é uma combinação poderosa**: Intuição + raciocínio = inteligência mais forte

Esses insights foram posteriormente aplicados a:
- **AlphaFold**: Previsão de estrutura de proteínas (conquista de nível Prêmio Nobel em 2020)
- **AlphaZero**: IA de jogos gerais
- **MuZero**: Aprendizado sem regras

---

## Correspondência de Animações

Conceitos principais abordados neste artigo e números de animação:

| Número | Conceito | Correspondência Física/Matemática |
|--------|----------|-----------------------------------|
| E7 | Do Zero | Auto-organização |
| E5 | Auto-Jogo | Convergência de ponto fixo |
| F8 | Capacidades Emergentes | Transição de fase |
| H4 | Gradiente de Política | Otimização estocástica |

---

## Leitura Adicional

- **Próximo artigo**: [Revisão das Partidas Principais](../key-matches) — Análise completa das partidas de Fan Hui, Lee Sedol, Ke Jie
- **Detalhes técnicos**: [Policy Network em Detalhes](../policy-network) — Como o AlphaGo aprendeu a jogar
- **Prática hands-on**: [Execute Sua Primeira IA de Go em 30 Minutos](/docs/tech/hands-on/) — Experimente você mesmo

---

## Referências

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. Documentário *AlphaGo* (2017), Diretor Greg Kohs.
