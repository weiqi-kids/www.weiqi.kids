---
sidebar_position: 8
title: Policy Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг
description: AlphaGo рдХреА рд░рдгрдиреАрддрд┐ рдиреЗрдЯрд╡рд░реНрдХ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛, рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╡рд┐рдзрд┐рдпреЛрдВ рдФрд░ рд╡реНрдпрд╛рд╡рд╣рд╛рд░рд┐рдХ рдЕрдиреБрдкреНрд░рдпреЛрдЧреЛрдВ рдХреА рдЧрд╣рди рд╕рдордЭ, 13 рдкрд░рдд convolution рд╕реЗ Softmax рдЖрдЙрдЯрдкреБрдЯ рддрдХ
---

import { PolicyHeatmap } from '@site/src/components/D3Charts';

# Policy Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг

рдЧреЛ рдХреА рдХрд┐рд╕реА рднреА рд╕реНрдерд┐рддрд┐ рдореЗрдВ, рд╡реИрдз рдЪрд╛рд▓реЛрдВ рдХреА рдФрд╕рдд рд╕рдВрдЦреНрдпрд╛ 250 рд╣реИред рдпрджрд┐ рдХрдВрдкреНрдпреВрдЯрд░ рдХреЛ рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рд░реВрдк рд╕реЗ рдЪреБрдирдиреЗ рджреЗрдВ, рддреЛ рд╡рд╣ рдХрднреА рднреА рдЕрдЪреНрдЫреА рдЪрд╛рд▓ рдирд╣реАрдВ рдЪрд▓ рдкрд╛рдПрдЧрд╛ред

AlphaGo рдХреА рд╕рдлрд▓рддрд╛ рдЗрд╕рдореЗрдВ рд╣реИ: рдЙрд╕рдиреЗ "рдПрдХ рдирдЬрд╝рд░ рдореЗрдВ рдмреЛрд░реНрдб рджреЗрдЦрдХрд░, рдпрд╣ рдЬрд╛рдирдирд╛ рд╕реАрдЦ рд▓рд┐рдпрд╛ рдХрд┐ рдХреМрди рд╕реА рд╕реНрдерд┐рддрд┐рдпрд╛рдБ рд╡рд┐рдЪрд╛рд░ рдХрд░рдиреЗ рдпреЛрдЧреНрдп рд╣реИрдВ"ред

рдпрд╣ рдХреНрд╖рдорддрд╛ **Policy Network (рд░рдгрдиреАрддрд┐ рдиреЗрдЯрд╡рд░реНрдХ)** рд╕реЗ рдЖрддреА рд╣реИред

---

## Policy Network рдХреНрдпрд╛ рд╣реИ?

### рдореБрдЦреНрдп рдХрд╛рд░реНрдп

Policy Network рдПрдХ рдЧрд╣рди convolutional neural network рд╣реИ, рдЗрд╕рдХрд╛ рдХрд╛рд░реНрдп рд╣реИ:

> **рд╡рд░реНрддрдорд╛рди рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐ рджреА рдЧрдИ, рдкреНрд░рддреНрдпреЗрдХ рд╕реНрдерд┐рддрд┐ рдХреА рдЪрд╛рд▓ рд╕рдВрднрд╛рд╡рдирд╛ рдЖрдЙрдЯрдкреБрдЯ рдХрд░реЗрдВ**

рдЧрдгрд┐рддреАрдп рд░реВрдк рдореЗрдВ:

```
p = f_╬╕(s)
```

рдЬрд╣рд╛рдБ:
- `s`: рд╡рд░реНрддрдорд╛рди рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐ (19├Ч19 рдмреЛрд░реНрдб + рдЕрдиреНрдп рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ)
- `f_╬╕`: Policy Network (╬╕ рдиреЗрдЯрд╡рд░реНрдХ рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИрдВ)
- `p`: 361 рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг (pass рд╕рд╣рд┐рдд)

### рд╕рд╣рдЬ рд╕рдордЭ

рдХрд▓реНрдкрдирд╛ рдХрд░реЗрдВ рдЖрдк рдПрдХ рдкреЗрд╢реЗрд╡рд░ рдЦрд┐рд▓рд╛рдбрд╝реА рд╣реИрдВред рдЬрдм рдЖрдк рдПрдХ рд╕реНрдерд┐рддрд┐ рджреЗрдЦрддреЗ рд╣реИрдВ, рдЖрдкрдХрд╛ рдорд╕реНрддрд┐рд╖реНрдХ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдХреБрдЫ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреЛ "рдкреНрд░рдХрд╛рд╢рд┐рдд" рдХрд░рддрд╛ рд╣реИтАФрдпреЗ рд╡реЗ рдмрд┐рдВрджреБ рд╣реИрдВ рдЬреЛ рдЖрдкрдХреА рд╕рд╣рдЬ рдмреБрджреНрдзрд┐ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рд╡рд┐рдЪрд╛рд░ рдХрд░рдиреЗ рдпреЛрдЧреНрдп рд╣реИрдВред

Policy Network рдЗрд╕реА рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХрд╛ рдЕрдиреБрдХрд░рдг рдХрд░ рд░рд╣рд╛ рд╣реИред

<PolicyHeatmap initialPosition="corner" size={400} />

рдКрдкрд░ рдХрд╛ рд╣реАрдЯ рдореИрдк Policy Network рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ рджрд┐рдЦрд╛рддрд╛ рд╣реИред рдЬрд┐рддрдирд╛ рдЪрдордХреАрд▓рд╛ рд░рдВрдЧ, рдЙрддрдирд╛ рд╣реА рдореЙрдбрд▓ рдЙрд╕ рд╕реНрдерд┐рддрд┐ рдХреЛ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдорд╛рдирддрд╛ рд╣реИред

### Policy Network рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдХреНрдпреЛрдВ?

рдЧреЛ рдХрд╛ рдЦреЛрдЬ рд╕реНрдерд╛рди рдмрд╣реБрдд рдмрдбрд╝рд╛ рд╣реИред рдпрджрд┐ рд╕рднреА рд╕рдВрднрд╛рд╡рд┐рдд рдЪрд╛рд▓реЛрдВ рдХреЛ рдмрд┐рдирд╛ рдлрд╝рд┐рд▓реНрдЯрд░ рдХрд┐рдП рдЦреЛрдЬреЗрдВ:

| рд░рдгрдиреАрддрд┐ | рдкреНрд░рддрд┐ рдЪрд╛рд▓ рд╡рд┐рдЪрд╛рд░рд┐рдд рдЪрд╛рд▓реЗрдВ | 10 рдЪрд╛рд▓реЛрдВ рдХреА рдЦреЛрдЬ рдореЗрдВ рдиреЛрдб рд╕рдВрдЦреНрдпрд╛ |
|------|--------------|------------------|
| рд╕рднреА рдкрд░ рд╡рд┐рдЪрд╛рд░ | 361 | 361^10 тЙИ 10^25 |
| Policy Network рдлрд╝рд┐рд▓реНрдЯрд░ | ~20 | 20^10 тЙИ 10^13 |

Policy Network рдЦреЛрдЬ рд╕реНрдерд╛рди рдХреЛ **10^12 рдЧреБрдирд╛** (рдПрдХ рдЯреНрд░рд┐рд▓рд┐рдпрди рдЧреБрдирд╛) рдХрдо рдХрд░ рджреЗрддрд╛ рд╣реИред

---

## рдиреЗрдЯрд╡рд░реНрдХ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛

### рд╕рдордЧреНрд░ рд╕рдВрд░рдЪрдирд╛

AlphaGo рдХрд╛ Policy Network рдЧрд╣рди convolutional neural network (CNN) рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдЕрдкрдирд╛рддрд╛ рд╣реИ:

```
рдЗрдирдкреБрдЯ рдкрд░рдд тЖТ Convolutional рдкрд░рдд ├Ч12 тЖТ рдЖрдЙрдЯрдкреБрдЯ Convolutional рдкрд░рдд тЖТ Softmax
   тЖУ         тЖУ            тЖУ           тЖУ
19├Ч19├Ч48   19├Ч19├Ч192   19├Ч19├Ч1     362 рд╕рдВрднрд╛рд╡рдирд╛рдПрдБ
```

### рдЗрдирдкреБрдЯ рдкрд░рдд

рдЗрдирдкреБрдЯ рдПрдХ **19├Ч19├Ч48** рд╡рд┐рд╢реЗрд╖рддрд╛ tensor рд╣реИ:
- **19├Ч19**: рдмреЛрд░реНрдб рдЖрдХрд╛рд░
- **48**: 48 рд╡рд┐рд╢реЗрд╖рддрд╛ рдкреНрд▓реЗрди (рд╡рд┐рд╡рд░рдг рдХреЗ рд▓рд┐рдП [рдЗрдирдкреБрдЯ рд╡рд┐рд╢реЗрд╖рддрд╛ рдбрд┐рдЬрд╝рд╛рдЗрди](../input-features) рджреЗрдЦреЗрдВ)

рдпреЗ 48 рдкреНрд▓реЗрди рдореЗрдВ рд╢рд╛рдорд┐рд▓ рд╣реИрдВ:
- рдХрд╛рд▓реЗ рдкрддреНрдерд░реЛрдВ рдХреА рд╕реНрдерд┐рддрд┐, рд╕рдлреЗрдж рдкрддреНрдерд░реЛрдВ рдХреА рд╕реНрдерд┐рддрд┐
- рд╣рд╛рд▓ рдХреА 8 рдЪрд╛рд▓реЛрдВ рдХрд╛ рдЗрддрд┐рд╣рд╛рд╕
- рд╕рд╛рдБрд╕реЗрдВ, рдЕрддрд╛рд░реА, рд▓реИрдбрд░ рдЖрджрд┐ рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ
- рд╡реИрдзрддрд╛ (рдХрд╣рд╛рдБ рдЪрд╛рд▓ рдЪрд▓ рд╕рдХрддреЗ рд╣реИрдВ)

### Convolutional рдкрд░рддреЗрдВ

рдиреЗрдЯрд╡рд░реНрдХ рдореЗрдВ **12 convolutional рдкрд░рддреЗрдВ** рд╣реИрдВ, рдкреНрд░рддреНрдпреЗрдХ рдкрд░рдд рдХреА рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди:

| рдкреИрд░рд╛рдореАрдЯрд░ | рдорд╛рди | рд╡рд┐рд╡рд░рдг |
|------|------|------|
| рдлрд╝рд┐рд▓реНрдЯрд░ рд╕рдВрдЦреНрдпрд╛ | 192 | рдкреНрд░рддреНрдпреЗрдХ рдкрд░рдд 192 рд╡рд┐рд╢реЗрд╖рддрд╛ рдореИрдк рдЖрдЙрдЯрдкреБрдЯ рдХрд░рддреА рд╣реИ |
| рдХрд░реНрдиреЗрд▓ рдЖрдХрд╛рд░ | 3├Ч3 (рдкрд╣рд▓реА рдкрд░рдд 5├Ч5) | рд╣рд░ рдмрд╛рд░ 3├Ч3 рдХреНрд╖реЗрддреНрд░ рджреЗрдЦреЗрдВ |
| рдкреИрдбрд┐рдВрдЧ рд╡рд┐рдзрд┐ | same | 19├Ч19 рдЖрдХрд╛рд░ рдмрдирд╛рдП рд░рдЦреЗрдВ |
| рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди | ReLU | max(0, x) |

#### 192 рдлрд╝рд┐рд▓реНрдЯрд░ рдХреНрдпреЛрдВ?

рдпрд╣ рдПрдХ рдЕрдиреБрднрд╡рдЬрдиреНрдп рдорд╛рди рд╣реИред рдмрд╣реБрдд рдХрдо рдореЙрдбрд▓ рдХреНрд╖рдорддрд╛ рдХреЛ рд╕реАрдорд┐рдд рдХрд░реЗрдЧрд╛, рдмрд╣реБрдд рдЕрдзрд┐рдХ рдЧрдгрдирд╛ рд▓рд╛рдЧрдд рдФрд░ overfitting рдЬреЛрдЦрд┐рдо рдмрдврд╝рд╛рдПрдЧрд╛ред DeepMind рдЯреАрдо рдиреЗ рдкреНрд░рдпреЛрдЧреЛрдВ рджреНрд╡рд╛рд░рд╛ 192 рдХреЛ рдПрдХ рдЕрдЪреНрдЫрд╛ рд╕рдВрддреБрд▓рди рдмрд┐рдВрджреБ рдирд┐рд░реНрдзрд╛рд░рд┐рдд рдХрд┐рдпрд╛ред

#### 3├Ч3 convolutional рдХрд░реНрдиреЗрд▓ рдХреНрдпреЛрдВ?

3├Ч3 convolutional neural networks рдореЗрдВ рд╕рдмрд╕реЗ рдЖрдо рдЖрдХрд╛рд░ рд╣реИ, рдХрд╛рд░рдг:
1. **рд╕реНрдерд╛рдиреАрдп рдкреИрдЯрд░реНрди рдкрдХрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдП рдкрд░реНрдпрд╛рдкреНрдд**: рдЧреЛ рдореЗрдВ рдЖрдБрдЦ, рдХрдиреЗрдХреНрдЯ, рдХрдЯ рд╕рднреА 3├Ч3 рд╕реАрдорд╛ рдореЗрдВ рд╣реИрдВ
2. **рдЧрдгрдирд╛ рджрдХреНрд╖рддрд╛**: рдмрдбрд╝реЗ рдХрд░реНрдиреЗрд▓ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ, 3├Ч3 рдореЗрдВ рдХрдо рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИрдВ
3. **рд╕реНрдЯреИрдХ рдХрд░рдиреЗ рдпреЛрдЧреНрдп**: рдХрдИ 3├Ч3 convolutions рдмрдбрд╝реЗ receptive field рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ

#### рдкрд╣рд▓реА рдкрд░рдд 5├Ч5 рдХреНрдпреЛрдВ?

рдкрд╣рд▓реА рдкрд░рдд рдмрдбрд╝рд╛ 5├Ч5 convolutional рдХрд░реНрдиреЗрд▓ рдЙрдкрдпреЛрдЧ рдХрд░рддреА рд╣реИ, рдЗрдирдкреБрдЯ рдкрд░рдд рдкрд░ рд╣реА рдереЛрдбрд╝реЗ рдмрдбрд╝реЗ рдкреИрдЯрд░реНрди (рдЬреИрд╕реЗ рдЫреЛрдЯреА рдЙрдбрд╝рд╛рди, рдХреВрдж) рдкрдХрдбрд╝рдиреЗ рдХреЗ рд▓рд┐рдПред рдпрд╣ рдПрдХ рдбрд┐рдЬрд╝рд╛рдЗрди рд╡рд┐рдХрд▓реНрдк рд╣реИ, рдмрд╛рдж рдХреЗ AlphaGo Zero рдиреЗ рдПрдХреАрдХреГрдд рд░реВрдк рд╕реЗ 3├Ч3 рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ред

### ReLU рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди

рдкреНрд░рддреНрдпреЗрдХ convolutional рдкрд░рдд рдХреЗ рдмрд╛рдж ReLU (Rectified Linear Unit) рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди:

```
ReLU(x) = max(0, x)
```

ReLU рдХреНрдпреЛрдВ?

1. **рд╕рд░рд▓ рдЧрдгрдирд╛**: рдХреЗрд╡рд▓ рдЕрдзрд┐рдХрддрдо рд▓реЗрдирд╛, sigmoid рд╕реЗ рдмрд╣реБрдд рддреЗрдЬрд╝
2. **рдЧреНрд░реЗрдбрд┐рдПрдВрдЯ vanishing рдХрдо рдХрд░рдирд╛**: рд╕рдХрд╛рд░рд╛рддреНрдордХ рдХреНрд╖реЗрддреНрд░ рдореЗрдВ рдЧреНрд░реЗрдбрд┐рдПрдВрдЯ рд╣рдореЗрд╢рд╛ 1
3. **рд╡рд┐рд░рд▓ рд╕рдХреНрд░рд┐рдпрдг**: рдЛрдгрд╛рддреНрдордХ рдорд╛рди рд╢реВрдиреНрдп рд╣реЛ рдЬрд╛рддреЗ рд╣реИрдВ, рд╡рд┐рд░рд▓ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдЙрддреНрдкрдиреНрди

### рдЖрдЙрдЯрдкреБрдЯ рдкрд░рдд

рдЕрдВрддрд┐рдо рдкрд░рдд рдПрдХ рд╡рд┐рд╢реЗрд╖ convolutional рдкрд░рдд рд╣реИ:

```
19├Ч19├Ч192 тЖТ Convolution(1├Ч1, 1 рдлрд╝рд┐рд▓реНрдЯрд░) тЖТ 19├Ч19├Ч1 тЖТ рд╕рдорддрд▓ тЖТ 362 рдЖрдпрд╛рдореА рд╡реЗрдХреНрдЯрд░ тЖТ Softmax
```

#### 1├Ч1 Convolution

рдЖрдЙрдЯрдкреБрдЯ рдкрд░рдд 1├Ч1 convolution рдЙрдкрдпреЛрдЧ рдХрд░рддреА рд╣реИ, 192 рдЪреИрдирд▓реЛрдВ рдХреЛ 1 рдореЗрдВ рд╕рдВрдкреАрдбрд╝рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдПред рдпрд╣ рдкреНрд░рддреНрдпреЗрдХ рд╕реНрдерд┐рддрд┐ рдХреЗ 192-рдЖрдпрд╛рдореА рд╡рд┐рд╢реЗрд╖рддрд╛ рдкрд░ рд░реИрдЦрд┐рдХ рд╕рдВрдпреЛрдЬрди рдХреЗ рдмрд░рд╛рдмрд░ рд╣реИред

#### Softmax рдЖрдЙрдЯрдкреБрдЯ

362-рдЖрдпрд╛рдореА рд╡реЗрдХреНрдЯрд░ (361 рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐рдпрд╛рдБ + 1 pass) Softmax рдлрд╝рдВрдХреНрд╢рди рд╕реЗ рдЧреБрдЬрд╝рд░рддрд╛ рд╣реИ:

```
Softmax(z_i) = exp(z_i) / ╬г_j exp(z_j)
```

Softmax рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИ рдХрд┐ рдЖрдЙрдЯрдкреБрдЯ рд╡реИрдз рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг рд╣реИ:
- рд╕рднреА рдорд╛рди 0 рдФрд░ 1 рдХреЗ рдмреАрдЪ
- рд╕рднреА рдорд╛рдиреЛрдВ рдХрд╛ рдпреЛрдЧ 1

### рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛

рдиреЗрдЯрд╡рд░реНрдХ рдХреА рдХреБрд▓ рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛ рдХреА рдЧрдгрдирд╛ рдХрд░реЗрдВ:

| рдкрд░рдд | рдЧрдгрдирд╛ | рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛ |
|---|------|---------|
| рдкрд╣рд▓реА convolutional рдкрд░рдд | 5├Ч5├Ч48├Ч192 + 192 | 230,592 |
| рдордзреНрдп convolutional рдкрд░рддреЗрдВ ├Ч11 | (3├Ч3├Ч192├Ч192 + 192) ├Ч 11 | 3,633,792 |
| рдЖрдЙрдЯрдкреБрдЯ convolutional рдкрд░рдд | 1├Ч1├Ч192├Ч1 + 1 | 193 |
| **рдХреБрд▓** | | **~3.9M** |

рд▓рдЧрднрдЧ **3.9 рдорд┐рд▓рд┐рдпрди рдкреИрд░рд╛рдореАрдЯрд░**, рдЖрдЬ рдХреЗ рдорд╛рдирдХреЛрдВ рд╕реЗ рдПрдХ рдЫреЛрдЯрд╛ рдиреЗрдЯрд╡рд░реНрдХред

---

## рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЙрджреНрджреЗрд╢реНрдп рдФрд░ рд╡рд┐рдзрд┐

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛

Policy Network **рд╕реБрдкрд░рд╡рд╛рдЗрдЬреНрдб рд▓рд░реНрдирд┐рдВрдЧ** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рдорд╛рдирд╡ рдЧреЗрдо рд░рд┐рдХреЙрд░реНрдб рд╕реЗ рд╕реАрдЦрддрд╛ рд╣реИред

рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд:
- **KGS Go Server**: рд╢реМрдХрд┐рдпрд╛ рдФрд░ рдкреЗрд╢реЗрд╡рд░ рдЦрд┐рд▓рд╛рдбрд╝рд┐рдпреЛрдВ рдХреЗ рдЦреЗрд▓
- **рд▓рдЧрднрдЧ 30 рдорд┐рд▓рд┐рдпрди рд╕реНрдерд┐рддрд┐рдпрд╛рдБ**: 160,000 рдЦреЗрд▓реЛрдВ рд╕реЗ рдирдореВрдиреЗ
- **рд▓реЗрдмрд▓**: рдкреНрд░рддреНрдпреЗрдХ рд╕реНрдерд┐рддрд┐ рдХреЗ рд▓рд┐рдП рдорд╛рдирд╡ рдХреА рдЕрдЧрд▓реА рдЪрд╛рд▓

### Cross-Entropy рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди

рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХрд╛ рдЙрджреНрджреЗрд╢реНрдп рдорд╛рдирд╡ рдЪрд╛рд▓ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рд╕рдВрднрд╛рд╡рдирд╛ рдХреЛ рдЕрдзрд┐рдХрддрдо рдХрд░рдирд╛ рд╣реИред Cross-entropy рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ:

```
L(╬╕) = -╬г log p_╬╕(a | s)
```

рдЬрд╣рд╛рдБ:
- `s`: рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐
- `a`: рдорд╛рдирд╡ рдХреА рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдЪрд╛рд▓ рд╕реНрдерд┐рддрд┐
- `p_╬╕(a | s)`: рдореЙрдбрд▓ рджреНрд╡рд╛рд░рд╛ рдЙрд╕ рд╕реНрдерд┐рддрд┐ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рд╕рдВрднрд╛рд╡рдирд╛

#### рд╕рд╣рдЬ рд╕рдордЭ

Cross-entropy рд╣рд╛рдирд┐ рдХрд╛ рдПрдХ рд╕рд░рд▓ рдЕрд░реНрде рд╣реИ:

> **рдЬрдм рдореЙрдбрд▓ рд╕рд╣реА рд╕реНрдерд┐рддрд┐ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдЬрд┐рддрдиреА рдЕрдзрд┐рдХ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░рддрд╛ рд╣реИ, рд╣рд╛рдирд┐ рдЙрддрдиреА рдХрдо**

рдпрджрд┐ рдорд╛рдирд╡ K10 рдкрд░ рдЪрд▓рд╛, рдФрд░ рдореЙрдбрд▓ K10 рдХреЛ рд╕рдВрднрд╛рд╡рдирд╛ рджреЗрддрд╛ рд╣реИ:
- 0.9 тЖТ рд╣рд╛рдирд┐ = -log(0.9) тЙИ 0.1 (рдмрд╣реБрдд рдХрдо, рдЕрдЪреНрдЫрд╛)
- 0.1 тЖТ рд╣рд╛рдирд┐ = -log(0.1) тЙИ 2.3 (рдмрд╣реБрдд рдЕрдзрд┐рдХ, рдЦрд░рд╛рдм)
- 0.01 тЖТ рд╣рд╛рдирд┐ = -log(0.01) тЙИ 4.6 (рдмрд╣реБрдд рдЕрдзрд┐рдХ, рдмрд╣реБрдд рдЦрд░рд╛рдм)

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкреНрд░рдХреНрд░рд┐рдпрд╛

```python
# рдЫрджреНрдо рдХреЛрдб
for epoch in range(num_epochs):
    for batch in dataloader:
        states, actions = batch

        # рдлреЙрд░рд╡рд░реНрдб рдкрд╛рд╕
        policy = network(states)  # 361 рдЖрдпрд╛рдореА рд╕рдВрднрд╛рд╡рдирд╛ рд╡реЗрдХреНрдЯрд░

        # рд╣рд╛рдирд┐ рдЧрдгрдирд╛ (cross-entropy)
        loss = cross_entropy(policy, actions)

        # рдмреИрдХрд╡рд░реНрдб рдкрд╛рд╕
        loss.backward()
        optimizer.step()
```

рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╡рд┐рд╡рд░рдг:
- **рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░**: SGD with momentum
- **рд▓рд░реНрдирд┐рдВрдЧ рд░реЗрдЯ**: рдкреНрд░рд╛рд░рдВрднрд┐рдХ 0.003, рдзреАрд░реЗ-рдзреАрд░реЗ рдХрдо
- **рдмреИрдЪ рдЖрдХрд╛рд░**: 16
- **рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕рдордп**: рд▓рдЧрднрдЧ 3 рд╕рдкреНрддрд╛рд╣ (50 GPUs)

### рдбреЗрдЯрд╛ рд╕рдВрд╡рд░реНрдзрди

рдЧреЛ рдмреЛрд░реНрдб рдореЗрдВ 8 рд╕рдорд░реВрдкрддрд╛рдПрдБ рд╣реИрдВ (4 рд░реЛрдЯреЗрд╢рди ├Ч 2 рдорд┐рд░рд░)ред рдкреНрд░рддреНрдпреЗрдХ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдирдореВрдиреЗ рдХреЛ 8 рд╕рдорддреБрд▓реНрдп рдирдореВрдиреЛрдВ рдореЗрдВ рдмрджрд▓рд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ:

```
рдореВрд▓ тЖТ 90┬░ рд░реЛрдЯреЗрд╢рди тЖТ 180┬░ рд░реЛрдЯреЗрд╢рди тЖТ 270┬░ рд░реЛрдЯреЗрд╢рди
  тЖУ       тЖУ         тЖУ          тЖУ
рдХреНрд╖реИрддрд┐рдЬ рдлреНрд▓рд┐рдк тЖТ ...
```

рдЗрд╕рд╕реЗ рдкреНрд░рднрд╛рд╡реА рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ 8 рдЧреБрдирд╛ рдмрдврд╝ рдЬрд╛рддрд╛ рд╣реИ, рдФрд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рд╣реЛрддрд╛ рд╣реИ рдХрд┐ рдореЙрдбрд▓ рджреНрд╡рд╛рд░рд╛ рд╕реАрдЦреЗ рдЧрдП рдкреИрдЯрд░реНрди рджрд┐рд╢рд╛ рдкрд░ рдирд┐рд░реНрднрд░ рди рд╣реЛрдВред

---

## рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкрд░рд┐рдгрд╛рдо

### 57% рд╕рдЯреАрдХрддрд╛

рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдмрд╛рдж, Policy Network **57% top-1 рд╕рдЯреАрдХрддрд╛** рдкреНрд░рд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИред

рдЗрд╕рдХрд╛ рдЕрд░реНрде рд╣реИ: рдХрд┐рд╕реА рднреА рд╕реНрдерд┐рддрд┐ рдореЗрдВ, рдореЙрдбрд▓ рдХреЗ рдкрд╛рд╕ 57% рд╕рдВрднрд╛рд╡рдирд╛ рд╣реИ рдХрд┐ рд╡рд╣ рд╡рд╣реА рдЪрд╛рд▓ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░реЗ рдЬреЛ рдорд╛рдирд╡ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рдиреЗ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рдЪрд▓реАред

#### рдХреНрдпрд╛ рдпрд╣ рд╕рдЯреАрдХрддрд╛ рдЙрдЪреНрдЪ рд╣реИ?

рдпрд╣ рджреЗрдЦрддреЗ рд╣реБрдП рдХрд┐ рдкреНрд░рддреНрдпреЗрдХ рд╕реНрдерд┐рддрд┐ рдореЗрдВ рдФрд╕рддрди 250 рд╡реИрдз рдЪрд╛рд▓реЗрдВ рд╣реИрдВ, рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рдЕрдиреБрдорд╛рди рдХреА рд╕рдЯреАрдХрддрд╛ рдХреЗрд╡рд▓ 0.4% рд╣реИред

| рд╡рд┐рдзрд┐ | Top-1 рд╕рдЯреАрдХрддрд╛ |
|------|-------------|
| рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рдЕрдиреБрдорд╛рди | 0.4% |
| рдкрд┐рдЫрд▓рд╛ рд╕рдмрд╕реЗ рдордЬрдмреВрдд рдХрдВрдкреНрдпреВрдЯрд░ рдЧреЛ | ~44% |
| AlphaGo Policy Network | **57%** |

13 рдкреНрд░рддрд┐рд╢рдд рдЕрдВрдХ рдХреА рд╡реГрджреНрдзрд┐, рдЬреНрдпрд╛рджрд╛ рдирд╣реАрдВ рд▓рдЧрддреА, рд▓реЗрдХрд┐рди рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред

### рдЦреЗрд▓ рд╢рдХреНрддрд┐ рдореЗрдВ рд╡реГрджреНрдзрд┐

рдХреЗрд╡рд▓ Policy Network (рдмрд┐рдирд╛ рдЦреЛрдЬ рдХреЗ) рд╕реЗ рдЦреЗрд▓рдиреЗ рдкрд░, рдХреМрди рд╕реА рд╢рдХреНрддрд┐ рдкреНрд░рд╛рдкреНрдд рд╣реЛрддреА рд╣реИ?

| рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди | Elo рд░реЗрдЯрд┐рдВрдЧ | рд▓рдЧрднрдЧ рд╕реНрддрд░ |
|------|---------|---------|
| рдкрд┐рдЫрд▓рд╛ рд╕рдмрд╕реЗ рдордЬрдмреВрдд рдкреНрд░реЛрдЧреНрд░рд╛рдо (Pachi) | 2,500 | рд╢реМрдХрд┐рдпрд╛ 4-5 рджрд╛рди |
| рдХреЗрд╡рд▓ Policy Network | 2,800 | рд╢реМрдХрд┐рдпрд╛ 6-7 рджрд╛рди |
| + MCTS 1600 рд╕рд┐рдореБрд▓реЗрд╢рди | 3,200+ | рдкреЗрд╢реЗрд╡рд░ рд╕реНрддрд░ |

рдЕрдХреЗрд▓рд╛ Policy Network рдкрд╣рд▓реЗ рд╕реЗ рд╢реМрдХрд┐рдпрд╛ рдЙрдЪреНрдЪ рджрд╛рди рд╣реИ, MCTS рдЬреЛрдбрд╝рдиреЗ рдкрд░ рдкреЗрд╢реЗрд╡рд░ рд╕реНрддрд░ рдкрд░ рдкрд╣реБрдБрдЪ рдЬрд╛рддрд╛ рд╣реИред

### рдХреЗрд╡рд▓ 57% рдХреНрдпреЛрдВ?

рдорд╛рдирд╡ рдЧреЗрдо рд░рд┐рдХреЙрд░реНрдб рдХреА рдирд┐рдореНрди рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ рд╕рдЯреАрдХрддрд╛ рдХреЛ рд╕реАрдорд┐рдд рдХрд░рддреА рд╣реИрдВ:

#### 1. рдХрдИ рдЕрдЪреНрдЫреА рдЪрд╛рд▓реЗрдВ

рдХрдИ рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдореЗрдВ рдХрдИ рдЪрд╛рд▓реЗрдВ рдЕрдЪреНрдЫреА рд╣реИрдВред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП "рдЕрдкреНрд░реЛрдЪ" рдФрд░ "рдбрд┐рдлреЗрдВрдб рдХреЙрд░реНрдирд░" рджреЛрдиреЛрдВ рд╕рд╣реА рд╡рд┐рдХрд▓реНрдк рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВред рдореЙрдбрд▓ рдиреЗ рджреВрд╕рд░реА рдЕрдЪреНрдЫреА рдЪрд╛рд▓ рдЪреБрдиреА, рддреЛ "рдЧрд▓рдд" рдЧрд┐рдиреА рдЬрд╛рдПрдЧреАред

#### 2. рд╢реИрд▓реА рдЕрдВрддрд░

рдЕрд▓рдЧ-рдЕрд▓рдЧ рдЦрд┐рд▓рд╛рдбрд╝рд┐рдпреЛрдВ рдХреА рдЕрд▓рдЧ рд╢реИрд▓реА рд╣реЛрддреА рд╣реИред рдЖрдХреНрд░рд╛рдордХ рдФрд░ рд╕реНрдерд┐рд░ рдЦрд┐рд▓рд╛рдбрд╝реА рдПрдХ рд╣реА рд╕реНрдерд┐рддрд┐ рдореЗрдВ рдЕрд▓рдЧ рдЪрд╛рд▓ рдЪрд▓ рд╕рдХрддреЗ рд╣реИрдВред рдореЙрдбрд▓ "рдФрд╕рдд" рд╢реИрд▓реА рд╕реАрдЦрддрд╛ рд╣реИред

#### 3. рдорд╛рдирд╡ рднреА рдЧрд▓рддреА рдХрд░рддреЗ рд╣реИрдВ

KGS рдбреЗрдЯрд╛ рдореЗрдВ рд╢реМрдХрд┐рдпрд╛ рдЦрд┐рд▓рд╛рдбрд╝рд┐рдпреЛрдВ рдХреЗ рдЦреЗрд▓ рд╢рд╛рдорд┐рд▓ рд╣реИрдВ, рдЙрдирдХреЗ рд╡рд┐рдХрд▓реНрдк рд╣рдореЗрд╢рд╛ рд╕рд░реНрд╡реЛрддреНрддрдо рдирд╣реАрдВ рд╣реЛрддреЗред рдореЙрдбрд▓ рдХреБрдЫ "рдЧрд▓рддрд┐рдпрд╛рдБ" рд╕реАрдЦрдирд╛ рд╕рд╛рдорд╛рдиреНрдп рд╣реИред

---

## MCTS рдореЗрдВ рднреВрдорд┐рдХрд╛

Policy Network AlphaGo рдХреЗ MCTS рдореЗрдВ рджреЛ рдорд╣рддреНрд╡рдкреВрд░реНрдг рднреВрдорд┐рдХрд╛рдПрдБ рдирд┐рднрд╛рддрд╛ рд╣реИ:

### 1. рдЦреЛрдЬ рджрд┐рд╢рд╛ рдирд┐рд░реНрджреЗрд╢рд┐рдд рдХрд░рдирд╛

MCTS рдХреЗ **Selection** рдЪрд░рдг рдореЗрдВ, Policy Network рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ UCB (Upper Confidence Bound) рдЧрдгрдирд╛ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рд╣реЛрддрд╛ рд╣реИ:

```
UCB(s, a) = Q(s, a) + c_puct ├Ч P(s, a) ├Ч тИЪ(N(s)) / (1 + N(s, a))
```

рдЬрд╣рд╛рдБ `P(s, a)` Policy Network рджреНрд╡рд╛рд░рд╛ рджреА рдЧрдИ рд╕рдВрднрд╛рд╡рдирд╛ рд╣реИред

рдЗрд╕рдХрд╛ рдЕрд░реНрде рд╣реИ:
- **рдЙрдЪреНрдЪ рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд╛рд▓реА рдЪрд╛рд▓реЗрдВ рдкрд╣рд▓реЗ рдЦреЛрдЬреА рдЬрд╛рддреА рд╣реИрдВ**
- **рдХрдо рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд╛рд▓реА рдЪрд╛рд▓реЛрдВ рдХреЛ рднреА рдЦреЛрдЬрдиреЗ рдХрд╛ рдЕрд╡рд╕рд░** (рдЕрдиреНрд╡реЗрд╖рдг рдкрдж рдХреЗ рдХрд╛рд░рдг)

### 2. рдиреЛрдб рд╡рд┐рд╕реНрддрд╛рд░ рдХреЗ рд▓рд┐рдП рдкреНрд░рд╛рдпрд░

рдЬрдм MCTS рдПрдХ рдирдпрд╛ рдиреЛрдб рд╡рд┐рд╕реНрддрд╛рд░рд┐рдд рдХрд░рддрд╛ рд╣реИ, Policy Network рд╕рднреА рдЪрд╛рдЗрд▓реНрдб рдиреЛрдбреНрд╕ рдХреЗ рд▓рд┐рдП **рдкреНрд░рд╛рдпрд░ рд╕рдВрднрд╛рд╡рдирд╛** рдкреНрд░рджрд╛рди рдХрд░рддрд╛ рд╣реИред

```
рдиреЛрдб s рд╡рд┐рд╕реНрддрд╛рд░рд┐рдд рдХрд░реЗрдВ:
  for each action a:
    child = Node()
    child.prior = policy_network(s)[a]  # рдкреНрд░рд╛рдпрд░ рд╕рдВрднрд╛рд╡рдирд╛
    child.value = 0
    child.visits = 0
```

рдпреЗ рдкреНрд░рд╛рдпрд░ рд╕рдВрднрд╛рд╡рдирд╛рдПрдБ MCTS рдХреЛ "рдЬрд╛рдирдиреЗ" рджреЗрддреА рд╣реИрдВ рдХрд┐ рдХреМрди рд╕реЗ рдЪрд╛рдЗрд▓реНрдб рдиреЛрдб рдЕрдзрд┐рдХ рдЦреЛрдЬрдиреЗ рдпреЛрдЧреНрдп рд╣реИрдВ, рднрд▓реЗ рд╣реА рдЙрдиреНрд╣реЗрдВ рдЕрднреА рддрдХ рд╡рд┐рдЬрд╝рд┐рдЯ рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реЛред

---

## рд▓рд╛рдЗрдЯрд╡реЗрдЯ vs рдкреВрд░реНрдг рд╕рдВрд╕реНрдХрд░рдг

AlphaGo рдореЗрдВ рд╡рд╛рд╕реНрддрд╡ рдореЗрдВ рджреЛ Policy Network рд╣реИрдВ:

### рдкреВрд░реНрдг рд╕рдВрд╕реНрдХрд░рдг (SL Policy Network)

- **рд╡рд╛рд╕реНрддреБрдХрд▓рд╛**: 13 рдкрд░рдд CNN, 192 filters
- **рд╕рдЯреАрдХрддрд╛**: 57%
- **рдЗрдирдлрд░реЗрдВрд╕ рд╕рдордп**: рд▓рдЧрднрдЧ 3 рдорд┐рд▓реАрд╕реЗрдХрдВрдб/рд╕реНрдерд┐рддрд┐
- **рдЙрдкрдпреЛрдЧ**: MCTS рдореЗрдВ Selection рдФрд░ Expansion

### рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг (Rollout Policy Network)

- **рд╡рд╛рд╕реНрддреБрдХрд▓рд╛**: рд▓реАрдирд┐рдпрд░ рдореЙрдбрд▓ + рд╣рд╕реНрддрдирд┐рд░реНрдорд┐рдд рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ
- **рд╕рдЯреАрдХрддрд╛**: 24%
- **рдЗрдирдлрд░реЗрдВрд╕ рд╕рдордп**: рд▓рдЧрднрдЧ 2 рдорд╛рдЗрдХреНрд░реЛрд╕реЗрдХрдВрдб/рд╕реНрдерд┐рддрд┐ (1500 рдЧреБрдирд╛ рддреЗрдЬрд╝)
- **рдЙрдкрдпреЛрдЧ**: рддреЗрдЬрд╝ рд╕рд┐рдореБрд▓реЗрд╢рди (rollout)

### рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдХреНрдпреЛрдВ?

MCTS рдХреЗ **Simulation** рдЪрд░рдг рдореЗрдВ, рд╡рд░реНрддрдорд╛рди рдиреЛрдб рд╕реЗ рдЦреЗрд▓ рд╕рдорд╛рдкреНрдд рд╣реЛрдиреЗ рддрдХ рдЪрд▓рдирд╛ рд╣реЛрддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ 100+ рдЪрд╛рд▓реЗрдВ рд▓рдЧ рд╕рдХрддреА рд╣реИрдВред рдпрджрд┐ рдкреНрд░рддреНрдпреЗрдХ рдЪрд╛рд▓ рдХреЗ рд▓рд┐рдП рдкреВрд░реНрдг Policy Network рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ, рддреЛ рдмрд╣реБрдд рдзреАрдорд╛ред

рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рдХреА рд╕рдЯреАрдХрддрд╛ рдХреЗрд╡рд▓ 24% рд╣реИ, рд▓реЗрдХрд┐рди 1500 рдЧреБрдирд╛ рддреЗрдЬрд╝ рд╣реИред Rollout рдореЗрдВ, рдЧрддрд┐ рд╕рдЯреАрдХрддрд╛ рд╕реЗ рдЕрдзрд┐рдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред

### рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рдХреА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ

рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рд╣рд╕реНрддрдирд┐рд░реНрдорд┐рдд рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рд╢рд╛рдорд┐рд▓ рд╣реИрдВ:

| рд╡рд┐рд╢реЗрд╖рддрд╛ рдкреНрд░рдХрд╛рд░ | рдЙрджрд╛рд╣рд░рдг |
|---------|------|
| рд╕реНрдерд╛рдиреАрдп рдкреИрдЯрд░реНрди | 3├Ч3 рдХреНрд╖реЗрддреНрд░ рдореЗрдВ рдкрддреНрдерд░ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди |
| рд╡реИрд╢реНрд╡рд┐рдХ рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ | рдХреЙрд░реНрдирд░ рдореЗрдВ рд╣реИ рдпрд╛ рдирд╣реАрдВ, рдмрдбрд╝рд╛ рдмрд┐рдВрджреБ |
| рд░рдгрдиреАрддрд┐рдХ рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ | рдЕрддрд╛рд░реА, рд▓реИрдбрд░, рдХрдиреЗрдХреНрд╢рди |

рдЗрди рд╡рд┐рд╢реЗрд╖рддрд╛рдУрдВ рдХреЛ рдПрдХ рд▓реАрдирд┐рдпрд░ рдореЙрдбрд▓ (рдмрд┐рдирд╛ рдЫрд┐рдкреА рдкрд░рдд) рдореЗрдВ рдЗрдирдкреБрдЯ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ, рдЧрдгрдирд╛ рдмрд╣реБрдд рддреЗрдЬрд╝ред

### AlphaGo Zero рдХрд╛ рд╕реБрдзрд╛рд░

рдмрд╛рдж рдХреЗ AlphaGo Zero рдиреЗ рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рдФрд░ rollout рдХреЛ рдкреВрд░реНрдгрддрдГ рддреНрдпрд╛рдЧ рджрд┐рдпрд╛ред рдпрд╣ рд╕реАрдзреЗ Value Network рд╕реЗ рд▓реАрдл рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рддрд╛ рд╣реИ, рддреЗрдЬрд╝ рд╕рд┐рдореБрд▓реЗрд╢рди рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдирд╣реАрдВред рдпрд╣ рдПрдХ рдмрдбрд╝рд╛ рд╕рд░рд▓реАрдХрд░рдг рд╣реИред

---

## рд░реАрдЗрдиреНрдлреЛрд░реНрд╕рдореЗрдВрдЯ рд▓рд░реНрдирд┐рдВрдЧ рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ (RL Policy Network)

### рд╕реБрдкрд░рд╡рд╛рдЗрдЬреНрдб рд▓рд░реНрдирд┐рдВрдЧ рдХреА рд╕реАрдорд╛рдПрдБ

рд╕реБрдкрд░рд╡рд╛рдЗрдЬреНрдб рд▓рд░реНрдирд┐рдВрдЧ рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд Policy Network рдореЗрдВ рдПрдХ рдореВрд▓рднреВрдд рд╕рдорд╕реНрдпрд╛ рд╣реИ:

> **рдпрд╣ "рдорд╛рдирд╡ рдХреА рдирдХрд▓" рд╕реАрдЦрддрд╛ рд╣реИ, "рдЬреАрддрдирд╛" рдирд╣реАрдВ**

рдЗрд╕рдХрд╛ рдЕрд░реНрде рд╣реИ рдпрд╣ рдорд╛рдирд╡ рдХреА рдмреБрд░реА рдЖрджрддреЗрдВ рд╕реАрдЦреЗрдЧрд╛, рдФрд░ рдЙрди рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдореЗрдВ рдЦрд░рд╛рдм рдкреНрд░рджрд░реНрд╢рди рдХрд░реЗрдЧрд╛ рдЬреЛ рдорд╛рдирд╡ рдиреЗ рдХрднреА рдирд╣реАрдВ рджреЗрдЦреАрдВред

### рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рд░реАрдЗрдиреНрдлреЛрд░реНрд╕рдореЗрдВрдЯ

DeepMind рдХрд╛ рд╕рдорд╛рдзрд╛рди **Policy Gradient** рд╡рд┐рдзрд┐ рд╕реЗ рд░реАрдЗрдиреНрдлреЛрд░реНрд╕рдореЗрдВрдЯ рд▓рд░реНрдирд┐рдВрдЧ рд╣реИ:

```
1. Policy Network рдХреЛ рд╕реНрд╡рдпрдВ рд╕реЗ рдЦреЗрд▓рдиреЗ рджреЗрдВ
2. рдкреНрд░рддреНрдпреЗрдХ рдЦреЗрд▓ рдХреА рд╕рднреА рдЪрд╛рд▓реЗрдВ рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ
3. рдЬреАрдд-рд╣рд╛рд░ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░реЗрдВ:
   - рдЬреАрддрд╛ тЖТ рдЗрди рдЪрд╛рд▓реЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдмрдврд╝рд╛рдПрдБ
   - рд╣рд╛рд░рд╛ тЖТ рдЗрди рдЪрд╛рд▓реЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдШрдЯрд╛рдПрдБ
```

### REINFORCE рдПрд▓реНрдЧреЛрд░рд┐рдердо

рд╡рд┐рд╢реЗрд╖ рд░реВрдк рд╕реЗ REINFORCE рдПрд▓реНрдЧреЛрд░рд┐рдердо рдЙрдкрдпреЛрдЧ:

```
тИЗJ(╬╕) = E[╬г_t тИЗlog ╧А_╬╕(a_t | s_t) ├Ч z]
```

рдЬрд╣рд╛рдБ:
- `z`: рдЗрд╕ рдЦреЗрд▓ рдХрд╛ рдкрд░рд┐рдгрд╛рдо (+1 рдЬреАрдд, -1 рд╣рд╛рд░)
- `╧А_╬╕(a_t | s_t)`: рд╕реНрдерд┐рддрд┐ `s_t` рдкрд░ рдХреНрд░рд┐рдпрд╛ `a_t` рдЪреБрдирдиреЗ рдХреА рд╕рдВрднрд╛рд╡рдирд╛

### рдкрд░рд┐рдгрд╛рдо

рд▓рдЧрднрдЧ 1 рджрд┐рди рдХреА рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг (1.28 рдорд┐рд▓рд┐рдпрди рдЦреЗрд▓) рдХреЗ рдмрд╛рдж, RL Policy Network:

| рдореЗрдЯреНрд░рд┐рдХ | SL Policy | RL Policy |
|------|-----------|-----------|
| SL Policy рдХреЗ рдЦрд┐рд▓рд╛рдл | 50% | **80%** |
| Elo рд╡реГрджреНрдзрд┐ | - | +100 |

рд╕рдЯреАрдХрддрд╛ рдереЛрдбрд╝реА рдХрдо рд╣реЛ рд╕рдХрддреА рд╣реИ (рдХреНрдпреЛрдВрдХрд┐ рдЕрдм рдкреВрд░реНрдгрддрдГ рдорд╛рдирд╡ рдХреА рдирдХрд▓ рдирд╣реАрдВ), рд▓реЗрдХрд┐рди рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдЬреАрдд рджрд░ рдмрд╣реБрдд рдмрдврд╝ рдЬрд╛рддреА рд╣реИред

### "рдирдХрд▓" рд╕реЗ "рдирд╡рд╛рдЪрд╛рд░" рддрдХ

рд░реАрдЗрдиреНрдлреЛрд░реНрд╕рдореЗрдВрдЯ рд▓рд░реНрдирд┐рдВрдЧ Policy Network рдХреЛ рдХреБрдЫ рдРрд╕реА рдЪрд╛рд▓реЗрдВ рд╕рд┐рдЦрд╛рддреА рд╣реИ рдЬреЛ рдорд╛рдирд╡ рдиреЗ рдХрднреА рдирд╣реАрдВ рд╕реЛрдЪреАрдВред рдпреЗ рдЪрд╛рд▓реЗрдВ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдореЗрдВ рдХрднреА рдирд╣реАрдВ рджрд┐рдЦреАрдВ, рд▓реЗрдХрд┐рди рдкреНрд░рднрд╛рд╡реА рд╣реИрдВред

рдЗрд╕реАрд▓рд┐рдП AlphaGo "рджрд┐рд╡реНрдп рдЪрд╛рд▓" рдЪрд▓ рд╕рдХрддрд╛ рд╣реИтАФрдпрд╣ рдорд╛рдирд╡ рдЕрдиреБрднрд╡ рд╕реЗ рд╕реАрдорд┐рдд рдирд╣реАрдВ рд╣реИред

---

## рд╡рд┐рдЬрд╝реБрдЕрд▓ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

### рд╡рд┐рднрд┐рдиреНрди рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХрд╛ рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг

рдЖрдЗрдП рджреЗрдЦреЗрдВ Policy Network рд╡рд┐рднрд┐рдиреНрди рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдореЗрдВ рдХреНрдпрд╛ рдЖрдЙрдЯрдкреБрдЯ рджреЗрддрд╛ рд╣реИ:

#### рдУрдкрдирд┐рдВрдЧ (рдлреБрд╕реЗрдХреА рдЪрд░рдг)

<PolicyHeatmap initialPosition="opening" size={400} />

рдУрдкрдирд┐рдВрдЧ рдореЗрдВ, рд╕рдВрднрд╛рд╡рдирд╛ рдореБрдЦреНрдп рд░реВрдк рд╕реЗ рдХреЗрдВрджреНрд░рд┐рдд рд╣реИ:
- рдХреЙрд░реНрдирд░ рдореЗрдВ (рдХреЙрд░реНрдирд░ рд▓реЗрдирд╛)
- рдХрд┐рдирд╛рд░реЗ рдкрд░ (рдЕрдкреНрд░реЛрдЪ, рдбрд┐рдлреЗрдВрдб рдХреЙрд░реНрдирд░)
- "рдмрдбрд╝реЗ рдмрд┐рдВрджреБ" рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдкрд░

рдпрд╣ рдЧреЛ рдХреЗ рдореВрд▓ рд╕рд┐рджреНрдзрд╛рдВрдд рд╕реЗ рдореЗрд▓ рдЦрд╛рддрд╛ рд╣реИ: рдЧреЛрд▓реНрдбрди рдХреЙрд░реНрдирд░, рд╕рд┐рд▓реНрд╡рд░ рдПрдЬ, рдЧреНрд░рд╛рд╕ рдмреЗрд▓реАред

#### рд▓рдбрд╝рд╛рдИ рдХреА рд╕реНрдерд┐рддрд┐

<PolicyHeatmap initialPosition="fighting" size={400} />

рд▓рдбрд╝рд╛рдИ рдореЗрдВ, рд╕рдВрднрд╛рд╡рдирд╛ рдХреЗрдВрджреНрд░рд┐рдд рд╣реИ:
- рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХрдЯ рдмрд┐рдВрджреБрдУрдВ рдкрд░
- рдЕрддрд╛рд░реА, рдХрдиреЗрдХреНрд╢рди рдкрд░
- рдЖрдБрдЦ рдмрдирд╛рдирд╛, рдЖрдБрдЦ рддреЛрдбрд╝рдирд╛

рдпрд╣ рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдореЙрдбрд▓ рдиреЗ рд╕реНрдерд╛рдиреАрдп рд░рдгрдиреАрддрд┐ рд╕реАрдЦреАред

#### рдпреЛрд╕реЗ рдЪрд░рдг

<PolicyHeatmap initialPosition="endgame" size={400} />

рдпреЛрд╕реЗ рдореЗрдВ, рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рднрд┐рдиреНрди рдпреЛрд╕реЗ рдмрд┐рдВрджреБрдУрдВ рдкрд░ рдлреИрд▓реА рд╣реЛрддреА рд╣реИ, рд╕рдЯреАрдХ рдЕрдВрдХ рдЧрдгрдирд╛ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ред

### рдЫрд┐рдкреА рдкрд░рддреЗрдВ рдХреНрдпрд╛ рд╕реАрдЦрддреА рд╣реИрдВ?

Convolutional рдкрд░рдд рдЖрдЙрдЯрдкреБрдЯ рдХреЛ рд╡рд┐рдЬрд╝реБрдЕрд▓рд╛рдЗрдЬрд╝ рдХрд░рдХреЗ, рд╣рдо рдореЙрдбрд▓ рджреНрд╡рд╛рд░рд╛ рд╕реАрдЦреА рдЧрдИ "рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ" рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ:

- **рдирд┐рдЪрд▓реА рдкрд░рддреЗрдВ**: рдореВрд▓ рдЖрдХрд╛рд░ (рдЖрдБрдЦ, рдХрдЯ рдмрд┐рдВрджреБ)
- **рдордзреНрдп рдкрд░рддреЗрдВ**: рд░рдгрдиреАрддрд┐рдХ рдкреИрдЯрд░реНрди (рдЕрддрд╛рд░реА, рд▓реИрдбрд░)
- **рдКрдкрд░реА рдкрд░рддреЗрдВ**: рд╡реИрд╢реНрд╡рд┐рдХ рдЕрд╡рдзрд╛рд░рдгрд╛рдПрдБ (рдкреНрд░рднрд╛рд╡, рдореЛрдЯрд╛рдИ)

рдпрд╣ рдЧреЛ рдХреЛ рд╕рдордЭрдиреЗ рдХреА рдорд╛рдирд╡ рд╕рдВрдЬреНрдЮрд╛рдирд╛рддреНрдордХ рдкрджрд╛рдиреБрдХреНрд░рдо рд╕реЗ рдмрд╣реБрдд рдорд┐рд▓рддрд╛ рд╣реИред

---

## рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдмрд┐рдВрджреБ

### PyTorch рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди

рдпрд╣рд╛рдБ рдПрдХ рд╕рд░рд▓реАрдХреГрдд Policy Network рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рд╣реИ:

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class PolicyNetwork(nn.Module):
    def __init__(self, input_channels=48, num_filters=192, num_layers=12):
        super().__init__()

        # рдкрд╣рд▓реА convolutional рдкрд░рдд (5├Ч5)
        self.conv1 = nn.Conv2d(input_channels, num_filters,
                               kernel_size=5, padding=2)

        # рдордзреНрдп convolutional рдкрд░рддреЗрдВ (3├Ч3)├Ч11
        self.conv_layers = nn.ModuleList([
            nn.Conv2d(num_filters, num_filters,
                     kernel_size=3, padding=1)
            for _ in range(num_layers - 1)
        ])

        # рдЖрдЙрдЯрдкреБрдЯ convolutional рдкрд░рдд (1├Ч1)
        self.conv_out = nn.Conv2d(num_filters, 1, kernel_size=1)

    def forward(self, x):
        # x: (batch, 48, 19, 19)

        # рдкрд╣рд▓реА рдкрд░рдд
        x = F.relu(self.conv1(x))

        # рдордзреНрдп рдкрд░рддреЗрдВ
        for conv in self.conv_layers:
            x = F.relu(conv(x))

        # рдЖрдЙрдЯрдкреБрдЯ рдкрд░рдд
        x = self.conv_out(x)  # (batch, 1, 19, 19)

        # рд╕рдорддрд▓ + Softmax
        x = x.view(x.size(0), -1)  # (batch, 361)
        x = F.softmax(x, dim=1)

        return x
```

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк

```python
def train_step(model, optimizer, states, actions):
    """
    states: (batch, 48, 19, 19) - рдмреЛрд░реНрдб рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ
    actions: (batch,) - рдорд╛рдирд╡ рдХреА рдЪрд╛рд▓ рд╕реНрдерд┐рддрд┐ (0-360)
    """
    # рдлреЙрд░рд╡рд░реНрдб рдкрд╛рд╕
    policy = model(states)  # (batch, 361)

    # Cross-entropy рд╣рд╛рдирд┐
    loss = F.cross_entropy(
        torch.log(policy + 1e-8),  # log(0) рд░реЛрдХреЗрдВ
        actions
    )

    # рдмреИрдХрд╡рд░реНрдб рдкрд╛рд╕
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # рд╕рдЯреАрдХрддрд╛ рдЧрдгрдирд╛
    predictions = policy.argmax(dim=1)
    accuracy = (predictions == actions).float().mean()

    return loss.item(), accuracy.item()
```

### рдЗрдирдлрд░реЗрдВрд╕ рд╕рдордп рдзреНрдпрд╛рди рджреЗрдиреЗ рдпреЛрдЧреНрдп рдмрд╛рддреЗрдВ

рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдЦреЗрд▓ рдореЗрдВ, рдзреНрдпрд╛рди рджреЗрдирд╛ рдЪрд╛рд╣рд┐рдП:

1. **рдЕрд╡реИрдз рдЪрд╛рд▓реЗрдВ рдлрд╝рд┐рд▓реНрдЯрд░ рдХрд░реЗрдВ**: рдЕрд╡реИрдз рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ 0 рдХрд░реЗрдВ, рдлрд┐рд░ рдкреБрдирдГ рд╕рд╛рдорд╛рдиреНрдпреАрдХрд░рдг
2. **рддрд╛рдкрдорд╛рди рд╕рдорд╛рдпреЛрдЬрди**: рддрд╛рдкрдорд╛рди рдкреИрд░рд╛рдореАрдЯрд░ рд╕реЗ рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг рдХреА "рддреАрдХреНрд╖реНрдгрддрд╛" рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░реЗрдВ
3. **рдмреИрдЪ рдЗрдирдлрд░реЗрдВрд╕**: MCTS рдореЗрдВ рдХрдИ рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреЛ рдПрдХ рд╕рд╛рде рдкреНрд░реЛрд╕реЗрд╕ рдХрд░реЗрдВ

```python
def get_move_probabilities(model, state, legal_moves, temperature=1.0):
    """рд╡реИрдз рдЪрд╛рд▓реЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ"""
    policy = model(state)  # (361,)

    # рдХреЗрд╡рд▓ рд╡реИрдз рдЪрд╛рд▓реЗрдВ рд░рдЦреЗрдВ
    mask = torch.zeros(361)
    mask[legal_moves] = 1
    policy = policy * mask

    # рддрд╛рдкрдорд╛рди рд╕рдорд╛рдпреЛрдЬрди
    if temperature != 1.0:
        policy = policy ** (1 / temperature)

    # рдкреБрдирдГ рд╕рд╛рдорд╛рдиреНрдпреАрдХрд░рдг
    policy = policy / policy.sum()

    return policy
```

---

## рдПрдирд┐рдореЗрд╢рди рд╕рдВрджрд░реНрдн

рдЗрд╕ рд▓реЗрдЦ рдХреА рдореБрдЦреНрдп рдЕрд╡рдзрд╛рд░рдгрд╛рдПрдБ рдФрд░ рдПрдирд┐рдореЗрд╢рди рдирдВрдмрд░:

| рдирдВрдмрд░ | рдЕрд╡рдзрд╛рд░рдгрд╛ | рднреМрддрд┐рдХреА/рдЧрдгрд┐рдд рд╕рдВрджрд░реНрдн |
|------|------|--------------|
| ЁЯОм E1 | Policy Network | рд╕рдВрднрд╛рд╡рдирд╛ рдХреНрд╖реЗрддреНрд░ |
| ЁЯОм D9 | CNN рд╡рд┐рд╢реЗрд╖рддрд╛ рдирд┐рд╖реНрдХрд░реНрд╖рдг | рдлрд╝рд┐рд▓реНрдЯрд░ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ |
| ЁЯОм D3 | рд╕реБрдкрд░рд╡рд╛рдЗрдЬреНрдб рд▓рд░реНрдирд┐рдВрдЧ | рдЕрдзрд┐рдХрддрдо рд╕рдВрднрд╛рд╡рдирд╛ рдЕрдиреБрдорд╛рди |
| ЁЯОм H4 | Policy Gradient | рд╕реНрдЯреЛрдХреЗрд╕реНрдЯрд┐рдХ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди |

---

## рдЖрдЧреЗ рдкрдврд╝реЗрдВ

- **рдЕрдЧрд▓рд╛ рд▓реЗрдЦ**: [Value Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг](../value-network) тАФ AlphaGo рд╕реНрдерд┐рддрд┐ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХреИрд╕реЗ рдХрд░рддрд╛ рд╣реИ
- **рд╕рдВрдмрдВрдзрд┐рдд рд╡рд┐рд╖рдп**: [рдЗрдирдкреБрдЯ рд╡рд┐рд╢реЗрд╖рддрд╛ рдбрд┐рдЬрд╝рд╛рдЗрди](../input-features) тАФ 48 рд╡рд┐рд╢реЗрд╖рддрд╛ рдкреНрд▓реЗрди рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг
- **рдЧрд╣рди рд╕рд┐рджреНрдзрд╛рдВрдд**: [CNN рдФрд░ рдЧреЛ рдХрд╛ рд╕рдВрдпреЛрдЬрди](../cnn-and-go) тАФ Convolutional neural network рдмреЛрд░реНрдб рдХреЗ рд▓рд┐рдП рдХреНрдпреЛрдВ рдЙрдкрдпреБрдХреНрдд

---

## рдореБрдЦреНрдп рдмрд┐рдВрджреБ

1. **Policy Network рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг рдЬрдирд░реЗрдЯрд░ рд╣реИ**: рдмреЛрд░реНрдб рдЗрдирдкреБрдЯ рдХрд░реЗрдВ, 361 рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдЖрдЙрдЯрдкреБрдЯ
2. **13 рдкрд░рдд CNN + Softmax**: рдЧрд╣рди convolution рд╡рд┐рд╢реЗрд╖рддрд╛ рдирд┐рд╖реНрдХрд░реНрд╖рдг, Softmax рд╕рдВрднрд╛рд╡рдирд╛ рдЖрдЙрдЯрдкреБрдЯ
3. **57% рд╕рдЯреАрдХрддрд╛**: рдкрд┐рдЫрд▓реЗ рдХрдВрдкреНрдпреВрдЯрд░ рдЧреЛ рдкреНрд░реЛрдЧреНрд░рд╛рдо рд╕реЗ рдмрд╣реБрдд рдЖрдЧреЗ
4. **рджреЛ рд╕рдВрд╕реНрдХрд░рдг**: рдкреВрд░реНрдг рд╕рдВрд╕реНрдХрд░рдг MCTS рдирд┐рд░реНрдгрдп рдХреЗ рд▓рд┐рдП, рд▓рд╛рдЗрдЯрд╡реЗрдЯ рд╕рдВрд╕реНрдХрд░рдг рддреЗрдЬрд╝ рд╕рд┐рдореБрд▓реЗрд╢рди рдХреЗ рд▓рд┐рдП
5. **рд░реАрдЗрдиреНрдлреЛрд░реНрд╕рдореЗрдВрдЯ рд▓рд░реНрдирд┐рдВрдЧ рдлрд╛рдЗрди-рдЯреНрдпреВрдирд┐рдВрдЧ**: "рдорд╛рдирд╡ рдХреА рдирдХрд▓" рд╕реЗ "рдЬреАрдд рдХреА рдЦреЛрдЬ" рддрдХ

Policy Network AlphaGo рдХреА "рд╕рд╣рдЬ рдмреБрджреНрдзрд┐" рд╣реИтАФрдпрд╣ AI рдХреЛ рдорд╛рдирд╡ рдХреА рддрд░рд╣, рдЬрд▓реНрджреА рд╕реЗ рд╡рд┐рдЪрд╛рд░ рдХрд░рдиреЗ рдпреЛрдЧреНрдп рдЪрд╛рд▓реЗрдВ рдкрд╣рдЪрд╛рдирдиреЗ рджреЗрддрд╛ рд╣реИред

---

## рд╕рдВрджрд░реНрдн

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Maddison, C. J., et al. (2014). "Move Evaluation in Go Using Deep Convolutional Neural Networks." *arXiv:1412.6564*.
3. Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction*. MIT Press.
4. LeCun, Y., Bengio, Y., & Hinton, G. (2015). "Deep learning." *Nature*, 521, 436-444.
