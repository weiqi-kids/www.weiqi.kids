---
sidebar_position: 9
title: Value Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг
description: AlphaGo рдХреЗ Value Network рдХреА рд╡рд╛рд╕реНрддреБрдХрд▓рд╛, рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЪреБрдиреМрддрд┐рдпреЛрдВ рдФрд░ MCTS рдореЗрдВ рдорд╣рддреНрд╡рдкреВрд░реНрдг рднреВрдорд┐рдХрд╛ рдХреА рдЧрд╣рди рд╕рдордЭ
---

# Value Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг

рдпрджрд┐ Policy Network AlphaGo рдХреЛ рдмрддрд╛рддрд╛ рд╣реИ "рдЕрдЧрд▓реА рдЪрд╛рд▓ рдХрд╣рд╛рдБ рдЪрд▓реЗрдВ", рддреЛ Value Network рдПрдХ рдЕрдзрд┐рдХ рдореВрд▓рднреВрдд рдкреНрд░рд╢реНрди рдХрд╛ рдЙрддреНрддрд░ рджреЗрддрд╛ рд╣реИ:

> **"рдпрд╣ рдЦреЗрд▓, рдХреНрдпрд╛ рдореИрдВ рдЬреАрддреВрдБрдЧрд╛?"**

---

## Value Network рдХреНрдпрд╛ рд╣реИ?

### рдореБрдЦреНрдп рдХрд╛рд░реНрдп

Value Network рдПрдХ рдЧрд╣рди convolutional neural network рд╣реИ, рдЗрд╕рдХрд╛ рдХрд╛рд░реНрдп рд╣реИ:

> **рд╡рд░реНрддрдорд╛рди рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐ рджреА рдЧрдИ, рдЕрдВрддрд┐рдо рдЬреАрдд рдХреА рд╕рдВрднрд╛рд╡рдирд╛ рдХрд╛ рдЕрдиреБрдорд╛рди рд▓рдЧрд╛рдПрдБ**

рдЧрдгрд┐рддреАрдп рд░реВрдк рдореЗрдВ:

```
v = f_╬╕(s)
```

рдЬрд╣рд╛рдБ:
- `s`: рд╡рд░реНрддрдорд╛рди рдмреЛрд░реНрдб рд╕реНрдерд┐рддрд┐
- `f_╬╕`: Value Network (╬╕ рдиреЗрдЯрд╡рд░реНрдХ рдкреИрд░рд╛рдореАрдЯрд░ рд╣реИрдВ)
- `v`: -1 рд╕реЗ +1 рдХреЗ рдмреАрдЪ рдПрдХ рдорд╛рди

### рдЖрдЙрдЯрдкреБрдЯ рдХрд╛ рдЕрд░реНрде

| рдЖрдЙрдЯрдкреБрдЯ рдорд╛рди | рдЕрд░реНрде |
|--------|------|
| +1 | рд╡рд░реНрддрдорд╛рди рдЦрд┐рд▓рд╛рдбрд╝реА рдирд┐рд╢реНрдЪрд┐рдд рдЬреАрдд |
| +0.5 | рд╡рд░реНрддрдорд╛рди рдЦрд┐рд▓рд╛рдбрд╝реА рд▓рдЧрднрдЧ 75% рдЬреАрдд рджрд░ |
| 0 | рджреЛрдиреЛрдВ рдкрдХреНрд╖реЛрдВ рдХреА рдЬреАрдд рджрд░ рд╕рдорд╛рди |
| -0.5 | рд╡рд░реНрддрдорд╛рди рдЦрд┐рд▓рд╛рдбрд╝реА рд▓рдЧрднрдЧ 25% рдЬреАрдд рджрд░ |
| -1 | рд╡рд░реНрддрдорд╛рди рдЦрд┐рд▓рд╛рдбрд╝реА рдирд┐рд╢реНрдЪрд┐рдд рд╣рд╛рд░ |

### рдПрдХрд▓ рдорд╛рди рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдХреНрдпреЛрдВ?

#### рд╡рд┐рднрд┐рдиреНрди рд╡рд┐рдХрд▓реНрдкреЛрдВ рдХреА рддреБрд▓рдирд╛

рдЦреЗрд▓рддреЗ рд╕рдордп, рд╣рдореЗрдВ рдЕрдХреНрд╕рд░ рдХрдИ рд╡рд┐рдХрд▓реНрдкреЛрдВ рдореЗрдВ рд╕реЗ рдЪреБрдирдирд╛ рд╣реЛрддрд╛ рд╣реИред Value Network рдЗрд╕ рддреБрд▓рдирд╛ рдХреЛ рд╕рд░рд▓ рдмрдирд╛рддрд╛ рд╣реИ:

```
рд╡рд┐рдХрд▓реНрдк A рдХрд╛ рд╕реНрдерд┐рддрд┐ рдорд╛рди: 0.3
рд╡рд┐рдХрд▓реНрдк B рдХрд╛ рд╕реНрдерд┐рддрд┐ рдорд╛рди: 0.5
рд╡рд┐рдХрд▓реНрдк C рдХрд╛ рд╕реНрдерд┐рддрд┐ рдорд╛рди: 0.2

тЖТ B рдЪреБрдиреЗрдВ (рд╕рдмрд╕реЗ рдЙрдЪреНрдЪ рдорд╛рди)
```

рдпрджрд┐ рдПрдХрд▓ рдорд╛рди рдирд╣реАрдВ рд╣реЛрддрд╛, рддреЛ "рдкреНрд░рддрд┐рджреНрд╡рдВрджреНрд╡реА рдХрд╛ рдПрдХ рд╕рдореВрд╣ рдХреИрдкреНрдЪрд░ рдХрд░рдирд╛" рдФрд░ "рдПрдХ рдмрдбрд╝рд╛ рдХреНрд╖реЗрддреНрд░ рдШреЗрд░рдирд╛" рдореЗрдВ рд╕реЗ рдХреМрди рдмреЗрд╣рддрд░ рд╣реИ, рдпрд╣ рдХреИрд╕реЗ рддреБрд▓рдирд╛ рдХрд░рддреЗ?

#### рдмрдбрд╝реА рд╕рдВрдЦреНрдпрд╛ рдореЗрдВ рд╕рд┐рдореБрд▓реЗрд╢рди рдХрд╛ рд╡рд┐рдХрд▓реНрдк

рдкрд╛рд░рдВрдкрд░рд┐рдХ Monte Carlo Tree Search рдореЗрдВ, рдПрдХ рд╕реНрдерд┐рддрд┐ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП **рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди (rollout)** рдХрд░рдирд╛ рд╣реЛрддрд╛ рд╣реИ:

1. рд╡рд░реНрддрдорд╛рди рд╕реНрдерд┐рддрд┐ рд╕реЗ рд╢реБрд░реВ рдХрд░реЗрдВ
2. рджреЛрдиреЛрдВ рдкрдХреНрд╖ рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рд░реВрдк рд╕реЗ рдЦреЗрд▓ рд╕рдорд╛рдкреНрдд рд╣реЛрдиреЗ рддрдХ рдЦреЗрд▓реЗрдВ
3. рдЬреАрдд-рд╣рд╛рд░ рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ
4. рд╣рдЬрд╛рд░реЛрдВ рдмрд╛рд░ рджреЛрд╣рд░рд╛рдПрдБ, рдЬреАрдд рджрд░ рдЧрдгрдирд╛ рдХрд░реЗрдВ

рдпрд╣ рдмрд╣реБрдд рдзреАрдорд╛ рд╣реИред Value Network **рдПрдХ forward pass** рдореЗрдВ рдореВрд▓реНрдпрд╛рдВрдХрди рджреЗ рд╕рдХрддрд╛ рд╣реИ, рдЧрддрд┐ рдХрдИ рдкрд░рд┐рдорд╛рдг рддреЗрдЬрд╝ред

| рд╡рд┐рдзрд┐ | рдореВрд▓реНрдпрд╛рдВрдХрди рд╕рдордп | рд╕рдЯреАрдХрддрд╛ |
|------|---------|------|
| 1000 рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди | ~2000 рдорд┐рд▓реАрд╕реЗрдХрдВрдб | рдХрдо |
| 15000 рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди | ~30000 рдорд┐рд▓реАрд╕реЗрдХрдВрдб | рдордзреНрдпрдо |
| Value Network | ~3 рдорд┐рд▓реАрд╕реЗрдХрдВрдб | рдЙрдЪреНрдЪ (15000 рд╕рд┐рдореБрд▓реЗрд╢рди рдХреЗ рд╕рдорддреБрд▓реНрдп) |

---

## рдиреЗрдЯрд╡рд░реНрдХ рд╡рд╛рд╕реНрддреБрдХрд▓рд╛

### Policy Network рд╕реЗ рд╕рдорд╛рдирддрд╛

Value Network рдХреА рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ Policy Network рд╕реЗ рдмрд╣реБрдд рдорд┐рд▓рддреА рд╣реИ, рджреЛрдиреЛрдВ рдЧрд╣рди convolutional neural networks рд╣реИрдВ:

```mermaid
flowchart LR
    A["рдЗрдирдкреБрдЯ рдкрд░рдд<br/>19├Ч19├Ч48"] --> B["Convolutional рдкрд░рдд ├Ч12<br/>19├Ч19├Ч192"]
    B --> C["Fully Connected рдкрд░рдд<br/>256 рдЖрдпрд╛рдо"]
    C --> D["рдЖрдЙрдЯрдкреБрдЯ<br/>рдПрдХрд▓ рдорд╛рди"]
```

### рдЗрдирдкреБрдЯ рдкрд░рдд

Policy Network рдХреЗ рд╕рдорд╛рди, рдЗрдирдкреБрдЯ рдПрдХ **19├Ч19├Ч49** рд╡рд┐рд╢реЗрд╖рддрд╛ tensor рд╣реИ:

- **19├Ч19**: рдмреЛрд░реНрдб рдЖрдХрд╛рд░
- **49**: 48 рд╡рд┐рд╢реЗрд╖рддрд╛ рдкреНрд▓реЗрди + 1 рд╡рд░реНрддрдорд╛рди рдЦрд┐рд▓рд╛рдбрд╝реА рджрд░реНрд╢рд╛рдиреЗ рд╡рд╛рд▓рд╛ рдкреНрд▓реЗрди

рдЕрддрд┐рд░рд┐рдХреНрдд 1 рдкреНрд▓реЗрди рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ: Value Network рдХреЛ рдЬрд╛рдирдирд╛ рдЪрд╛рд╣рд┐рдП рдХрд┐рд╕рдХреА рдмрд╛рд░реА рд╣реИ, рдХреНрдпреЛрдВрдХрд┐ рдПрдХ рд╣реА рд╕реНрдерд┐рддрд┐ рдХрд╛рд▓реЗ рдФрд░ рд╕рдлреЗрдж рдХреЗ рд▓рд┐рдП рд╡рд┐рдкрд░реАрдд рдореВрд▓реНрдп рдХреА рд╣реИред

### Convolutional рдкрд░рддреЗрдВ

Policy Network рдХреЗ рд╕рдорд╛рди:
- **12 convolutional рдкрд░рддреЗрдВ**
- **192 рдлрд╝рд┐рд▓реНрдЯрд░**
- **3├Ч3 convolutional рдХрд░реНрдиреЗрд▓** (рдкрд╣рд▓реА рдкрд░рдд 5├Ч5)
- **ReLU рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди**

### рдЖрдЙрдЯрдкреБрдЯ рдкрд░рдд рдХрд╛ рдЕрдВрддрд░

рдпрд╣ Value Network рдФрд░ Policy Network рдХрд╛ рдореБрдЦреНрдп рдЕрдВрддрд░ рд╣реИ:

#### Policy Network рдЖрдЙрдЯрдкреБрдЯ
```
19├Ч19├Ч192 тЖТ 1├Ч1 Convolution тЖТ 19├Ч19├Ч1 тЖТ рд╕рдорддрд▓ тЖТ 361 рдЖрдпрд╛рдо тЖТ Softmax тЖТ рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг
```

#### Value Network рдЖрдЙрдЯрдкреБрдЯ
```
19├Ч19├Ч192 тЖТ 1├Ч1 Convolution тЖТ 19├Ч19├Ч1 тЖТ рд╕рдорддрд▓ тЖТ 361 рдЖрдпрд╛рдо тЖТ FC 256 тЖТ ReLU тЖТ FC 1 тЖТ Tanh тЖТ рдПрдХрд▓ рдорд╛рди
```

### Tanh рд╕рдХреНрд░рд┐рдпрдг рдлрд╝рдВрдХреНрд╢рди

Value Network рдХреА рдЕрдВрддрд┐рдо рдкрд░рдд **Tanh** (рд╣рд╛рдЗрдкрд░рдмреЛрд▓рд┐рдХ рдЯреИрдВрдЬреЗрдВрдЯ) рдлрд╝рдВрдХреНрд╢рди рдЙрдкрдпреЛрдЧ рдХрд░рддреА рд╣реИ:

```
Tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))
```

Tanh рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ рд░реЗрдВрдЬ **(-1, +1)** рд╣реИ, рдЬреЛ рдЬреАрдд-рд╣рд╛рд░ рд╕реЗ рд╕рдЯреАрдХ рдореЗрд▓ рдЦрд╛рддрд╛ рд╣реИред

#### Sigmoid рдХреЗ рдмрдЬрд╛рдп Tanh рдХреНрдпреЛрдВ?

Sigmoid рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ рд░реЗрдВрдЬ (0, 1) рд╣реИ, рдЬреЛ рдЬреАрдд рджрд░ рднреА рджрд░реНрд╢рд╛ рд╕рдХрддрд╛ рд╣реИред рд▓реЗрдХрд┐рди Tanh рдХреЗ рдХреБрдЫ рдлрд╛рдпрджреЗ рд╣реИрдВ:

1. **рд╕рдорд░реВрдкрддрд╛**: 0 рдХреЗ рдЪрд╛рд░реЛрдВ рдУрд░ рдХреЗрдВрджреНрд░рд┐рдд, рдЖрдЙрдЯрдкреБрдЯ рд╕рдХрд╛рд░рд╛рддреНрдордХ рдпрд╛ рдирдХрд╛рд░рд╛рддреНрдордХ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ
2. **рдмреЗрд╣рддрд░ рдЧреНрд░реЗрдбрд┐рдПрдВрдЯ**: 0 рдХреЗ рдкрд╛рд╕ рдЧреНрд░реЗрдбрд┐рдПрдВрдЯ 1 рдХреЗ рдХрд░реАрдм
3. **рд╕реНрдкрд╖реНрдЯ рдЕрд░реНрде**: рд╕рдХрд╛рд░рд╛рддреНрдордХ рдорд╛рди рдЬреАрдд, рдирдХрд╛рд░рд╛рддреНрдордХ рд╣рд╛рд░, рд╢реВрдиреНрдп рдмрд░рд╛рдмрд░реА

### рдкреВрд░реНрдг рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдЪрд┐рддреНрд░

```mermaid
flowchart TB
    A["рдЗрдирдкреБрдЯ: 19├Ч19├Ч49"] --> B["Conv 5├Ч5, 192 filters"]
    B --> C["ReLU"]
    C --> D["Conv 3├Ч3, 192 filters (├Ч11)"]
    D --> E["ReLU"]
    E --> F["Conv 1├Ч1, 1 filter"]
    F --> G["рд╕рдорддрд▓ (361 рдЖрдпрд╛рдо)"]
    G --> H["Fully Connected (256 рдЖрдпрд╛рдо)"]
    H --> I["ReLU"]
    I --> J["Fully Connected (1 рдЖрдпрд╛рдо)"]
    J --> K["Tanh"]
    K --> L["рдЖрдЙрдЯрдкреБрдЯ: [-1, +1]"]
```

### рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛

| рдкрд░рдд | рдЧрдгрдирд╛ | рдкреИрд░рд╛рдореАрдЯрд░ рд╕рдВрдЦреНрдпрд╛ |
|---|------|---------|
| Convolutional рдкрд░рддреЗрдВ | Policy Network рдХреЗ рд╕рдорд╛рди | ~3.9M |
| Fully Connected рдкрд░рдд 1 | 361├Ч256 + 256 | 92,672 |
| Fully Connected рдкрд░рдд 2 | 256├Ч1 + 1 | 257 |
| **рдХреБрд▓** | | **~4.0M** |

рд▓рдЧрднрдЧ 4 рдорд┐рд▓рд┐рдпрди рдкреИрд░рд╛рдореАрдЯрд░, Policy Network рд╕реЗ рдереЛрдбрд╝рд╛ рдЕрдзрд┐рдХред

---

## рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреА рдЪреБрдиреМрддрд┐рдпрд╛рдБ

### Overfitting рд╕рдорд╕реНрдпрд╛

Value Network рдХрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг Policy Network рд╕реЗ рдмрд╣реБрдд рдХрдард┐рди рд╣реИред рдореБрдЦреНрдп рд╕рдорд╕реНрдпрд╛ **overfitting** рд╣реИред

#### Overfitting рдХреНрдпрд╛ рд╣реИ?

Overfitting рдХрд╛ рдЕрд░реНрде рд╣реИ рдореЙрдбрд▓ рдиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдХреЛ "рдпрд╛рдж" рдХрд░ рд▓рд┐рдпрд╛, рд╕рд╛рдорд╛рдиреНрдпреАрдХрд░рдг рдирд╣реАрдВ рд╕реАрдЦрд╛ред рдкреНрд░рджрд░реНрд╢рди:
- рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕реЗрдЯ рдкрд░ рдмрд╣реБрдд рдЕрдЪреНрдЫрд╛
- рдЯреЗрд╕реНрдЯ рд╕реЗрдЯ рдкрд░ рдЦрд░рд╛рдм

#### Value Network рдореЗрдВ overfitting рдХреНрдпреЛрдВ?

рдПрдХ рдЦреЗрд▓ рдХреЗ рдбреЗрдЯрд╛ рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░реЗрдВ:

```
рд╕реНрдерд┐рддрд┐ 1 тЖТ рд╕реНрдерд┐рддрд┐ 2 тЖТ рд╕реНрдерд┐рддрд┐ 3 тЖТ ... тЖТ рд╕реНрдерд┐рддрд┐ 200 тЖТ рдкрд░рд┐рдгрд╛рдо: рдХрд╛рд▓рд╛ рдЬреАрддрд╛
```

рдпрджрд┐ рд╕реАрдзреЗ рдЗрд╕ рдбреЗрдЯрд╛ рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХрд░реЗрдВ:
- рдпреЗ 200 рд╕реНрдерд┐рддрд┐рдпрд╛рдБ рдмрд╣реБрдд рд╕рд╣рд╕рдВрдмрджреНрдз рд╣реИрдВ
- рд╡реЗ рдПрдХ рд╣реА рдЦреЗрд▓ рд╕реЗ рд╣реИрдВ, рдПрдХ рд╣реА рдкрд░рд┐рдгрд╛рдо
- рдореЙрдбрд▓ рдЗрд╕ рдЦреЗрд▓ рдХреЛ "рдкрд╣рдЪрд╛рдирдирд╛" рд╕реАрдЦ рд╕рдХрддрд╛ рд╣реИ, рд╕реНрдерд┐рддрд┐ рд╕рдордЭрдирд╛ рдирд╣реАрдВ

DeepMind рдиреЗ рдкрд╛рдпрд╛: рдпрджрд┐ Policy рдФрд░ Value Network рдХреЗ рд▓рд┐рдП рдПрдХ рд╣реА рдорд╛рдирд╡ рдЧреЗрдо рд░рд┐рдХреЙрд░реНрдб рд╕реЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХрд░реЗрдВ, Value Network рдЧрдВрднреАрд░ рд░реВрдк рд╕реЗ overfit рд╣реЛ рдЬрд╛рддрд╛ рд╣реИред

### рд╕рдорд╛рдзрд╛рди: рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рдбреЗрдЯрд╛

DeepMind рдХрд╛ рд╕рдорд╛рдзрд╛рди рдирдпрд╛ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ **рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ** рд╕реЗ рдЙрддреНрдкрдиреНрди рдХрд░рдирд╛ рд╣реИ:

```
1. рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд RL Policy Network рд╕реЗ рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рдХрд░реЗрдВ
2. рдкреНрд░рддреНрдпреЗрдХ рдЦреЗрд▓ рд╕реЗ рдХреЗрд╡рд▓ рдПрдХ рд╕реНрдерд┐рддрд┐ рд▓реЗрдВ (рд╕рд╣рд╕рдВрдмрдВрдз рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП)
3. рдЗрд╕ рд╕реНрдерд┐рддрд┐ рдХрд╛ рд▓реЗрдмрд▓ рдЙрд╕ рдЦреЗрд▓ рдХрд╛ рдЕрдВрддрд┐рдо рдкрд░рд┐рдгрд╛рдо рд╣реИ
4. рдРрд╕реЗ 30 рдорд┐рд▓рд┐рдпрди рдирдореВрдиреЗ рдЙрддреНрдкрдиреНрди рдХрд░реЗрдВ
```

#### рдпрд╣ overfitting рдХреНрдпреЛрдВ рд╣рд▓ рдХрд░рддрд╛ рд╣реИ?

1. **рдмрдбрд╝рд╛ рдбреЗрдЯрд╛**: 30 рдорд┐рд▓рд┐рдпрди рд╕реНрд╡рддрдВрддреНрд░ рд╕реНрдерд┐рддрд┐рдпрд╛рдБ
2. **рдХреЛрдИ рд╕рд╣рд╕рдВрдмрдВрдз рдирд╣реАрдВ**: рдкреНрд░рддреНрдпреЗрдХ рдЦреЗрд▓ рд╕реЗ рдХреЗрд╡рд▓ рдПрдХ рд╕реНрдерд┐рддрд┐
3. **рдЕрд▓рдЧ рд╡рд┐рддрд░рдг**: рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рдХреА рд╕реНрдерд┐рддрд┐рдпрд╛рдБ рдорд╛рдирд╡ рдЧреЗрдо рд░рд┐рдХреЙрд░реНрдб рд╕реЗ рдЕрд▓рдЧ

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдЙрддреНрдкрд╛рджрди

```python
# рдЫрджреНрдо рдХреЛрдб
training_data = []

for game_id in range(30_000_000):
    # рдПрдХ рдЦреЗрд▓ рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ
    states, result = self_play(rl_policy_network)

    # рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рд░реВрдк рд╕реЗ рдПрдХ рд╕реНрдерд┐рддрд┐ рдЪреБрдиреЗрдВ
    random_index = random.randint(0, len(states) - 1)
    state = states[random_index]

    # рд╕реНрдерд┐рддрд┐ рдФрд░ рдкрд░рд┐рдгрд╛рдо рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ
    training_data.append((state, result))
```

---

## рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЙрджреНрджреЗрд╢реНрдп рдФрд░ рд╡рд┐рдзрд┐

### Mean Squared Error рд╣рд╛рдирд┐

Value Network **Mean Squared Error (MSE)** рдХреЛ рд╣рд╛рдирд┐ рдлрд╝рдВрдХреНрд╢рди рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ:

```
L(╬╕) = (1/n) ├Ч ╬г (v_╬╕(s) - z)┬▓
```

рдЬрд╣рд╛рдБ:
- `v_╬╕(s)`: рдореЙрдбрд▓ рджреНрд╡рд╛рд░рд╛ рдЕрдиреБрдорд╛рдирд┐рдд рдорд╛рди
- `z`: рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдкрд░рд┐рдгрд╛рдо (+1 рдпрд╛ -1)

#### Cross-entropy рдХреЗ рдмрдЬрд╛рдп MSE рдХреНрдпреЛрдВ?

- **Cross-entropy** рд╡рд░реНрдЧреАрдХрд░рдг рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд (рдЕрд╕рддрдд рд▓реЗрдмрд▓)
- **MSE** рд░рд┐рдЧреНрд░реЗрд╢рди рд╕рдорд╕реНрдпрд╛рдУрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреБрдХреНрдд (рд╕рддрдд рдорд╛рди)

рд╣рд╛рд▓рд╛рдБрдХрд┐ рдкрд░рд┐рдгрд╛рдо рдХреЗрд╡рд▓ +1 рдпрд╛ -1 рд╣реИ, рдореЙрдбрд▓ рд╕рддрдд рдорд╛рди (-1 рд╕реЗ +1 рдХреЗ рдмреАрдЪ рдХреЛрдИ рднреА рд╕рдВрдЦреНрдпрд╛) рдЕрдиреБрдорд╛рди рдХрд░рддрд╛ рд╣реИред MSE рдореЙрдбрд▓ рдХреЛ +1 рдпрд╛ -1 рдХреЗ рдХрд░реАрдм рдорд╛рди рдЕрдиреБрдорд╛рди рдХрд░рдирд╛ рд╕рд┐рдЦрд╛рддрд╛ рд╣реИред

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдкреНрд░рдХреНрд░рд┐рдпрд╛

```python
# рдЫрджреНрдо рдХреЛрдб
for epoch in range(num_epochs):
    for batch in dataloader:
        states, outcomes = batch

        # рдлреЙрд░рд╡рд░реНрдб рдкрд╛рд╕
        values = network(states)  # (batch, 1)

        # рд╣рд╛рдирд┐ рдЧрдгрдирд╛ (MSE)
        loss = mse_loss(values, outcomes)

        # рдмреИрдХрд╡рд░реНрдб рдкрд╛рд╕
        loss.backward()
        optimizer.step()
```

рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╡рд┐рд╡рд░рдг:
- **рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝рд░**: SGD with momentum
- **рд▓рд░реНрдирд┐рдВрдЧ рд░реЗрдЯ**: 0.003
- **рдмреИрдЪ рдЖрдХрд╛рд░**: 32
- **рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд╕рдордп**: рд▓рдЧрднрдЧ 1 рд╕рдкреНрддрд╛рд╣ (50 GPUs)

---

## рд╕рдЯреАрдХрддрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

### рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди рд╕реЗ рддреБрд▓рдирд╛

DeepMind рдиреЗ рдкреЗрдкрд░ рдореЗрдВ рд╡рд┐рд╕реНрддреГрдд рддреБрд▓рдирд╛ рдХреА:

| рдореВрд▓реНрдпрд╛рдВрдХрди рд╡рд┐рдзрд┐ | рдЕрдиреБрдорд╛рди рддреНрд░реБрдЯрд┐ |
|---------|---------|
| 1000 рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди | рдЕрдзрд┐рдХ |
| 15000 рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди | рдордзреНрдпрдо |
| Value Network | 15000 рд╕рд┐рдореБрд▓реЗрд╢рди рдХреЗ рд╕рдорддреБрд▓реНрдп |

рдЗрд╕рдХрд╛ рдЕрд░реНрде рд╣реИ рдПрдХ Value Network рдореВрд▓реНрдпрд╛рдВрдХрди тЙИ 15000 рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди, рд▓реЗрдХрд┐рди рд▓рдЧрднрдЧ 1000 рдЧреБрдирд╛ рддреЗрдЬрд╝ред

### рд╡рд┐рднрд┐рдиреНрди рдЪрд░рдгреЛрдВ рдореЗрдВ рд╕рдЯреАрдХрддрд╛

Value Network рдХреА рд╕рдЯреАрдХрддрд╛ рдЦреЗрд▓ рдХреА рдкреНрд░рдЧрддрд┐ рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░рддреА рд╣реИ:

| рдЪрд░рдг | рд╢реЗрд╖ рдЪрд╛рд▓реЗрдВ | рдЕрдиреБрдорд╛рди рдХрдард┐рдирд╛рдИ | рд╕рдЯреАрдХрддрд╛ |
|------|---------|---------|--------|
| рдУрдкрдирд┐рдВрдЧ | ~300 | рдмрд╣реБрдд рдХрдард┐рди | рдХрдо |
| рдорд┐рдбрдЧреЗрдо | ~150 | рдХрдард┐рди | рдордзреНрдпрдо |
| рдпреЛрд╕реЗ | ~50 | рдЖрд╕рд╛рди | рдЕрдзрд┐рдХ |
| рдПрдВрдбрдЧреЗрдо | ~10 | рд╕рд░рд▓ | рдмрд╣реБрдд рдЕрдзрд┐рдХ |

рдпрд╣ рд╕рд╣рдЬ рд░реВрдк рд╕реЗ рд╕рд╣реА рд╣реИ: рдЦреЗрд▓ рд╕рдорд╛рдкреНрддрд┐ рдХреЗ рдЬрд┐рддрдирд╛ рдХрд░реАрдм, рдкрд░рд┐рдгрд╛рдо рдЙрддрдирд╛ рдирд┐рд╢реНрдЪрд┐рддред

### рдЖрдЙрдЯрдкреБрдЯ рд╡рд┐рддрд░рдг

рдПрдХ рдЕрдЪреНрдЫреА рддрд░рд╣ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд Value Network рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ рд╡рд┐рддрд░рдг:

```
        рдЖрд╡реГрддреНрддрд┐
          |
          |    *
          |   * *
          |  *   *
          | *     *
          |*       *
          +----+----+---- рдЖрдЙрдЯрдкреБрдЯ рдорд╛рди
         -1    0   +1

рдЕрдзрд┐рдХрд╛рдВрд╢ рдЖрдЙрдЯрдкреБрдЯ -1 рдФрд░ +1 рдХреЗ рдкрд╛рд╕ рдХреЗрдВрджреНрд░рд┐рдд
(рдХреНрдпреЛрдВрдХрд┐ рдЕрдзрд┐рдХрд╛рдВрд╢ рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдореЗрдВ рд╕реНрдкрд╖реНрдЯ рдЬреАрдд-рд╣рд╛рд░ рдЭреБрдХрд╛рд╡)
```

### рдЕрдирд┐рд╢реНрдЪрд┐рдд рд╕реНрдерд┐рддрд┐рдпрд╛рдБ

рдЬрдм Value Network рдЖрдЙрдЯрдкреБрдЯ 0 рдХреЗ рдХрд░реАрдм рд╣реЛ, рддреЛ рд╕реНрдерд┐рддрд┐ рдмрд╣реБрдд рдЬрдЯрд┐рд▓ рд╣реИ, рдЬреАрдд-рд╣рд╛рд░ рдХрдард┐рдиред рдпреЗ рд╕реНрдерд┐рддрд┐рдпрд╛рдБ рдЖрдорддреМрд░ рдкрд░:
- рдмрдбрд╝реА рд▓рдбрд╝рд╛рдИ рдореЗрдВ
- рджреЛрдиреЛрдВ рдкрдХреНрд╖ рдмрд░рд╛рдмрд░
- рдХрдИ рд╕рдВрднрд╛рд╡рд┐рдд рдмрджрд▓рд╛рд╡

MCTS рдореЗрдВ, рдЗрди рдиреЛрдбреНрд╕ рдХреЛ рдЕрдзрд┐рдХ рдЦреЛрдЬ рд╕рдВрд╕рд╛рдзрди рдорд┐рд▓рддреЗ рд╣реИрдВ (рдХреНрдпреЛрдВрдХрд┐ рдЕрдирд┐рд╢реНрдЪрд┐рддрддрд╛ рдЕрдзрд┐рдХ)ред

---

## MCTS рдореЗрдВ рднреВрдорд┐рдХрд╛

### Leaf рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрди

Value Network MCTS рдХреЗ **Evaluation** рдЪрд░рдг рдореЗрдВ рдорд╣рддреНрд╡рдкреВрд░реНрдг рднреВрдорд┐рдХрд╛ рдирд┐рднрд╛рддрд╛ рд╣реИ:

```mermaid
flowchart TB
    Root["рд░реВрдЯ рдиреЛрдб<br/>(рд╡рд░реНрддрдорд╛рди рд╕реНрдерд┐рддрд┐)"] --> A["A"]
    Root --> B["B"]
    A --> A1["A1<br/>Leaf рдиреЛрдб"]
    A --> A2["A2<br/>Leaf рдиреЛрдб"]
    B --> B1["B1<br/>Leaf рдиреЛрдб"]
    B --> B2["B2<br/>Leaf рдиреЛрдб"]
    A1 --> E1["рдореВрд▓реНрдпрд╛рдВрдХрди"]
    A2 --> E2["рдореВрд▓реНрдпрд╛рдВрдХрди"]
    B1 --> E3["рдореВрд▓реНрдпрд╛рдВрдХрди"]
    B2 --> E4["рдореВрд▓реНрдпрд╛рдВрдХрди"]
```

рдЬрдм MCTS рдПрдХ leaf рдиреЛрдб рдкрд░ рдкрд╣реБрдБрдЪрддрд╛ рд╣реИ, рдЗрд╕ рд╕реНрдерд┐рддрд┐ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдирд╛ рд╣реЛрддрд╛ рд╣реИред рджреЛ рд╡рд┐рдзрд┐рдпрд╛рдБ рд╣реИрдВ:

1. **рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди (Rollout)**: Leaf рдиреЛрдб рд╕реЗ рдЦреЗрд▓ рд╕рдорд╛рдкреНрдд рд╣реЛрдиреЗ рддрдХ рдпрд╛рджреГрдЪреНрдЫрд┐рдХ рдЦреЗрд▓реЗрдВ
2. **Value Network рдореВрд▓реНрдпрд╛рдВрдХрди**: рд╕реАрдзреЗ neural network рд╕реЗ рдЕрдиреБрдорд╛рди

AlphaGo рджреЛрдиреЛрдВ рдХреЛ рдЬреЛрдбрд╝рддрд╛ рд╣реИ:

```
V(leaf) = (1-╬╗) ├Ч V_network(leaf) + ╬╗ ├Ч V_rollout(leaf)
```

рдЬрд╣рд╛рдБ ╬╗ = 0.5, рдпрд╛рдиреА рдЖрдзрд╛-рдЖрдзрд╛ рд╡рдЬрд╝рдиред

#### рджреЛрдиреЛрдВ рдХреНрдпреЛрдВ рдЬреЛрдбрд╝реЗрдВ?

- **Value Network** рдЕрдзрд┐рдХ рд╕рдЯреАрдХ, рд▓реЗрдХрд┐рди рд╡реНрдпрд╡рд╕реНрдерд┐рдд рдкреВрд░реНрд╡рд╛рдЧреНрд░рд╣ рд╣реЛ рд╕рдХрддрд╛ рд╣реИ
- **рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди** рдХрдо рд╕рдЯреАрдХ, рд▓реЗрдХрд┐рди рд╕реНрд╡рддрдВрддреНрд░ рдЕрдиреБрдорд╛рди
- рджреЛрдиреЛрдВ рдЬреЛрдбрд╝рдХрд░ рдПрдХ-рджреВрд╕рд░реЗ рдХреА рдХрдореА рдкреВрд░реА

### AlphaGo Zero рдХрд╛ рд╕рд░рд▓реАрдХрд░рдг

рдмрд╛рдж рдХреЗ AlphaGo Zero рдиреЗ рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди рдкреВрд░реНрдгрддрдГ рддреНрдпрд╛рдЧ рджрд┐рдпрд╛:

```
V(leaf) = V_network(leaf)
```

рдЗрд╕рд╕реЗ рдкреНрд░рдгрд╛рд▓реА рдмрд╣реБрдд рд╕рд░рд▓ рд╣реЛ рдЧрдИ, рд╕рд╛рде рд╣реА рдЦреЗрд▓ рд╢рдХреНрддрд┐ рднреА рдордЬрдмреВрддред рдпрд╣ рд╕рд╛рдмрд┐рдд рдХрд░рддрд╛ рд╣реИ рдХрд┐ Value Network рдкрд░реНрдпрд╛рдкреНрдд рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рд╣реИ, рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди рдХреЗ "рдмреАрдорд╛" рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдирд╣реАрдВред

### Backpropagation рдЕрдкрдбреЗрдЯ

Leaf рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрди рдХреЗ рдмрд╛рдж, рдпрд╣ рдорд╛рди рдкрде рдкрд░ рд╡рд╛рдкрд╕ рдЕрдкрдбреЗрдЯ рд╣реЛрддрд╛ рд╣реИ:

```
v3 = V(leaf) = 0.6
      тЖС
A2 рдХрд╛ Q рдорд╛рди рдЕрдкрдбреЗрдЯ
      тЖС
A рдХрд╛ Q рдорд╛рди рдЕрдкрдбреЗрдЯ
      тЖС
рд░реВрдЯ рдиреЛрдб рдХреЗ рдЖрдБрдХрдбрд╝реЗ рдЕрдкрдбреЗрдЯ
```

рдкреНрд░рддреНрдпреЗрдХ рдиреЛрдб рдХрд╛ Q рдорд╛рди рдЙрд╕рд╕реЗ рдЧреБрдЬрд╝рд░рдиреЗ рд╡рд╛рд▓реЗ рд╕рднреА leaf рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрдиреЛрдВ рдХрд╛ рдФрд╕рдд рд╣реИ:

```
Q(s, a) = (1/N(s,a)) ├Ч ╬г V(leaf)
```

---

## рд╡рд┐рдЬрд╝реБрдЕрд▓ рд╡рд┐рд╢реНрд▓реЗрд╖рдг

### рдорд╛рди рд╕рддрд╣

рдПрдХ рд╕рд░рд▓реАрдХреГрдд 3├Ч3 рдмреЛрд░реНрдб рдХреА рдХрд▓реНрдкрдирд╛ рдХрд░реЗрдВред Value Network рдЬреЛ рд╕реАрдЦрддрд╛ рд╣реИ рд╡рд╣ рдПрдХ "рдорд╛рди рд╕рддрд╣" рд╣реИ:

|  | рд╕рдлреЗрдж 1 | рд╕рдлреЗрдж 2 | рд╕рдлреЗрдж 3 |
|---|--------|--------|--------|
| **рдХрд╛рд▓рд╛ 1** | +0.3 | -0.1 | +0.2 |
| **рдХрд╛рд▓рд╛ 2** | -0.2 | +0.5 | -0.3 |
| **рдХрд╛рд▓рд╛ 3** | +0.1 | -0.2 | +0.4 |

рдпрд╣ рд╕рддрд╣ рд╣рдореЗрдВ рдмрддрд╛рддреА рд╣реИ рдкреНрд░рддреНрдпреЗрдХ рд╕реНрдерд┐рддрд┐ рд╕рдВрдпреЛрдЬрди рдХрд╛ рдорд╛рдиред рд╕рдХрд╛рд░рд╛рддреНрдордХ рдорд╛рди рдХрд╛рд▓реЗ рдХреЗ рд▓рд┐рдП рдЕрдиреБрдХреВрд▓, рдирдХрд╛рд░рд╛рддреНрдордХ рд╕рдлреЗрдж рдХреЗ рд▓рд┐рдПред

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рджреМрд░рд╛рди рд╡рд┐рдХрд╛рд╕

рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рд╕рд╛рде, Value Network рдХрд╛ рдЕрдиреБрдорд╛рди рдзреАрд░реЗ-рдзреАрд░реЗ рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рд╣реЛрддрд╛ рд╣реИ:

```
       рдЕрдиреБрдорд╛рди рддреНрд░реБрдЯрд┐
          |
     1.0  |*
          | *
     0.5  |  *
          |   *
     0.1  |    * * * * *
          +тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФА рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдЪрд░рдг
          0   100K  500K  1M
```

рддреНрд░реБрдЯрд┐ рдЬрд▓реНрджреА рдЧрд┐рд░рддреА рд╣реИ, рдлрд┐рд░ рд╕реНрдерд┐рд░ рд╣реЛрддреА рд╣реИред

### рдХрдард┐рди рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреА рдкрд╣рдЪрд╛рди

Value Network рдХрдард┐рди рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреА рдкрд╣рдЪрд╛рди рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реИ:

| рдЖрдЙрдЯрдкреБрдЯ | рдЕрд░реНрде | рд░рдгрдиреАрддрд┐ |
|------|------|---------|
| +1 рдХреЗ рдХрд░реАрдм | рдмрдбрд╝рд╛ рдлрд╛рдпрджрд╛ | рд╕реБрд░рдХреНрд╖рд┐рдд рдЪрд╛рд▓реЗрдВ |
| -1 рдХреЗ рдХрд░реАрдм | рдмрдбрд╝рд╛ рдиреБрдХрд╕рд╛рди | рдкрд▓рдЯрд╛рд╡ рдХреЗ рдЕрд╡рд╕рд░ рдЦреЛрдЬреЗрдВ |
| 0 рдХреЗ рдХрд░реАрдм | рдЬрдЯрд┐рд▓ рд╕реНрдерд┐рддрд┐ | рдЧрд╣рди рдЧрдгрдирд╛ рдЖрд╡рд╢реНрдпрдХ |

AlphaGo 0 рдХреЗ рдХрд░реАрдм рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдореЗрдВ рдЕрдзрд┐рдХ рд╕реЛрдЪрдиреЗ рдХрд╛ рд╕рдордп рд▓рдЧрд╛рддрд╛ рд╣реИред

---

## рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди рдмрд┐рдВрджреБ

### PyTorch рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрди

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class ValueNetwork(nn.Module):
    def __init__(self, input_channels=49, num_filters=192, num_layers=12):
        super().__init__()

        # рдкрд╣рд▓реА convolutional рдкрд░рдд (5├Ч5)
        self.conv1 = nn.Conv2d(input_channels, num_filters,
                               kernel_size=5, padding=2)

        # рдордзреНрдп convolutional рдкрд░рддреЗрдВ (3├Ч3)├Ч11
        self.conv_layers = nn.ModuleList([
            nn.Conv2d(num_filters, num_filters,
                     kernel_size=3, padding=1)
            for _ in range(num_layers - 1)
        ])

        # рдЖрдЙрдЯрдкреБрдЯ convolutional рдкрд░рдд
        self.conv_out = nn.Conv2d(num_filters, 1, kernel_size=1)

        # Fully connected рдкрд░рддреЗрдВ
        self.fc1 = nn.Linear(361, 256)
        self.fc2 = nn.Linear(256, 1)

    def forward(self, x):
        # x: (batch, 49, 19, 19)

        # Convolutional рдкрд░рддреЗрдВ
        x = F.relu(self.conv1(x))
        for conv in self.conv_layers:
            x = F.relu(conv(x))
        x = self.conv_out(x)

        # рд╕рдорддрд▓
        x = x.view(x.size(0), -1)  # (batch, 361)

        # Fully connected рдкрд░рддреЗрдВ
        x = F.relu(self.fc1(x))
        x = torch.tanh(self.fc2(x))

        return x.squeeze(-1)  # (batch,)
```

### рдкреНрд░рд╢рд┐рдХреНрд╖рдг рд▓реВрдк

```python
def train_value_network(model, optimizer, states, outcomes):
    """
    states: (batch, 49, 19, 19) - рдмреЛрд░реНрдб рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ
    outcomes: (batch,) - рдЦреЗрд▓ рдкрд░рд┐рдгрд╛рдо (+1 рдпрд╛ -1)
    """
    # рдлреЙрд░рд╡рд░реНрдб рдкрд╛рд╕
    values = model(states)  # (batch,)

    # MSE рд╣рд╛рдирд┐
    loss = F.mse_loss(values, outcomes)

    # рдмреИрдХрд╡рд░реНрдб рдкрд╛рд╕
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # рд╕рдЯреАрдХрддрд╛ рдЧрдгрдирд╛ (рд╕рд╣реА рдЬреАрдд-рд╣рд╛рд░ рдЕрдиреБрдорд╛рди)
    predictions = (values > 0).float() * 2 - 1  # +1/-1 рдореЗрдВ рдмрджрд▓реЗрдВ
    accuracy = (predictions == outcomes).float().mean()

    return loss.item(), accuracy.item()
```

### Overfitting рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рддрд░реАрдХреЗ

```python
# 1. рдбреЗрдЯрд╛ рд╕рдВрд╡рд░реНрдзрди (8 рд╕рдорд░реВрдкрддрд╛рдПрдБ)
def augment(state, outcome):
    augmented = []
    for rotation in [0, 90, 180, 270]:
        s = rotate(state, rotation)
        augmented.append((s, outcome))
        augmented.append((flip(s), outcome))
    return augmented

# 2. Dropout
class ValueNetworkWithDropout(ValueNetwork):
    def __init__(self, *args, dropout_rate=0.5, **kwargs):
        super().__init__(*args, **kwargs)
        self.dropout = nn.Dropout(dropout_rate)

    def forward(self, x):
        # ... convolutional рдкрд░рддреЗрдВ ...
        x = self.dropout(x)  # fully connected рдкрд░рдд рд╕реЗ рдкрд╣рд▓реЗ dropout
        # ... fully connected рдкрд░рддреЗрдВ ...

# 3. Early Stopping
best_val_loss = float('inf')
patience = 10
counter = 0

for epoch in range(max_epochs):
    train_loss = train_one_epoch()
    val_loss = evaluate()

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        save_model()
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping!")
            break
```

---

## Policy Network рдХреЗ рд╕рд╛рде рд╕рд╣рдпреЛрдЧ

### рдкреВрд░рдХ рд╕рдВрдмрдВрдз

Policy Network рдФрд░ Value Network AlphaGo рдореЗрдВ рдПрдХ-рджреВрд╕рд░реЗ рдХреЗ рдкреВрд░рдХ рд╣реИрдВ:

| рдиреЗрдЯрд╡рд░реНрдХ | рдЙрддреНрддрд░ рджрд┐рдпрд╛ рдкреНрд░рд╢реНрди | рдЖрдЙрдЯрдкреБрдЯ | MCTS рднреВрдорд┐рдХрд╛ |
|------|-----------|------|----------|
| Policy | рдЕрдЧрд▓реА рдЪрд╛рд▓ рдХрд╣рд╛рдБ? | рд╕рдВрднрд╛рд╡рдирд╛ рд╡рд┐рддрд░рдг | рдЦреЛрдЬ рджрд┐рд╢рд╛ рдирд┐рд░реНрджреЗрд╢рди |
| Value | рдпрд╣ рдЦреЗрд▓ рдЬреАрддреЗрдВрдЧреЗ? | рдПрдХрд▓ рдорд╛рди | Leaf рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрди |

### рдПрдХреАрдХреГрдд Dual-Head рдиреЗрдЯрд╡рд░реНрдХ

AlphaGo Zero рдореЗрдВ, рдпреЗ рджреЛрдиреЛрдВ рдиреЗрдЯрд╡рд░реНрдХ рдПрдХ **Dual-Head рдиреЗрдЯрд╡рд░реНрдХ** рдореЗрдВ рдорд░реНрдЬ рд╣реЛ рдЧрдП:

```mermaid
flowchart TB
    A["рд╕рд╛рдЭрд╛ рд╡рд┐рд╢реЗрд╖рддрд╛ рдирд┐рд╖реНрдХрд░реНрд╖рдг рдкрд░рддреЗрдВ"] --> B["Policy Head"]
    A --> C["Value Head"]
    B --> D["361 рд╕рдВрднрд╛рд╡рдирд╛рдПрдБ"]
    C --> E["рдПрдХрд▓ рдорд╛рди"]
```

рдЗрд╕ рдбрд┐рдЬрд╝рд╛рдЗрди рдХреЗ рдлрд╛рдпрджреЗ:
- **рдкреИрд░рд╛рдореАрдЯрд░ рд╕рд╛рдЭрд╛рдХрд░рдг**: рдЧрдгрдирд╛ рдХрдо
- **рд╡рд┐рд╢реЗрд╖рддрд╛ рд╕рд╛рдЭрд╛рдХрд░рдг**: Policy рдФрд░ Value рд╕рдорд╛рди рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдБ рдЙрдкрдпреЛрдЧ
- **рд╕реНрдерд┐рд░ рдкреНрд░рд╢рд┐рдХреНрд╖рдг**: рджреЛрдиреЛрдВ рдЙрджреНрджреЗрд╢реНрдп рдПрдХ-рджреВрд╕рд░реЗ рдХреЛ regularize рдХрд░рддреЗ рд╣реИрдВ

рд╡рд┐рд╡рд░рдг рдХреЗ рд▓рд┐рдП [Dual-Head Network рдФрд░ Residual Network](../dual-head-resnet) рджреЗрдЦреЗрдВред

---

## рдПрдирд┐рдореЗрд╢рди рд╕рдВрджрд░реНрдн

рдЗрд╕ рд▓реЗрдЦ рдХреА рдореБрдЦреНрдп рдЕрд╡рдзрд╛рд░рдгрд╛рдПрдБ рдФрд░ рдПрдирд┐рдореЗрд╢рди рдирдВрдмрд░:

| рдирдВрдмрд░ | рдЕрд╡рдзрд╛рд░рдгрд╛ | рднреМрддрд┐рдХреА/рдЧрдгрд┐рдд рд╕рдВрджрд░реНрдн |
|------|------|--------------|
| ЁЯОм E2 | Value Network | рдкреЛрдЯреЗрдВрд╢рд┐рдпрд▓ рдПрдирд░реНрдЬреА рд╕рддрд╣ |
| ЁЯОм D4 | рдорд╛рди рдлрд╝рдВрдХреНрд╢рди | рдЕрдкреЗрдХреНрд╖рд┐рдд рд░рд┐рдЯрд░реНрди |
| ЁЯОм C6 | Leaf рдиреЛрдб рдореВрд▓реНрдпрд╛рдВрдХрди | рдлрд╝рдВрдХреНрд╢рди рдЕрдиреБрдорд╛рди |
| ЁЯОм H3 | Temporal Difference | рдмреВрдЯрд╕реНрдЯреНрд░реИрдк рд▓рд░реНрдирд┐рдВрдЧ |

---

## рдЖрдЧреЗ рдкрдврд╝реЗрдВ

- **рдкрд┐рдЫрд▓рд╛ рд▓реЗрдЦ**: [Policy Network рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг](../policy-network) тАФ рд░рдгрдиреАрддрд┐ рдиреЗрдЯрд╡рд░реНрдХ рдЪрд╛рд▓ рдХреИрд╕реЗ рдЪреБрдирддрд╛ рд╣реИ
- **рдЕрдЧрд▓рд╛ рд▓реЗрдЦ**: [рдЗрдирдкреБрдЯ рд╡рд┐рд╢реЗрд╖рддрд╛ рдбрд┐рдЬрд╝рд╛рдЗрди](../input-features) тАФ 48 рд╡рд┐рд╢реЗрд╖рддрд╛ рдкреНрд▓реЗрди рд╡рд┐рд╕реНрддреГрдд рд╡рд┐рд╢реНрд▓реЗрд╖рдг
- **рдЙрдиреНрдирдд рд╡рд┐рд╖рдп**: [MCTS рдФрд░ Neural Network рдХрд╛ рд╕рдВрдпреЛрдЬрди](../mcts-neural-combo) тАФ рдкреВрд░реНрдг рдЦреЛрдЬ рдкреНрд░рдХреНрд░рд┐рдпрд╛

---

## рдореБрдЦреНрдп рдмрд┐рдВрджреБ

1. **Value Network рдЬреАрдд рджрд░ рдЕрдиреБрдорд╛рди рдХрд░рддрд╛ рд╣реИ**: -1 рд╕реЗ +1 рдХреЗ рдмреАрдЪ рдПрдХрд▓ рдорд╛рди рдЖрдЙрдЯрдкреБрдЯ
2. **Tanh рдЖрдЙрдЯрдкреБрдЯ**: рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддрд╛ рд╣реИ рдЖрдЙрдЯрдкреБрдЯ рд╕рд╣реА рд░реЗрдВрдЬ рдореЗрдВ
3. **MSE рд╣рд╛рдирд┐**: рдЕрдиреБрдорд╛рдирд┐рдд рдорд╛рди рдХреЛ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдкрд░рд┐рдгрд╛рдо рдХреЗ рдХрд░реАрдм рд▓рд╛рддрд╛ рд╣реИ
4. **Overfitting рдЪреБрдиреМрддреА**: рд╕реЗрд▓реНрдл-рдкреНрд▓реЗ рдбреЗрдЯрд╛ рд╕реЗ рдмрдЪрдирд╛ рд╣реЛрдЧрд╛
5. **рд░реИрдВрдбрдо рд╕рд┐рдореБрд▓реЗрд╢рди рдХрд╛ рд╡рд┐рдХрд▓реНрдк**: рдПрдХ рдореВрд▓реНрдпрд╛рдВрдХрди тЙИ 15000 рд╕рд┐рдореБрд▓реЗрд╢рди

Value Network AlphaGo рдХреА "рдирд┐рд░реНрдгрдп рдХреНрд╖рдорддрд╛" рд╣реИтАФрдпрд╣ AI рдХреЛ рдХрд┐рд╕реА рднреА рд╕реНрдерд┐рддрд┐ рдХреА рдЕрдЪреНрдЫрд╛рдИ-рдмреБрд░рд╛рдИ рдХрд╛ рдореВрд▓реНрдпрд╛рдВрдХрди рдХрд░рдиреЗ рджреЗрддрд╛ рд╣реИ, рдмрд┐рдирд╛ рд╕рднреА рд╕рдВрднрд╛рд╡рдирд╛рдУрдВ рдХреЛ рдЦреЛрдЬреЗред

---

## рд╕рдВрджрд░реНрдн

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 551, 354-359.
3. Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction*. MIT Press.
4. Tesauro, G. (1995). "Temporal difference learning and TD-Gammon." *Communications of the ACM*, 38(3), 58-68.
