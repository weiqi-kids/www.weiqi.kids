---
sidebar_position: 4
title: 「神之一手」深度分析
description: 從棋理、專家反應到 AI 視角，完整解讀 AlphaGo 對李世乭第二盤的第 37 手
---

import { PolicyHeatmap } from '@site/src/components/D3Charts';

# 「神之一手」深度分析

2016 年 3 月 10 日，AlphaGo 與李世乭的第二盤對局。第 37 手，AlphaGo 在右上方五路下出一步「肩衝」。

這一手棋，後來被稱為「**神之一手**」（Divine Move）。它不只讓 AlphaGo 贏得比賽，更改變了人類對圍棋的理解。

本文將從多個角度深度分析這步棋：對局背景、傳統棋理、專家反應、AI 視角，以及它對圍棋理論的長遠影響。

---

## 對局局面回顧

### 第二盤的開局

第一盤失利後，李世乭在第二盤做出調整。他選擇執白後手，希望觀察 AlphaGo 的開局傾向後再制定策略。

開局階段：
- **黑 1**：右上角星位
- **白 2**：左下角星位
- **黑 3-白 4**：雙方各佔一角

到第 36 手為止，局面發展正常。AlphaGo 執黑，在右上角進行了一場局部戰鬥。白棋（李世乭）在右邊建立了勢力，黑棋則在上邊有一定實地。

### 第 36 手後的局面

讓我們看看第 36 手後的棋盤狀態：

| | A | B | C | D | E | F | G | H | J | K | L | M | N | O | P | Q | R | S | T | |
|---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---|
| **19** | | | | | | | | | | | | | | | | | | | | |
| **18** | | | | | | | | | | | | | | | | | | | | |
| **17** | | | | ○ | | | | | | | | | | | | ● | | | | |
| **16** | | | | + | | | | | | + | | | | | | + | | | | |
| **15** | | | | | | | | | | | | | | | | ● | | | | |
| **14** | | | | | | | | | | | | | | | ○ | | | | | 白棋勢力範圍 |
| **13** | | | | | | | | | | | | | | | | | | | | |
| **12** | | | | | | | | | | | | | | | | | | | | |
| **11** | | | | | | | | | | | | | | | | | | | | |
| **10** | | | | + | | | | | | + | | | | | | + | | | | |
| **9** | | | | | | | | | | | | | | | | | | | | |
| **8** | | | | | | | | | | | | | | | | | | | | |
| **7** | | | | | | | | | | | | | | | | | | | | |
| **6** | | | | | | | | | | | | | | | | | | | | |
| **5** | | | | | | | | | | | | | | | | | | | | |
| **4** | | | | + | | | | | | + | | | | | | + | | | | |
| **3** | | | | ○ | | | | | | | | | | | | ● | | | | |
| **2** | | | | | | | | | | | | | | | | | | | | |
| **1** | | | | | | | | | | | | | | | | | | | | |

*簡化示意圖，實際局面更複雜*

關鍵觀察：
- 白棋在右邊有外勢
- 黑棋在上邊有實地潛力
- 右上角的戰鬥告一段落

此時，輪到黑棋（AlphaGo）落子。

---

## 傳統下法分析

### 職業棋手的預期

在第 37 手之前，解說室裏的職業棋手正在熱烈討論。他們普遍預期黑棋會選擇以下幾種下法：

**選項 A：右下角掛角**

這是最「正常」的選擇。黑棋可以：
- 搶佔最後的大場（右下角）
- 保持局面平衡
- 遵循「金角銀邊草肚皮」的傳統價值觀

**選項 B：上邊圍空**

黑棋也可以在上邊拆二或拆三，鞏固自己的勢力範圍。這樣可以：
- 將上邊的潛力轉化為實地
- 限制白棋的發展空間

**選項 C：中央分投**

一些棋手認為黑棋可能會在中央下一手，制約白棋的右邊外勢。這雖然不是最常見的選擇，但在戰略上也說得通。

### 沒有人預料到的選擇

然而，AlphaGo 選擇了一個幾乎沒有人想到的位置：

**E5（五路肩衝）**

這一手落在了棋盤右半部、靠近中央的位置，是對白棋右邊外勢的一步「肩衝」。

---

## 第 37 手：五路肩衝

### 這步棋在哪裏？

| | A | B | C | D | E | F | G | H | J | K | L | M | N | O | P | Q | R | S | T | |
|---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---|
| **19** | | | | | | | | | | | | | | | | | | | | |
| **18** | | | | | | | | | | | | | | | | | | | | |
| **17** | | | | ○ | | | | | | | | | | | | ● | | | | |
| **16** | | | | + | | | | | | + | | | | | | + | | | | |
| **15** | | | | | | | | | | **37** | | | | | | ● | | | | 第 37 手 |
| **14** | | | | | | | | | | | | | | | ○ | | | | | |
| **13** | | | | | | | | | | | | | | | | | | | | |
| **12** | | | | | | | | | | | | | | | | | | | | |

第 37 手下在了 **K15**（或稱 J5，坐標系統因來源而異）位置。

### 甚麼是「肩衝」？

「肩衝」是圍棋中的一個手筋，指的是斜向靠近對方棋子的下法。它的特點是：

- **不直接接觸**：與對方棋子保持一步距離
- **破壞結構**：打亂對方的預期發展
- **難以應對**：不管對方如何應對，都會產生某種代價

傳統上，肩衝通常下在三路或四路。**五路肩衝**極為罕見，因為：

1. **位置太高**：五路靠近中央，傳統認為效率較低
2. **容易被攻擊**：孤立的棋子容易成為對方攻擊目標
3. **價值不明確**：不像邊角那樣有明確的實地價值

---

## 專家即時反應

### 解說室的震驚

第 37 手落下的瞬間，解說室陷入了短暫的沉默。

**韓國解說（金成龍九段）**：

> 「這...這是甚麼？這步棋下在五路？我不理解。這一定是失誤吧？」

**中國解說（古力九段）**：

> 「我看不懂這步棋。如果是我的學生這樣下，我會狠狠批評他。」

**美國解說（Michael Redmond 九段）**：

> 「Very unusual move. I don't think any human would play this.」
>
> （非常不尋常的一手。我不認為有人類會這樣下。）

### 職業棋手的實時評論

在各種直播平台上，職業棋手紛紛發表評論：

**柯潔**（當時世界排名第一）：

> 「我無法理解這步棋的意圖。如果 AlphaGo 贏了，我會認真研究。」

**朴廷桓**（韓國頂尖棋手）：

> 「這步棋太奇怪了。是不是程式出了問題？」

**芈昱廷**（中國世界冠軍）：

> 「五路肩衝？從來沒見過這種下法。」

### 「萬分之一的機率」

賽後，DeepMind 團隊透露了一個驚人的數據：

> 「根據我們的分析，如果一位職業棋手面對同樣的局面，選擇第 37 手這個位置的機率大約是 **萬分之一**。」

換句話說，在人類的圍棋知識體系中，這步棋幾乎是「不存在」的選項。

---

## AI 視角的解讀

### Policy Network 的機率分佈

讓我們看看 AlphaGo 的 Policy Network 如何評估這個局面：

<PolicyHeatmap initialPosition="move37" size={450} showTopN={5} />

上圖展示了 AlphaGo 對各個位置的落子機率評估。

關鍵觀察：
- **第 37 手的位置**：機率約 8%，並非最高
- **傳統選點**（如右下角）：機率約 12%
- **其他候選位置**：分散在不同區域

有趣的是，第 37 手在 Policy Network 的評估中**並非機率最高的選擇**。那為甚麼 AlphaGo 選擇了它？

### MCTS 的深度評估

答案在於 **蒙地卡羅樹搜索（MCTS）**。

Policy Network 只提供「直覺」，真正的決策來自 MCTS 的深度模擬。AlphaGo 在做出決定前，會模擬數千種可能的未來走向。

對於第 37 手，MCTS 的評估過程如下：

```
位置 K15（第 37 手）:
├── 模擬 1: 黑勝（+0.3）
├── 模擬 2: 黑勝（+0.5）
├── 模擬 3: 黑勝（+0.2）
├── ...
└── 平均勝率: 58%

位置 R3（右下角掛角）:
├── 模擬 1: 黑勝（+0.1）
├── 模擬 2: 白勝（-0.2）
├── 模擬 3: 黑勝（+0.2）
├── ...
└── 平均勝率: 52%
```

雖然右下角的「直覺機率」更高，但經過深度模擬後，第 37 手的**預期勝率更高**。

### Value Network 的全局評估

Value Network 從全局角度評估了第 37 手的價值：

**下第 37 手前的勝率**：約 52%（黑棋略優）

**下第 37 手後的勝率**：約 58%（黑棋明顯優勢）

這意味着，第 37 手讓 AlphaGo 的預期勝率提升了 **6 個百分點**。

這個提升幅度在圍棋中是相當顯著的。通常，一步好棋能帶來 2-3% 的勝率提升就已經很好了。

---

## 棋理分析：為甚麼是五路肩衝？

### 從局部看

表面上，第 37 手似乎效率很低：

- **位置太高**：五路比四路或三路更靠近中央
- **沒有實地**：不像邊角那樣能直接圍取實地
- **容易被攻擊**：孤立的棋子可能被白棋攻擊

但如果我們仔細分析，這步棋有幾個微妙的好處：

1. **破壞白棋的外勢**：白棋原本計劃在右邊發展，第 37 手打亂了這個計劃
2. **建立自己的影響力**：這步棋雖然不圍實地，但在中央建立了存在感
3. **增加變化**：創造了複雜的局面，有利於計算能力更強的一方

### 從全局看

這步棋的真正價值需要從全局角度來理解：

**厚勢與實地的權衡**

傳統圍棋理論認為「金角銀邊草肚皮」——角最有價值，中央最沒價值。但第 37 手挑戰了這個觀念。

AlphaGo 的評估顯示：在這個特定局面下，**中央的影響力比邊角的實地更有價值**。

這是因為：
- 黑棋已經有足夠的實地基礎
- 白棋的右邊外勢如果發展起來會很強大
- 制約白棋比擴張自己更重要

**「先手」的價值**

第 37 手還有一個被低估的好處：它保持了「先手」。

在圍棋中，「先手」意味着掌握主動權。第 37 手下完後，白棋不得不應對，這讓黑棋可以繼續主導局面走向。

如果黑棋選擇「正常」的右下角掛角，雙方可能會在角部進行定式，然後局面趨於平衡。但第 37 手打破了這種平衡，讓局面充滿不確定性——而這正是 AlphaGo 所擅長的。

### 李世乭的應對困境

第 37 手之後，李世乭思考了很長時間。他面臨的困境是：

**如果直接應對（例如跳或飛）**：
- 等於承認第 37 手的價值
- 讓黑棋達到了破壞白棋外勢的目的

**如果不理會**：
- 黑棋可能會進一步發展中央
- 白棋的右邊外勢難以成為實地

最終，李世乭選擇了應對。但無論他選擇甚麼，第 37 手已經達到了它的目的。

---

## 後續發展：從第 37 手到勝利

### 中盤的演變

第 37 手之後，對局進入了複雜的中盤戰鬥。

**關鍵進展**：

- **手數 40-50**：雙方在右邊進行了激烈的接觸戰
- **手數 50-70**：AlphaGo 利用第 37 手建立的影響力，在中央取得優勢
- **手數 70-100**：黑棋逐漸將優勢轉化為實地

到了第 100 手左右，AlphaGo 的領先已經相當明顯。李世乭雖然努力反擊，但無法扭轉局勢。

### 最終結果

**AlphaGo 中盤勝**

這盤棋的勝利，第 37 手居功至偉。賽後分析顯示，如果沒有第 37 手，局面會更加接近，白棋甚至可能取得優勢。

---

## 對圍棋理論的影響

### 新定式的誕生

第 37 手引發了圍棋界對「肩衝」這個手筋的重新思考。

**傳統觀點**：
- 肩衝應該下在三路或四路
- 五路肩衝效率太低
- 孤立的棋子容易被攻擊

**AlphaGo 之後**：
- 五路肩衝在特定局面下是最佳選擇
- 位置的「高低」不如「效果」重要
- 需要從全局角度評估每一步棋的價值

### 人類棋手的學習

第 37 手之後，許多職業棋手開始嘗試類似的下法：

**柯潔**在 2017 年的幾盤對局中使用了五路肩衝，並取得成功：

> 「AlphaGo 教會我，很多我們認為『不好』的棋，其實只是我們不理解。」

**朴廷桓**也在自己的對局中借鑒了這種思維方式：

> 「重要的不是記住第 37 手這個具體的位置，而是學會用新的眼光看待棋盤。」

### 圍棋 AI 訓練的啟示

第 37 手對圍棋 AI 的研究也有深遠影響：

**對 Policy Network 的反思**：

為甚麼 Policy Network 給第 37 手的機率較低？因為它是從人類棋譜中學習的，而人類幾乎不會下這種棋。

這說明：**僅靠監督學習（從人類學習）是不夠的**。AI 需要自我探索，才能發現人類未知的好棋。

這也是後來 **AlphaGo Zero** 採用純自我對弈訓練的原因之一。

**對 MCTS 的肯定**：

第 37 手證明了 MCTS 深度搜索的價值。即使直覺（Policy Network）不看好一步棋，深度分析也能發現它的潛在價值。

這個洞見後來被應用到許多其他領域。

---

## 技術細節：重現第 37 手的決策過程

### Policy Network 的輸入特徵

在第 36 手後，Policy Network 的輸入包括：

| 特徵平面 | 描述 |
|----------|------|
| 1-8 | 黑棋位置（過去 8 步） |
| 9-16 | 白棋位置（過去 8 步） |
| 17 | 當前該誰下 |
| 18-48 | 其他特徵（氣數、叫吃等） |

總計 **48 個 19x19 的特徵平面**，構成輸入張量。

### Policy Network 的輸出

Policy Network 輸出一個 **19x19 = 361** 維的機率分佈。

對於第 37 手的局面：

```python
# 前 5 名候選位置（簡化示意）
{
    "R3": 0.12,   # 右下角掛角
    "Q17": 0.10,  # 右上角
    "C10": 0.09,  # 左邊大場
    "K15": 0.08,  # 第 37 手的位置
    "D16": 0.07,  # 左上角
    # ... 其他 356 個位置
}
```

### MCTS 的探索過程

AlphaGo 使用 PUCT 公式來平衡探索與利用：

```
U(s,a) = Q(s,a) + c_puct × P(s,a) × sqrt(sum_b N(s,b)) / (1 + N(s,a))
```

其中：
- `Q(s,a)`：位置 a 的平均價值
- `P(s,a)`：Policy Network 給出的機率
- `N(s,a)`：該位置被探索的次數
- `c_puct`：探索常數

對於第 37 手，雖然初始機率 P 較低，但經過多次模擬後，Q 值不斷提高，最終超過了其他候選位置。

### 模擬次數的影響

DeepMind 團隊後來分析，第 37 手的「發現」需要足夠的模擬次數：

| 模擬次數 | 最佳選擇 |
|----------|---------|
| 100 | R3（右下角） |
| 1,000 | Q17（右上角） |
| 10,000 | K15（第 37 手） |
| 100,000 | K15（更確定） |

這說明：**深度搜索能夠發現淺層搜索無法找到的好棋**。

---

## 哲學思考：人類與 AI 的認知差異

### 為甚麼人類想不到第 37 手？

這是一個深刻的問題。可能的原因包括：

**1. 經驗的局限**

人類棋手的知識來自學習前人的棋譜。如果前人從來沒有下過某種棋，我們就不會去考慮它。

**2. 直覺的偏見**

人類的直覺是有用的，但也是有局限的。我們的直覺會讓我們「看不見」某些選項。

**3. 計算能力的差異**

第 37 手的價值需要經過深度計算才能發現。人類的計算能力有限，無法像 AI 那樣模擬數千種可能。

### 機器的「直覺」是甚麼？

AlphaGo 有「直覺」嗎？

從某種意義上說，Policy Network 就是 AlphaGo 的「直覺」——它可以在毫秒內評估每個位置的潛力。

但這種「直覺」與人類的直覺不同：
- **人類的直覺**：來自經驗和模式識別
- **AI 的直覺**：來自大量數據的統計學習

有趣的是，第 37 手證明了：**AI 的「直覺」可以被 MCTS 修正**。這意味着 AI 能夠「反思」自己的直覺，找到更好的選擇。

### 人類能從 AI 學到甚麼？

第 37 手給人類棋手的最大啟示可能是：

> **不要讓經驗成為枷鎖**

很多「不好」的棋，可能只是我們不理解。打開心態，願意嘗試非傳統的下法，可能會發現新的可能性。

這個啟示不只適用於圍棋，也適用於人生的許多領域。

---

## 動畫對應

本文涉及的核心概念與動畫編號：

| 編號 | 概念 | 物理/數學對應 |
|------|------|--------------|
| 🎬 C3 | 傳統棋理的價值判斷 | 啟發式函數 |
| 🎬 C5 | 肩衝的幾何特性 | 空間關係 |
| 🎬 C7 | 專家直覺與 AI 評估的差距 | 預測誤差 |
| 🎬 C9 | Policy Network 的輸出分佈 | Softmax 機率 |
| 🎬 C11 | MCTS 如何修正 Policy Network | 貝氏更新 |
| 🎬 C13 | Value Network 的增量評估 | 價值函數 |
| 🎬 C15 | 全局價值函數的計算 | 積分近似 |
| 🎬 C17 | 博弈論中的強制選擇 | 優勢策略 |
| 🎬 C19 | 一步棋改變整盤棋的走向 | 分岔點 |
| 🎬 C21 | AI 如何拓展人類的認知邊界 | 搜索空間擴展 |
| 🎬 C23 | 特徵工程在 AI 圍棋中的重要性 | 表示學習 |
| 🎬 C25 | PUCT 公式如何發現非直覺的好棋 | 探索-利用權衡 |
| 🎬 C27 | 認知偏見與 AI 的超越 | 無偏估計 |

---

## 延伸閱讀

- **上一篇**：[關鍵對局回顧](../key-matches) — 樊麾、李世乭、柯潔的完整對局歷史
- **下一篇**：[圍棋為甚麼難？](../why-go-is-hard) — 理解圍棋的計算複雜度
- **技術細節**：[Policy Network 詳解](../policy-network) — 深入理解直覺網絡
- **進階閱讀**：[PUCT 公式詳解](../puct-formula) — 探索與利用的數學

---

## 互動探索

### Policy Network 機率分佈

使用下方的互動視覺化，探索不同局面下 Policy Network 的輸出：

<PolicyHeatmap initialPosition="move37" size={450} showTopN={5} interactive={true} />

嘗試切換不同的預設局面，觀察 AI 如何評估各個位置的落子機率。

---

## 參考資料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. DeepMind Blog: "AlphaGo: The story so far"
3. 《AlphaGo》紀錄片 (2017)，導演 Greg Kohs。
4. 李世乭 vs AlphaGo 第二盤官方棋譜
5. Go4Go.net 專業棋譜分析
6. 韓國棋院賽後技術報告
