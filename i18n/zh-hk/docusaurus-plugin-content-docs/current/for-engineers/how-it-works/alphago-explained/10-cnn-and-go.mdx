---
sidebar_position: 11
title: CNN 與圍棋嘅結合
description: 深入探討卷積神經網絡點解特別適合圍棋，由感受野到批次正規化嘅完整解析
---

# CNN 與圍棋嘅結合

當 DeepMind 揀用**卷積神經網絡（CNN）**嚟處理圍棋嘅時候，呢個係一個天才嘅設計決策。

CNN 本身係為圖像識別設計嘅。點解佢都適合圍棋？呢篇文章會深入探討 CNN 嘅運作原理，以及佢同圍棋嘅完美契合。

---

## 點解 CNN 適合棋盤？

### 棋盤係「圖像」

由某個角度睇，19×19 嘅圍棋棋盤就係一張**圖像**：

| 圖像 | 圍棋棋盤 |
|------|---------|
| 像素 | 交叉點 |
| RGB 通道 | 特徵平面（黑、白、空...） |
| 224×224 | 19×19 |
| 辨識貓狗 | 判斷好棋壞棋 |

呢個類比並唔係偶然。CNN 擅長圖像嘅原因，都令佢擅長棋盤。

### 三個關鍵特性

CNN 有三個特性，令佢特別適合棋盤類型嘅資料：

#### 1. 局部連接（Local Connectivity）

CNN 嘅卷積核只睇局部區域，呢個同圍棋嘅特性完美匹配：

**圖像識別 vs 圍棋局部特徵比較：**

| 圖像識別 | 圍棋 |
|----------|------|
| 貓耳朵係局部特徵 | 「眼」係局部棋形 |
| 唔使睇成張圖 | 唔使睇成個棋盤 |

**3×3 區域示例（眼位）：**

|   |   |   |
|:-:|:-:|:-:|
| ○ | ● | ○ |
| ● | · | ● |
| ○ | ● | ○ |

好多圍棋概念都係「局部」嘅：
- **眼**：2×2 或 3×3 嘅區域
- **叫吃**：3×3 嘅區域
- **接、斷**：2×2 嘅區域

#### 2. 權重共享（Weight Sharing）

同一個卷積核會掃描成個棋盤，呢個意味住：

> **棋盤左上角嘅「眼」同右下角嘅「眼」，用同樣嘅方式識別**

呢個係合理嘅——圍棋規則唔會因位置而異（邊角例外，但可以用邊角特徵平面處理）。

權重共享都大幅減少咗參數量：

| 方法 | 參數量 |
|------|--------|
| 全連接網絡 | 361 × 361 × 通道數 = 數千萬 |
| CNN | 3 × 3 × 通道數 × 濾波器數 = 數百萬 |

#### 3. 平移等變性（Translation Equivariance）

如果輸入平移，CNN 嘅輸出都會相應平移：

```
輸入:                    輸出 (高機率區域):
  A B C D E               A B C D E
1 . . . . .            1  . . . . .
2 . ● . . .   →        2  . * . . .
3 . . . . .            3  . . . . .

輸入平移後:              輸出都平移:
  A B C D E               A B C D E
1 . . . . .            1  . . . . .
2 . . . . .   →        2  . . . . .
3 . . ● . .            3  . . * . .
```

呢個對圍棋好重要：相同嘅局部棋形，無論出現喺棋盤邊度，應該有類似嘅評估。

---

## 卷積運算

### 基本原理

卷積運算係 CNN 嘅核心。佢係一種「滑動窗口」操作：

```
輸入 (5×5):              卷積核 (3×3):         輸出 (5×5, padding=same):
┌───────────────┐       ┌─────────┐           ┌───────────────┐
│ 1 0 1 0 0     │       │ 1 0 1   │           │ 2 1 3 1 2     │
│ 0 1 1 1 0     │   *   │ 0 1 0   │    =      │ 1 4 3 3 1     │
│ 1 1 1 1 1     │       │ 1 0 1   │           │ 3 3 5 3 3     │
│ 0 0 1 1 0     │       └─────────┘           │ 1 3 3 4 1     │
│ 0 1 0 0 1     │                             │ 2 1 3 1 2     │
└───────────────┘                             └───────────────┘
```

計算過程（以中心點為例）：

```
輸出[2,2] = 1×1 + 1×0 + 1×1 +
            1×0 + 1×1 + 1×0 +
            1×1 + 1×0 + 1×1
          = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1
          = 5
```

### 多通道卷積

當輸入有多個通道（好似 48 個特徵平面）嘅時候，卷積核都變成 3D：

```
輸入: 19×19×48          卷積核: 3×3×48          輸出: 19×19×1
    ┌─────┐               ┌───┐                  ┌─────┐
   ╱     ╱│              ╱   ╱│                 │     │
  ╱     ╱ │   卷積      ╱   ╱ │                 │     │
 ╱     ╱  │   →        ╱   ╱  │    →            │     │
┌─────┐   │           ┌───┐   │                 └─────┘
│     │  ╱            │   │  ╱
│     │ ╱             │   │╱
└─────┘╱              └───┘
48 層                  48 層                    1 層
```

每個卷積核會跨所有輸入通道計算，產生一個輸出通道。

### 多個濾波器

AlphaGo 使用 192 個濾波器，每個濾波器學習唔同嘅特徵：

```
輸入: 19×19×48

      ┌─────┐
     ╱     ╱│
    ╱     ╱ │     192 個 3×3×48 卷積核
   ╱     ╱  │     ────────────────────►
  ┌─────┐   │
  │     │  ╱
  │     │ ╱
  └─────┘╱

輸出: 19×19×192

      ┌─────┐
     ╱     ╱│
    ╱     ╱ │
   ╱     ╱  │
  ┌─────┐   │
  │     │  ╱
  │     │ ╱
  └─────┘╱
```

每個濾波器可能學到唔同嘅棋形：
- 濾波器 1：眼位檢測
- 濾波器 2：斷點檢測
- 濾波器 3：連接檢測
- ...
- 濾波器 192：某種複雜模式

---

## 感受野

### 咩係感受野？

**感受野（Receptive Field）**係指輸出嘅一個位置，受到輸入嘅邊啲位置影響。

#### 單層卷積

使用 3×3 卷積核嘅時候，輸出嘅每個位置只受輸入 3×3 區域影響：

```
輸入:                   輸出:
  ┌─────────────┐       ┌───────────┐
  │ . . . . .   │       │ . . . .   │
  │ . ● ● ● .   │  →    │ . ● . .   │
  │ . ● ● ● .   │       │ . . . .   │
  │ . ● ● ● .   │       │ . . . .   │
  │ . . . . .   │       └───────────┘
  └─────────────┘
     感受野 3×3
```

#### 多層卷積

堆疊多層卷積之後，感受野會擴大：

| 層數 | 感受野 | 計算 |
|------|--------|------|
| 1 | 3×3 | 3 |
| 2 | 5×5 | 3 + (3-1) = 5 |
| 3 | 7×7 | 5 + (3-1) = 7 |
| ... | ... | ... |
| 12 | 25×25 | 3 + 11×2 = 25 |

AlphaGo 嘅 12 層卷積畀出 **25×25 嘅感受野**，已經超過 19×19 嘅棋盤！

呢個意味住：
- **輸出嘅每個位置都可以「睇到」成個棋盤**
- 但「睇」嘅方式唔同：近處細節清楚，遠處概括
- 呢個同人類棋手嘅思維方式類似

### 感受野與圍棋

感受野嘅概念解釋咗點解 AlphaGo 能夠處理「全局」問題：

```
局部問題（3×3 感受野）:     全局問題（25×25 感受野）:
- 呢度有眼咩？              - 呢塊棋有眼位咩？
- 可以叫吃咩？              - 征子有利咩？
- 可以接上咩？              - 全局形勢點？
```

淺層處理局部特徵，深層處理全局特徵。

---

## 局部 vs 全局特徵

### CNN 嘅層次結構

CNN 自然形成層次結構：

```
輸入層:        黑子、白子、空點
   ↓
淺層 (1-3):    眼、接、斷、叫吃
   ↓
中層 (4-8):    棋形、活棋、死棋
   ↓
深層 (9-12):   勢力、厚薄、大場
   ↓
輸出層:        落子機率 / 勝率
```

呢個同人類學習圍棋嘅過程驚人地相似：
1. 先學規則（邊度有子）
2. 再學戰術（點樣食子）
3. 然後學棋形（咩係好形）
4. 最後學大局觀（全局判斷）

### 視覺化隱藏層

研究人員發現，CNN 嘅隱藏層確實學到咗有意義嘅特徵：

#### 淺層濾波器

**濾波器 A（眼位檢測）：**

|   |   |   |
|:-:|:-:|:-:|
| + | - | + |
| - | + | - |
| + | - | + |

**濾波器 B（叫吃檢測）：**

|   |   |   |
|:-:|:-:|:-:|
| + | + | + |
| + | - | - |
| + | + | + |

#### 深層濾波器

深層嘅濾波器更加抽象，難以直接解釋，但佢哋捕捉咗複雜嘅棋形模式。

---

## 激活函數嘅選擇

### ReLU：簡單而有效

AlphaGo 喺所有卷積層後使用 **ReLU（Rectified Linear Unit）**：

```python
def relu(x):
    return max(0, x)
```

**ReLU 函數特性：**

- 當輸入 x ≤ 0 嗰陣，輸出為 0（水平線）
- 當輸入 x > 0 嗰陣，輸出等於 x（斜率為 1 嘅直線）
- 圖形呈「折線」狀：喺原點左邊為零，右邊為線性遞增

### 點解唔用其他函數？

| 激活函數 | 公式 | 優點 | 缺點 |
|----------|------|------|------|
| ReLU | max(0, x) | 計算快、梯度好 | 負值死亡 |
| Sigmoid | 1/(1+e^-x) | 輸出有界 | 梯度消失 |
| Tanh | (e^x-e^-x)/(e^x+e^-x) | 零中心 | 梯度消失 |
| LeakyReLU | max(0.01x, x) | 解決死亡問題 | 多一個超參數 |

對於深度網絡，ReLU 嘅優勢明顯：
1. **計算簡單**：只係比較同取最大值
2. **梯度唔會消失**：正區間梯度恆為 1
3. **稀疏激活**：好多神經元輸出 0，提高效率

### ReLU 喺圍棋入面嘅含義

ReLU 嘅稀疏性喺圍棋入面有有趣嘅解釋：

```
某個濾波器檢測「斷點」:
- 有斷點 → 正值輸出（激活）
- 冇斷點 → 零輸出（唔激活）

呢個就好似棋手只關注「有事」嘅位置
```

---

## 批次正規化

### 咩係批次正規化？

**批次正規化（Batch Normalization）**係一種技術，令每層嘅輸出維持穩定嘅分佈：

```python
def batch_norm(x, gamma, beta):
    # 計算批次嘅均值同標準差
    mean = x.mean(axis=0)
    std = x.std(axis=0)

    # 正規化
    x_norm = (x - mean) / (std + 1e-8)

    # 縮放同平移
    return gamma * x_norm + beta
```

### 點解需要？

#### 內部協變量偏移

當網絡訓練嘅時候，每層嘅輸入分佈會隨住前面層嘅權重變化而改變。呢個叫做「內部協變量偏移」：

```
第一層權重更新 → 第一層輸出分佈改變
                    ↓
               第二層輸入分佈改變 → 第二層需要重新適應
                                        ↓
                                   ... (傳遞落去)
```

批次正規化透過強制每層輸入有固定嘅分佈（均值 0，標準差 1），嚟穩定訓練。

### 喺 AlphaGo 入面嘅應用

AlphaGo 喺每個卷積層後、激活函數前使用批次正規化：

```
Conv → BatchNorm → ReLU → Conv → BatchNorm → ReLU → ...
```

好處：
1. **訓練更快**：可以使用更大嘅學習率
2. **更穩定**：減少對初始化嘅敏感性
3. **正則化效果**：有輕微嘅 dropout 效果

### 推理時嘅處理

訓練時，使用當前批次嘅統計量。推理時，使用成個訓練集嘅統計量（移動平均）：

```python
# 訓練時
mean = batch_mean
var = batch_var

# 推理時
mean = running_mean  # 訓練期間累積嘅均值
var = running_var    # 訓練期間累積嘅方差
```

---

## AlphaGo 嘅具體配置

### 完整架構

```
輸入: 19×19×48

第 1 層:
  Conv2D(5×5, 192 filters, padding='same')
  BatchNorm
  ReLU
  輸出: 19×19×192

第 2-12 層 (共 11 層):
  Conv2D(3×3, 192 filters, padding='same')
  BatchNorm
  ReLU
  輸出: 19×19×192

輸出層 (Policy):
  Conv2D(1×1, 1 filter)
  Flatten
  Softmax
  輸出: 361 維機率

輸出層 (Value):
  Conv2D(1×1, 1 filter)
  Flatten
  Dense(256)
  ReLU
  Dense(1)
  Tanh
  輸出: 單一數值
```

### 參數配置

| 參數 | 數值 | 說明 |
|------|------|------|
| 輸入通道 | 48 | 特徵平面數 |
| 濾波器數 | 192 | 每層嘅通道數 |
| 卷積核大小 | 3×3（第一層 5×5） | 感受野 |
| 層數 | 13（含輸出層） | 深度 |
| 激活函數 | ReLU | 非線性 |
| 正規化 | BatchNorm | 穩定訓練 |

### PyTorch 實現

```python
import torch
import torch.nn as nn

class AlphaGoCNN(nn.Module):
    def __init__(self, input_channels=48, num_filters=192, num_layers=12):
        super().__init__()

        # 第一層（5×5 卷積）
        self.conv1 = nn.Sequential(
            nn.Conv2d(input_channels, num_filters, kernel_size=5, padding=2),
            nn.BatchNorm2d(num_filters),
            nn.ReLU(inplace=True)
        )

        # 中間層（3×3 卷積）
        self.conv_layers = nn.Sequential(*[
            nn.Sequential(
                nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),
                nn.BatchNorm2d(num_filters),
                nn.ReLU(inplace=True)
            )
            for _ in range(num_layers - 1)
        ])

        # Policy 輸出頭
        self.policy_head = nn.Sequential(
            nn.Conv2d(num_filters, 1, kernel_size=1),
            nn.Flatten(),
            nn.Softmax(dim=1)
        )

        # Value 輸出頭
        self.value_head = nn.Sequential(
            nn.Conv2d(num_filters, 1, kernel_size=1),
            nn.Flatten(),
            nn.Linear(361, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 1),
            nn.Tanh()
        )

    def forward(self, x):
        # 共享特徵提取
        x = self.conv1(x)
        x = self.conv_layers(x)

        # 分頭輸出
        policy = self.policy_head(x)
        value = self.value_head(x)

        return policy, value
```

---

## 同其他架構嘅比較

### 全連接網絡

如果用全連接網絡處理圍棋：

| 特性 | 全連接 | CNN |
|------|--------|-----|
| 參數量 | 極大（數億） | 較細（數百萬） |
| 位置不變性 | 冇 | 有 |
| 局部特徵 | 難學 | 自然捕捉 |
| 訓練效率 | 低 | 高 |

全連接網絡冇辦法利用棋盤嘅空間結構，效率極低。

### 循環神經網絡（RNN）

RNN 適合序列資料（好似棋局歷史），但：

| 特性 | RNN | CNN |
|------|-----|-----|
| 空間處理 | 弱 | 強 |
| 序列處理 | 強 | 弱（需要歷史平面） |
| 並行化 | 難 | 易 |
| 長距離依賴 | 需要 LSTM | 深層即可 |

AlphaGo 揀咗 CNN + 歷史平面，而唔係 CNN + RNN。

### 殘差網絡（ResNet）

AlphaGo Zero 升級為 ResNet：

```
普通 CNN:                ResNet:
  x                        x
  ↓                        ↓
 Conv                     Conv
  ↓                        ↓
 ReLU                    ReLU
  ↓                        ↓
 Conv                     Conv
  ↓                        ↓
  y                      y + x  ← 殘差連接
```

殘差連接令梯度更容易流動，可以訓練更深嘅網絡（40 層 vs 12 層）。

詳見 [雙頭網絡與殘差網絡](../dual-head-resnet)。

---

## 視覺化理解

### 卷積過程

**輸入棋盤（簡化為 5×5）：**

|   | A | B | C | D | E |
|:-:|:-:|:-:|:-:|:-:|:-:|
| 1 | · | · | · | · | · |
| 2 | · | ● | · | · | · |
| 3 | · | · | ○ | · | · |
| 4 | · | · | · | ● | · |
| 5 | · | · | · | · | · |

**濾波器（3×3，檢測「十字形」）：**

|   |   |   |
|:-:|:-:|:-:|
| 0 | 1 | 0 |
| 1 | 1 | 1 |
| 0 | 1 | 0 |

**卷積輸出（中心有強響應，十字形匹配）：**

|   | A | B | C | D | E |
|:-:|:-:|:-:|:-:|:-:|:-:|
| 1 | 0 | 0 | 0 | 0 | 0 |
| 2 | 0 | 0 | 0 | 0 | 0 |
| 3 | 0 | 0 | **1** | 0 | 0 |
| 4 | 0 | 0 | 0 | 0 | 0 |
| 5 | 0 | 0 | 0 | 0 | 0 |

### 多層特徵

**第 1 層輸出（192 個通道入面嘅 4 個）：**

**通道 1（眼位）：**

|   |   |   |   |
|:-:|:-:|:-:|:-:|
| 0 | 0 | 0 | 0 |
| 0 | 0.9 | 0 | 0 |
| 0 | 0 | 0 | 0 |
| 0 | 0 | 0 | 0 |

**通道 2（邊線）：**

|   |   |   |   |
|:-:|:-:|:-:|:-:|
| 0.8 | 0 | 0 | 0 |
| 0.8 | 0 | 0 | 0 |
| 0.8 | 0 | 0 | 0 |
| 0.8 | 0 | 0 | 0 |

**通道 3（斷點）：**

|   |   |   |   |
|:-:|:-:|:-:|:-:|
| 0 | 0 | 0 | 0 |
| 0 | 0 | 0.7 | 0 |
| 0 | 0 | 0 | 0 |
| 0 | 0 | 0 | 0 |

**通道 4（連接）：**

|   |   |   |   |
|:-:|:-:|:-:|:-:|
| 0 | 0 | 0 | 0 |
| 0 | 0.5 | 0 | 0 |
| 0 | 0.8 | 0 | 0 |
| 0 | 0.5 | 0 | 0 |

呢啲特徵喺更深層會被組合成更複雜嘅概念...

---

## 動畫對應

本文涉及嘅核心概念與動畫編號：

| 編號 | 概念 | 物理/數學對應 |
|------|------|--------------|
| 🎬 D9 | 卷積運算 | 濾波器響應 |
| 🎬 D10 | 感受野 | 局部→全局 |
| 🎬 D11 | 批次正規化 | 分佈穩定 |
| 🎬 D1 | 多通道輸入 | 張量運算 |

---

## 延伸閱讀

- **上一篇**：[輸入特徵設計](../input-features) — 48 個特徵平面詳解
- **下一篇**：[監督學習階段](../supervised-learning) — 點樣由人類棋譜學習
- **進階主題**：[雙頭網絡與殘差網絡](../dual-head-resnet) — AlphaGo Zero 嘅網絡升級

---

## 關鍵要點

1. **CNN 天然適合棋盤**：局部連接、權重共享、平移等變性
2. **卷積提取局部特徵**：3×3 區域嘅模式識別
3. **深層網絡獲得全局視野**：12 層 → 25×25 感受野
4. **ReLU 快速有效**：簡單嘅非線性激活
5. **BatchNorm 穩定訓練**：標準化每層輸出

CNN 令 AlphaGo 能夠「睇」棋盤——就好似人類用眼睛睇圖像一樣自然。

---

## 參考資料

1. LeCun, Y., Bengio, Y., & Hinton, G. (2015). "Deep learning." *Nature*, 521, 436-444.
2. He, K., et al. (2015). "Deep Residual Learning for Image Recognition." *CVPR*.
3. Ioffe, S., & Szegedy, C. (2015). "Batch Normalization: Accelerating Deep Network Training." *ICML*.
4. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). "ImageNet Classification with Deep Convolutional Neural Networks." *NeurIPS*.
