---
sidebar_position: 2
title: AlphaGo 嘅誕生
description: 從 DeepMind 創立到 Google 收購，AlphaGo 點樣從一個瘋狂嘅想法變成改變世界嘅 AI
---

# AlphaGo 嘅誕生

2016 年 3 月，當 AlphaGo 以 4:1 擊敗李世乭嗰陣，全世界都喺度問：呢個改變人工智能歷史嘅程式，究竟係點樣誕生嘅？

答案要從一位西洋棋神童嘅夢想講起。

---

## DeepMind 嘅創立

### Demis Hassabis：從神童到 AI 先驅

**Demis Hassabis** 係 DeepMind 嘅共同創辦人兼行政總裁。佢嘅人生經歷，幾乎就係為創造 AlphaGo 而準備嘅。

#### 西洋棋神童

1975 年出生於倫敦嘅 Hassabis，喺 4 歲嗰陣學識下西洋棋，13 歲嗰陣達到西洋棋大師等級（Elo 2300+），係英國史上第二年輕達到呢個水平嘅棋手。

呢段經歷令佢深刻理解：
- **棋類遊戲係智能嘅試金石**：下棋需要規劃、直覺、模式識別
- **人類智能嘅本質**：棋手點樣喺龐大嘅可能性中搵到好棋？
- **電腦嘅局限**：1997 年深藍擊敗卡斯帕洛夫靠嘅係暴力搜索，而唔係真正嘅「理解」

#### 遊戲設計師

17 歲嗰陣，Hassabis 加入 Bullfrog Productions（由《上帝也瘋狂》創作者 Peter Molyneux 創立嘅遊戲公司），參與開發咗經典遊戲《乾坤大挪移》（Theme Park）。呢段經歷教識佢：

- **點樣設計複雜系統**：遊戲係模擬現實世界嘅簡化模型
- **玩家行為預測**：AI 需要理解人類嘅決策過程

#### 認知神經科學家

喺劍橋大學取得電腦科學學位之後，Hassabis 喺倫敦大學學院（UCL）取得認知神經科學博士學位。佢嘅研究主題係：**海馬迴點樣令人類進行想像與規劃**。

呢項研究發現：
- 人類嘅記憶與想像使用相同嘅腦區
- 我哋透過「心理時間旅行」嚟規劃未來
- 呢種能力可能係智能嘅核心

呢啲洞見直接影響咗後來 AlphaGo 嘅設計——令 AI 能夠「想像」未來嘅走法，並從中學習。

### 共同創辦人

2010 年，Hassabis 與兩位夥伴共同創立 DeepMind：

| 創辦人 | 背景 | 貢獻 |
|--------|------|------|
| **Demis Hassabis** | 神經科學、遊戲設計 | 願景與策略 |
| **Shane Legg** | 機器學習博士 | AGI 理論基礎 |
| **Mustafa Suleyman** | 社會企業家 | 商業與應用 |

### 「解決智能，用智能解決一切」

DeepMind 嘅使命宣言係：

> **"Solve intelligence, and then use that to solve everything else."**
>
> 「解決智能，然後用佢嚟解決所有其他問題。」

呢個唔係一間普通嘅 AI 公司。佢哋嘅目標唔係做產品，而係創造**通用人工智能（AGI）**——一種能夠好似人類咁思考、學習、解決任何問題嘅 AI。

點解要先「解決智能」？因為一旦我哋有咗 AGI，佢就可以幫助我哋解決氣候變化、疾病、能源等人類最大嘅挑戰。

---

## 早期突破：Atari 遊戲

喺挑戰圍棋之前，DeepMind 首先證明咗自己嘅能力——用 AI 玩 Atari 遊戲。

### DQN：學識玩遊戲嘅 AI

2013 年，DeepMind 發表咗 **DQN（Deep Q-Network）** 演算法。呢個 AI 能夠：

1. **淨係睇熒幕像素**——唔畀佢任何遊戲規則
2. **自己學識玩遊戲**——透過嘗試錯誤
3. **達到人類水平**——甚至喺某啲遊戲超越人類

DQN 喺《打磚塊》（Breakout）中學識咗一個人類需要幾個鐘頭先發現到嘅策略：**挖隧道令波跑到磚塊後面，一次過消除一大片**。

呢個證明咗深度學習 + 強化學習嘅組合，能夠發現人類未曾諗過嘅策略。

### 點解從遊戲開始？

Hassabis 揀遊戲作為研究平台，有幾個原因：

1. **環境可控**：遊戲有明確嘅規則同目標
2. **可測量進步**：有客觀嘅分數嚟評估 AI 能力
3. **人類基準**：可以同人類玩家比較
4. **多樣性**：唔同遊戲測試唔同能力

呢套方法論，後來都用喺圍棋上面。

---

## Google 嘅收購

### 5 億美元嘅賭注

2014 年 1 月，Google 以大約 **5 億美元**收購 DeepMind。呢個係當時 AI 領域最大嘅收購案之一。

點解 Google 願意畀咁多錢買一間得 75 人、仲未有產品嘅公司？

答案喺於 **博弈論**：

- **Facebook 都喺度競標**：傳聞 Facebook 出價 4 億美元
- **AI 係未來嘅關鍵技術**：邊個先掌握 AI，邊個就掌握未來
- **DeepMind 係最好嘅團隊**：佢哋證明咗深度強化學習嘅可行性

Google 行政總裁 Larry Page 親自出面，先說服到 Hassabis 揀 Google 而唔係 Facebook。

### 收購條件

Hassabis 喺談判中爭取到幾個關鍵條件：

1. **獨立運營**：DeepMind 保持倫敦總部，獨立研發
2. **學術自由**：可以發表論文，而唔係全部保密
3. **倫理委員會**：成立 AI 倫理審查機制
4. **長期研究**：唔需要短期商業化壓力

呢啲條件令 DeepMind 能夠追求長期、高風險嘅研究——例如用 AI 征服圍棋。

### Google 嘅 AI 戰略

收購 DeepMind 係 Google 「AI 優先」戰略嘅一部分：

| 時間 | 事件 |
|------|------|
| 2011 | 成立 Google Brain |
| 2013 | 收購 DNNresearch（Hinton 團隊） |
| 2014 | 收購 DeepMind |
| 2015 | TensorFlow 開源 |
| 2016 | TPU 發表 |

Google 意識到：搜尋、廣告、翻譯、語音——所有核心業務都會被 AI 重塑。邊個有最好嘅 AI，邊個就係贏家。

---

## 揀圍棋作為目標

### 點解係圍棋？

被 Google 收購之後，DeepMind 有咗更多資源。Hassabis 決定挑戰一個睇落唔可能嘅目標：**用 AI 擊敗人類圍棋冠軍**。

點解揀圍棋，而唔係其他問題？

#### 1. 圍棋係「AI 嘅聖杯」

2016 年之前，專家普遍認為 AI 起碼需要 10-20 年先可以喺圍棋上擊敗人類。圍棋被稱為「AI 最後嘅堡壘」。

原因：
- **搜索空間巨大**：10^170 種可能嘅局面（宇宙原子數只有 10^80）
- **評估困難**：唔似西洋棋有明確嘅棋子價值
- **直覺依賴**：頂尖棋手成日話「呢步棋感覺啱」，但係解釋唔到原因

#### 2. 深藍嘅啟示

1997 年，IBM 嘅深藍（Deep Blue）擊敗咗西洋棋世界冠軍卡斯帕洛夫。但係呢個勝利有爭議：

- 深藍靠嘅係**暴力搜索**（每秒評估 2 億個位置）
- 使用**人類專家設計嘅評估函數**
- 呢個唔係真正嘅「智能」，而係「計算力」

Hassabis 想證明：AI 可以用**學習**而唔係暴力搜索嚟解決問題。

#### 3. 可測量嘅目標

圍棋有國際排名系統（Elo rating）同職業棋手，提供咗客觀嘅衡量標準。如果 AI 能夠擊敗世界冠軍，就係無可爭辯嘅成功。

#### 4. 與神經科學嘅連結

人類棋手嘅直覺——望一眼棋盤就知道邊啲位置重要——正正係 Hassabis 想用 AI 複製嘅能力。圍棋係測試「機器直覺」嘅完美場景。

---

## AlphaGo 團隊

### 核心人物

AlphaGo 嘅成功，來自一支多學科背景嘅團隊：

#### David Silver：首席研究員

**David Silver** 係 AlphaGo 論文嘅第一作者，都係強化學習領域嘅頂尖專家。

- **背景**：劍橋大學數學系畢業，阿爾伯塔大學 RL 博士
- **導師**：Richard Sutton（強化學習教父）
- **專長**：蒙地卡羅樹搜索、時序差分學習

Silver 喺博士論文中就研究過電腦圍棋，但當時嘅技術遠未成熟。加入 DeepMind 之後，佢終於有機會實現呢個夢想。

#### Aja Huang：圍棋專家

**Aja Huang**（黃士傑）係台灣人，業餘六段棋手，都係電腦圍棋領域嘅先驅。

- **背景**：國立台灣師範大學資工博士
- **專長**：電腦圍棋程式設計
- **著名作品**：Erica（早期電腦圍棋程式）

Huang 喺 AlphaGo 團隊中扮演關鍵角色：佢唔單止理解圍棋，都理解 AI。喺同李世乭嘅對局中，佢係實際操作 AlphaGo 嘅人。

#### 其他關鍵成員

| 成員 | 角色 |
|------|------|
| Chris J. Maddison | 蒙地卡羅樹搜索專家 |
| Arthur Guez | 強化學習研究員 |
| Laurent Sifre | 深度學習工程師 |
| George van den Driessche | 分散式系統工程師 |

### 跨領域合作

AlphaGo 嘅成功證明咗**跨領域合作**嘅力量：

- **圍棋專家**提供領域知識
- **機器學習研究員**設計演算法
- **工程師**實現大規模訓練系統
- **神經科學家**提供理論靈感

呢種團隊組成，後來成為 DeepMind 嘅標準模式。

---

## Nature 論文發表

### 秘密嘅驚喜

2016 年 1 月 27 日，DeepMind 喺頂級學術期刊《Nature》發表論文：

> **"Mastering the game of Go with deep neural networks and tree search"**

論文宣布 AlphaGo 已經：
1. 擊敗咗所有其他圍棋程式
2. 以 **5:0** 擊敗咗歐洲冠軍 **樊麾**（職業二段）

呢個消息震驚咗世界。喺論文發表之前，無人知道 DeepMind 喺度研究圍棋。

### 論文嘅核心貢獻

《Nature》論文描述咗 AlphaGo 嘅三大創新：

#### 1. Policy Network（策略網絡）

用深度卷積神經網絡預測人類棋手嘅下一步。訓練資料來自 **3000 萬局** 嘅人類棋譜。

```
準確率：57%（預測人類專家嘅下一步）
```

呢個比之前最好嘅電腦圍棋程式高出 10 個百分點以上。

#### 2. Value Network（價值網絡）

用另一個神經網絡評估當前局面嘅勝率。呢個取代咗傳統嘅隨機模擬（Monte Carlo rollout）。

```
精度：與 15000 次隨機模擬相當，但計算速度快 15000 倍
```

#### 3. 蒙地卡羅樹搜索整合

將兩個神經網絡整合入 MCTS 框架：
- Policy Network 引導搜索方向
- Value Network 評估葉節點

呢個令 AlphaGo 既有「直覺」（神經網絡），又有「推理」（樹搜索）。

### 學術界嘅反應

論文發表之後，學術界反應熱烈：

> 「呢個係人工智能嘅登月時刻。」
> — **Stuart Russell**，UC Berkeley 教授，AI 教科書作者

> 「我原本以為仲要 10 年，估唔到咁快。」
> — **Martin Müller**，電腦圍棋專家

但都有人持懷疑態度：

> 「樊麾只係職業二段，唔係真正嘅頂尖棋手。等 AlphaGo 同 Lee Sedol 落一場先算啦。」

DeepMind 接受咗呢個挑戰。

---

## 挑戰李世乭

### 點解係李世乭？

**李世乭**（Lee Sedol）係韓國棋手，當時被認為係過去十年最強嘅棋手之一：

| 指標 | 數據 |
|------|------|
| 世界冠軍頭銜 | 18 個 |
| 國際賽冠軍 | 32 個 |
| 最高世界排名 | 第 1 |
| 風格 | 「天才」「神算」 |

揀李世乭，DeepMind 係喺度挑戰最強嘅人類對手。

### 1 百萬美元獎金

Google 為呢場比賽提供咗 **100 萬美元** 獎金：

- 如果李世乭贏：獎金歸李世乭
- 如果 AlphaGo 贏：獎金捐畀 UNICEF、STEM 教育等慈善機構

呢個唔單止係一場技術展示，都係全球矚目嘅體育賽事。

### 比賽前嘅預測

比賽前，大部分職業棋手預測李世乭會輕鬆獲勝：

> 「AlphaGo 可能贏一盤，但 5 盤比賽我會 5:0 獲勝。」
> — **李世乭**，賽前訪談

> 「電腦下棋死板，頂尖棋手好容易搵到弱點。」
> — 某位職業九段

但 DeepMind 團隊有唔同嘅睇法。David Silver 後來透露：

> 「我哋喺內部測試中，已經令 AlphaGo 對陣樊麾嗰個版本落咗 500 盤。新版本贏咗 499 盤。」

---

## 2016 年 3 月：改變世界嘅五盤棋

### 第一盤：震驚開始

2016 年 3 月 9 日，首爾四季酒店。

李世乭執黑先行，AlphaGo 執白。經過 3 小時 28 分嘅對弈，AlphaGo 中盤勝出。

呢個係人類頂尖棋手首次正式輸畀 AI。

### 第二盤：神之一手

第二盤誕生咗被稱為「**神之一手**」嘅第 37 手——AlphaGo 喺五路落咗一步肩衝，所有職業棋手都以為係失誤，結果證明係致勝關鍵。

（詳見下一篇：[「神之一手」深度分析](../move-37)）

AlphaGo 再次獲勝。

### 第三盤：3:0

第三盤，李世乭嘗試咗非傳統嘅開局，但 AlphaGo 應對自如。3:0。

全世界開始意識到：呢個唔係偶然，AI 真係超越咗人類。

### 第四盤：人類嘅反擊

第四盤，李世乭落出咗被稱為「**神之一手**」嘅第 78 手——一步精妙嘅挖，令 AlphaGo 出現咗混亂。

AlphaGo 喺之後嘅幾步中落出明顯嘅壞棋，最終認輸。

呢場勝利證明：AI 都有弱點。李世乭搵到咗佢。

### 第五盤：最終比數

第五盤，AlphaGo 恢復正常，以中盤勝結束比賽。

**最終比數：AlphaGo 4:1 李世乭**

---

## 影響與餘波

### 全球關注

呢場比賽嘅影響遠超圍棋界：

- **全球 2 億人** 睇咗直播
- 《紐約時報》、《經濟學人》等主流媒體大篇幅報導
- Google 股價喺比賽期間上升
- 「人工智能」成為當年最熱門嘅科技話題

### 對圍棋界嘅影響

比賽之後，職業棋手嘅態度從「輕視」轉為「敬畏」：

> 「我哋以前以為人類理解圍棋，而家發現我哋只係識少少皮毛。」
> — **柯潔**，中國棋手，當時世界排名第一

好多職業棋手開始用 AI 嚟訓練，圍棋嘅下法都因此改變。

### 對 AI 領域嘅影響

AlphaGo 證明咗幾件事：

1. **深度學習可以解決專家級問題**：唔單止識別貓狗，仲可以落圍棋
2. **強化學習可以超越人類**：透過自我對弈，AI 可以發現人類未知嘅策略
3. **神經網絡 + 搜索係強大嘅組合**：直覺 + 推理 = 更強嘅智能

呢啲洞見後來被應用到：
- **AlphaFold**：蛋白質結構預測（2020 諾貝爾獎級成就）
- **AlphaZero**：通用遊戲 AI
- **MuZero**：唔需要規則嘅學習

---

## 動畫對應

本文涉及嘅核心概念與動畫編號：

| 編號 | 概念 | 物理/數學對應 |
|------|------|--------------|
| E7 | 從零開始 | 自組織 |
| E5 | 自我對弈 | 不動點收斂 |
| F8 | 湧現能力 | 相變 |
| H4 | 策略梯度 | 隨機優化 |

---

## 延伸閱讀

- **下一篇**：[關鍵對局回顧](../key-matches) — 樊麾、李世乭、柯潔嘅完整對局分析
- **技術細節**：[Policy Network 詳解](../policy-network) — AlphaGo 點樣學識落棋
- **動手實作**：[30 分鐘跑起第一個圍棋 AI](../../../hands-on/) — 親自體驗

---

## 參考資料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. 《AlphaGo》紀錄片 (2017)，導演 Greg Kohs。
