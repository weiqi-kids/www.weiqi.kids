---
sidebar_position: 2
title: AlphaGo 的诞生
description: 从 DeepMind 创立到 Google 收购，AlphaGo 如何从一个疯狂的想法变成改变世界的 AI
---

# AlphaGo 的诞生

2016 年 3 月，当 AlphaGo 以 4:1 击败李世石时，全世界都在问：这个改变人工智能历史的程序，究竟是怎么诞生的？

答案要从一位国际象棋神童的梦想说起。

---

## DeepMind 的创立

### Demis Hassabis：从神童到 AI 先驱

**Demis Hassabis** 是 DeepMind 的共同创始人兼首席执行官。他的人生经历，几乎就是为创造 AlphaGo 而准备的。

#### 国际象棋神童

1975 年出生于伦敦的 Hassabis，在 4 岁时学会下国际象棋，13 岁时达到国际象棋大师等级（Elo 2300+），是英国史上第二年轻达到此水平的棋手。

这段经历让他深刻理解：
- **棋类游戏是智能的试金石**：下棋需要规划、直觉、模式识别
- **人类智能的本质**：棋手如何在庞大的可能性中找到好棋？
- **计算机的局限**：1997 年深蓝击败卡斯帕罗夫靠的是暴力搜索，而非真正的「理解」

#### 游戏设计师

17 岁时，Hassabis 加入 Bullfrog Productions（由《上帝也疯狂》创作者 Peter Molyneux 创立的游戏公司），参与开发了经典游戏《主题公园》（Theme Park）。这段经历教会他：

- **如何设计复杂系统**：游戏是模拟现实世界的简化模型
- **玩家行为预测**：AI 需要理解人类的决策过程

#### 认知神经科学家

在剑桥大学取得计算机科学学位后，Hassabis 在伦敦大学学院（UCL）取得认知神经科学博士学位。他的研究主题是：**海马体如何让人类进行想象与规划**。

这项研究发现：
- 人类的记忆与想象使用相同的脑区
- 我们通过「心理时间旅行」来规划未来
- 这种能力可能是智能的核心

这些洞见直接影响了后来 AlphaGo 的设计——让 AI 能够「想象」未来的走法，并从中学习。

### 共同创始人

2010 年，Hassabis 与两位伙伴共同创立 DeepMind：

| 创始人 | 背景 | 贡献 |
|--------|------|------|
| **Demis Hassabis** | 神经科学、游戏设计 | 愿景与战略 |
| **Shane Legg** | 机器学习博士 | AGI 理论基础 |
| **Mustafa Suleyman** | 社会企业家 | 商业与应用 |

### 「解决智能，用智能解决一切」

DeepMind 的使命宣言是：

> **"Solve intelligence, and then use that to solve everything else."**
>
> 「解决智能，然后用它来解决所有其他问题。」

这不是一家普通的 AI 公司。他们的目标不是做产品，而是创造**通用人工智能（AGI）**——一种能像人类一样思考、学习、解决任何问题的 AI。

为什么要先「解决智能」？因为一旦我们有了 AGI，它就能帮助我们解决气候变化、疾病、能源等人类最大的挑战。

---

## 早期突破：Atari 游戏

在挑战围棋之前，DeepMind 首先证明了自己的能力——用 AI 玩 Atari 游戏。

### DQN：学会玩游戏的 AI

2013 年，DeepMind 发表了 **DQN（Deep Q-Network）** 算法。这个 AI 能够：

1. **只看屏幕像素**——不给它任何游戏规则
2. **自己学会玩游戏**——通过试错
3. **达到人类水平**——甚至在某些游戏超越人类

DQN 在《打砖块》（Breakout）中学会了一个人类需要几个小时才能发现的策略：**挖隧道让球跑到砖块后面，一次消除一大片**。

这证明了深度学习 + 强化学习的组合，能够发现人类未曾想过的策略。

### 为什么从游戏开始？

Hassabis 选择游戏作为研究平台，有几个原因：

1. **环境可控**：游戏有明确的规则和目标
2. **可衡量进步**：有客观的分数来评估 AI 能力
3. **人类基准**：可以与人类玩家比较
4. **多样性**：不同游戏测试不同能力

这套方法论，后来也用在围棋上。

---

## Google 的收购

### 5 亿美元的赌注

2014 年 1 月，Google 以约 **5 亿美元**收购 DeepMind。这是当时 AI 领域最大的收购案之一。

为什么 Google 愿意付这么多钱买一家只有 75 人、还没有产品的公司？

答案在于 **博弈论**：

- **Facebook 也在竞标**：传闻 Facebook 出价 4 亿美元
- **AI 是未来的关键技术**：谁先掌握 AI，谁就掌握未来
- **DeepMind 是最好的团队**：他们证明了深度强化学习的可行性

Google 首席执行官 Larry Page 亲自出面，才说服 Hassabis 选择 Google 而非 Facebook。

### 收购条件

Hassabis 在谈判中争取到几个关键条件：

1. **独立运营**：DeepMind 保持伦敦总部，独立研发
2. **学术自由**：可以发表论文，而非全部保密
3. **伦理委员会**：成立 AI 伦理审查机制
4. **长期研究**：不需要短期商业化压力

这些条件让 DeepMind 能够追求长期、高风险的研究——比如用 AI 征服围棋。

### Google 的 AI 战略

收购 DeepMind 是 Google 「AI 优先」战略的一部分：

| 时间 | 事件 |
|------|------|
| 2011 | 成立 Google Brain |
| 2013 | 收购 DNNresearch（Hinton 团队） |
| 2014 | 收购 DeepMind |
| 2015 | TensorFlow 开源 |
| 2016 | TPU 发布 |

Google 意识到：搜索、广告、翻译、语音——所有核心业务都将被 AI 重塑。谁有最好的 AI，谁就是赢家。

---

## 选择围棋作为目标

### 为什么是围棋？

被 Google 收购后，DeepMind 有了更多资源。Hassabis 决定挑战一个看似不可能的目标：**用 AI 击败人类围棋冠军**。

为什么选择围棋，而不是其他问题？

#### 1. 围棋是「AI 的圣杯」

2016 年之前，专家普遍认为 AI 至少需要 10-20 年才能在围棋上击败人类。围棋被称为「AI 最后的堡垒」。

原因：
- **搜索空间巨大**：10^170 种可能的局面（宇宙原子数只有 10^80）
- **评估困难**：不像国际象棋有明确的棋子价值
- **直觉依赖**：顶尖棋手常说「这步棋感觉对」，却无法解释原因

#### 2. 深蓝的启示

1997 年，IBM 的深蓝（Deep Blue）击败了国际象棋世界冠军卡斯帕罗夫。但这个胜利有争议：

- 深蓝靠的是**暴力搜索**（每秒评估 2 亿个位置）
- 使用**人类专家设计的评估函数**
- 这不是真正的「智能」，而是「计算力」

Hassabis 想证明：AI 可以用**学习**而非暴力搜索来解决问题。

#### 3. 可衡量的目标

围棋有国际排名系统（Elo rating）和职业棋手，提供了客观的衡量标准。如果 AI 能击败世界冠军，就是无可争辩的成功。

#### 4. 与神经科学的联系

人类棋手的直觉——看一眼棋盘就知道哪些位置重要——正是 Hassabis 想用 AI 复制的能力。围棋是测试「机器直觉」的完美场景。

---

## AlphaGo 团队

### 核心人物

AlphaGo 的成功，来自一支多学科背景的团队：

#### David Silver：首席研究员

**David Silver** 是 AlphaGo 论文的第一作者，也是强化学习领域的顶尖专家。

- **背景**：剑桥大学数学系毕业，阿尔伯塔大学 RL 博士
- **导师**：Richard Sutton（强化学习之父）
- **专长**：蒙特卡洛树搜索、时序差分学习

Silver 在博士论文中就研究过计算机围棋，但当时的技术远未成熟。加入 DeepMind 后，他终于有机会实现这个梦想。

#### Aja Huang：围棋专家

**Aja Huang**（黄士杰）是台湾人，业余六段棋手，也是计算机围棋领域的先驱。

- **背景**：国立台湾师范大学计算机博士
- **专长**：计算机围棋程序设计
- **著名作品**：Erica（早期计算机围棋程序）

Huang 在 AlphaGo 团队中扮演关键角色：他不只理解围棋，也理解 AI。在与李世石的对局中，他是实际操作 AlphaGo 的人。

#### 其他关键成员

| 成员 | 角色 |
|------|------|
| Chris J. Maddison | 蒙特卡洛树搜索专家 |
| Arthur Guez | 强化学习研究员 |
| Laurent Sifre | 深度学习工程师 |
| George van den Driessche | 分布式系统工程师 |

### 跨领域合作

AlphaGo 的成功证明了**跨领域合作**的力量：

- **围棋专家**提供领域知识
- **机器学习研究员**设计算法
- **工程师**实现大规模训练系统
- **神经科学家**提供理论灵感

这种团队组成，后来成为 DeepMind 的标准模式。

---

## Nature 论文发表

### 秘密的惊喜

2016 年 1 月 27 日，DeepMind 在顶级学术期刊《Nature》发表论文：

> **"Mastering the game of Go with deep neural networks and tree search"**

论文宣布 AlphaGo 已经：
1. 击败了所有其他围棋程序
2. 以 **5:0** 击败了欧洲冠军 **樊麾**（职业二段）

这个消息震惊了世界。在论文发表之前，没有人知道 DeepMind 在研究围棋。

### 论文的核心贡献

《Nature》论文描述了 AlphaGo 的三大创新：

#### 1. Policy Network（策略网络）

用深度卷积神经网络预测人类棋手的下一步。训练数据来自 **3000 万局** 的人类棋谱。

```
准确率：57%（预测人类专家的下一步）
```

这比之前最好的计算机围棋程序高出 10 个百分点以上。

#### 2. Value Network（价值网络）

用另一个神经网络评估当前局面的胜率。这取代了传统的随机模拟（Monte Carlo rollout）。

```
精度：与 15000 次随机模拟相当，但计算速度快 15000 倍
```

#### 3. 蒙特卡洛树搜索整合

将两个神经网络整合进 MCTS 框架：
- Policy Network 引导搜索方向
- Value Network 评估叶节点

这让 AlphaGo 既有「直觉」（神经网络），又有「推理」（树搜索）。

### 学术界的反应

论文发表后，学术界反应热烈：

> "这是人工智能的登月时刻。"
> — **Stuart Russell**，UC Berkeley 教授，AI 教科书作者

> "我原本认为还要 10 年，没想到这么快。"
> — **Martin Müller**，计算机围棋专家

但也有人持怀疑态度：

> "樊麾只是职业二段，不是真正的顶尖棋手。让 AlphaGo 和 Lee Sedol 下一场再说。"

DeepMind 接受了这个挑战。

---

## 挑战李世石

### 为什么是李世石？

**李世石**（Lee Sedol）是韩国棋手，当时被认为是过去十年最强的棋手之一：

| 指标 | 数据 |
|------|------|
| 世界冠军头衔 | 18 个 |
| 国际赛冠军 | 32 个 |
| 最高世界排名 | 第 1 |
| 风格 | 「天才」「神算」 |

选择李世石，DeepMind 是在挑战最强的人类对手。

### 1 百万美元奖金

Google 为这场比赛提供了 **100 万美元** 奖金：

- 如果李世石获胜：奖金归李世石
- 如果 AlphaGo 获胜：奖金捐给 UNICEF、STEM 教育等慈善机构

这不只是一场技术展示，也是全球瞩目的体育赛事。

### 比赛前的预测

比赛前，多数职业棋手预测李世石会轻松获胜：

> "AlphaGo 可能赢一盘，但 5 盘比赛我会 5:0 获胜。"
> — **李世石**，赛前采访

> "计算机下棋死板，顶尖棋手很容易找到弱点。"
> — 某位职业九段

但 DeepMind 团队有不同的看法。David Silver 后来透露：

> "我们在内部测试中，已经让 AlphaGo 对阵樊麾的版本下了 500 盘。新版本赢了 499 盘。"

---

## 2016 年 3 月：改变世界的五盘棋

### 第一盘：震惊开始

2016 年 3 月 9 日，首尔四季酒店。

李世石执黑先行，AlphaGo 执白。经过 3 小时 28 分的对弈，AlphaGo 中盘获胜。

这是人类顶尖棋手首次正式输给 AI。

### 第二盘：神之一手

第二盘诞生了被称为「**神之一手**」的第 37 手——AlphaGo 在五路下出一步肩冲，所有职业棋手都认为是失误，结果证明是制胜关键。

（详见下一篇：[「神之一手」深度分析](../move-37)）

AlphaGo 再次获胜。

### 第三盘：3:0

第三盘，李世石尝试了非传统的开局，但 AlphaGo 应对自如。3:0。

全世界开始意识到：这不是偶然，AI 真的超越了人类。

### 第四盘：人类的反击

第四盘，李世石下出了被称为「**神之一手**」的第 78 手——一步精妙的挖，让 AlphaGo 出现了混乱。

AlphaGo 在接下来的几步中下出明显的坏棋，最终认输。

这场胜利证明：AI 也有弱点。李世石找到了它。

### 第五盘：最终比分

第五盘，AlphaGo 恢复正常，以中盘获胜结束比赛。

**最终比分：AlphaGo 4:1 李世石**

---

## 影响与余波

### 全球关注

这场比赛的影响远超围棋界：

- **全球 2 亿人** 观看了直播
- 《纽约时报》、《经济学人》等主流媒体大篇幅报道
- Google 股价在比赛期间上涨
- 「人工智能」成为当年最热门的科技话题

### 对围棋界的影响

比赛后，职业棋手的态度从「轻视」转为「敬畏」：

> "我们以前认为人类理解围棋，现在发现我们只是懂一点皮毛。"
> — **柯洁**，中国棋手，当时世界排名第一

许多职业棋手开始使用 AI 来训练，围棋的下法也因此改变。

### 对 AI 领域的影响

AlphaGo 证明了几件事：

1. **深度学习可以解决专家级问题**：不只是识别猫狗，还能下围棋
2. **强化学习可以超越人类**：通过自我对弈，AI 可以发现人类未知的策略
3. **神经网络 + 搜索是强大的组合**：直觉 + 推理 = 更强的智能

这些洞见后来被应用到：
- **AlphaFold**：蛋白质结构预测（2020 诺贝尔奖级成就）
- **AlphaZero**：通用游戏 AI
- **MuZero**：不需要规则的学习

---

## 动画对应

本文涉及的核心概念与动画编号：

| 编号 | 概念 | 物理/数学对应 |
|------|------|--------------|
| E7 | 从零开始 | 自组织 |
| E5 | 自我对弈 | 不动点收敛 |
| F8 | 涌现能力 | 相变 |
| H4 | 策略梯度 | 随机优化 |

---

## 延伸阅读

- **下一篇**：[关键对局回顾](../key-matches) — 樊麾、李世石、柯洁的完整对局分析
- **技术细节**：[Policy Network 详解](../policy-network) — AlphaGo 如何学会下棋
- **动手实践**：[30 分钟跑起第一个围棋 AI](/docs/tech/hands-on/) — 亲自体验

---

## 参考资料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. 《AlphaGo》纪录片 (2017)，导演 Greg Kohs。
