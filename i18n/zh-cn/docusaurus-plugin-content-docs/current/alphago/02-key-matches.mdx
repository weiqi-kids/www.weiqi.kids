---
sidebar_position: 3
title: 关键对局回顾
description: 从樊麾的秘密对局到柯洁的三番胜负，完整回顾 AlphaGo 的每一场重要对局
---

# 关键对局回顾

AlphaGo 的历史，是由一场场震撼世界的对局写成的。从 2015 年 10 月在伦敦的秘密对局，到 2017 年 5 月在乌镇的告别演出，每一盘棋都在改写人类对围棋与人工智能的认知。

本文将完整回顾这些关键对局的背景、过程与意义。

---

## 樊麾对局（2015.10）：秘密进行的 5:0

### 背景：为什么选择樊麾？

在 AlphaGo 挑战世界顶尖棋手之前，DeepMind 需要一个「测试场」。他们需要一位职业棋手来验证 AlphaGo 的真实实力，但这位棋手必须满足几个条件：

1. **真正的职业水准**：业余棋手无法准确测试 AI 实力
2. **愿意保密**：在论文发表前不能泄露消息
3. **地理位置方便**：便于进行多盘正式对局
4. **开放心态**：愿意认真对待 AI 对手

**樊麾**完美符合这些条件。这位出生于中国西安的职业棋手，1996 年入段，2000 年升为二段，后移居法国并成为欧洲围棋冠军。他是当时欧洲最强的职业棋手，同时也对人工智能抱持开放态度。

### 对局安排

2015 年 10 月，樊麾受邀前往伦敦 DeepMind 总部。在签署保密协议后，他与 AlphaGo 进行了 **5 盘正式对局**。

对局条件：
- **用时**：每方 1 小时，每手 30 秒读秒
- **规则**：中国规则，7.5 目贴目
- **环境**：DeepMind 办公室，由 Aja Huang 代为落子

### 5:0 的震撼

结果令所有人震惊：**AlphaGo 5:0 完胜**。

| 盘次 | 日期 | 结果 | 备注 |
|------|------|------|------|
| 第 1 盘 | 10 月 5 日 | AlphaGo 中盘胜 | 樊麾执黑 |
| 第 2 盘 | 10 月 6 日 | AlphaGo 中盘胜 | 樊麾执白 |
| 第 3 盘 | 10 月 7 日 | AlphaGo 中盘胜 | 樊麾执黑 |
| 第 4 盘 | 10 月 8 日 | AlphaGo 1.5 目胜 | 樊麾执白 |
| 第 5 盘 | 10 月 9 日 | AlphaGo 中盘胜 | 樊麾执黑 |

🎬 E1：这 5 盘棋展示了 Policy Network 如何引导搜索方向

樊麾后来回忆：

> 「第一盘我输了，我想一定是我大意了。第二盘输了，我开始认真。第三盘、第四盘、第五盘全输了，我知道这不是我的问题——是围棋变了。」

### 为什么保密？

DeepMind 选择保密有几个原因：

1. **学术发表**：论文需要经过同行审查才能发表
2. **验证时间**：需要时间确认结果的可重复性
3. **商业策略**：选择最佳时机公布消息
4. **保护樊麾**：避免他在消息公开前承受压力

这个秘密被保守了整整三个月，直到 2016 年 1 月《Nature》论文发表。

### 樊麾的转变

输掉这 5 盘棋后，樊麾并没有感到沮丧。相反，他成为了 AlphaGo 团队的一员，负责测试和改进系统。

> 「我不是被 AI 击败了，我是成为了 AI 发展的一部分。这是荣幸，不是耻辱。」

这种开放心态，后来成为围棋界面对 AI 的典范。

---

## 李世乭对局（2016.03）：改变世界的五盘棋

### 世纪对决的筹备

2016 年 1 月 27 日，《Nature》论文发表后，DeepMind 宣布将挑战世界顶尖棋手。目标人选：**李世乭**（Lee Sedol）。

为什么是李世乭？

- **18 个世界冠军头衔**：过去十年最成功的棋手之一
- **「神算」的美誉**：以精准计算著称
- **战斗型风格**：喜欢复杂、激烈的对局
- **35 岁正值巅峰**：经验与体力的最佳平衡

🎬 E3：李世乭的风格正好能测试 MCTS 的极限

### 比赛设置

- **地点**：韩国首尔四季酒店
- **日期**：2016 年 3 月 9-15 日
- **奖金**：100 万美元（胜者得，平分或捐赠慈善）
- **规则**：中国规则，7.5 目贴目
- **用时**：每方 2 小时，每手 1 分钟读秒 3 次

全球 200 多个国家和地区进行直播，预计观众超过 **2 亿人**。

### 第一盘：震惊的开始

**2016 年 3 月 9 日**

李世乭执黑先行。开局阶段，双方中规中矩。但到了中盘，AlphaGo 展现了惊人的大局观。

在第 102 手时，AlphaGo 下出一步看似退让的棋，让出了右边的实地。职业棋手们纷纷表示不解。但 20 手后，这步棋的妙处显现——AlphaGo 用牺牲的棋子建立了中央厚势，最终在全盘取得优势。

**结果：AlphaGo 中盘胜**

赛后，李世乭表示：

> 「我很震惊。我没想到会输，更没想到会输得这么彻底。」

🎬 E5：这盘棋展示了 Value Network 评估全局的能力

### 第二盘：「神之一手」的诞生

**2016 年 3 月 10 日**

这盘棋诞生了被称为「**神之一手**」的第 37 手。（详见下一篇：[「神之一手」深度分析](../move-37)）

AlphaGo 在右上角下出一步「五路肩冲」——一个人类几乎不会考虑的位置。解说员当场表示这是「失误」，但 50 手后，这步棋被证明是制胜关键。

**结果：AlphaGo 中盘胜**

韩国解说员金成龙九段赛后说：

> 「我下了 50 年的棋，从没见过这样的棋。AlphaGo 让我重新思考什么是围棋。」

🎬 E7：第 37 手展示了 AI 如何发现人类未知的策略

### 第三盘：绝望的 3:0

**2016 年 3 月 12 日**

李世乭在这盘棋尝试了非常规开局，希望将 AlphaGo 带入未知领域。他采用了「小林流」布局的变形，企图用复杂的战斗取胜。

但 AlphaGo 的应对依然从容。它展现了惊人的适应能力——无论人类如何出招，它都能找到最佳应手。

**结果：AlphaGo 中盘胜**

比数来到 3:0，比赛已经失去悬念。但所有人都在期待：人类能否赢得一盘？

### 第四盘：人类的反击

**2016 年 3 月 13 日**

这盘棋将永载史册——不是因为 AI 的神奇，而是因为**人类的反击**。

局面进行到第 78 手时，李世乭在读秒中下出了一步惊世之作：**五路的妙手**。

这是一步「挖」的手筋，看似普通，却让 AlphaGo 陷入混乱。在接下来的几手棋中，AlphaGo 的胜率评估出现剧烈波动，它下出了几步明显的坏棋。

🎬 E9：这盘棋暴露了 MCTS 在特定局面下的弱点

DeepMind 团队后来分析，AlphaGo 在那个局面下的胜率评估出现了错误。它低估了李世乭那步棋的威力，导致后续应对失误。

**结果：李世乭 中盘胜**

这是 AlphaGo 正式比赛中唯一的一场败北。李世乭激动地说：

> 「这场胜利无价。它证明了人类棋手仍然能够战胜 AI——至少在某些局面下可以。」

Google DeepMind 执行长 Demis Hassabis 发推特：

> 「李世乭是真正的传奇。他找到了 AlphaGo 的弱点，并精确地利用了它。」

### 第五盘：最终的结局

**2016 年 3 月 15 日**

在获得一场宝贵的胜利后，李世乭带着更轻松的心态进入第五盘。他采用了更为激进的策略，试图再次找到 AlphaGo 的弱点。

但 DeepMind 团队在第四盘后进行了紧急调整。这一版本的 AlphaGo 似乎更加稳健，不再出现之前的评估错误。

**结果：AlphaGo 中盘胜**

**最终比分：AlphaGo 4:1 李世乭**

### 对局的历史意义

这场比赛的影响远超围棋界：

#### 对人工智能

- **证明深度学习的威力**：AI 可以在复杂决策任务上超越人类
- **强化学习的里程碑**：自我对弈训练被证明有效
- **激发后续研究**：引发了 AI 领域的投资热潮

#### 对围棋界

- **传统理论被挑战**：很多「定式」被证明次优
- **训练方式改变**：职业棋手开始使用 AI 辅助训练
- **新下法的诞生**：AI 引入了许多创新手法

#### 对公众

- **AI 意识觉醒**：普通人开始关注人工智能
- **科技报道增加**：主流媒体大量报道 AI 进展
- **电影与纪录片**：催生了《AlphaGo》纪录片

🎬 E11：这场比赛标志着 AI 能力的「相变」时刻

---

## Master 60 连胜（2017.01）：线上快棋的震撼

### 神秘的「Master」账号

2016 年 12 月 29 日，一个名为「**Master**」的账号出现在中国弈城围棋和腾讯野狐围棋网站上。

这个账号的表现令人难以置信：
- **连胜所有对手**：无一败绩
- **对手全是顶尖棋手**：包括世界冠军和九段高手
- **用时极短**：每步棋几乎都是秒下

很快，整个围棋界都在讨论：「Master」到底是谁？

### 60 连胜的壮举

从 12 月 29 日到 2017 年 1 月 4 日，「Master」进行了 60 盘快棋，**全部获胜**。

被击败的棋手名单犹如世界围棋名人堂：

| 排名 | 棋手 | 战绩 |
|------|------|------|
| 世界第 1 | 柯洁（中国） | 0-3 |
| 世界第 2 | 朴廷桓（韩国） | 0-2 |
| 世界第 3 | 井山裕太（日本） | 0-1 |
| 传奇棋手 | 聂卫平（中国） | 0-1 |
| 传奇棋手 | 古力（中国） | 0-2 |
| ... | ... | ... |

总计包括超过 **50 位职业九段**，涵盖中日韩三国顶尖棋手。

🎬 E13：快棋展示了 Policy Network 即时决策的能力

### 身份揭晓

2017 年 1 月 4 日，在完成第 60 胜后，「Master」在聊天室透露了身份：

> 「我是 AlphaGo 的黄博士。」

黄博士就是 Aja Huang（黄士杰），AlphaGo 团队的核心成员。

DeepMind 随后正式确认：「Master」是 AlphaGo 的新版本，这次测试的目的是验证系统在线上环境中的稳定性。

### 职业棋手的反应

60 连胜的冲击，比李世乭对局更加深刻。因为这次的对手更多、范围更广。

**柯洁**（三次败给 Master）：

> 「人类与 AI 的差距比我们想象的还要大。我们一直以为自己理解围棋，但 Master 让我觉得我们连入门都谈不上。」

**聂卫平**（中国棋圣）：

> 「我下了 60 年的棋，第一次感觉如此无力。这不是技术的差距，是维度的差距。」

**古力**（八个世界冠军）：

> 「输给 Master 后，我开始思考人类棋手的价值在哪里。我们还需要职业比赛吗？」

### 技术分析

这一版本的 AlphaGo（后来被称为 **AlphaGo Master**）相比李世乭对局版本有显著提升：

| 指标 | Lee 版本 | Master 版本 | 提升 |
|------|----------|-------------|------|
| Elo 评分 | ~3,600 | ~4,800 | +1,200 |
| 自我对弈胜率 | - | 99%+ | - |
| Policy 准确度 | ~57% | ~62% | +5% |
| 训练时间 | 数月 | 额外数月 | - |

🎬 E15：Elo 的提升展示了自我对弈的指数级进步

---

## 柯洁对局（2017.05）：王者的谢幕

### 最后的挑战者

在 Master 60 连胜后，很少有人还认为人类有机会战胜 AlphaGo。但有一个人依然渴望一战——**柯洁**。

当时 19 岁的柯洁，是世界排名第一的棋手。他曾多次公开表示：

> 「我不认为 AlphaGo 能击败我。即使 Master 赢了我三盘快棋，正式比赛是不同的。」

Google 接受了挑战。

### 乌镇围棋峰会

2017 年 5 月，「**未来围棋峰会**」在中国浙江乌镇举行。这是一场围绕 AlphaGo 的盛大活动，包括：

1. **柯洁三番棋**：人类最强对 AI 最强
2. **配对赛**：人类 + AlphaGo vs 人类 + AlphaGo
3. **团队赛**：五位中国顶尖棋手联手对抗 AlphaGo

### 三番棋：3:0 的结局

**第一盘（5 月 23 日）**

柯洁执黑先行，开局采用了较为稳健的「中国流」布局。这是经过深思熟虑的选择——柯洁希望避免被 AlphaGo 的大局观击败，转而在细节处争取机会。

但 AlphaGo 的应对完美无瑕。它在每个关键时刻都找到了最准确的下法，逐渐累积优势。

**结果：AlphaGo 以 1/4 子（0.5 目）获胜**

这是围棋中可能的最小胜利差距。柯洁赛后落泪：

> 「我已经用尽全力，但还是差了一点点。」

🎬 E17：1/4 子的差距展示了 AI 的精确控制能力

**第二盘（5 月 25 日）**

柯洁改变策略，采用了模仿 AlphaGo 的开局方式。他使用了「点三三」直接进角的新手法——这正是 AlphaGo 带给围棋界的创新。

> 「既然你的下法更好，我就学你的下法。」

但 AlphaGo 不为所动。它依然按照自己的节奏进行，在中盘战斗中展现了惊人的计算能力。

**结果：AlphaGo 中盘胜**

**第三盘（5 月 27 日）**

最后一盘，柯洁孤注一掷。他采用了极为激进的战斗风格，试图将 AlphaGo 拖入混战。

开局阶段，柯洁确实制造了一些复杂局面。但 AlphaGo 的应对依然精准，它没有给柯洁任何翻盘的机会。

**结果：AlphaGo 中盘胜**

**最终比分：AlphaGo 3:0 柯洁**

🎬 E19：三番棋展示了 AlphaGo 的绝对统治力

### 配对赛与团队赛

除了柯洁三番棋，峰会还进行了两种创新赛制：

**配对赛**（5 月 26 日）

连笑 + AlphaGo vs 古力 + AlphaGo

这场比赛的有趣之处在于：当人类棋手与 AlphaGo 意见不同时，会发生什么？

结果显示：**完全遵从 AlphaGo 建议的一方表现更好**。当人类棋手试图「修正」AlphaGo 的下法时，往往会导致局面恶化。

**结果：连笑 + AlphaGo 胜**

**团队赛**（5 月 26 日）

中国队（周睿羊、时越、唐韦星、陈耀烨、芈昱廷） vs AlphaGo

五位中国顶尖棋手合作对抗一台 AI。他们可以充分讨论，共同决定每一步棋。

但结果没有悬念：**AlphaGo 中盘胜**。

这场比赛证明：即使人类顶尖棋手联手，也无法战胜 AlphaGo。

### AlphaGo 的退役宣言

2017 年 5 月 27 日，在柯洁三番棋结束后，DeepMind 发表了一份重要声明：

> 「这是 AlphaGo 最后一次公开对弈。我们相信 AlphaGo 已经完成了它的使命——证明 AI 可以在围棋这个人类智慧的巅峰领域达到超越人类的水平。
>
> 接下来，我们将把从 AlphaGo 学到的技术应用到更重要的问题上：医疗、能源、材料科学。这才是人工智能的真正价值所在。」

同时宣布：

1. **AlphaGo 教学工具**：将发布 AlphaGo 的对局分析供棋手学习
2. **50 盘自我对弈棋谱**：公开 AlphaGo vs AlphaGo 的棋谱
3. **技术论文**：将在《Nature》发表 AlphaGo Zero 的研究成果

🎬 E21：AlphaGo 的退役标志着一个时代的结束

---

## 对局的历史定位

### 技术里程碑

AlphaGo 的对局在人工智能史上具有里程碑意义：

| 年份 | 事件 | 意义 |
|------|------|------|
| 1997 | 深蓝击败卡斯帕洛夫 | 暴力搜索的胜利 |
| 2011 | Watson 赢得 Jeopardy! | 自然语言处理的突破 |
| **2016** | **AlphaGo 击败李世乭** | **深度学习 + 强化学习的胜利** |
| 2017 | AlphaGo Zero 100:0 | 纯粹自我学习的胜利 |

🎬 E23：每个里程碑都代表了 AI 方法论的演进

### 对围棋界的影响

**棋谱研究的改变**

传统上，职业棋手主要研究人类棋谱。但 AlphaGo 之后，AI 棋谱成为必修课。

- **点三三开局**：AlphaGo 证明直接点角是有效策略
- **肩冲的妙用**：第 37 手改变了对「肩冲」这个手筋的认知
- **厚势的价值**：AI 展示了厚势转化的新方式

**训练方式的变革**

职业棋手的训练方式发生根本改变：

| 传统方式 | AI 时代方式 |
|----------|-------------|
| 研究人类棋谱 | 研究 AI 棋谱 |
| 依靠师父指导 | 使用 AI 分析工具 |
| 记忆定式 | 理解 AI 的评估逻辑 |
| 实战练习 | AI 复盘分析 |

**新一代棋手的崛起**

2016 年后成长起来的棋手，被称为「AI 原住民」。他们的棋风明显受到 AI 影响：

- 更注重效率而非传统美学
- 更愿意尝试非传统下法
- 更依赖精确计算而非直觉

### 哲学反思

AlphaGo 的胜利引发了深刻的哲学讨论：

**智慧的本质是什么？**

AlphaGo 「理解」围棋吗？还是它只是在进行精确的计算？这个问题至今没有定论。

**人类的价值在哪里？**

当 AI 在围棋上超越人类，围棋比赛还有意义吗？很多棋手重新思考自己的职业意义。

有趣的是，AlphaGo 之后，围棋的全球关注度反而提高了。人们意识到：围棋不只是竞技，也是艺术和哲学。

**AI 的发展方向**

AlphaGo 的成功让人们对 AI 既期待又担忧。DeepMind 选择让 AlphaGo 退役，转向解决「真正重要的问题」，这本身就是一个伦理选择。

🎬 E25：AlphaGo 引发了关于 AI 伦理的广泛讨论

---

## 遗珠：其他重要对局

### 与其他 AI 的对决

在公开赛之外，AlphaGo 还与其他围棋 AI 进行了大量对局：

| 对手 | 版本 | 结果 |
|------|------|------|
| Crazy Stone | 2015 年最强围棋程序 | 全胜 |
| Zen | 日本最强围棋 AI | 全胜 |
| 旧版 AlphaGo | 各版本自我对弈 | - |

### 内部测试

DeepMind 团队进行了大量内部测试：

- **AlphaGo Lee vs AlphaGo Master**：Master 版本胜率超过 99%
- **AlphaGo Master vs AlphaGo Zero**：Zero 版本胜率超过 89%
- **不同训练时间的版本对弈**：观察学习曲线

这些测试数据后来都在论文中公开，成为研究 AI 学习的重要资料。

---

## 动画对应

本文涉及的核心概念与动画编号：

| 编号 | 概念 | 物理/数学对应 |
|------|------|--------------|
| 🎬 E1 | Policy Network 引导搜索 | 概率分布 |
| 🎬 E3 | 测试 MCTS 的极限 | 树搜索深度 |
| 🎬 E5 | Value Network 全局评估 | 价值函数 |
| 🎬 E7 | 发现未知策略 | 探索 vs 利用 |
| 🎬 E9 | MCTS 的弱点 | 边界条件 |
| 🎬 E11 | 能力的「相变」 | 临界现象 |
| 🎬 E13 | 即时决策能力 | 推理速度 |
| 🎬 E15 | 自我对弈的指数进步 | 迭代优化 |
| 🎬 E17 | 精确控制能力 | 数值稳定性 |
| 🎬 E19 | 绝对统治力 | 收敛到最优 |
| 🎬 E21 | 时代的结束 | 任务完成 |
| 🎬 E23 | 方法论演进 | 典范转移 |
| 🎬 E25 | AI 伦理讨论 | 社会影响 |

---

## 延伸阅读

- **上一篇**：[AlphaGo 的诞生](../birth-of-alphago) — DeepMind 创立、团队组成
- **下一篇**：[「神之一手」深度分析](../move-37) — 第 37 手的完整解读
- **技术细节**：[MCTS 与神经网络的结合](../mcts-neural-combo) — 理解对局背后的技术
- **后续发展**：[AlphaGo 的遗产](../legacy-and-impact) — 对围棋与 AI 的长期影响

---

## 参考资料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 550, 354-359.
3. 《AlphaGo》纪录片 (2017)，导演 Greg Kohs。
4. DeepMind 官方 Blog：AlphaGo 系列文章
5. 李世乭对局官方棋谱与评论（韩国棋院）
6. 乌镇围棋峰会官方纪录
