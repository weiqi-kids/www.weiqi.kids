---
sidebar_position: 1
title: AlphaGo 时代
---

# AlphaGo 时代（2015-2017）

2015 年至 2017 年，Google DeepMind 的 AlphaGo 系列程式创造了人工智能历史上最具标志性的突破之一。在短短两年内，围棋从「人工智能无法征服的游戏」变成了「AI 完全超越人类的领域」。

## 2015 年 10 月：AlphaGo 击败樊麾

### 历史性的秘密对局

2015 年 10 月，在伦敦的一间办公室里，DeepMind 安排了一场秘密对局。对手是欧洲围棋冠军、职业二段棋手**樊麾**。

比赛结果：AlphaGo 以 5:0 完胜。

这是历史上第一次有电脑程式在公平条件下（无让子）击败职业围棋棋手。消息在 2016 年 1 月正式公布，立即引起全球轰动。

### 初代 AlphaGo 的技术

这一版本的 AlphaGo 使用了两个关键技术的结合：

1. **深度神经网络**：通过学习数十万局人类职业对局，训练出能够评估局面的「价值网络」和能够预测下一手的「策略网络」

2. **蒙特卡罗树搜索（MCTS）**：利用神经网络的输出来指导搜索，大幅减少需要计算的变化数量

这种「直觉」加「计算」的结合，正是人类棋手思考问题的方式——只是 AI 在两方面都做得更好。

## 2016 年 3 月：AlphaGo vs 李世乭

### 世纪对决

2016 年 3 月 9 日至 15 日，AlphaGo 与世界顶尖棋手**李世乭**在首尔进行五番棋对决。这场比赛吸引了全球超过两亿人观看，成为人工智能历史上最受关注的事件之一。

### 比赛结果

| 局数 | 日期 | 结果 | 备注 |
|------|------|------|------|
| 第 1 局 | 3 月 9 日 | AlphaGo 胜 | 中盘胜 |
| 第 2 局 | 3 月 10 日 | AlphaGo 胜 | 中盘胜，出现著名的「第 37 手」 |
| 第 3 局 | 3 月 12 日 | AlphaGo 胜 | 中盘胜 |
| 第 4 局 | 3 月 13 日 | 李世乭胜 | **李世乭第 78 手「神之一手」** |
| 第 5 局 | 3 月 15 日 | AlphaGo 胜 | 中盘胜 |

最终比分：**AlphaGo 4:1 李世乭**

### 第 2 局第 37 手：「神之一手」

在第二局中，AlphaGo 在右边下出了一手让所有观战棋手困惑的「肩冲」。

这手棋看起来毫无道理，不符合任何人类已知的定式。解说员估计这手棋的人类下出机率不到万分之一。然而，随着棋局进行，这手棋的深意逐渐显现——它同时对多个方向施加影响，效率极高。

这一手棋被称为「神之一手」，象征着 AI 已经发展出人类无法理解的围棋理念。

### 第 4 局第 78 手：人类的反击

在连输三局后，李世乭在第四局中下出了同样惊人的一手——第 78 手「挖」。

这手棋是一个巧妙的手筋，在复杂的缠斗中制造了 AlphaGo 未能预见的变化。AlphaGo 在这手棋之后出现了明显的混乱，最终认输。

这是人类在正式比赛中唯一一次击败 AlphaGo，李世乭的这手棋被永远铭记为人类智慧的象征。

### 比赛的影响

这场比赛的影响远超围棋界：

- **人工智能的里程碑**：证明了深度学习可以处理极其复杂的问题
- **韩国的全民关注**：据统计，韩国有超过一半的人口观看了比赛
- **围棋的新纪元**：职业棋手开始意识到必须向 AI 学习
- **科技投资热潮**：推动了全球对 AI 研究的投资

## 2017 年 1 月：Master 60 连胜

### 神秘的线上棋手

2016 年底至 2017 年初，一个名为「Master」的帐号出现在弈城和野狐等围棋对弈网站上。它以极快的速度击败了所有挑战者，包括柯洁、朴廷桓、井山裕太等世界顶尖棋手。

最终战绩：**60 战 60 胜**（包括一局因对手掉线判和）

在第 60 局结束后，DeepMind 正式宣布：Master 就是 AlphaGo 的新版本。

### Master 展现的新理念

Master 的棋风与一年前击败李世乭的版本明显不同：

- **更快的计算速度**：每手棋只用几十秒
- **更激进的下法**：频繁使用传统理论认为「不好」的下法
- **点三三成为主流**：Master 经常在开局直接点三三

这些下法彻底颠覆了人类数百年积累的围棋理论，职业棋手开始大量模仿 AI 的下法。

## 2017 年 5 月：AlphaGo vs 柯洁

### 人类的最后挑战

2017 年 5 月，在中国乌镇，AlphaGo 与当时世界排名第一的**柯洁**进行三番棋对决。这被视为「人类最后的挑战」。

### 比赛结果

| 局数 | 日期 | 结果 | 备注 |
|------|------|------|------|
| 第 1 局 | 5 月 23 日 | AlphaGo 胜 | 1/4 子胜（最小差距） |
| 第 2 局 | 5 月 25 日 | AlphaGo 胜 | 中盘胜 |
| 第 3 局 | 5 月 27 日 | AlphaGo 胜 | 中盘胜 |

最终比分：**AlphaGo 3:0 柯洁**

### 柯洁的眼泪

在第二局比赛中途，柯洁一度离席，回来时眼眶泛红。赛后他说：

> 「它太完美了，我看不到任何胜利的希望。」

> 「和 AlphaGo 下棋，我感受到的是它对围棋的热爱。」

这场比赛结束后，DeepMind 宣布 AlphaGo 退役，不再参加公开比赛。

## 2017 年 10 月：AlphaZero 论文

### 从零开始的超越

2017 年 10 月，DeepMind 发表了 AlphaZero 论文，展示了更惊人的成就。

AlphaZero 的突破在于：**它完全不需要人类棋谱**。

程式只被告知围棋的规则，然后通过自我对弈学习。从「零」开始，AlphaZero 仅用 **40 天** 的自我训练，就超越了所有之前的 AlphaGo 版本。

### 统一的智慧

更令人惊奇的是，同样的 AlphaZero 程式（只改变游戏规则）在围棋、国际象棋、日本将棋三种游戏中，都达到了超越所有人类和之前最强程式的水平。

这证明了深度强化学习的通用性——同样的算法可以掌握完全不同的智力游戏。

## 技术解析

### 深度神经网络

AlphaGo 使用的神经网络有两个主要部分：

**策略网络（Policy Network）**
- 输入：当前棋盘局面
- 输出：每一个位置的落子机率
- 功能：模拟人类的「直觉」，快速缩小搜索范围

**价值网络（Value Network）**
- 输入：当前棋盘局面
- 输出：当前局面的胜率估计
- 功能：评估局面的好坏，替代传统的穷举搜索

### 蒙特卡罗树搜索（MCTS）

MCTS 是一种搜索算法，通过以下步骤工作：

1. **选择（Selection）**：从根节点开始，根据某种策略选择子节点
2. **扩展（Expansion）**：在叶节点处增加新的子节点
3. **模拟（Simulation）**：从新节点开始，进行随机模拟直到游戏结束
4. **反向传播（Backpropagation）**：将模拟结果向上传递，更新路径上所有节点的统计资料

AlphaGo 的创新在于用神经网络取代了随机模拟，大大提高了搜索效率。

### 强化学习

从 AlphaGo Lee 到 AlphaZero，强化学习扮演了越来越重要的角色：

- **AlphaGo Fan**（击败樊麾）：主要依靠人类棋谱训练
- **AlphaGo Lee**（击败李世乭）：人类棋谱 + 自我对弈
- **AlphaGo Master**（60 连胜）：增强的自我对弈训练
- **AlphaZero**：完全的自我对弈，无需人类棋谱

这个演进过程显示，AI 最终可以完全依靠自我学习达到超人类水平。

---

AlphaGo 的时代在 2017 年结束，但它开创的技术和理念继续影响着围棋和人工智能领域。接下来的 KataGo 时代，让这些技术走进了每一个围棋爱好者的电脑和手机。

下一篇：[KataGo 时代](/docs/learn/history/ai-history/katago-era)
