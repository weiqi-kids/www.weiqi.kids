---
sidebar_position: 1
title: 给想深入研究的人
description: 进阶主题导览：神经网络、MCTS、训练、优化、部署
---

# 给想深入研究的人

这个章节适合想要深入研究围棋 AI 的工程师，涵盖技术实现、理论基础与实务应用。

---

## 文章总览

### 核心技术

| 文章 | 说明 |
|------|------|
| [神经网络架构详解](./neural-network) | KataGo 的残差网络、输入特征、多头输出设计 |
| [MCTS 实现细节](./mcts-implementation) | PUCT 选择、虚拟损失、批量评估、并行化 |
| [KataGo 训练机制解析](./training) | 自我对弈、损失函数、训练循环 |

### 性能优化

| 文章 | 说明 |
|------|------|
| [GPU 后端与优化](./gpu-optimization) | CUDA、OpenCL、Metal 后端比较与调优 |
| [模型量化与部署](./quantization-deploy) | FP16、INT8、TensorRT、各平台部署 |
| [评估与基准测试](./evaluation) | Elo 评分、对局测试、SPRT 统计方法 |

### 进阶主题

| 文章 | 说明 |
|------|------|
| [分布式训练架构](./distributed-training) | Self-play Worker、数据收集、模型发布 |
| [自定义规则与变体](./custom-rules) | 中国、日本、AGA 规则，棋盘大小变体 |
| [关键论文导读](./papers) | AlphaGo、AlphaZero、KataGo 论文重点解析 |

### 开源与实现

| 文章 | 说明 |
|------|------|
| [KataGo 源代码导读](./source-code) | 目录结构、核心模块、代码风格 |
| [参与开源社区](./contributing) | 贡献方式、分布式训练、社区参与 |
| [从零打造围棋 AI](./build-from-scratch) | 一步步实现简易版 AlphaGo Zero |

---

## 你想做什么？

| 目标 | 建议路径 |
|------|---------|
| 理解神经网络设计 | [神经网络架构详解](./neural-network) → [MCTS 实现细节](./mcts-implementation) |
| 优化执行性能 | [GPU 后端与优化](./gpu-optimization) → [模型量化与部署](./quantization-deploy) |
| 研究训练方法 | [KataGo 训练机制解析](./training) → [分布式训练架构](./distributed-training) |
| 理解论文原理 | [关键论文导读](./papers) → [神经网络架构详解](./neural-network) |
| 动手写程序 | [从零打造围棋 AI](./build-from-scratch) → [KataGo 源代码导读](./source-code) |
| 参与开源项目 | [参与开源社区](./contributing) → [KataGo 源代码导读](./source-code) |

---

## 进阶概念索引

深入研究时，你会接触到以下进阶概念：

### F 系列：缩放（8 个）

| 编号 | 围棋概念 | 物理/数学对应 |
|------|---------|--------------|
| F1 | 棋盘大小 vs 复杂度 | 复杂度缩放 |
| F2 | 网络大小 vs 棋力 | 容量缩放 |
| F3 | 训练时间 vs 收益 | 收益递减律 |
| F4 | 数据量 vs 泛化 | 样本复杂度 |
| F5 | 计算资源缩放 | 缩放定律 |
| F6 | 神经缩放律 | 双对数关系 |
| F7 | 大批量训练 | 临界批量 |
| F8 | 参数效率 | 压缩界限 |

### G 系列：维度（6 个）

| 编号 | 围棋概念 | 物理/数学对应 |
|------|---------|--------------|
| G1 | 高维表示 | 向量空间 |
| G2 | 维度灾难 | 高维困境 |
| G3 | 流形假设 | 低维流形 |
| G4 | 中间表示 | 隐空间 |
| G5 | 特征解耦 | 独立成分 |
| G6 | 语义方向 | 几何代数 |

### H 系列：强化学习（9 个）

| 编号 | 围棋概念 | 物理/数学对应 |
|------|---------|--------------|
| H1 | MDP | 马尔可夫链 |
| H2 | 贝尔曼方程 | 动态规划 |
| H3 | 价值迭代 | 不动点定理 |
| H4 | 策略梯度 | 随机优化 |
| H5 | 经验回放 | 重要性采样 |
| H6 | 折扣因子 | 时间偏好 |
| H7 | TD 学习 | 增量估计 |
| H8 | 优势函数 | 基线减方差 |
| H9 | PPO 裁剪 | 信赖域 |

### K 系列：优化方法（6 个）

| 编号 | 围棋概念 | 物理/数学对应 |
|------|---------|--------------|
| K1 | SGD | 随机逼近 |
| K2 | 动量 | 惯性 |
| K3 | Adam | 自适应步长 |
| K4 | 学习率衰减 | 退火 |
| K5 | 梯度裁剪 | 饱和限制 |
| K6 | SGD 噪声 | 随机扰动 |

### L 系列：泛化与稳定（5 个）

| 编号 | 围棋概念 | 物理/数学对应 |
|------|---------|--------------|
| L1 | 过拟合 | 过度适应 |
| L2 | 正则化 | 约束优化 |
| L3 | Dropout | 稀疏激活 |
| L4 | 数据增强 | 对称破缺 |
| L5 | 早停 | 最优停止 |

---

## 硬件需求

### 阅读与学习

无特殊需求，任何电脑都可以。

### 训练模型

| 规模 | 建议硬件 | 训练时间 |
|------|---------|---------|
| 迷你（b6c96） | GTX 1060 6GB | 数小时 |
| 小型（b10c128） | RTX 3060 12GB | 1-2 天 |
| 中型（b18c384） | RTX 4090 24GB | 1-2 周 |
| 完整（b40c256） | 多 GPU 集群 | 数周 |

### 分布式训练贡献

- 任何有 GPU 的电脑都可以参与
- 建议至少 GTX 1060 或同等级
- 需要稳定的网络连接

---

## 开始阅读

**推荐从这里开始：**

- 想了解原理？→ [神经网络架构详解](./neural-network)
- 想动手实现？→ [从零打造围棋 AI](./build-from-scratch)
- 想读论文？→ [关键论文导读](./papers)
