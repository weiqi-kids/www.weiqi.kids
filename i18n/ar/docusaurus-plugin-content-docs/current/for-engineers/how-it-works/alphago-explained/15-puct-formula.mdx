---
sidebar_position: 16
title: ุดุฑุญ ุชูุตููู ููุนุงุฏูุฉ PUCT
description: ููู ุนููู ูุขููุฉ ุงูุงุฎุชูุงุฑ ุงูุฃุณุงุณูุฉ ูู AlphaGo - ุงููุจุงุฏุฆ ุงูุฑูุงุถูุฉ ููุนุงุฏูุฉ PUCT ูุฎุจุฑุฉ ุถุจุท ุงููุนุงููุงุช
---

import { MCTSTree } from '@site/src/components/D3Charts';

# ุดุฑุญ ุชูุตููู ููุนุงุฏูุฉ PUCT

ูู ุงูููุงู ุงูุณุงุจูุ ุงุณุชุนุฑุถูุง ุฏูุฌ MCTS ูุน ุงูุดุจูุงุช ุงูุนุตุจูุฉ. ุงูุขูุ ุฏุนููุง ูุชุนูู ูู ุฌููุฑ ูุฑุญูุฉ ุงูุงุฎุชูุงุฑ ูู MCTS โ **ูุนุงุฏูุฉ PUCT**.

ูุฐู ุงููุนุงุฏูุฉ ุชุจุฏู ุจุณูุทุฉุ ููููุง ูู ููุงุชูุญ ูุฌุงุญ AlphaGo. ุฅููุง ุชูุงุฒู ุจุฃูุงูุฉ ุจูู ูุฏููู ูุจุฏูุงู ูุชูุงูุถูู: "ุงุณุชุบูุงู ุงูุญุฑูุงุช ุงูุฌูุฏุฉ ุงููุนุฑููุฉ" ู"ุงุณุชูุดุงู ุงูุญุฑูุงุช ุงูุชู ูุฏ ุชููู ุฃูุถู".

---

## ูุนุงุฏูุฉ PUCT

### ุชุนุฑูู ุงููุนุงุฏูุฉ

ูุนุงุฏูุฉ **PUCT (Predictor Upper Confidence Trees)** ุงููุณุชุฎุฏูุฉ ูู AlphaGo:

$$a^* = \arg\max_a \left[ Q(s,a) + U(s,a) \right]$$

ุญูุซ:

$$U(s,a) = c_{\text{puct}} \cdot P(s,a) \cdot \frac{\sqrt{N(s)}}{1 + N(s,a)}$$

ุงูุชูุณูุน ุงููุงูู:

$$a^* = \arg\max_a \left[ Q(s,a) + c_{\text{puct}} \cdot P(s,a) \cdot \frac{\sqrt{N(s)}}{1 + N(s,a)} \right]$$

### ุดุฑุญ ุงูุฑููุฒ

| ุงูุฑูุฒ | ุงููุนูู | ุงููุตุฏุฑ |
|------|------|------|
| $Q(s,a)$ | ูุชูุณุท ูููุฉ ุงูุฅุฌุฑุงุก $a$ | ุฅุญุตุงุฆูุงุช MCTS |
| $P(s,a)$ | ุงูุงุญุชูุงููุฉ ุงููุณุจูุฉ ููุฅุฌุฑุงุก $a$ | Policy Network |
| $N(s)$ | ุนุฏุฏ ุฒูุงุฑุงุช ุงูุนูุฏุฉ ุงูุฃุจ | ุฅุญุตุงุฆูุงุช MCTS |
| $N(s,a)$ | ุนุฏุฏ ุฒูุงุฑุงุช ุงูุนูุฏุฉ ุงูุงุจู | ุฅุญุตุงุฆูุงุช MCTS |
| $c_{\text{puct}}$ | ุซุงุจุช ุงูุงุณุชูุดุงู | ูุนุงูู ูุงุฆู |

### ุงูููู ุงูุญุฏุณู

ูุนุงุฏูุฉ PUCT ูููู ุชูุณูููุง ุฅูู ุฌุฒุฆูู:

```
ุงูุฏุฑุฌุฉ ุงููููุฉ = Q(s,a)        + U(s,a)
               โ              โ
             ุนูุตุฑ ุงูุงุณุชุบูุงู    ุนูุตุฑ ุงูุงุณุชูุดุงู
           "ูุง ูุฏู ุฌูุฏุฉ ูุฐู ุงูุญุฑูุฉุ"   "ูู ุชุณุชุญู ูุฒูุฏุงู ูู ุงูุงุณุชูุดุงูุ"
```

**ุนูุตุฑ ุงูุงุณุชุบูุงู Q(s,a)**:
- ุงูุฃุฏุงุก ุงููุชูุณุท ุงูุณุงุจู ููุฐู ุงูุญุฑูุฉ
- ูููุง ุฒุงุฏุช ุงูุฒูุงุฑุงุชุ ุฒุงุฏุช ุฏูุฉ ุงูุชูุฏูุฑ
- ูุดุฌุน ุนูู ุงุฎุชูุงุฑ ุงูุญุฑูุงุช "ุงููุนุฑููุฉ ุจุฃููุง ุฌูุฏุฉ"

**ุนูุตุฑ ุงูุงุณุชูุดุงู U(s,a)**:
- ูู ูู ูููุฉ ุงูุงุณุชูุดุงู ุงููุชุจููุฉ ููุฐู ุงูุญุฑูุฉ
- ูููุง ููุช ุงูุฒูุงุฑุงุชุ ุฒุงุฏุช ููุงูุฃุฉ ุงูุงุณุชูุดุงู
- ูุดุฌุน ุนูู ุชุฌุฑุจุฉ ุงูุญุฑูุงุช "ุงูุชู ูุฏ ุชููู ุฌูุฏุฉ"

---

## ูุนูู ูู ุนูุตุฑ

### Q(s,a): ูุชูุณุท ุงููููุฉ

$Q(s,a)$ ูู ูุชูุณุท ูุชุงุฆุฌ ุฌููุน ุงููุญุงูุงุงุช ูู ุงูุนูุฏุฉ $(s,a)$:

$$Q(s,a) = \frac{W(s,a)}{N(s,a)} = \frac{\sum_i z_i}{N(s,a)}$$

ุญูุซ $z_i \in \{-1, +1\}$ ูู ูุชูุฌุฉ ุงููุญุงูุงุฉ $i$.

**ุงูุฎุตุงุฆุต**:
- ุงููุทุงู: $[-1, +1]$
- ุงููููุฉ ุงูุฃูููุฉ: ุบูุฑ ูุญุฏุฏุฉ (ุชุญุชุงุฌ ุฒูุงุฑุฉ ูุงุญุฏุฉ ุนูู ุงูุฃูู)
- ุชุณุชูุฑ ูุน ุฒูุงุฏุฉ ุนุฏุฏ ุงูุฒูุงุฑุงุช

**ุงูุชูุณูุฑ**:
- $Q = 0.6$: ูุณุจุฉ ููุฒ ูุฐู ุงูุญุฑูุฉ ุญูุงูู 80% (ูุฃู $Q = 2 \times \text{ูุณุจุฉ ุงูููุฒ} - 1$)
- $Q = 0$: ุชุนุงุฏู ุงูููุฒ ูุงูุฎุณุงุฑุฉ
- $Q = -0.3$: ูุณุจุฉ ููุฒ ูุฐู ุงูุญุฑูุฉ ุญูุงูู 35%

### P(s,a): ุงูุงุญุชูุงููุฉ ุงููุณุจูุฉ

$P(s,a)$ ุชุฃุชู ูู ุฅุฎุฑุงุฌ Policy Network:

$$P(s,a) = \pi_\theta(a|s)$$

**ุงูุฎุตุงุฆุต**:
- ุงููุทุงู: $[0, 1]$ุ ู $\sum_a P(s,a) = 1$
- ุชูุญุณุจ ุนูุฏ ุฃูู ุชูุณูุน ููุนูุฏุฉ
- ุชุนูุณ ุญูู ุงูุดุจูุฉ ุงูุนุตุจูุฉ ุนูู "ูุฏู ุฌูุฏุฉ ูุฐู ุงูุญุฑูุฉ"

**ุงูุฏูุฑ**:
- ุงูุฅุฌุฑุงุกุงุช ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุนุงููุฉ ุชูุณุชูุดู ุฃููุงู
- ุญุชู ูู ูุงู ุนุฏุฏ ุงูุฒูุงุฑุงุช 0ุ ููุงู ุฏุงูุน ููุงุณุชูุดุงู
- ุชูุฌู ุงูุจุญุซ ููุชุฑููุฒ ุนูู ุงูุญุฑูุงุช "ุงูุชู ุชุจุฏู ููุทููุฉ"

### N(s) ู N(s,a): ุนุฏุฏ ุงูุฒูุงุฑุงุช

$N(s)$ ูู ุฅุฌูุงูู ุนุฏุฏ ุฒูุงุฑุงุช ุงูุนูุฏุฉ ุงูุฃุจ:

$$N(s) = \sum_a N(s,a)$$

**ุฏูุฑ ุนูุตุฑ ุงูุงุณุชูุดุงู**:

$$\frac{\sqrt{N(s)}}{1 + N(s,a)}$$

ุณููู ูุฐุง ุงููุณุฑ:
- ุนูุฏูุง $N(s,a) = 0$ุ ุงูุฏุฑุฌุฉ = $\sqrt{N(s)}$ (ุฃูุตู ุฏุงูุน ููุงุณุชูุดุงู)
- ูุน ุฒูุงุฏุฉ $N(s,a)$ุ ุงูุฏุฑุฌุฉ ุชูุฎูุถ
- ุนูุฏูุง $N(s,a) \gg \sqrt{N(s)}$ุ ุงูุฏุฑุฌุฉ ุชูุชุฑุจ ูู 0

ูุฐุง ูุถูู:
1. **ูู ุฅุฌุฑุงุก ููุณุชูุดู ูุฑุฉ ูุงุญุฏุฉ ุนูู ุงูุฃูู** (ุฅุฐุง ูุงู $P(s,a) > 0$)
2. **ุฏุงูุน ุงูุงุณุชูุดุงู ูุชูุงูุต ูุน ุงูุฒูุงุฑุงุช**
3. **ุงูุงุฎุชูุงุฑ ุงูููุงุฆู ุชูููู ุนููู ูููุฉ $Q$**

### c_puct: ุซุงุจุช ุงูุงุณุชูุดุงู

$c_{\text{puct}}$ ูุชุญูู ูู ุงูุชูุงุฒู ุจูู ุงูุงุณุชูุดุงู ูุงูุงุณุชุบูุงู:

| ูููุฉ $c_{\text{puct}}$ | ุงูุชุฃุซูุฑ |
|-------------------|------|
| ุตุบูุฑุฉ (ูุซู 0.5) | ููู ุฃูุซุฑ ููุงุณุชุบูุงูุ ุชุฑููุฒ ุณุฑูุน ุนูู ุงูุญุฑูุงุช ุงูุฌูุฏุฉ |
| ูุชูุณุทุฉ (ูุซู 1-2) | ุชูุงุฒู ุงูุงุณุชูุดุงู ูุงูุงุณุชุบูุงู |
| ูุจูุฑุฉ (ูุซู 5) | ููู ุฃูุซุฑ ููุงุณุชูุดุงูุ ุชุฌุฑุจุฉ ุงููุฒูุฏ ูู ุงูุงุญุชูุงูุงุช |

ุงููููุฉ ุงููุณุชุฎุฏูุฉ ูู AlphaGo: $c_{\text{puct}} = 1.5$ (ุญุณุจ ุงููุฑูุฉ ุงูุจุญุซูุฉ).

---

## ุงูุนูุงูุฉ ูุน UCB1

### ูุฑุงุฌุนุฉ ูุนุงุฏูุฉ UCB1

ูุนุงุฏูุฉ **UCB1** ุงููุณุชุฎุฏูุฉ ูู MCTS ุงูุชูููุฏู:

$$\text{UCB1}(s,a) = \bar{X}_{s,a} + c \sqrt{\frac{\ln N(s)}{N(s,a)}}$$

ุญูุซ $\bar{X}_{s,a}$ ูู ูุชูุณุท ุงูุนุงุฆุฏ.

### ุงูููุงุฑูุฉ

| ุงูุฌุงูุจ | UCB1 | PUCT |
|------|------|------|
| ุนูุตุฑ ุงูุงุณุชุบูุงู | $\bar{X}_{s,a}$ (ูุชูุณุท ุงูุนุงุฆุฏ) | $Q(s,a)$ (ูุชูุณุท ุงููููุฉ) |
| ุนูุตุฑ ุงูุงุณุชูุดุงู | $\sqrt{\frac{\ln N}{n}}$ (ุญุฏูุฏ ุงูุซูุฉ) | $P \cdot \frac{\sqrt{N}}{1+n}$ (ุฅุฑุดุงุฏ ูุณุจู) |
| ูุนูููุงุช ูุณุจูุฉ | ูุง ููุฌุฏ | ูุณุชุฎุฏู Policy Network |
| ุชูุงูุต ุงูุงุณุชูุดุงู | ุชูุงูุต ููุบุงุฑูุชูู | ุชูุงูุต ุฎุทู |

### ูุฒุงูุง PUCT

1. **ุงุณุชุฎุฏุงู ุงููุนุฑูุฉ ุงููุณุจูุฉ**: $P(s,a)$ ูู Policy Network ุชุฌุนู ุงูุจุญุซ ูุฑูุฒ ูู ุงูุจุฏุงูุฉ ุนูู ุงูุญุฑูุงุช ุงูููุทููุฉ

2. **ุชูุงุฑุจ ุฃุณุฑุน**: ุงูุชูุงูุต ุงูุฎุทู ($1/(1+n)$) ุฃุณุฑุน ูู ุงูุชูุงูุต ุงูููุบุงุฑูุชูู ($1/\sqrt{\ln N / n}$) ูู ุชุฑููุฒ ุงูุจุญุซ

3. **ุงุณุชูุดุงู ูุงุจู ููุชุญูู**: $P(s,a)$ ู $c_{\text{puct}}$ ุชููุฑุงู ูุณุงุฆู ุฃูุซุฑ ููุชุญูู ูู ุงูุงุณุชูุดุงู

### ุงูุฎูููุฉ ุงููุธุฑูุฉ

UCB1 ููุง ุถูุงูุงุช ูุธุฑูุฉ ุตุงุฑูุฉ (ุญุฏูุฏ ุงููุฏู)ุ ููู ูุฐู ุงูุถูุงูุงุช ุชูุชุฑุถ:
- ูู ุฐุฑุงุน (ุฅุฌุฑุงุก) ูุณุชูู
- ูุง ุชูุฌุฏ ูุนูููุงุช ูุณุจูุฉ

ูู ุงูุบูุ ูุฏููุง ูุนุฑูุฉ ูุณุจูุฉ ูููุฉ (Policy Network)ุ ูPUCT ุชุณุชุทูุน ุงุณุชุบูุงู ูุฐู ุงููุนูููุงุช ุจุดูู ุฃูุถู.

---

## ุงูุงุดุชูุงู ุงูุฑูุงุถู

### ุจุฏุกุงู ูู ูุดููุฉ ุงููุตูุต ูุชุนุฏุฏู ุงูุฃุฐุฑุน

ุฅููุงู PUCT ูุฃุชู ูู ูุดููุฉ **ุงููุตูุต ูุชุนุฏุฏู ุงูุฃุฐุฑุน (Multi-Armed Bandit)**.

ุชุฎูู ุฃู ุฃูุงูู $K$ ูุงูููุฉ ููุงุฑุ ูู ูุงุญุฏุฉ ููุง ุงุญุชูุงููุฉ ููุฒ ูุฎุชููุฉ ููู ุบูุฑ ูุนุฑููุฉ. ูุฏูู ูู ุชุนุธูู ุฅุฌูุงูู ุนุฏุฏ ุงูููุฒ. ุงูุงุณุชุฑุงุชูุฌูุฉ ูู:
- **ุงูุงุณุชุบูุงู**: ุณุญุจ ุงููุงูููุฉ ุงูุชู ุชุจุฏู ุงูุฃูุถู
- **ุงูุงุณุชูุดุงู**: ุชุฌุฑุจุฉ ูุงูููุงุช ุฃุฎุฑูุ ูุฏ ุชุฌุฏ ุฃูุถู

UCB1 ูู ุงูุญู ุงูููุงุณููู ููุฐู ุงููุดููุฉุ ูPUCT ูู ุชูููุนุฉ ูููุง.

### ุงูุฃุณุงุณ ุงููุธุฑู ูู UCB

ูููุชุบูุฑ ุงูุนุดูุงุฆู $X$ุ ูู ูุชุฑุงุฌุญุฉ ูููุฏููุฌ:

$$P(|\bar{X}_n - \mu| \geq \epsilon) \leq 2 \exp(-2n\epsilon^2)$$

ุฅุฐุง ุฃุฑุฏูุง ุงูุฎุทุฃ ุจุงุญุชูุงู $1/t^4$ุ ูุญุชุงุฌ:

$$\epsilon = \sqrt{\frac{2 \ln t}{n}}$$

ูุฐุง ูู ูุตุฏุฑ ุนูุตุฑ ุงูุงุณุชูุดุงู ูู UCB1.

### ุชุนุฏููุงุช PUCT

PUCT ุชุฌุฑู ุนุฏุฉ ุชุนุฏููุงุช ุนูู UCB ุงูููุงุณููู:

**1. ุฅุถุงูุฉ ุงูุงุญุชูุงููุฉ ุงููุณุจูุฉ**

$$U(s,a) \propto P(s,a) \cdot (\text{ุนูุตุฑ ุงูุงุณุชูุดุงู})$$

ูุฐุง ูุฑูุฒ ุงูุงุณุชูุดุงู ุนูู ุงูุฅุฌุฑุงุกุงุช ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุนุงููุฉ.

**2. ุชุบููุฑ ุดูู ุนูุตุฑ ุงูุงุณุชูุดุงู**

ูู $\sqrt{\frac{\ln N}{n}}$ ุฅูู $\frac{\sqrt{N}}{1+n}$

ูุฐุง ูุณุฑูุน ุงูุชูุงุฑุจ:

```
ุงูููุงุฑูุฉ (ุจูุฑุถ N = 1000, n = 10):

UCB1:  sqrt(ln(1000) / 10) = sqrt(0.69) โ 0.83
PUCT:  sqrt(1000) / 11 โ 2.87

PUCT ุชุนุทู ููุงูุฃุฉ ุงุณุชูุดุงู ุฃูุซุฑุ ููููุง ุชุชูุงูุต ุฃุณุฑุน
```

**3. ูุนุฑูุฉ ูุณุจูุฉ ูุงุจูุฉ ููุชุนูู**

$P(s,a)$ ุชุฃุชู ูู ุงูุดุจูุฉ ุงูุนุตุจูุฉุ ูุชุชุญุณู ูุน ุงูุชุฏุฑูุจ. ูุฐุง ูุฌุนู MCTS ูุงูุดุจูุฉ ุงูุนุตุจูุฉ ุชุดููุงู ุฏูุฑุฉ ุฅูุฌุงุจูุฉ.

### ููุงุฐุง ูุฐุง ุงูุดูู ูุนุงูุ

ุงูุชูุณูุฑ ุงูุญุฏุณู:

$$U(s,a) = c_{\text{puct}} \cdot P(s,a) \cdot \frac{\sqrt{N(s)}}{1 + N(s,a)}$$

1. **$P(s,a)$**: "ุงูุฎุจูุฑ ูููู ูุฐู ุงูุญุฑูุฉ ุจูุฐุง ุงููุณุชูู ูู ุงูุฌูุฏุฉ"
2. **$\sqrt{N(s)}$**: "ูู ูุนุฑู ุนู ูุฐุง ุงููุถุน"
3. **$1/(1 + N(s,a))$**: "ูู ูุนุฑู ุนู ูุฐู ุงูุญุฑูุฉ"

ูุฌุชูุนุฉ: **ุนูุฏูุง ูุนุฑู ุงููุซูุฑ ุนู ุงููุถุนุ ููู ุงููููู ุนู ุญุฑูุฉ ูุนููุฉุ ูุงูุฎุจูุฑ ูุนุชูุฏ ุฃููุง ุฌูุฏุฉุ ูุฌุจ ุงุณุชูุดุงููุง**.

---

## ุงูููู ุงูุจุตุฑู

### ุชุบูุฑ ุนูุตุฑ ุงูุงุณุชูุดุงู

ุฏุนููุง ูุชุตูุฑ ููู ูุชุบูุฑ ุนูุตุฑ ุงูุงุณุชูุดุงู ูุน ุนุฏุฏ ุงูุฒูุงุฑุงุช:

```
U(s,a) = c_puct ร P(s,a) ร โN(s) / (1 + N(s,a))

ุจูุฑุถ P(s,a) = 0.1, c_puct = 1.5, N(s) = 1600

N(s,a)  |  U(s,a)
--------|----------
   0    |  6.00      โ ุบูุฑ ูุฒุงุฑุ ุฃูุตู ููุงูุฃุฉ ุงุณุชูุดุงู
   1    |  3.00
   5    |  1.00
  10    |  0.55
  50    |  0.12
 100    |  0.06
 400    |  0.015     โ ุจุนุฏ ุฒูุงุฑุงุช ูุซูุฑุฉุ ููุงูุฃุฉ ุงูุงุณุชูุดุงู ุตุบูุฑุฉ ุฌุฏุงู
```

### ุชุฃุซูุฑ ุงูุงุญุชูุงููุงุช ุงููุณุจูุฉ ุงููุฎุชููุฉ

```
ุจูุฑุถ c_puct = 1.5, N(s) = 1600, N(s,a) = 0

P(s,a)  |  U(s,a)
--------|----------
  0.30  |  18.00     โ ุงูุฅุฌุฑุงุกุงุช ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูุนุงููุฉ ููุง ุฏุงูุน ุงุณุชูุดุงู ุฃูุจุฑ
  0.10  |   6.00
  0.03  |   1.80
  0.01  |   0.60
  0.001 |   0.06     โ ุงูุฅุฌุฑุงุกุงุช ุฐุงุช ุงูุงุญุชูุงููุฉ ุงูููุฎูุถุฉ ุชูุงุฏ ูุง ุชูุณุชูุดู
```

### ุงูุงุณุชูุดุงู ุงูุชูุงุนูู

ุฌุฑุจ ุถุจุท ูุนุงูู $c_{\text{puct}}$ ุฃุฏูุงูุ ูุฑุงูุจ ููู ูุคุซุฑ ุนูู ุงุฎุชูุงุฑ MCTS:

<MCTSTree width={700} height={450} showPUCT={true} interactive={true} cPuct={1.5} />

---

## ุงูุชูููุฐ ุงููุนูู ูู AlphaGo

### ุชูููุฐ AlphaGo Fan/Lee

ุงููุณุฎุฉ ุงูุฃุตููุฉ ูู AlphaGo ุชุณุชุฎุฏู ูุนุงุฏูุฉ ูุฎุชููุฉ ููููุงู:

$$U(s,a) = c_{\text{puct}} \cdot P(s,a) \cdot \frac{\sqrt{\sum_b N(s,b)}}{1 + N(s,a)}$$

ูุญุณุงุจ $Q(s,a)$ ูุฃุฎุฐ ุงูุฎุณุงุฑุฉ ุงูุงูุชุฑุงุถูุฉ ุจุนูู ุงูุงุนุชุจุงุฑ:

```python
def get_ucb_score(node, action, c_puct=1.5):
    Q = node.W[action] / (node.N[action] + 1)  # ุชุฌูุจ ุงููุณูุฉ ุนูู ุตูุฑ
    P = node.prior[action]
    N_parent = sum(node.N.values())
    N_child = node.N[action]

    U = c_puct * P * math.sqrt(N_parent) / (1 + N_child)

    return Q + U
```

### ุชูููุฐ AlphaGo Zero

AlphaGo Zero ูุณุชุฎุฏู ุชูููุฐุงู ุฃุจุณุท:

```python
def select_action(node, c_puct=1.5):
    """ุงุฎุชูุงุฑ ุงูุฅุฌุฑุงุก ุฐู ุฃุนูู ุฏุฑุฌุฉ PUCT"""
    N_parent = sum(node.visit_count.values())

    def puct_score(action):
        Q = node.value_sum[action] / (node.visit_count[action] + 1)
        P = node.prior[action]
        U = c_puct * P * math.sqrt(N_parent) / (1 + node.visit_count[action])
        return Q + U

    return max(node.legal_actions, key=puct_score)
```

### ูุนุงูุฌุฉ ุงูุนูุฏ ุบูุฑ ุงููุฒุงุฑุฉ

ุนูุฏูุง $N(s,a) = 0$ุ $Q(s,a)$ ุบูุฑ ูุญุฏุฏ. ุทุฑู ุงููุนุงูุฌุฉ ุงูุดุงุฆุนุฉ:

**ุงูุทุฑููุฉ 1: ุงุณุชุฎุฏุงู ูููุฉ ุงูุนูุฏุฉ ุงูุฃุจ**
```python
Q = parent_value if N[action] == 0 else W[action] / N[action]
```

**ุงูุทุฑููุฉ 2: ุงุณุชุฎุฏุงู ูููุฉ ุฃูููุฉ**
```python
Q = 0 if N[action] == 0 else W[action] / N[action]
```

**ุงูุทุฑููุฉ 3: ุงุณุชุฎุฏุงู FPU (First Play Urgency)**
```python
# ุงูุนูุฏ ุบูุฑ ุงููุฒุงุฑุฉ ุชุณุชุฎุฏู ูููุฉ Q ููุฎูุถุฉ
fpu_value = parent_Q - fpu_reduction
Q = fpu_value if N[action] == 0 else W[action] / N[action]
```

AlphaGo Zero ูุณุชุฎุฏู FPUุ ููุง ูุฌุนู ุงูุจุญุซ ูููู ุฃูุซุฑ ูุชุฌุฑุจุฉ ุงูุนูุฏ ุงูุชู ุชูุช ุฒูุงุฑุชูุง ุฃููุงู.

---

## ุฎุจุฑุฉ ุถุจุท ุงููุนุงููุงุช ุงูุนูููุฉ

### ุงุฎุชูุงุฑ c_puct

$c_{\text{puct}}$ ูู ุฃูู ูุนุงูู ูุงุฆู. ูุจุงุฏุฆ ุชูุฌูููุฉ ุนูููุฉ:

**1. ุนูุงูุชูุง ุจุฌูุฏุฉ ุงูุดุจูุฉ**
- ุงูุดุจูุฉ ูููุฉ (ุฏูุฉ ุนุงููุฉ): ูููู ุงุณุชุฎุฏุงู $c_{\text{puct}}$ ุฃุตุบุฑ
- ุงูุดุจูุฉ ุถุนููุฉ: ุชุญุชุงุฌ $c_{\text{puct}}$ ุฃูุจุฑ ูุชุตุญูุญ ุงูุฃุฎุทุงุก

**2. ุนูุงูุชูุง ุจููุฒุงููุฉ ุงูุจุญุซ**
- ุนุฏุฏ ูุญุงูุงุงุช ูุซูุฑ: ูููู ุงุณุชุฎุฏุงู $c_{\text{puct}}$ ุฃูุจุฑ (ููุช ูุงูู ููุงุณุชูุดุงู)
- ุนุฏุฏ ูุญุงูุงุงุช ูููู: ุงุณุชุฎุฏุงู $c_{\text{puct}}$ ุฃุตุบุฑ (ุชุฑููุฒ ุณุฑูุน)

**3. ุนูุงูุชูุง ุจุฎุตุงุฆุต ุงููุนุจุฉ**
- ุงูุฃูุนุงุจ ุงูุชูุชูููุฉ ุงููููุฉ: ูุฏ ุชุญุชุงุฌ ุงุณุชูุดุงูุงู ุฃูุซุฑ
- ุงูุฃูุนุงุจ ุงูุงุณุชุฑุงุชูุฌูุฉ ุงููููุฉ: ูููู ุงููุซูู ุฃูุซุฑ ุจุงููุนุฑูุฉ ุงููุณุจูุฉ

### ุงูููู ุงููููุฐุฌูุฉ

| ุงููุดุฑูุน | $c_{\text{puct}}$ |
|------|-------------------|
| AlphaGo | 1.5 |
| AlphaGo Zero | 1.0 - 2.0 |
| AlphaZero | 1.25 |
| KataGo | 0.5 - 1.0 (ุถุจุท ุฏููุงูููู) |
| Leela Zero | 1.5 - 2.0 |

### ุงูุถุจุท ุงูุฏููุงูููู

ุจุนุถ ุงูุชูููุฐุงุช ุงููุชูุฏูุฉ ุชุณุชุฎุฏู $c_{\text{puct}}$ ุฏููุงูููู:

```python
def dynamic_cpuct(visit_count):
    """ุถุจุท ุซุงุจุช ุงูุงุณุชูุดุงู ุญุณุจ ุนุฏุฏ ุงูุฒูุงุฑุงุช"""
    base = 1.0
    init = 1.5
    log_base = 19652  # ูุนุงูู ุงูุถุจุท

    return math.log((visit_count + log_base + 1) / log_base) + init
```

ูุฐุง ูุฌุนู ุงูุจุญุซ ูููู ููุงุณุชูุดุงู ูู ุงูุจุฏุงูุฉุ ูููุงุณุชุบูุงู ูู ุงูููุงูุฉ.

### ุชุญููู ุงูุญุณุงุณูุฉ

ุชุฃุซูุฑ $c_{\text{puct}}$ ุนูู ููุฉ ุงููุนุจ:

```
ุชุฌุฑุจุฉ (ุธุฑูู ุฃุฎุฑู ุซุงุจุชุฉุ ุชุบููุฑ c_puct):

c_puct | Elo ุงููุณุจู
-------|----------
  0.5  |   -50     โ ุงุณุชุบูุงู ููุฑุทุ ุชูููุช ุญุฑูุงุช ุฌูุฏุฉ
  1.0  |   +20
  1.5  |    0      โ ุงูุฃุณุงุณ
  2.0  |   -10
  3.0  |   -30     โ ุงุณุชูุดุงู ููุฑุทุ ุฅูุฏุงุฑ ุงูุจุญุซ
  5.0  |   -80
```

ุงููููุฉ ุงููุซูู ุนุงุฏุฉู ุจูู 1.0-2.0ุ ููููุง ุชุนุชูุฏ ุนูู ุฌูุฏุฉ ุงูุดุจูุฉ ูููุฒุงููุฉ ุงูุจุญุซ.

---

## ุงููุชุบูุฑุงุช ุงููุชูุฏูุฉ

### ูุชุบูุฑุงุช PUCT

**1. PUCT ูุชุนุฏุฏุฉ ุงูุญุฏูุฏ (Polynomial PUCT / P-UCT)**

$$U(s,a) = c \cdot P(s,a) \cdot \frac{N(s)^\alpha}{1 + N(s,a)}$$

ุญูุซ $\alpha$ ูุนุงูู ูุงุจู ููุถุจุท (ุนุงุฏุฉู $\alpha = 0.5$).

**2. PUCT ูุน ุงูุถูุถุงุก**

ุฅุถุงูุฉ ุถูุถุงุก ุฏูุฑููููู ูู ุงูุนูุฏุฉ ุงูุฌุฐุฑูุฉ:

$$P'(s,a) = (1-\varepsilon) P(s,a) + \varepsilon \cdot \eta_a$$

ุญูุซ $\eta \sim \text{Dir}(\alpha)$. ูุฐุง ูุฒูุฏ ุชููุน ุงูุงุณุชูุดุงู.

**3. PUCT ุดุจููุฉ ุจู UCT**

$$U(s,a) = c \cdot P(s,a) \cdot \sqrt{\frac{\ln(1 + N(s) + c_{\text{base}})}{1 + N(s,a)}}$$

ูุฐู ุชุฌูุน ุจูู ุงูุดูู ุงูููุบุงุฑูุชูู ูู UCT ูุงูุฅุฑุดุงุฏ ุงููุณุจู ูู PUCT.

### ุชุญุณููุงุช KataGo

KataGo ุฃุฌุฑุช ุนุฏุฉ ุชุญุณููุงุช ุนูู PUCT:

**1. $c_{\text{puct}}$ ุฏููุงูููู**
ุงูุถุจุท ุญุณุจ ุชุนููุฏ ุงููุถุน ูุชูุฏู ุงูุจุญุซ.

**2. ุนุฏู ุงููููู ูู ุชููุน ุงููููุฉ**
ุงูุฃุฎุฐ ุจุนูู ุงูุงุนุชุจุงุฑ ุซูุฉ Value Network ูู ุชูุจุคุงุชูุง.

**3. ุชุนูู ูุฏู ุงูุณูุงุณุฉ**
ุงูุชุนูู ุงููุจุงุดุฑ ูุชูุฒูุน ุฒูุงุฑุงุช MCTSุ ูููุณ ููุท ุฅุฎุฑุงุฌ ุฑุฃุณ ุงูุณูุงุณุฉ.

### ุตูุบ ุงุฎุชูุงุฑ ุฃุฎุฑู

ุจุฌุงูุจ PUCTุ ููุงู ุตูุบ ุงุฎุชูุงุฑ ุฃุฎุฑู:

**RAVE (Rapid Action Value Estimation)**

$$Q_{\text{RAVE}}(s,a) = (1-\beta) Q(s,a) + \beta Q_{\text{AMAF}}(s,a)$$

ุชุณุชุฎุฏู ุฅุญุตุงุฆูุงุช "All Moves As First" ูุชุณุฑูุน ุงูุชุนูู.

**GRAVE (Generalized RAVE)**

ูุชุบูุฑุฉ ูู RAVEุ ุชุณุชุฎุฏู ุฅุญุตุงุฆูุงุช ุงูุนูุฏ ุงูุณูููุฉ.

---

## ุงูุชุญููู ุงููุธุฑู

### ุงูุชูุงุฑุจ

ูู ุชุถูู PUCT ุงูุชูุงุฑุจ ุฅูู ุงูุญู ุงูุฃูุซูุ

**ุจุดูู ุตุงุฑู**: ูุง ููุฌุฏ ุถูุงู ูุธุฑู ูุซู UCB1.

**ุนูููุงู**: ุจุนุฏ ูุญุงูุงุงุช ูุงููุฉุ ุชุชูุงุฑุจ PUCT ุฅูู ุญู ุนุงูู ุงูุฌูุฏุฉุ ูุฃู:
1. ุนูุตุฑ ุงูุงุณุชูุดุงู ููุชุฑุจ ูู ุงูุตูุฑ ูู ุงูููุงูุฉ
2. ุฌููุน ุงูุฅุฌุฑุงุกุงุช ุชูุฒุงุฑ ูู ุงูููุงูุฉ
3. ููู $Q$ ุชุชูุงุฑุจ ุฅูู ุงููููุฉ ุงูุญููููุฉ

### ุชุญููู ุงูุชุนููุฏ

**ุชุนููุฏ ุงูููุช** (ููู ูุญุงูุงุฉ):
- ุงูุงุฎุชูุงุฑ: $O(\log N)$ (ุนูู ุงูุดุฌุฑุฉ)
- ุงูุชูุณูุน: $O(A)$ (ุนุฏุฏ ุงูุฅุฌุฑุงุกุงุช ุงููุงููููุฉุ ูุญุชุงุฌ ุงุณุชูุชุงุฌ ุดุจูุฉ ุนุตุจูุฉ)
- ุงูุชูููู: $O(1)$ (Value Network) ุฃู $O(T)$ (Rolloutุ $T$ ุทูู ุงููุนุจุฉ)
- ุงูุงูุชุดุงุฑ ุงูุนูุณู: $O(\log N)$

**ุชุนููุฏ ุงููุณุงุญุฉ**:
- ูู ุนูุฏุฉ: $O(A)$ (ุชุฎุฒูู ุงููุนุฑูุฉ ุงููุณุจูุฉ ูุฅุญุตุงุฆูุงุช ุงูุฒูุงุฑุงุช)
- ุงูุดุฌุฑุฉ ูุงููุฉ: $O(N \cdot A)$ ($N$ ุนุฏุฏ ุงูุนูุฏ)

### ุงูุนูุงูุฉ ูุน Minimax

ุนูุฏูุง $c_{\text{puct}} \to 0$ ูุนุฏุฏ ุงููุญุงูุงุงุช $\to \infty$ุ MCTS + PUCT ููุชุฑุจ ูู ุจุญุซ Minimax.

ููู ูู ููุฒุงููุฉ ูุญุฏูุฏุฉุ PUCT ุนุงุฏุฉู ุฃูุซุฑ ููุงุกุฉ ูู Minimax + Alpha-Betaุ ูุฃููุง ุชุณุชุทูุน ุงุณุชุบูุงู ุงููุนุฑูุฉ ุงููุณุจูุฉ ุจุดูู ุฃูุถู.

---

## ุงูุฃุณุฆูุฉ ุงูุดุงุฆุนุฉ

### ุณ: ููุงุฐุง ูุง ูุณุชุฎุฏู ุฅุฎุฑุงุฌ Policy Network ูุจุงุดุฑุฉ ูุงุฎุชูุงุฑุ

**ุฌ: Policy Network ูุฏ ุชุฎุทุฆ**. ุจุญุซ MCTS ูุณุชุทูุน:
1. ุงูุชุญูู ูู ุญูู ุงูุดุจูุฉ ุงูุนุตุจูุฉ
2. ุงูุชุดุงู ุญุฑูุงุช ุฌูุฏุฉ ุชุฌุงููุชูุง ุงูุดุจูุฉ ุงูุนุตุจูุฉ
3. ุชุตุญูุญ ุงูุชุญูุฒุงุช ุงููููุฌูุฉ ููุดุจูุฉ ุงูุนุตุจูุฉ

ุงูุชุฌุงุฑุจ ุชุธูุฑ ุฃูู ุญุชู ูุน ุดุจูุฉ ุนุตุจูุฉ ูููุฉุ ุฅุถุงูุฉ ุงูุจุญุซ ุชุญุณู ููุฉ ุงููุนุจ ุจุดูู ููุญูุธ.

### ุณ: ูู ุฃู ููุงูู ูููู ุฃุฏุงุก PUCT ุถุนููุงูุ

1. **ุงูุงุญุชูุงููุฉ ุงููุณุจูุฉ ุฎุงุทุฆุฉ ุชูุงูุงู**: ุฅุฐุง ููููุช Policy Network ุญุฑูุฉ ุฌูุฏุฉ ุจุงุญุชูุงููุฉ ููุฎูุถุฉุ PUCT ุชุญุชุงุฌ ูุญุงูุงุงุช ูุซูุฑุฉ ูุชุตุญูุญูุง

2. **ุงูุชูุชููุงุช ุทูููุฉ ุงููุฏู**: PUCT ูุฏ ุชุฌุฏ ุตุนูุจุฉ ูู ุงูุชุดุงู ุชุณูุณูุงุช ุชูุชูููุฉ ุทูููุฉ ุชุชุทูุจ ุญุณุงุจุงู ุฏูููุงู

3. **ุบูุงุจ ูููุฐุฌ ุงูุฎุตู**: PUCT ุชูุชุฑุถ ุฃู ุงูุฎุตู ูุณุชุฎุฏู ุฃูุถุงู ุงูุงุณุชุฑุงุชูุฌูุฉ ุงููุซููุ ูุฏ ูุง ุชููู ุงูุฃูุซู ุฃูุงู ุฎุตู ุบูุฑ ููุทูู

### ุณ: ููู ูุชุนุงูู ูุน ูุถุงุกุงุช ุงูุฅุฌุฑุงุกุงุช ุงูุถุฎูุฉุ

ุจุนุถ ุงูุชูููุงุช:
1. **ุชุตููุฉ Policy Network**: ููุท ุงููุธุฑ ูู ุงูุฅุฌุฑุงุกุงุช ุญูุซ $P(s,a) > \epsilon$
2. **ุงูุชูุณูุน ุงูุชุฏุฑูุฌู**: ุชูุณูุน ุนุฏุฏ ูููู ูู ุงูุฅุฌุฑุงุกุงุช ุฃููุงูุ ุซู ุงูุชูุณูุน ุนูุฏ ุงูุญุงุฌุฉ
3. **ุงูุชูููู ุงูุฏููุงูููู**: ุฅุฒุงูุฉ ุงูุฅุฌุฑุงุกุงุช ุงููุงุถุญุฉ ุงูุณูุฆุฉ

---

## ุชุทุงุจู ุงูุฑุณูู ุงููุชุญุฑูุฉ

ุงูููุงููู ุงูุฃุณุงุณูุฉ ูู ูุฐู ุงูููุงูุฉ ูุฑูู ุงูุฑุณูู ุงููุชุญุฑูุฉ ุงูููุงุจู:

| ุงูุฑูู | ุงูููููู | ุงูุชุทุงุจู ุงูููุฒูุงุฆู/ุงูุฑูุงุถู |
|------|------|--------------|
| ๐ฌ E4 | ุงูุงุณุชูุดุงู ูุงูุงุณุชุบูุงู | ุงููุตูุต ูุชุนุฏุฏู ุงูุฃุฐุฑุน |
| ๐ฌ C3 | ุงุฎุชูุงุฑ PUCT | ุญุฏูุฏ ุงูุซูุฉ |

---

## ุงูููุฎุต

ูุนุงุฏูุฉ PUCT ูู ุฌููุฑ MCTS ูู AlphaGoุ ุชุนูููุง:

1. **ูููู ุงููุนุงุฏูุฉ**: $Q + U$ุ ุนูุตุฑ ุงูุงุณุชุบูุงู ุฒุงุฆุฏ ุนูุตุฑ ุงูุงุณุชูุดุงู
2. **ูุนูู ูู ุนูุตุฑ**: $Q$ ูู ูููุฉ ุงูุฎุจุฑุฉุ $P$ ูู ุงูุงุญุชูุงููุฉ ุงููุณุจูุฉุ $N$ ูุชุญูู ูู ุชูุงูุต ุงูุงุณุชูุดุงู
3. **ุงูุนูุงูุฉ ูุน UCB1**: PUCT ุชุถูู ูุนุฑูุฉ ูุณุจูุฉ ูุชุณุชุฎุฏู ุดูู ุนูุตุฑ ุงุณุชูุดุงู ูุฎุชูู
4. **ุงูุงุดุชูุงู ุงูุฑูุงุถู**: ูู ุงููุตูุต ูุชุนุฏุฏู ุงูุฃุฐุฑุน ุฅูู ุงุฎุชูุงุฑ MCTS
5. **ุถุจุท ุงููุนุงููุงุช ุงูุนููู**: ุงุฎุชูุงุฑ ูุชุฃุซูุฑ $c_{\text{puct}}$
6. **ุงููุชุบูุฑุงุช ุงููุชูุฏูุฉ**: ุงูุถุจุท ุงูุฏููุงููููุ ุงูุถูุถุงุกุ ุชุญุณููุงุช KataGo

ุฃูุงูุฉ PUCT ุชููู ูู ุจุณุงุทุชูุง ููุนุงููุชูุง โ ูุนุงุฏูุฉ ูุงุญุฏุฉ ุชูุงุฒู ุจูู ุงูุงุณุชูุดุงู ูุงูุงุณุชุบูุงูุ ูุชุฏูุฌ ุจุฃูุงูุฉ ุงููุนุฑูุฉ ุงููุณุจูุฉ ูู ุงูุดุจูุฉ ุงูุนุตุจูุฉ.

---

## ูุฑุงุกุฉ ููุณุนุฉ

- **ุงูููุงู ุงูุชุงูู**: [ูุธุฑุฉ ุนุงูุฉ ุนูู AlphaGo Zero](./16-alphago-zero) โ ุงูุงุฎุชุฑุงู ูู ุงูุตูุฑ
- **ุงูููุงู ุงูุณุงุจู**: [ุฏูุฌ MCTS ูุน ุงูุดุจูุงุช ุงูุนุตุจูุฉ](./14-mcts-neural-combo) โ ุงูุจููุฉ ุงููููุฉ
- **ุฐู ุตูุฉ**: [ุญุฏูุฏ ุงูุทุฑู ุงูุชูููุฏูุฉ](./05-traditional-limits) โ ููุงุฐุง ูุญุชุงุฌ ุทุฑูุงู ุฌุฏูุฏุฉ

---

## ุงููุฑุงุฌุน

1. Rosin, C. D. (2011). "Multi-armed bandits with episode context." *Annals of Mathematics and Artificial Intelligence*, 61(3), 203-230.
2. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
3. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 550, 354-359.
4. Kocsis, L., & Szepesvรกri, C. (2006). "Bandit based Monte-Carlo Planning." *ECML*.
5. Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). "Finite-time analysis of the multiarmed bandit problem." *Machine Learning*, 47(2), 235-256.
6. Wu, D., et al. (2019). "Accelerating Self-Play Learning in Go." *arXiv preprint* (ุชูุฑูุฑ ุชููู KataGo).

---

## ุงูููุญู: ูุซุงู ุชูููุฐ ูุงูู

```python
import math
import numpy as np
from typing import Dict, List, Optional

class MCTSNode:
    """ุนูุฏุฉ MCTS"""
    def __init__(self, prior: float = 0.0):
        self.prior = prior          # P(s,a)
        self.visit_count = 0        # N(s,a)
        self.value_sum = 0.0        # W(s,a)
        self.children: Dict[int, 'MCTSNode'] = {}

    @property
    def q_value(self) -> float:
        """ุญุณุงุจ Q(s,a)"""
        if self.visit_count == 0:
            return 0.0
        return self.value_sum / self.visit_count


class MCTS:
    """ุจุงุญุซ MCTSุ ูุณุชุฎุฏู PUCT"""

    def __init__(
        self,
        policy_network,
        value_network,
        c_puct: float = 1.5,
        num_simulations: int = 800
    ):
        self.policy_network = policy_network
        self.value_network = value_network
        self.c_puct = c_puct
        self.num_simulations = num_simulations

    def search(self, root_state) -> Dict[int, float]:
        """ุชูููุฐ ุจุญุซ MCTSุ ุฅุฑุฌุงุน ุชูุฒูุน ุฒูุงุฑุงุช ุงูุฅุฌุฑุงุกุงุช"""
        root = MCTSNode()

        # ุชูุณูุน ุงูุนูุฏุฉ ุงูุฌุฐุฑูุฉ
        policy = self.policy_network(root_state)
        for action, prob in enumerate(policy):
            if is_legal(root_state, action):
                root.children[action] = MCTSNode(prior=prob)

        # ุชูููุฐ ุงููุญุงูุงุงุช
        for _ in range(self.num_simulations):
            self._simulate(root, root_state)

        # ุฅุฑุฌุงุน ุชูุฒูุน ุงูุฒูุงุฑุงุช
        total_visits = sum(
            child.visit_count for child in root.children.values()
        )
        return {
            action: child.visit_count / total_visits
            for action, child in root.children.items()
        }

    def _simulate(self, node: MCTSNode, state) -> float:
        """ุชูููุฐ ูุญุงูุงุฉ ูุงุญุฏุฉ"""

        # ุฅุฐุง ูุงูุช ุญุงูุฉ ููุงุฆูุฉ
        if is_terminal(state):
            return get_result(state)

        # ุฅุฐุง ูุงูุช ุนูุฏุฉ ูุฑููุฉุ ุชูุณูุน ูุชูููู
        if not node.children:
            policy = self.policy_network(state)
            value = self.value_network(state)

            for action, prob in enumerate(policy):
                if is_legal(state, action):
                    node.children[action] = MCTSNode(prior=prob)

            return value

        # ุงูุงุฎุชูุงุฑ: ุงุฎุชูุงุฑ ุงูุฅุฌุฑุงุก ุฐู ุฃุนูู ุฏุฑุฌุฉ PUCT
        action = self._select_action(node)
        child = node.children[action]
        next_state = apply_action(state, action)

        # ูุญุงูุงุฉ ุชูุฑุงุฑูุฉ
        value = -self._simulate(child, next_state)

        # ุงูุงูุชุดุงุฑ ุงูุนูุณู: ุชุญุฏูุซ ุงูุฅุญุตุงุฆูุงุช
        child.visit_count += 1
        child.value_sum += value

        return value

    def _select_action(self, node: MCTSNode) -> int:
        """ุงุณุชุฎุฏุงู ูุนุงุฏูุฉ PUCT ูุงุฎุชูุงุฑ ุงูุฅุฌุฑุงุก"""
        total_visits = sum(
            child.visit_count for child in node.children.values()
        )

        def puct_score(action: int, child: MCTSNode) -> float:
            # Q(s,a): ูุชูุณุท ุงููููุฉ
            q = child.q_value

            # U(s,a): ููุงูุฃุฉ ุงูุงุณุชูุดุงู
            u = (
                self.c_puct
                * child.prior
                * math.sqrt(total_visits)
                / (1 + child.visit_count)
            )

            return q + u

        return max(
            node.children.keys(),
            key=lambda a: puct_score(a, node.children[a])
        )


# ูุซุงู ุงูุงุณุชุฎุฏุงู
def play_game():
    policy_net = PolicyNetwork()
    value_net = ValueNetwork()

    mcts = MCTS(
        policy_network=policy_net,
        value_network=value_net,
        c_puct=1.5,
        num_simulations=1600
    )

    state = initial_state()

    while not is_terminal(state):
        # ุชูููุฐ ุจุญุซ MCTS
        visit_distribution = mcts.search(state)

        # ุงุฎุชูุงุฑ ุงูุฅุฌุฑุงุก ุฐู ุฃูุซุฑ ุนุฏุฏ ุฒูุงุฑุงุช
        action = max(visit_distribution.keys(),
                     key=lambda a: visit_distribution[a])

        # ุชูููุฐ ุงูุฅุฌุฑุงุก
        state = apply_action(state, action)
        print(f"Selected action {action} with visit ratio "
              f"{visit_distribution[action]:.2%}")

    print(f"Game result: {get_result(state)}")
```

ูุฐุง ุงูุชูููุฐ ููุถุญ ุงูุฏูุฑ ุงูุฃุณุงุณู ููุนุงุฏูุฉ PUCT ูู MCTS. ุชูููุฐ AlphaGo ุงููุนูู ูุชุถูู ุฃูุถุงู:
- ุงูุจุญุซ ุงููุชูุงุฒู (ุงูุฎุณุงุฑุฉ ุงูุงูุชุฑุงุถูุฉ)
- ุชูููู ุงูุดุจูุฉ ุงูุนุตุจูุฉ ุงูุฏูุนู
- ุฅุนุงุฏุฉ ุงุณุชุฎุฏุงู ุงูุดุฌุฑุฉ
- ุถูุถุงุก ุฏูุฑููููู
- ุงูุชุญูู ูู ุฏุฑุฌุฉ ุงูุญุฑุงุฑุฉ ูุบูุฑูุง ูู ุงููุธุงุฆู
