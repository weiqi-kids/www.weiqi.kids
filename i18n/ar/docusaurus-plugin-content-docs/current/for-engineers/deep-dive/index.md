---
sidebar_position: 1
title: للباحثين المتعمقين
description: "دليل المواضيع المتقدمة: الشبكات العصبية، MCTS، التدريب، التحسين، النشر"
---

# للباحثين المتعمقين

هذا القسم مخصص للمهندسين الذين يرغبون في التعمق في دراسة الذكاء الاصطناعي للعبة الغو، ويشمل التنفيذ التقني والأسس النظرية والتطبيقات العملية.

---

## نظرة عامة على المقالات

### التقنيات الأساسية

| المقالة | الوصف |
|---------|-------|
| [شرح تفصيلي لبنية الشبكة العصبية](./neural-network) | الشبكة المتبقية في KataGo، ميزات الإدخال، تصميم الإخراج متعدد الرؤوس |
| [تفاصيل تنفيذ MCTS](./mcts-implementation) | اختيار PUCT، الخسارة الافتراضية، التقييم الدفعي، التوازي |
| [تحليل آلية تدريب KataGo](./training) | اللعب الذاتي، دوال الخسارة، دورة التدريب |

### تحسين الأداء

| المقالة | الوصف |
|---------|-------|
| [واجهات GPU والتحسين](./gpu-optimization) | مقارنة وضبط واجهات CUDA وOpenCL وMetal |
| [تكميم النموذج والنشر](./quantization-deploy) | FP16، INT8، TensorRT، النشر على منصات مختلفة |
| [التقييم والاختبار المعياري](./evaluation) | تقييم Elo، اختبار المباريات، طرق SPRT الإحصائية |

### المواضيع المتقدمة

| المقالة | الوصف |
|---------|-------|
| [بنية التدريب الموزع](./distributed-training) | عمال اللعب الذاتي، جمع البيانات، نشر النماذج |
| [القواعد المخصصة والمتغيرات](./custom-rules) | قواعد صينية ويابانية وAGA، متغيرات حجم اللوحة |
| [دليل قراءة الأوراق البحثية الرئيسية](./papers) | تحليل النقاط الرئيسية في أوراق AlphaGo وAlphaZero وKataGo |

### المصادر المفتوحة والتنفيذ

| المقالة | الوصف |
|---------|-------|
| [دليل قراءة الكود المصدري لـ KataGo](./source-code) | هيكل الدليل، الوحدات الأساسية، أسلوب البرمجة |
| [المشاركة في مجتمع المصادر المفتوحة](./contributing) | طرق المساهمة، التدريب الموزع، المشاركة المجتمعية |
| [بناء ذكاء اصطناعي للغو من الصفر](./build-from-scratch) | تنفيذ نسخة مبسطة من AlphaGo Zero خطوة بخطوة |

---

## ماذا تريد أن تفعل؟

| الهدف | المسار المقترح |
|-------|---------------|
| فهم تصميم الشبكة العصبية | [شرح بنية الشبكة العصبية](./neural-network) ← [تفاصيل تنفيذ MCTS](./mcts-implementation) |
| تحسين أداء التنفيذ | [واجهات GPU والتحسين](./gpu-optimization) ← [تكميم النموذج والنشر](./quantization-deploy) |
| دراسة طرق التدريب | [تحليل آلية تدريب KataGo](./training) ← [بنية التدريب الموزع](./distributed-training) |
| فهم مبادئ الأوراق البحثية | [دليل قراءة الأوراق الرئيسية](./papers) ← [شرح بنية الشبكة العصبية](./neural-network) |
| البرمجة العملية | [بناء ذكاء اصطناعي للغو من الصفر](./build-from-scratch) ← [دليل قراءة الكود المصدري لـ KataGo](./source-code) |
| المشاركة في المشاريع مفتوحة المصدر | [المشاركة في مجتمع المصادر المفتوحة](./contributing) ← [دليل قراءة الكود المصدري لـ KataGo](./source-code) |

---

## فهرس المفاهيم المتقدمة

عند التعمق في البحث، ستواجه المفاهيم المتقدمة التالية:

### سلسلة F: القياس (8 مفاهيم)

| الرقم | مفهوم الغو | المقابل في الفيزياء/الرياضيات |
|-------|-----------|------------------------------|
| F1 | حجم اللوحة مقابل التعقيد | قياس التعقيد |
| F2 | حجم الشبكة مقابل قوة اللعب | قياس السعة |
| F3 | وقت التدريب مقابل العائد | قانون تناقص العوائد |
| F4 | كمية البيانات مقابل التعميم | تعقيد العينة |
| F5 | قياس موارد الحوسبة | قوانين القياس |
| F6 | قوانين القياس العصبية | العلاقة اللوغاريتمية المزدوجة |
| F7 | التدريب بدفعات كبيرة | الدفعة الحرجة |
| F8 | كفاءة المعلمات | حدود الضغط |

### سلسلة G: الأبعاد (6 مفاهيم)

| الرقم | مفهوم الغو | المقابل في الفيزياء/الرياضيات |
|-------|-----------|------------------------------|
| G1 | التمثيل عالي الأبعاد | الفضاء المتجهي |
| G2 | لعنة الأبعاد | معضلة الأبعاد العالية |
| G3 | فرضية التشعب | التشعب منخفض الأبعاد |
| G4 | التمثيل الوسيط | الفضاء الكامن |
| G5 | فصل الميزات | المكونات المستقلة |
| G6 | الاتجاه الدلالي | الجبر الهندسي |

### سلسلة H: التعلم المعزز (9 مفاهيم)

| الرقم | مفهوم الغو | المقابل في الفيزياء/الرياضيات |
|-------|-----------|------------------------------|
| H1 | MDP | سلسلة ماركوف |
| H2 | معادلة بيلمان | البرمجة الديناميكية |
| H3 | تكرار القيمة | نظرية النقطة الثابتة |
| H4 | تدرج السياسة | التحسين العشوائي |
| H5 | إعادة التجربة | أخذ العينات الأهمية |
| H6 | عامل الخصم | التفضيل الزمني |
| H7 | تعلم TD | التقدير التزايدي |
| H8 | دالة الميزة | خط الأساس لتقليل التباين |
| H9 | قص PPO | منطقة الثقة |

### سلسلة K: طرق التحسين (6 مفاهيم)

| الرقم | مفهوم الغو | المقابل في الفيزياء/الرياضيات |
|-------|-----------|------------------------------|
| K1 | SGD | التقريب العشوائي |
| K2 | الزخم | القصور الذاتي |
| K3 | Adam | حجم الخطوة التكيفي |
| K4 | تناقص معدل التعلم | التبريد |
| K5 | قص التدرج | حد التشبع |
| K6 | ضوضاء SGD | الاضطراب العشوائي |

### سلسلة L: التعميم والاستقرار (5 مفاهيم)

| الرقم | مفهوم الغو | المقابل في الفيزياء/الرياضيات |
|-------|-----------|------------------------------|
| L1 | فرط التخصيص | التكيف المفرط |
| L2 | التنظيم | التحسين المقيد |
| L3 | Dropout | التنشيط المتفرق |
| L4 | زيادة البيانات | كسر التناظر |
| L5 | التوقف المبكر | التوقف الأمثل |

---

## متطلبات الأجهزة

### للقراءة والتعلم

لا توجد متطلبات خاصة، أي حاسوب يكفي.

### لتدريب النماذج

| الحجم | الأجهزة المقترحة | وقت التدريب |
|-------|-----------------|-------------|
| صغير جداً (b6c96) | GTX 1060 6GB | عدة ساعات |
| صغير (b10c128) | RTX 3060 12GB | 1-2 يوم |
| متوسط (b18c384) | RTX 4090 24GB | 1-2 أسبوع |
| كامل (b40c256) | مجموعة GPU متعددة | عدة أسابيع |

### المساهمة في التدريب الموزع

- أي حاسوب مع GPU يمكنه المشاركة
- يُنصح بـ GTX 1060 أو ما يعادلها على الأقل
- يتطلب اتصال إنترنت مستقر

---

## ابدأ القراءة

**يُنصح بالبدء من هنا:**

- تريد فهم المبادئ؟ ← [شرح بنية الشبكة العصبية](./neural-network)
- تريد التنفيذ العملي؟ ← [بناء ذكاء اصطناعي للغو من الصفر](./build-from-scratch)
- تريد قراءة الأوراق البحثية؟ ← [دليل قراءة الأوراق الرئيسية](./papers)
