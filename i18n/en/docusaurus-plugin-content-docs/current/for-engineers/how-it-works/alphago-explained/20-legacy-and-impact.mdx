---
sidebar_position: 21
title: AlphaGo's Legacy
description: From Go to protein structure, how AlphaGo's technical legacy changed AI research and the entire scientific world
keywords: [AlphaGo, AlphaZero, MuZero, AlphaFold, deep reinforcement learning, AI impact, Go AI]
---

# AlphaGo's Legacy

In March 2016, the moment AlphaGo defeated Lee Sedol was not just a turning point in Go history, but a milestone in artificial intelligence development. Since then, AlphaGo's technical core has been applied to more and more fields, from games to scientific discovery, from fundamental research to practical applications.

This article will review AlphaGo's profound impact on the Go world, AI research, and the broader scientific domain.

---

## Impact on the Go World

### Shock and Acceptance

Before AlphaGo defeated Lee Sedol, professional players generally believed AI was still far behind:

> "I will win 5:0."
> — **Lee Sedol**, pre-match prediction

But the result was 4:1. Even more shocking, AlphaGo's playing style made professional players realize: **our understanding of Go might be wrong**.

### Revolution in Go Theory

AlphaGo brought a series of theoretical revolutions:

| Traditional View | AlphaGo's Challenge |
|------------------|---------------------|
| 3-3 invasion at the right timing | Direct 3-3 invasion in opening is viable |
| Joseki must be strictly followed | Can actively deviate from joseki |
| Balance territory and influence | Win rate is the only standard |
| Bad shapes must be avoided | Some "bad shapes" are actually good moves |
| Opening should grab big points | Local fighting might be more important |

These changes weren't because AlphaGo "told" humans how to play, but because humans actively studied and validated AI game records.

### AI Training Becomes Standard

In the 2024 professional Go world, AI training has become standard:

| Change | Description |
|--------|-------------|
| Game review | Use AI to analyze win rate and suggestions for each move |
| Opening preparation | Study AI-recommended opening variations |
| Tactical training | Practice with AI-generated life-and-death problems and tesuji |
| Practical application | Some professional matches allow AI consultation during breaks |

### Impact on Professional Players

Different players' attitudes toward AI:

> "AI made me fall in love with Go again. There's so much about Go I didn't know."
> — **Ke Jie**, 2017

> "Playing against AI made me feel despair, but studying AI helped me find a new direction."
> — **Lee Sedol**, 2019 (before retirement)

> "AI is not an opponent, but a teacher."
> — Consensus among many professional players

### New Generation of Players

Professional players who debuted after 2016 grew up with AI training:

- More diverse openings
- More precise tactics
- More flexible with "traditional theory"
- Overall level may be higher than previous generations

This is an unprecedented learning resource in Go history - an always-available, never-tired, superhuman teacher.

---

## AlphaZero: General Game AI

### From Go to Three Board Games

In December 2017, DeepMind published **AlphaZero**, extending AlphaGo Zero's technology to three different board games:

| Game | Training Time | Opponent | Record |
|------|---------------|----------|--------|
| Go | 8 hours | AlphaGo Zero | 60:40 |
| Chess | 4 hours | Stockfish | 155:6 (including draws) |
| Shogi | 2 hours | Elmo | 90:8:2 |

**The same algorithm, three different games, all reaching superhuman level.**

### Impact on Chess World

Chess has over a century of AI research history, and Stockfish was the culmination of decades of engineering optimization. AlphaZero trained from scratch for 4 hours and defeated all of that.

More importantly, AlphaZero's playing style:

> "AlphaZero's chess seems to come from another planet. It's willing to sacrifice material for long-term positional advantage, which was unthinkable in traditional chess."
> — **Garry Kasparov**, former Chess World Champion

### Technical Significance

AlphaZero proved:

1. **Generality**: The same method applies to different domains
2. **First-principles learning**: No domain expert knowledge needed
3. **Efficiency**: Training time reduced from months to hours

This was a crucial step toward AI generalization.

---

## MuZero: Learning Without Rules

### A Further Breakthrough

In 2019, DeepMind published **MuZero**, going even further than AlphaZero:

> **AlphaZero needed to know game rules; MuZero doesn't even need the rules.**

MuZero learns the environment's dynamics model through interaction with the environment, then uses this learned model for planning.

### How It Works

```
AlphaGo/AlphaZero:
Environment rules (known) → MCTS search → Best action

MuZero:
Environment observation → Learn dynamics model → MCTS with learned model → Best action
```

MuZero learns three models:
- **Representation function**: Convert observations to hidden state
- **Dynamics function**: Predict next hidden state and reward
- **Prediction function**: Predict policy and value

### Expanded Application Range

Since explicit rules aren't needed, MuZero can be applied to more domains:

| Domain | Description |
|--------|-------------|
| Atari games | 57 games, most surpassing humans |
| Board games | Same level as AlphaZero |
| Video compression | Used for YouTube video encoding, saving 4% bandwidth |
| Data center cooling | Optimizing Google data center energy efficiency |

### Insights for AI Research

MuZero demonstrated the power of **Model-based RL**:

- No need to manually define environment rules
- Can handle continuous state spaces
- Can handle partially observable environments
- Closer to how humans learn

---

## AlphaFold: AI That Changed Biology

### Protein Structure Prediction

In 2020, DeepMind published **AlphaFold 2**, achieving stunning results in the protein structure prediction competition (CASP14):

| Metric | AlphaFold 2 | Second Place |
|--------|-------------|--------------|
| GDT-TS score | 92.4 | 67.0 |
| Median error | 0.96 A | ~2.5 A |

This accuracy approaches experimental measurement levels, solving a 50-year-old problem in biology.

### Technical Connection to AlphaGo

AlphaFold doesn't directly use AlphaGo's code, but inherited core ideas:

| AlphaGo Technology | Corresponding in AlphaFold |
|--------------------|---------------------------|
| Deep neural networks | Transformer + Attention |
| Iterative optimization | Iterative structure prediction refinement |
| End-to-end learning | Predict structure directly from sequence |
| Large-scale training | Train using large amounts of known structures |

### Scientific Community Response

> "This will change everything. We no longer need to wait years for experiments to know a protein's structure."
> — **Structural biologist**

AlphaFold's impact:

- **Drug development**: Accelerate new drug design
- **Disease research**: Understand disease mechanisms
- **Synthetic biology**: Design new proteins
- **Basic research**: Advance life sciences

In 2024, AlphaFold's creators Demis Hassabis and John Jumper received the **Nobel Prize in Chemistry** for this work.

### Open Science

DeepMind made **200+ million protein structures** predicted by AlphaFold freely available to researchers worldwide. This is a model of AI promoting open science.

---

## Insights for AI Research

### Methodological Shift

AlphaGo represents a shift in AI research methodology:

| Traditional Approach | AlphaGo Approach |
|---------------------|------------------|
| Hand-designed features | End-to-end learning |
| Expert rules | Learn from data |
| Step-by-step optimization | Joint optimization |
| Encode human knowledge | Learn from scratch |

This philosophy of "less human design, more learning" has influenced all AI subfields.

### Reinforcement Learning Renaissance

AlphaGo brought reinforcement learning back to prominence:

| Period | RL Status |
|--------|-----------|
| Before 2010 | Theoretically interesting, practically difficult |
| 2013 DQN | Began showing potential |
| 2016 AlphaGo | Proved it can solve complex problems |
| After 2017 | Became AI research hotspot |

Now, reinforcement learning is applied to:
- Robot control
- Autonomous driving
- Recommendation systems
- Large language model alignment (RLHF)

### Computation vs. Algorithm Trade-off

The evolution of the AlphaGo series shows the trade-off between computation and algorithms:

```
AlphaGo Fan:  Lots of human knowledge + lots of computation
AlphaGo Lee:  Human knowledge + more computation
AlphaGo Zero: Zero human knowledge + medium computation + better algorithm
AlphaZero:    Zero human knowledge + less computation + best algorithm
```

Better algorithms can reduce computational resource requirements. This is important for AI democratization.

---

## Spreading of Technical Legacy

### Open Source Community

AlphaGo's technology was quickly replicated and improved by the open source community:

| Project | Features | Status |
|---------|----------|--------|
| **Leela Zero** | Community distributed training | Active |
| **KataGo** | Single GPU efficient training | Very active |
| **ELF OpenGo** | Facebook open source | Maintained |
| **Minigo** | Google open source educational project | Complete |
| **Pachi** | Traditional MCTS, pre-AI era king | Historical significance |

### Research Paper Citations

Impact of AlphaGo-related papers:

| Paper | Citations (approx.) |
|-------|---------------------|
| AlphaGo (2016, Nature) | 20,000+ |
| AlphaGo Zero (2017, Nature) | 15,000+ |
| AlphaZero (2018, Science) | 10,000+ |

These papers are cited by multiple fields including AI, neuroscience, cognitive science, and game research.

### Educational Impact

AlphaGo became a classic AI education case:

- Required reading for university courses
- Important chapters in reinforcement learning textbooks
- Popular topic for popular science articles and documentaries
- Inspired a new generation of researchers to enter AI

---

## Broader Social Impact

### Raising AI Awareness

AlphaGo made the public aware of AI's capabilities:

| Aspect | Impact |
|--------|--------|
| Media coverage | AI became mainstream news topic |
| Investment boom | AI startups and investment increased dramatically |
| Policy discussion | Countries began formulating AI strategies |
| Public awareness | More people understand AI's possibilities and risks |

### Thinking About Human-Machine Relationships

AlphaGo sparked deep thinking about human-machine relationships:

> "If machines surpass humans in Go, where is human value?"

The Go world gave an answer:
- AI is a tool, not an opponent
- Human value is not in competing with machines
- The joy of Go won't disappear because of AI

This way of thinking is also relevant for other fields where AI might surpass humans.

### Ethical Considerations

DeepMind also faced ethical issues in the AlphaGo project:

- **Competition fairness**: Is AI vs. human fair?
- **Future of professional players**: Will AI replace humans?
- **Technical responsibility**: How should powerful AI be used?

DeepMind established an ethics committee and included AI safety clauses in acquisition agreements. This practice influenced later AI companies.

---

## Future Outlook

### AI's Next Challenge

After AlphaGo, AI researchers ask: what's the next "Go"?

| Candidate Domain | Difficulty | Progress |
|------------------|------------|----------|
| Real-time strategy games (e.g., StarCraft) | Extremely high | AlphaStar reached Grandmaster level |
| Open world games (e.g., Minecraft) | Very high | Under research |
| Scientific discovery | Extremely high | AlphaFold breakthrough in proteins |
| Mathematical theorem proving | Extremely high | AlphaProof making progress |
| Artificial General Intelligence (AGI) | Unknown | Long-term goal |

### From Specialized to General

The evolution direction of the AlphaGo series:

```
AlphaGo (Go-specific)
    ↓
AlphaZero (Board game general)
    ↓
MuZero (Game general)
    ↓
? (Domain general)
    ↓
AGI (Fully general)
```

Each step reduces dependence on domain-specific knowledge, increasing generality.

### DeepMind's Vision

DeepMind's mission remains:

> "Solve intelligence, and then use that to solve everything else."

AlphaGo was the first important milestone for this vision. AlphaFold was the second. There will be more to come.

---

## Conclusion

Looking back at AlphaGo's story, we see not just an AI that beat humans, but:

- **Technical breakthrough**: The powerful combination of deep learning + reinforcement learning + tree search
- **Methodological innovation**: Learning from scratch, surpassing human knowledge
- **Engineering achievement**: Perfect coordination of distributed systems and specialized hardware
- **Scientific application**: The leap from games to protein structures
- **Cultural impact**: Changing human understanding of AI and ourselves

AlphaGo proved: **the right method + sufficient computation can solve problems once thought impossible**.

This lesson will continue to guide future AI research. And Go - this game with thousands of years of history - will forever be a witness to this history.

---

## Animation Reference

Core concepts covered in this article with animation numbers:

| Number | Concept | Physics/Math Correspondence |
|--------|---------|----------------------------|
| Animation F8 | Emergent abilities | Phase transition |
| Animation E7 | From scratch | Self-organization |
| Animation F1 | General intelligence | Universality |
| Animation F5 | Transfer learning | Knowledge transfer |

---

## Further Reading

- **Back to the Beginning**: [Birth of AlphaGo](../birth-of-alphago) - How it all started
- **Technical Summary**: [AlphaGo Complete Analysis](../) - Series article overview
- **Hands-on Practice**: [Run Your First Go AI in 30 Minutes](../../../hands-on/) - Experience it yourself

---

## References

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 550, 354-359.
3. Silver, D., et al. (2018). "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play." *Science*, 362(6419), 1140-1144.
4. Schrittwieser, J., et al. (2020). "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model." *Nature*, 588, 604-609.
5. Jumper, J., et al. (2021). "Highly accurate protein structure prediction with AlphaFold." *Nature*, 596, 583-589.
6. *AlphaGo* documentary (2017), directed by Greg Kohs.
7. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
8. Kasparov, G. (2018). "Chess, a Drosophila of reasoning." *Science*, 362(6419), 1087.
