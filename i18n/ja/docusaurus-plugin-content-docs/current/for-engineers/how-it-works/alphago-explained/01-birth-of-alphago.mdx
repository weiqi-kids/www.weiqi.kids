---
sidebar_position: 2
title: AlphaGo の誕生
description: DeepMind の創立から Google による買収まで、AlphaGo がいかにして一つの大胆なアイデアから世界を変える AI になったか
---

# AlphaGo の誕生

2016 年 3 月、AlphaGo が 4:1 でイ・セドルを破ったとき、世界中の人々が問いかけました：人工知能の歴史を変えたこのプログラムは、一体どのようにして生まれたのか？

その答えは、一人のチェス神童の夢から始まります。

---

## DeepMind の創立

### Demis Hassabis：神童から AI パイオニアへ

**Demis Hassabis** は DeepMind の共同創設者兼 CEO です。彼の人生経験は、まるで AlphaGo を創造するために準備されていたかのようです。

#### チェスの神童

1975 年ロンドン生まれの Hassabis は、4 歳でチェスを学び、13 歳でチェスマスターレベル（Elo 2300+）に到達しました。これは英国史上 2 番目に若い記録です。

この経験から彼は深く理解しました：
- **ボードゲームは知性の試金石**：チェスには計画、直感、パターン認識が必要
- **人間の知性の本質**：棋士はいかにして膨大な可能性の中から良い手を見つけるのか？
- **コンピュータの限界**：1997 年にディープ・ブルーがカスパロフを破ったのは、本当の「理解」ではなく、力任せの探索によるもの

#### ゲームデザイナー

17 歳のとき、Hassabis は Bullfrog Productions（『ポピュラス』の創作者 Peter Molyneux が設立したゲーム会社）に入社し、名作ゲーム『Theme Park』の開発に参加しました。この経験で彼は学びました：

- **複雑なシステムの設計方法**：ゲームは現実世界を簡略化したシミュレーションモデル
- **プレイヤー行動の予測**：AI は人間の意思決定プロセスを理解する必要がある

#### 認知神経科学者

ケンブリッジ大学でコンピュータサイエンスの学位を取得した後、Hassabis はユニバーシティ・カレッジ・ロンドン（UCL）で認知神経科学の博士号を取得しました。彼の研究テーマは：**海馬がいかにして人間の想像と計画を可能にするか**。

この研究で発見されたこと：
- 人間の記憶と想像は同じ脳領域を使用する
- 私たちは「メンタルタイムトラベル」を通じて未来を計画する
- この能力は知性の核心かもしれない

これらの洞察は、後の AlphaGo の設計に直接影響を与えました——AI が将来の手を「想像」し、そこから学習できるようにすること。

### 共同創設者たち

2010 年、Hassabis は 2 人のパートナーと共に DeepMind を創立しました：

| 創設者 | 経歴 | 貢献 |
|--------|------|------|
| **Demis Hassabis** | 神経科学、ゲームデザイン | ビジョンと戦略 |
| **Shane Legg** | 機械学習博士 | AGI 理論基盤 |
| **Mustafa Suleyman** | 社会起業家 | ビジネスと応用 |

### 「知性を解決し、それですべてを解決する」

DeepMind のミッションステートメントは：

> **"Solve intelligence, and then use that to solve everything else."**
>
> 「知性を解決し、それであらゆる問題を解決する」

これは普通の AI 企業ではありません。彼らの目標は製品を作ることではなく、**汎用人工知能（AGI）**を創造すること——人間のように考え、学び、あらゆる問題を解決できる AI です。

なぜまず「知性を解決する」必要があるのか？それは、AGI があれば、気候変動、病気、エネルギーなど人類最大の課題を解決する助けになるからです。

---

## 初期の突破：Atari ゲーム

囲碁に挑戦する前に、DeepMind はまず自らの能力を証明しました——AI で Atari ゲームをプレイすること。

### DQN：ゲームを学習する AI

2013 年、DeepMind は **DQN（Deep Q-Network）** アルゴリズムを発表しました。この AI は：

1. **画面のピクセルだけを見る**——ゲームルールは一切教えない
2. **自分でゲームを学ぶ**——試行錯誤を通じて
3. **人間レベルに達する**——いくつかのゲームでは人間を超える

DQN は『ブロック崩し』（Breakout）で、人間が発見するのに数時間かかる戦略を学びました：**トンネルを掘ってボールをブロックの後ろに回し込み、一度に大量のブロックを消す**。

これは、深層学習＋強化学習の組み合わせが、人間が思いもよらなかった戦略を発見できることを証明しました。

### なぜゲームから始めたのか？

Hassabis が研究プラットフォームとしてゲームを選んだ理由：

1. **環境が制御可能**：ゲームには明確なルールと目標がある
2. **進歩が測定可能**：AI の能力を評価する客観的なスコアがある
3. **人間の基準**：人間プレイヤーと比較できる
4. **多様性**：異なるゲームで異なる能力をテストできる

この方法論は、後に囲碁にも適用されました。

---

## Google による買収

### 5 億ドルの賭け

2014 年 1 月、Google は約 **5 億ドル** で DeepMind を買収しました。これは当時の AI 分野で最大の買収案件の一つでした。

なぜ Google は、たった 75 人の従業員で製品もない会社にこれほどの金額を支払ったのでしょうか？

答えは **ゲーム理論** にあります：

- **Facebook も入札していた**：Facebook は 4 億ドルを提示したと言われている
- **AI は未来の鍵となる技術**：AI を先に手にした者が未来を制する
- **DeepMind は最高のチーム**：彼らは深層強化学習の実現可能性を証明した

Google CEO の Larry Page が自ら出向き、Hassabis を Facebook ではなく Google を選ぶよう説得しました。

### 買収条件

Hassabis は交渉でいくつかの重要な条件を勝ち取りました：

1. **独立運営**：DeepMind はロンドン本社を維持し、独立して研究開発
2. **学術的自由**：論文を発表でき、全てを機密にしない
3. **倫理委員会**：AI 倫理審査メカニズムを設立
4. **長期研究**：短期的な商業化のプレッシャーがない

これらの条件により、DeepMind は長期的でハイリスクな研究を追求できました——例えば、AI で囲碁を征服すること。

### Google の AI 戦略

DeepMind の買収は Google の「AI ファースト」戦略の一部でした：

| 時期 | 出来事 |
|------|------|
| 2011 | Google Brain 設立 |
| 2013 | DNNresearch 買収（Hinton チーム） |
| 2014 | DeepMind 買収 |
| 2015 | TensorFlow オープンソース化 |
| 2016 | TPU 発表 |

Google は認識しました：検索、広告、翻訳、音声——すべてのコアビジネスが AI によって再形成される。最高の AI を持つ者が勝者になる。

---

## 囲碁を目標に選ぶ

### なぜ囲碁なのか？

Google に買収された後、DeepMind はより多くのリソースを得ました。Hassabis は一見不可能な目標に挑戦することを決めました：**AI で人間の囲碁チャンピオンを破る**。

なぜ他の問題ではなく囲碁を選んだのでしょうか？

#### 1. 囲碁は「AI の聖杯」

2016 年以前、専門家は AI が囲碁で人類を破るには少なくとも 10〜20 年かかると考えていました。囲碁は「AI 最後の砦」と呼ばれていました。

理由：
- **探索空間が膨大**：10^170 の可能な局面（宇宙の原子数は 10^80 しかない）
- **評価が困難**：チェスのような明確な駒の価値がない
- **直感への依存**：トップ棋士はよく「この手は感覚的に正しい」と言うが、理由を説明できない

#### 2. ディープ・ブルーからの教訓

1997 年、IBM のディープ・ブルーはチェス世界チャンピオンのカスパロフを破りました。しかし、この勝利には議論がありました：

- ディープ・ブルーは**力任せの探索**に頼った（毎秒 2 億局面を評価）
- **人間の専門家が設計した評価関数**を使用
- これは真の「知性」ではなく、「計算力」だった

Hassabis は証明したかったのです：AI は力任せの探索ではなく、**学習**によって問題を解決できると。

#### 3. 測定可能な目標

囲碁には国際ランキングシステム（Elo rating）とプロ棋士がおり、客観的な基準を提供しています。AI が世界チャンピオンを破れば、それは議論の余地のない成功です。

#### 4. 神経科学との関連

人間の棋士の直感——盤面を一目見ただけでどの位置が重要かわかる——これこそ Hassabis が AI で再現したかった能力です。囲碁は「機械の直感」をテストする完璧な場面です。

---

## AlphaGo チーム

### 中心人物

AlphaGo の成功は、学際的な背景を持つチームから生まれました：

#### David Silver：主任研究員

**David Silver** は AlphaGo 論文の筆頭著者であり、強化学習分野のトップ専門家です。

- **経歴**：ケンブリッジ大学数学科卒業、アルバータ大学 RL 博士
- **指導教官**：Richard Sutton（強化学習の父）
- **専門**：モンテカルロ木探索、時間差分学習

Silver は博士論文でコンピュータ囲碁を研究しましたが、当時の技術は成熟していませんでした。DeepMind に加入後、彼はついにこの夢を実現する機会を得ました。

#### Aja Huang：囲碁の専門家

**Aja Huang**（黄士傑）は台湾人で、アマチュア六段の棋士であり、コンピュータ囲碁分野のパイオニアでもあります。

- **経歴**：国立台湾師範大学情報工学博士
- **専門**：コンピュータ囲碁プログラム設計
- **著名な作品**：Erica（初期のコンピュータ囲碁プログラム）

Huang は AlphaGo チームで重要な役割を果たしました：彼は囲碁だけでなく、AI も理解していました。イ・セドルとの対局では、実際に AlphaGo を操作したのは彼でした。

#### その他の主要メンバー

| メンバー | 役割 |
|------|------|
| Chris J. Maddison | モンテカルロ木探索専門家 |
| Arthur Guez | 強化学習研究員 |
| Laurent Sifre | 深層学習エンジニア |
| George van den Driessche | 分散システムエンジニア |

### 学際的コラボレーション

AlphaGo の成功は**学際的コラボレーション**の力を証明しました：

- **囲碁の専門家**がドメイン知識を提供
- **機械学習研究者**がアルゴリズムを設計
- **エンジニア**が大規模学習システムを実装
- **神経科学者**が理論的インスピレーションを提供

このチーム構成は、後に DeepMind の標準モデルとなりました。

---

## Nature 論文発表

### 秘密のサプライズ

2016 年 1 月 27 日、DeepMind はトップ学術誌『Nature』に論文を発表しました：

> **"Mastering the game of Go with deep neural networks and tree search"**

論文は AlphaGo がすでに達成したことを発表しました：
1. 他のすべての囲碁プログラムを破った
2. ヨーロッパチャンピオン **ファン・フイ**（プロ二段）を **5:0** で破った

このニュースは世界を驚かせました。論文発表前、DeepMind が囲碁を研究していることを誰も知りませんでした。

### 論文の核心的貢献

『Nature』論文は AlphaGo の 3 つの主要イノベーションを説明しました：

#### 1. ポリシーネットワーク（Policy Network）

深層畳み込みニューラルネットワークを使って、人間の棋士の次の手を予測します。学習データは **3000 万局** の人間の棋譜から得ています。

```
精度：57%（人間の専門家の次の手を予測）
```

これは以前の最高のコンピュータ囲碁プログラムより 10 パーセントポイント以上高い数値です。

#### 2. バリューネットワーク（Value Network）

別のニューラルネットワークを使って、現在の局面の勝率を評価します。これは従来のランダムシミュレーション（モンテカルロ・ロールアウト）に取って代わるものです。

```
精度：15000 回のランダムシミュレーションと同等だが、計算速度は 15000 倍速い
```

#### 3. モンテカルロ木探索との統合

2 つのニューラルネットワークを MCTS フレームワークに統合：
- ポリシーネットワークが探索方向を導く
- バリューネットワークがリーフノードを評価

これにより AlphaGo は「直感」（ニューラルネットワーク）と「推論」（木探索）の両方を持つことができました。

### 学術界の反応

論文発表後、学術界は熱狂的に反応しました：

> 「これは人工知能のアポロ計画の瞬間だ。」
> — **Stuart Russell**、UC Berkeley 教授、AI 教科書著者

> 「あと 10 年はかかると思っていた。こんなに早いとは。」
> — **Martin Müller**、コンピュータ囲碁専門家

しかし、懐疑的な意見もありました：

> 「ファン・フイはプロ二段にすぎない。本当のトップ棋士ではない。AlphaGo とイ・セドルの対局を見てから判断しよう。」

DeepMind はこの挑戦を受け入れました。

---

## イ・セドルへの挑戦

### なぜイ・セドルなのか？

**イ・セドル**（Lee Sedol）は韓国の棋士で、当時は過去 10 年で最強の棋士の一人と考えられていました：

| 指標 | データ |
|------|------|
| 世界タイトル | 18 個 |
| 国際大会優勝 | 32 回 |
| 最高世界ランキング | 1 位 |
| スタイル | 「天才」「神算」 |

イ・セドルを選ぶことで、DeepMind は最強の人間の対戦相手に挑戦していました。

### 100 万ドルの賞金

Google はこの対局に **100 万ドル** の賞金を提供しました：

- イ・セドルが勝った場合：賞金はイ・セドルに
- AlphaGo が勝った場合：賞金は UNICEF、STEM 教育などの慈善団体に寄付

これは単なる技術デモではなく、世界が注目するスポーツイベントでもありました。

### 対局前の予測

対局前、ほとんどのプロ棋士はイ・セドルが楽勝すると予測していました：

> 「AlphaGo は 1 局は勝てるかもしれないが、5 局の対局なら私が 5:0 で勝つ。」
> — **イ・セドル**、対局前インタビュー

> 「コンピュータの打ち方は硬直している。トップ棋士なら簡単に弱点を見つけられる。」
> — あるプロ九段

しかし DeepMind チームは違う見方をしていました。David Silver は後に明かしました：

> 「内部テストでは、AlphaGo をファン・フイに勝ったバージョンと 500 局対局させた。新バージョンは 499 局勝った。」

---

## 2016 年 3 月：世界を変えた 5 局

### 第 1 局：衝撃の始まり

2016 年 3 月 9 日、ソウルのフォーシーズンズホテル。

イ・セドルが黒番で先手、AlphaGo が白番。3 時間 28 分の対局の末、AlphaGo が中押し勝ち。

これは人類のトップ棋士が初めて正式に AI に負けた瞬間でした。

### 第 2 局：神の一手

第 2 局では「**神の一手**」と呼ばれる 37 手目が生まれました——AlphaGo は五路に肩ツキを打ち、すべてのプロ棋士が失着だと思いましたが、結果的に勝利の鍵となりました。

（詳細は次の記事：[「神の一手」の深層分析](../move-37)）

AlphaGo が再び勝利。

### 第 3 局：3:0

第 3 局、イ・セドルは非伝統的な布石を試みましたが、AlphaGo は冷静に対応。3:0。

世界中が気づき始めました：これは偶然ではない、AI は本当に人類を超えた。

### 第 4 局：人類の反撃

第 4 局、イ・セドルは「**神の一手**」と呼ばれる 78 手目を打ちました——絶妙なワリコミで、AlphaGo を混乱させました。

AlphaGo は続く数手で明らかな悪手を打ち、最終的に投了しました。

この勝利は証明しました：AI にも弱点がある。イ・セドルはそれを見つけた。

### 第 5 局：最終スコア

第 5 局、AlphaGo は正常に戻り、中押し勝ちで対局を終えました。

**最終スコア：AlphaGo 4:1 イ・セドル**

---

## 影響と余波

### 世界的注目

この対局の影響は囲碁界をはるかに超えました：

- **世界で 2 億人** がライブ配信を視聴
- 『ニューヨーク・タイムズ』『エコノミスト』など主要メディアが大きく報道
- Google の株価は対局中に上昇
- 「人工知能」がその年最もホットなテクノロジートピックに

### 囲碁界への影響

対局後、プロ棋士の態度は「軽視」から「畏敬」に変わりました：

> 「以前は人間が囲碁を理解していると思っていた。今ではほんの表面しかわかっていなかったと気づいた。」
> — **柯潔**、中国の棋士、当時世界ランキング 1 位

多くのプロ棋士が AI を使って訓練するようになり、囲碁の打ち方も変化しました。

### AI 分野への影響

AlphaGo はいくつかのことを証明しました：

1. **深層学習は専門家レベルの問題を解決できる**：猫や犬の認識だけでなく、囲碁も打てる
2. **強化学習は人類を超えられる**：自己対戦を通じて、AI は人間が知らなかった戦略を発見できる
3. **ニューラルネットワーク＋探索は強力な組み合わせ**：直感＋推論＝より強い知性

これらの洞察は後に以下に応用されました：
- **AlphaFold**：タンパク質構造予測（2020 年ノーベル賞級の成果）
- **AlphaZero**：汎用ゲーム AI
- **MuZero**：ルールなしでの学習

---

## アニメーション対応表

本記事で扱う核心概念とアニメーション番号：

| 番号 | 概念 | 物理/数学対応 |
|------|------|--------------|
| E7 | ゼロから始める | 自己組織化 |
| E5 | 自己対戦 | 不動点収束 |
| F8 | 創発能力 | 相転移 |
| H4 | ポリシー勾配 | 確率的最適化 |

---

## 関連読み物

- **次の記事**：[重要な対局の振り返り](../key-matches) — ファン・フイ、イ・セドル、柯潔の完全対局分析
- **技術詳細**：[ポリシーネットワーク詳解](../policy-network) — AlphaGo がいかにして囲碁を学んだか
- **ハンズオン実践**：[30 分で初めての囲碁 AI を動かす](../../../hands-on/) — 自分で体験する

---

## 参考資料

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. 『AlphaGo』ドキュメンタリー (2017)、監督 Greg Kohs。
