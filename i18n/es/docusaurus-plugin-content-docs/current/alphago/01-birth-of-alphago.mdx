---
sidebar_position: 2
title: El Nacimiento de AlphaGo
description: Desde la fundacion de DeepMind hasta la adquisicion por Google, como AlphaGo paso de ser una idea descabellada a una IA que cambio el mundo
---

# El Nacimiento de AlphaGo

En marzo de 2016, cuando AlphaGo derroto a Lee Sedol con un marcador de 4:1, el mundo entero se preguntaba: este programa que cambio la historia de la inteligencia artificial, como nacio exactamente?

La respuesta comienza con el sueno de un nino prodigio del ajedrez.

---

## La Fundacion de DeepMind

### Demis Hassabis: De Nino Prodigio a Pionero de la IA

**Demis Hassabis** es cofundador y CEO de DeepMind. Su trayectoria vital parece haber sido disenada especificamente para crear AlphaGo.

#### Nino Prodigio del Ajedrez

Nacido en Londres en 1975, Hassabis aprendio a jugar ajedrez a los 4 anos y alcanzo el nivel de maestro de ajedrez (Elo 2300+) a los 13, siendo el segundo jugador mas joven en alcanzar este nivel en la historia britanica.

Esta experiencia le dio una comprension profunda de:
- **Los juegos de tablero son la piedra de toque de la inteligencia**: jugar requiere planificacion, intuicion y reconocimiento de patrones
- **La naturaleza de la inteligencia humana**: como encuentran los jugadores buenas jugadas entre enormes posibilidades?
- **Las limitaciones de las computadoras**: en 1997, Deep Blue vencio a Kasparov mediante busqueda de fuerza bruta, no mediante verdadera "comprension"

#### Disenador de Videojuegos

A los 17 anos, Hassabis se unio a Bullfrog Productions (compania de videojuegos fundada por Peter Molyneux, creador de "Populous"), participando en el desarrollo del clasico juego "Theme Park". Esta experiencia le enseno:

- **Como disenar sistemas complejos**: los juegos son modelos simplificados que simulan el mundo real
- **Prediccion del comportamiento del jugador**: la IA necesita entender el proceso de toma de decisiones humano

#### Neurocientifico Cognitivo

Despues de obtener su titulo en Ciencias de la Computacion en la Universidad de Cambridge, Hassabis obtuvo su doctorado en Neurociencia Cognitiva en el University College London (UCL). Su tema de investigacion fue: **como el hipocampo permite a los humanos imaginar y planificar**.

Este estudio descubrio:
- La memoria e imaginacion humanas usan la misma region cerebral
- Planificamos el futuro a traves del "viaje mental en el tiempo"
- Esta capacidad podria ser el nucleo de la inteligencia

Estas ideas influyeron directamente en el diseno posterior de AlphaGo: permitir que la IA "imagine" movimientos futuros y aprenda de ellos.

### Cofundadores

En 2010, Hassabis fundo DeepMind junto con dos socios:

| Fundador | Experiencia | Contribucion |
|----------|-------------|--------------|
| **Demis Hassabis** | Neurociencia, diseno de juegos | Vision y estrategia |
| **Shane Legg** | Doctor en Machine Learning | Base teorica de AGI |
| **Mustafa Suleyman** | Emprendedor social | Negocio y aplicaciones |

### "Resolver la Inteligencia, Usar la Inteligencia para Resolver Todo lo Demas"

La declaracion de mision de DeepMind es:

> **"Solve intelligence, and then use that to solve everything else."**
>
> "Resolver la inteligencia, y luego usarla para resolver todo lo demas."

Esta no es una compania de IA comun. Su objetivo no es hacer productos, sino crear **Inteligencia Artificial General (AGI)**: una IA que pueda pensar, aprender y resolver cualquier problema como un humano.

Por que "resolver la inteligencia" primero? Porque una vez que tengamos AGI, podra ayudarnos a resolver los mayores desafios de la humanidad como el cambio climatico, enfermedades y energia.

---

## Avance Temprano: Juegos de Atari

Antes de desafiar al Go, DeepMind primero demostro su capacidad usando IA para jugar juegos de Atari.

### DQN: IA que Aprende a Jugar

En 2013, DeepMind publico el algoritmo **DQN (Deep Q-Network)**. Esta IA podia:

1. **Solo ver pixeles de pantalla**: sin darle ninguna regla del juego
2. **Aprender a jugar por si misma**: a traves de prueba y error
3. **Alcanzar nivel humano**: incluso superar a los humanos en algunos juegos

DQN aprendio en "Breakout" una estrategia que a los humanos les toma horas descubrir: **cavar un tunel para que la pelota pase detras de los ladrillos y elimine una gran area de una vez**.

Esto probo que la combinacion de deep learning + aprendizaje por refuerzo puede descubrir estrategias que los humanos nunca habian pensado.

### Por que Empezar con Juegos?

Hassabis eligio los juegos como plataforma de investigacion por varias razones:

1. **Entorno controlable**: los juegos tienen reglas y objetivos claros
2. **Progreso medible**: hay puntuaciones objetivas para evaluar la capacidad de la IA
3. **Referencia humana**: se puede comparar con jugadores humanos
4. **Diversidad**: diferentes juegos prueban diferentes capacidades

Esta metodologia se uso posteriormente en el Go.

---

## La Adquisicion por Google

### Una Apuesta de 500 Millones de Dolares

En enero de 2014, Google adquirio DeepMind por aproximadamente **500 millones de dolares**. Esta fue una de las mayores adquisiciones en el campo de la IA en ese momento.

Por que Google estaba dispuesto a pagar tanto por una compania de solo 75 personas y sin productos?

La respuesta esta en la **teoria de juegos**:

- **Facebook tambien estaba en la puja**: segun rumores, Facebook ofrecio 400 millones de dolares
- **La IA es la tecnologia clave del futuro**: quien domine primero la IA, dominara el futuro
- **DeepMind es el mejor equipo**: habian demostrado la viabilidad del deep reinforcement learning

El CEO de Google, Larry Page, intervino personalmente para convencer a Hassabis de elegir Google en lugar de Facebook.

### Condiciones de la Adquisicion

Hassabis negocio varias condiciones clave:

1. **Operacion independiente**: DeepMind mantiene su sede en Londres, I+D independiente
2. **Libertad academica**: pueden publicar articulos en lugar de mantener todo en secreto
3. **Comite de etica**: establecer un mecanismo de revision etica de IA
4. **Investigacion a largo plazo**: sin presion de comercializacion a corto plazo

Estas condiciones permitieron a DeepMind perseguir investigacion a largo plazo y de alto riesgo, como conquistar el Go con IA.

### Estrategia de IA de Google

La adquisicion de DeepMind fue parte de la estrategia "AI First" de Google:

| Fecha | Evento |
|-------|--------|
| 2011 | Se funda Google Brain |
| 2013 | Adquisicion de DNNresearch (equipo de Hinton) |
| 2014 | Adquisicion de DeepMind |
| 2015 | TensorFlow se vuelve open source |
| 2016 | Se presenta TPU |

Google se dio cuenta: busqueda, publicidad, traduccion, voz - todos los negocios principales seran transformados por la IA. Quien tenga la mejor IA sera el ganador.

---

## Eligiendo el Go como Objetivo

### Por que el Go?

Despues de ser adquirido por Google, DeepMind tenia mas recursos. Hassabis decidio desafiar un objetivo aparentemente imposible: **usar IA para derrotar al campeon humano de Go**.

Por que eligio el Go y no otros problemas?

#### 1. El Go es "El Santo Grial de la IA"

Antes de 2016, los expertos generalmente creian que la IA necesitaria al menos 10-20 anos para derrotar a los humanos en el Go. El Go era llamado "la ultima fortaleza de la IA".

Razones:
- **Espacio de busqueda enorme**: 10^170 posiciones posibles (el numero de atomos en el universo es solo 10^80)
- **Evaluacion dificil**: no hay valores de piezas claros como en el ajedrez
- **Dependencia de la intuicion**: los mejores jugadores a menudo dicen "este movimiento se siente correcto" pero no pueden explicar por que

#### 2. La Leccion de Deep Blue

En 1997, Deep Blue de IBM derroto al campeon mundial de ajedrez Kasparov. Pero esta victoria fue controvertida:

- Deep Blue dependia de **busqueda de fuerza bruta** (evaluando 200 millones de posiciones por segundo)
- Usaba **funciones de evaluacion disenadas por expertos humanos**
- Esto no era verdadera "inteligencia", sino "poder de computo"

Hassabis queria probar: la IA puede resolver problemas a traves del **aprendizaje** en lugar de la fuerza bruta.

#### 3. Objetivo Medible

El Go tiene un sistema de clasificacion internacional (Elo rating) y jugadores profesionales, proporcionando estandares objetivos de medicion. Si la IA puede derrotar al campeon mundial, es un exito indiscutible.

#### 4. Conexion con la Neurociencia

La intuicion de los jugadores humanos - saber con una mirada al tablero que posiciones son importantes - es exactamente la capacidad que Hassabis queria replicar con IA. El Go es el escenario perfecto para probar la "intuicion de maquina".

---

## El Equipo de AlphaGo

### Figuras Clave

El exito de AlphaGo vino de un equipo con experiencia multidisciplinaria:

#### David Silver: Investigador Principal

**David Silver** es el primer autor del articulo de AlphaGo y un experto lider en aprendizaje por refuerzo.

- **Formacion**: Graduado en Matematicas de Cambridge, Doctor en RL de la Universidad de Alberta
- **Mentor**: Richard Sutton (padre del aprendizaje por refuerzo)
- **Especialidad**: Busqueda de arbol Monte Carlo, aprendizaje por diferencia temporal

Silver ya habia investigado el Go computacional en su tesis doctoral, pero la tecnologia de entonces estaba lejos de madurar. Al unirse a DeepMind, finalmente tuvo la oportunidad de realizar este sueno.

#### Aja Huang: Experto en Go

**Aja Huang** (Huang Shih-chieh) es taiwanes, jugador amateur 6 dan, y tambien pionero en el campo del Go computacional.

- **Formacion**: Doctor en Ciencias de la Computacion de la Universidad Normal Nacional de Taiwan
- **Especialidad**: Programacion de Go computacional
- **Trabajo famoso**: Erica (programa temprano de Go computacional)

Huang desempeno un papel clave en el equipo de AlphaGo: no solo entendia el Go, sino tambien la IA. En las partidas contra Lee Sedol, el fue quien opero AlphaGo.

#### Otros Miembros Clave

| Miembro | Rol |
|---------|-----|
| Chris J. Maddison | Experto en busqueda de arbol Monte Carlo |
| Arthur Guez | Investigador de aprendizaje por refuerzo |
| Laurent Sifre | Ingeniero de deep learning |
| George van den Driessche | Ingeniero de sistemas distribuidos |

### Colaboracion Interdisciplinaria

El exito de AlphaGo demostro el poder de la **colaboracion interdisciplinaria**:

- **Expertos en Go** proporcionaron conocimiento del dominio
- **Investigadores de machine learning** disenaron algoritmos
- **Ingenieros** implementaron sistemas de entrenamiento a gran escala
- **Neurocientificos** proporcionaron inspiracion teorica

Esta composicion de equipo se convirtio posteriormente en el modelo estandar de DeepMind.

---

## Publicacion en Nature

### La Sorpresa Secreta

El 27 de enero de 2016, DeepMind publico un articulo en la prestigiosa revista academica *Nature*:

> **"Mastering the game of Go with deep neural networks and tree search"**

El articulo anuncio que AlphaGo habia:
1. Derrotado a todos los otros programas de Go
2. Vencido al campeon europeo **Fan Hui** (profesional 2 dan) con un marcador de **5:0**

Esta noticia conmociono al mundo. Antes de la publicacion del articulo, nadie sabia que DeepMind estaba investigando el Go.

### Contribuciones Clave del Articulo

El articulo de *Nature* describio las tres grandes innovaciones de AlphaGo:

#### 1. Policy Network (Red de Politica)

Uso una red neuronal convolucional profunda para predecir el siguiente movimiento de los jugadores humanos. Los datos de entrenamiento vinieron de **30 millones de partidas** de registros humanos.

```
Precision: 57% (prediciendo el siguiente movimiento de expertos humanos)
```

Esto fue mas de 10 puntos porcentuales mas alto que el mejor programa de Go computacional anterior.

#### 2. Value Network (Red de Valor)

Uso otra red neuronal para evaluar la tasa de victoria de la posicion actual. Esto reemplazo la simulacion aleatoria tradicional (Monte Carlo rollout).

```
Precision: equivalente a 15000 simulaciones aleatorias, pero 15000 veces mas rapido
```

#### 3. Integracion con Busqueda de Arbol Monte Carlo

Integro las dos redes neuronales en el marco MCTS:
- Policy Network guia la direccion de busqueda
- Value Network evalua los nodos hoja

Esto dio a AlphaGo tanto "intuicion" (redes neuronales) como "razonamiento" (busqueda de arbol).

### Reaccion de la Comunidad Academica

Despues de la publicacion del articulo, la comunidad academica reacciono con entusiasmo:

> "Este es el momento del alunizaje de la inteligencia artificial."
> — **Stuart Russell**, Profesor de UC Berkeley, autor de libros de texto de IA

> "Originalmente pensaba que tomaria 10 anos mas, no esperaba que fuera tan rapido."
> — **Martin Muller**, experto en Go computacional

Pero algunos tambien fueron escepticos:

> "Fan Hui es solo profesional 2 dan, no es un jugador de elite real. Deja que AlphaGo juegue contra Lee Sedol y luego hablaremos."

DeepMind acepto el desafio.

---

## El Desafio a Lee Sedol

### Por que Lee Sedol?

**Lee Sedol** es un jugador coreano, considerado en ese momento como uno de los jugadores mas fuertes de la decada pasada:

| Indicador | Datos |
|-----------|-------|
| Titulos de campeon mundial | 18 |
| Campeonatos internacionales | 32 |
| Clasificacion mundial mas alta | #1 |
| Estilo | "Genio" "Calculador divino" |

Al elegir a Lee Sedol, DeepMind estaba desafiando al oponente humano mas fuerte.

### Premio de 1 Millon de Dolares

Google proporciono un premio de **1 millon de dolares** para este partido:

- Si Lee Sedol ganaba: el premio era para Lee Sedol
- Si AlphaGo ganaba: el premio se donaba a UNICEF, educacion STEM y otras organizaciones beneficas

Esto no fue solo una demostracion tecnica, sino un evento deportivo de atencion mundial.

### Predicciones Antes del Partido

Antes del partido, la mayoria de los jugadores profesionales predijeron que Lee Sedol ganaria facilmente:

> "AlphaGo podria ganar una partida, pero en un partido de 5 partidas ganare 5:0."
> — **Lee Sedol**, entrevista previa al partido

> "Las computadoras juegan de manera rigida, los mejores jugadores pueden encontrar facilmente sus debilidades."
> — Un profesional 9 dan

Pero el equipo de DeepMind tenia una vision diferente. David Silver revelo mas tarde:

> "En nuestras pruebas internas, ya habiamos hecho que AlphaGo jugara 500 partidas contra la version que enfrento a Fan Hui. La nueva version gano 499."

---

## Marzo de 2016: Las Cinco Partidas que Cambiaron el Mundo

### Primera Partida: Comienza la Conmocion

9 de marzo de 2016, Hotel Four Seasons de Seul.

Lee Sedol jugo con negras primero, AlphaGo con blancas. Despues de 3 horas y 28 minutos de juego, AlphaGo gano por abandono.

Esta fue la primera vez que un jugador humano de elite perdio formalmente contra una IA.

### Segunda Partida: La Jugada Divina

La segunda partida vio nacer lo que se llamo "**La Jugada Divina**" en el movimiento 37: AlphaGo jugo un hombro en la quinta linea que todos los jugadores profesionales pensaron que era un error, pero resulto ser la clave de la victoria.

(Ver mas detalles en: [Analisis Profundo de "La Jugada Divina"](../move-37))

AlphaGo gano de nuevo.

### Tercera Partida: 3:0

En la tercera partida, Lee Sedol intento una apertura no tradicional, pero AlphaGo respondio con facilidad. 3:0.

El mundo entero comenzo a darse cuenta: esto no fue casualidad, la IA realmente habia superado a los humanos.

### Cuarta Partida: El Contraataque Humano

En la cuarta partida, Lee Sedol jugo lo que se llamo "**La Jugada Divina**" en el movimiento 78: una brillante invasion que causo confusion en AlphaGo.

AlphaGo jugo movimientos claramente malos en los siguientes turnos y finalmente se rindio.

Esta victoria demostro: la IA tambien tiene debilidades. Lee Sedol las encontro.

### Quinta Partida: Marcador Final

En la quinta partida, AlphaGo volvio a la normalidad y gano por abandono.

**Marcador final: AlphaGo 4:1 Lee Sedol**

---

## Impacto y Consecuencias

### Atencion Global

El impacto de este partido fue mucho mas alla del mundo del Go:

- **200 millones de personas** en todo el mundo vieron la transmision en vivo
- The New York Times, The Economist y otros medios principales publicaron extensos reportajes
- Las acciones de Google subieron durante el partido
- "Inteligencia artificial" se convirtio en el tema tecnologico mas candente del ano

### Impacto en el Mundo del Go

Despues del partido, la actitud de los jugadores profesionales cambio de "desprecio" a "reverencia":

> "Antes pensabamos que los humanos entendian el Go, ahora descubrimos que solo sabemos un poco."
> — **Ke Jie**, jugador chino, clasificado numero uno en el mundo en ese momento

Muchos jugadores profesionales comenzaron a usar IA para entrenar, y la forma de jugar Go cambio como resultado.

### Impacto en el Campo de la IA

AlphaGo demostro varias cosas:

1. **El deep learning puede resolver problemas de nivel experto**: no solo reconocer gatos y perros, sino jugar Go
2. **El aprendizaje por refuerzo puede superar a los humanos**: a traves del auto-juego, la IA puede descubrir estrategias desconocidas para los humanos
3. **Redes neuronales + busqueda es una combinacion poderosa**: intuicion + razonamiento = inteligencia mas fuerte

Estas ideas se aplicaron posteriormente a:
- **AlphaFold**: prediccion de estructura de proteinas (logro nivel Premio Nobel en 2020)
- **AlphaZero**: IA de juegos general
- **MuZero**: aprendizaje sin necesidad de reglas

---

## Correspondencia con Animaciones

Conceptos centrales y numeros de animacion cubiertos en este articulo:

| Numero | Concepto | Correspondencia Fisica/Matematica |
|--------|----------|-----------------------------------|
| E7 | Desde cero | Auto-organizacion |
| E5 | Auto-juego | Convergencia de punto fijo |
| F8 | Capacidad emergente | Transicion de fase |
| H4 | Gradiente de politica | Optimizacion estocastica |

---

## Lecturas Adicionales

- **Siguiente articulo**: [Resena de Partidas Clave](../key-matches) — Analisis completo de las partidas de Fan Hui, Lee Sedol y Ke Jie
- **Detalles tecnicos**: [Policy Network en Detalle](../policy-network) — Como AlphaGo aprendio a jugar Go
- **Practica**: [Tu Primera IA de Go en 30 Minutos](/docs/tech/hands-on/) — Experimenta tu mismo

---

## Referencias

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. Documental "AlphaGo" (2017), dirigido por Greg Kohs.
