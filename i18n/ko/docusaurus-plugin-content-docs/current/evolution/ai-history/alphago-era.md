---
sidebar_position: 1
title: AlphaGo 시대
---

# AlphaGo 시대 (2015-2017)

2015년부터 2017년까지, Google DeepMind의 AlphaGo 시리즈 프로그램은 인공지능 역사상 가장 상징적인 돌파구 중 하나를 창출했습니다. 불과 2년 만에 바둑은 '인공지능이 정복할 수 없는 게임'에서 'AI가 완전히 인류를 초월한 영역'으로 바뀌었습니다.

## 2015년 10월: AlphaGo, 판후이 격파

### 역사적인 비밀 대국

2015년 10월, 런던의 한 사무실에서 DeepMind는 비밀 대국을 주선했습니다. 상대는 유럽 바둑 챔피언이자 프로 2단 기사 **판후이**였습니다.

대국 결과: AlphaGo가 5:0으로 완승.

이것은 역사상 최초로 컴퓨터 프로그램이 공정한 조건에서(접바둑 없이) 프로 바둑 기사를 꺾은 것입니다. 이 소식은 2016년 1월 공식 발표되어 즉시 전 세계적인 관심을 받았습니다.

### 초대 AlphaGo의 기술

이 버전의 AlphaGo는 두 가지 핵심 기술의 결합을 사용했습니다:

1. **심층 신경망**: 수십만 국의 인간 프로 대국을 학습하여 국면을 평가하는 '가치 네트워크'와 다음 수를 예측하는 '정책 네트워크'를 훈련

2. **몬테카를로 트리 탐색(MCTS)**: 신경망의 출력을 활용하여 탐색을 안내하고, 계산해야 할 변화의 수를 대폭 감소

이러한 '직관'과 '계산'의 결합은 정확히 인간 기사가 문제를 사고하는 방식입니다 — 다만 AI가 두 측면 모두에서 더 잘했습니다.

## 2016년 3월: AlphaGo vs 이세돌

### 세기의 대결

2016년 3월 9일부터 15일까지, AlphaGo와 세계 정상급 기사 **이세돌**이 서울에서 5번기 대결을 펼쳤습니다. 이 대국은 전 세계 2억 명 이상이 시청하여 인공지능 역사상 가장 주목받은 사건 중 하나가 되었습니다.

### 대국 결과

| 국 | 날짜 | 결과 | 비고 |
|------|------|------|------|
| 제1국 | 3월 9일 | AlphaGo 승 | 중반 승 |
| 제2국 | 3월 10일 | AlphaGo 승 | 중반 승, 유명한 '37수' 등장 |
| 제3국 | 3월 12일 | AlphaGo 승 | 중반 승 |
| 제4국 | 3월 13일 | 이세돌 승 | **이세돌 78수 '신의 한 수'** |
| 제5국 | 3월 15일 | AlphaGo 승 | 중반 승 |

최종 점수: **AlphaGo 4:1 이세돌**

### 제2국 37수: '신의 한 수'

제2국에서 AlphaGo는 오른쪽에 관전하던 모든 기사들을 당혹스럽게 한 '어깨짚기' 한 수를 두었습니다.

이 수는 전혀 이치에 맞지 않는 것처럼 보였으며, 어떤 알려진 정석에도 부합하지 않았습니다. 해설자는 이 수를 인간이 둘 확률을 만분의 일 이하로 추정했습니다. 그러나 대국이 진행되면서 이 수의 깊은 의미가 점차 드러났습니다 — 여러 방향에 동시에 영향을 미치며 효율이 극도로 높았습니다.

이 한 수는 '신의 한 수'로 불리며, AI가 이미 인간이 이해할 수 없는 바둑 이념을 발전시켰음을 상징합니다.

### 제4국 78수: 인류의 반격

3연패 후, 이세돌은 제4국에서 마찬가지로 놀라운 한 수를 두었습니다 — 78수 '끼워넣기'.

이 수는 교묘한 수법으로, 복잡한 전투 중에 AlphaGo가 예견하지 못한 변화를 만들어냈습니다. AlphaGo는 이 수 이후 명백한 혼란을 보였고, 결국 불계패했습니다.

이것은 정식 대국에서 인간이 AlphaGo를 꺾은 유일한 경기이며, 이세돌의 이 수는 영원히 인류 지혜의 상징으로 기억될 것입니다.

### 대국의 영향

이 대국의 영향은 바둑계를 훨씬 넘어섰습니다:

- **인공지능의 이정표**: 딥러닝이 극도로 복잡한 문제를 처리할 수 있음을 증명
- **한국의 전국민적 관심**: 통계에 따르면 한국 인구의 절반 이상이 대국을 시청
- **바둑의 새 시대**: 프로 기사들이 AI에게 배워야 함을 인식하기 시작
- **기술 투자 열풍**: 전 세계적으로 AI 연구에 대한 투자를 촉진

## 2017년 1월: Master 60연승

### 신비로운 온라인 기사

2016년 말부터 2017년 초까지, 'Master'라는 계정이 이청(Tygem)과 야호(Fox) 등 바둑 대국 사이트에 나타났습니다. 극도로 빠른 속도로 커제, 박정환, 이야마 유타 등 세계 정상급 기사들을 포함한 모든 도전자를 꺾었습니다.

최종 전적: **60전 60승** (1국은 상대방 연결 끊김으로 무승부 판정 포함)

60국이 끝난 후, DeepMind는 공식 발표했습니다: Master는 AlphaGo의 새 버전입니다.

### Master가 보여준 새로운 이념

Master의 기풍은 1년 전 이세돌을 꺾은 버전과 명확히 달랐습니다:

- **더 빠른 계산 속도**: 매 수에 수십 초만 사용
- **더 공격적인 착수**: 전통 이론에서 '좋지 않다'고 여기는 착수를 빈번히 사용
- **삼삼 점입이 주류가 됨**: Master는 자주 포석 초반에 직접 삼삼에 점입

이러한 착수법은 인류가 수백 년간 축적한 바둑 이론을 완전히 뒤집었고, 프로 기사들은 대량으로 AI의 착수를 모방하기 시작했습니다.

## 2017년 5월: AlphaGo vs 커제

### 인류의 마지막 도전

2017년 5월, 중국 우전에서 AlphaGo와 당시 세계 랭킹 1위 **커제**가 3번기 대결을 펼쳤습니다. 이것은 '인류의 마지막 도전'으로 여겨졌습니다.

### 대국 결과

| 국 | 날짜 | 결과 | 비고 |
|------|------|------|------|
| 제1국 | 5월 23일 | AlphaGo 승 | 1/4집 승 (최소 차이) |
| 제2국 | 5월 25일 | AlphaGo 승 | 중반 승 |
| 제3국 | 5월 27일 | AlphaGo 승 | 중반 승 |

최종 점수: **AlphaGo 3:0 커제**

### 커제의 눈물

제2국 대국 중간에 커제는 한때 자리를 비웠다가 돌아왔을 때 눈시울이 붉었습니다. 경기 후 그는 말했습니다:

> "그것은 너무 완벽합니다. 저는 어떤 승리의 희망도 보이지 않습니다."

> "AlphaGo와 바둑을 두면서 저는 그것의 바둑에 대한 사랑을 느꼈습니다."

이 대국이 끝난 후, DeepMind는 AlphaGo의 은퇴를 선언하며 더 이상 공개 대국에 참가하지 않겠다고 했습니다.

## 2017년 10월: AlphaZero 논문

### 제로에서 시작한 초월

2017년 10월, DeepMind는 AlphaZero 논문을 발표하여 더 놀라운 성취를 보여주었습니다.

AlphaZero의 돌파구: **인간 기보가 전혀 필요 없다.**

프로그램에게 바둑의 규칙만 알려주고, 자기 대국을 통해 학습하게 했습니다. '제로'에서 시작하여, AlphaZero는 단 **40일**의 자기 훈련으로 이전의 모든 AlphaGo 버전을 초월했습니다.

### 통합된 지능

더 놀라운 것은, 같은 AlphaZero 프로그램(게임 규칙만 변경)이 바둑, 체스, 일본 장기 세 가지 게임에서 모두 모든 인간과 이전 최강 프로그램을 초월하는 수준에 도달했다는 것입니다.

이것은 심층 강화 학습의 범용성을 증명했습니다 — 같은 알고리즘이 완전히 다른 지적 게임들을 마스터할 수 있습니다.

## 기술 해설

### 심층 신경망

AlphaGo가 사용한 신경망에는 두 가지 주요 부분이 있습니다:

**정책 네트워크(Policy Network)**
- 입력: 현재 바둑판 국면
- 출력: 각 위치의 착수 확률
- 기능: 인간의 '직관'을 시뮬레이션하여 탐색 범위를 빠르게 축소

**가치 네트워크(Value Network)**
- 입력: 현재 바둑판 국면
- 출력: 현재 국면의 승률 추정
- 기능: 국면의 좋고 나쁨을 평가하여 전통적인 완전 탐색을 대체

### 몬테카를로 트리 탐색(MCTS)

MCTS는 다음 단계로 작동하는 탐색 알고리즘입니다:

1. **선택(Selection)**: 루트 노드에서 시작하여 특정 정책에 따라 자식 노드 선택
2. **확장(Expansion)**: 리프 노드에서 새 자식 노드 추가
3. **시뮬레이션(Simulation)**: 새 노드에서 시작하여 게임이 끝날 때까지 무작위 시뮬레이션 수행
4. **역전파(Backpropagation)**: 시뮬레이션 결과를 위로 전달하여 경로상의 모든 노드 통계 업데이트

AlphaGo의 혁신은 무작위 시뮬레이션을 신경망으로 대체하여 탐색 효율을 크게 높인 것입니다.

### 강화 학습

AlphaGo Lee에서 AlphaZero까지, 강화 학습은 점점 더 중요한 역할을 했습니다:

- **AlphaGo Fan** (판후이 격파): 주로 인간 기보 훈련에 의존
- **AlphaGo Lee** (이세돌 격파): 인간 기보 + 자기 대국
- **AlphaGo Master** (60연승): 강화된 자기 대국 훈련
- **AlphaZero**: 완전한 자기 대국, 인간 기보 불필요

이 진화 과정은 AI가 궁극적으로 완전히 자기 학습에 의존하여 초인간 수준에 도달할 수 있음을 보여줍니다.

---

AlphaGo 시대는 2017년에 끝났지만, 그것이 개척한 기술과 이념은 바둑과 인공지능 분야에 계속 영향을 미치고 있습니다. 이어지는 KataGo 시대는 이러한 기술을 모든 바둑 애호가의 컴퓨터와 휴대폰으로 가져왔습니다.

다음 편: [KataGo 시대](/docs/evolution/ai-history/katago-era)

