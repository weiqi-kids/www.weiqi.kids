---
sidebar_position: 11
title: CNN과 바둑의 결합
description: 합성곱 신경망이 왜 바둑에 특히 적합한지, 수용 영역부터 배치 정규화까지 완전 분석
---

# CNN과 바둑의 결합

DeepMind가 **합성곱 신경망(CNN)**을 사용하여 바둑을 처리하기로 결정한 것은 천재적인 설계 결정이었습니다.

CNN은 원래 이미지 인식을 위해 설계되었습니다. 왜 바둑에도 적합할까요? 이 글에서는 CNN의 작동 원리와 바둑과의 완벽한 조합에 대해 깊이 살펴보겠습니다.

---

## 왜 CNN이 바둑판에 적합한가?

### 바둑판은 '이미지'이다

어떤 관점에서 보면, 19×19 바둑판은 하나의 **이미지**입니다:

| 이미지 | 바둑판 |
|------|---------|
| 픽셀 | 교차점 |
| RGB 채널 | 특징 평면(흑, 백, 빈칸...) |
| 224×224 | 19×19 |
| 개와 고양이 인식 | 좋은 수와 나쁜 수 판단 |

이 비유는 우연이 아닙니다. CNN이 이미지에 뛰어난 이유가 바둑판에도 적용됩니다.

### 세 가지 핵심 특성

CNN에는 바둑판 유형의 데이터에 특히 적합한 세 가지 특성이 있습니다:

#### 1. 지역 연결(Local Connectivity)

CNN의 합성곱 커널은 지역 영역만 봅니다. 이는 바둑의 특성과 완벽하게 일치합니다:

```
이미지 인식:             바둑:
고양이 귀는 지역 특징      '집'은 지역 바둑 형태
전체 이미지를 볼 필요 없음  전체 바둑판을 볼 필요 없음

    3×3 영역              3×3 영역
   ┌───────┐            ┌───────┐
   │ ○ ● ○ │            │ ○ ● ○ │
   │ ● ○ ● │  ←  집     │ ● · ● │
   │ ○ ● ○ │            │ ○ ● ○ │
   └───────┘            └───────┘
```

많은 바둑 개념이 '지역적'입니다:
- **집**: 2×2 또는 3×3 영역
- **단수**: 3×3 영역
- **연결, 끊기**: 2×2 영역

#### 2. 가중치 공유(Weight Sharing)

동일한 합성곱 커널이 전체 바둑판을 스캔합니다. 이는 다음을 의미합니다:

> **바둑판 왼쪽 상단의 '집'과 오른쪽 하단의 '집'을 같은 방식으로 인식한다**

이것은 합리적입니다—바둑 규칙은 위치에 따라 다르지 않습니다(변과 귀는 예외지만, 변/귀 특징 평면으로 처리할 수 있습니다).

가중치 공유는 또한 파라미터 수를 크게 줄입니다:

| 방법 | 파라미터 수 |
|------|--------|
| 완전 연결 네트워크 | 361 × 361 × 채널 수 = 수천만 |
| CNN | 3 × 3 × 채널 수 × 필터 수 = 수백만 |

#### 3. 이동 등변성(Translation Equivariance)

입력이 이동하면 CNN의 출력도 그에 맞게 이동합니다:

```
입력:                    출력 (고확률 영역):
  A B C D E               A B C D E
1 . . . . .            1  . . . . .
2 . ● . . .   →        2  . * . . .
3 . . . . .            3  . . . . .

입력 이동 후:              출력도 이동:
  A B C D E               A B C D E
1 . . . . .            1  . . . . .
2 . . . . .   →        2  . . . . .
3 . . ● . .            3  . . * . .
```

이것은 바둑에서 매우 중요합니다: 동일한 지역 바둑 형태는 바둑판 어디에 나타나든 비슷한 평가를 받아야 합니다.

---

## 합성곱 연산

### 기본 원리

합성곱 연산은 CNN의 핵심입니다. 이것은 '슬라이딩 윈도우' 연산입니다:

```
입력 (5×5):              합성곱 커널 (3×3):         출력 (5×5, padding=same):
┌───────────────┐       ┌─────────┐           ┌───────────────┐
│ 1 0 1 0 0     │       │ 1 0 1   │           │ 2 1 3 1 2     │
│ 0 1 1 1 0     │   *   │ 0 1 0   │    =      │ 1 4 3 3 1     │
│ 1 1 1 1 1     │       │ 1 0 1   │           │ 3 3 5 3 3     │
│ 0 0 1 1 0     │       └─────────┘           │ 1 3 3 4 1     │
│ 0 1 0 0 1     │                             │ 2 1 3 1 2     │
└───────────────┘                             └───────────────┘
```

계산 과정(중심점을 예로):

```
출력[2,2] = 1×1 + 1×0 + 1×1 +
            1×0 + 1×1 + 1×0 +
            1×1 + 1×0 + 1×1
          = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1
          = 5
```

### 다중 채널 합성곱

입력에 여러 채널(예: 48개의 특징 평면)이 있을 때, 합성곱 커널도 3D가 됩니다:

```
입력: 19×19×48          합성곱 커널: 3×3×48          출력: 19×19×1
    ┌─────┐               ┌───┐                  ┌─────┐
   ╱     ╱│              ╱   ╱│                 │     │
  ╱     ╱ │   합성곱    ╱   ╱ │                 │     │
 ╱     ╱  │   →        ╱   ╱  │    →            │     │
┌─────┐   │           ┌───┐   │                 └─────┘
│     │  ╱            │   │  ╱
│     │ ╱             │   │╱
└─────┘╱              └───┘
48 층                  48 층                    1 층
```

각 합성곱 커널은 모든 입력 채널에서 계산하여 하나의 출력 채널을 생성합니다.

### 다중 필터

AlphaGo는 192개의 필터를 사용하며, 각 필터는 다른 특징을 학습합니다:

```
입력: 19×19×48

      ┌─────┐
     ╱     ╱│
    ╱     ╱ │     192개의 3×3×48 합성곱 커널
   ╱     ╱  │     ────────────────────►
  ┌─────┐   │
  │     │  ╱
  │     │ ╱
  └─────┘╱

출력: 19×19×192

      ┌─────┐
     ╱     ╱│
    ╱     ╱ │
   ╱     ╱  │
  ┌─────┐   │
  │     │  ╱
  │     │ ╱
  └─────┘╱
```

각 필터는 다른 바둑 형태를 학습할 수 있습니다:
- 필터 1: 집 감지
- 필터 2: 단점 감지
- 필터 3: 연결 감지
- ...
- 필터 192: 어떤 복잡한 패턴

---

## 수용 영역

### 수용 영역이란?

**수용 영역(Receptive Field)**은 출력의 한 위치가 입력의 어떤 위치들에 의해 영향을 받는지를 나타냅니다.

#### 단일 층 합성곱

3×3 합성곱 커널을 사용할 때, 출력의 각 위치는 입력의 3×3 영역에만 영향을 받습니다:

```
입력:                   출력:
  ┌─────────────┐       ┌───────────┐
  │ . . . . .   │       │ . . . .   │
  │ . ● ● ● .   │  →    │ . ● . .   │
  │ . ● ● ● .   │       │ . . . .   │
  │ . ● ● ● .   │       │ . . . .   │
  │ . . . . .   │       └───────────┘
  └─────────────┘
     수용 영역 3×3
```

#### 다중 층 합성곱

여러 층의 합성곱을 쌓으면 수용 영역이 확장됩니다:

| 층 수 | 수용 영역 | 계산 |
|------|--------|------|
| 1 | 3×3 | 3 |
| 2 | 5×5 | 3 + (3-1) = 5 |
| 3 | 7×7 | 5 + (3-1) = 7 |
| ... | ... | ... |
| 12 | 25×25 | 3 + 11×2 = 25 |

AlphaGo의 12층 합성곱은 **25×25의 수용 영역**을 제공하며, 이는 이미 19×19 바둑판을 초과합니다!

이것은 다음을 의미합니다:
- **출력의 각 위치가 전체 바둑판을 '볼' 수 있다**
- 하지만 '보는' 방식이 다릅니다: 가까운 곳은 자세히, 먼 곳은 개괄적으로
- 이것은 인간 기사의 사고 방식과 유사합니다

### 수용 영역과 바둑

수용 영역의 개념은 AlphaGo가 '전역' 문제를 처리할 수 있는 이유를 설명합니다:

```
지역 문제(3×3 수용 영역):     전역 문제(25×25 수용 영역):
- 여기에 집이 있는가?          - 이 그룹에 집이 있는가?
- 단수를 부를 수 있는가?       - 축이 유리한가?
- 연결할 수 있는가?            - 전체 형세가 어떠한가?
```

얕은 층은 지역 특징을 처리하고, 깊은 층은 전역 특징을 처리합니다.

---

## 지역 vs 전역 특징

### CNN의 계층 구조

CNN은 자연스럽게 계층 구조를 형성합니다:

```
입력층:        흑돌, 백돌, 빈칸
   ↓
얕은 층 (1-3):    집, 연결, 끊기, 단수
   ↓
중간 층 (4-8):    바둑 형태, 삶, 죽음
   ↓
깊은 층 (9-12):   세력, 두께, 큰 장소
   ↓
출력층:        착수 확률 / 승률
```

이것은 인간이 바둑을 배우는 과정과 놀랍도록 유사합니다:
1. 먼저 규칙을 배운다(어디에 돌이 있는지)
2. 그 다음 전술을 배운다(어떻게 돌을 잡는지)
3. 그 다음 바둑 형태를 배운다(좋은 모양이 무엇인지)
4. 마지막으로 대국관을 배운다(전체 판단)

### 은닉층 시각화

연구자들은 CNN의 은닉층이 실제로 의미 있는 특징을 학습한다는 것을 발견했습니다:

#### 얕은 층 필터

```
필터 A(집 감지):         필터 B(단수 감지):
┌───────┐                ┌───────┐
│ + - + │                │ + + + │
│ - + - │                │ + - - │
│ + - + │                │ + + + │
└───────┘                └───────┘
```

#### 깊은 층 필터

깊은 층의 필터는 더 추상적이며 직접 설명하기 어렵지만, 복잡한 바둑 형태 패턴을 포착합니다.

---

## 활성화 함수 선택

### ReLU: 단순하지만 효과적

AlphaGo는 모든 합성곱 층 뒤에 **ReLU(Rectified Linear Unit)**를 사용합니다:

```python
def relu(x):
    return max(0, x)
```

그래프:

```
출력
  │
  │    /
  │   /
  │  /
  │ /
──┼────── 입력
  │
```

### 왜 다른 함수를 사용하지 않는가?

| 활성화 함수 | 공식 | 장점 | 단점 |
|----------|------|------|------|
| ReLU | max(0, x) | 계산이 빠름, 좋은 기울기 | 음수 값 사망 |
| Sigmoid | 1/(1+e^-x) | 출력이 제한됨 | 기울기 소실 |
| Tanh | (e^x-e^-x)/(e^x+e^-x) | 0 중심 | 기울기 소실 |
| LeakyReLU | max(0.01x, x) | 사망 문제 해결 | 하이퍼파라미터 추가 |

깊은 네트워크에서 ReLU의 장점은 분명합니다:
1. **계산이 간단함**: 비교와 최댓값만
2. **기울기 소실 없음**: 양의 영역에서 기울기가 항상 1
3. **희소 활성화**: 많은 뉴런이 0을 출력하여 효율성 향상

### 바둑에서 ReLU의 의미

ReLU의 희소성은 바둑에서 흥미로운 해석이 있습니다:

```
어떤 필터가 '단점'을 감지:
- 단점 있음 → 양수 출력(활성화)
- 단점 없음 → 0 출력(비활성화)

이것은 기사가 '문제가 있는' 위치에만 주목하는 것과 같다
```

---

## 배치 정규화

### 배치 정규화란?

**배치 정규화(Batch Normalization)**는 각 층의 출력이 안정적인 분포를 유지하게 하는 기술입니다:

```python
def batch_norm(x, gamma, beta):
    # 배치의 평균과 표준편차 계산
    mean = x.mean(axis=0)
    std = x.std(axis=0)

    # 정규화
    x_norm = (x - mean) / (std + 1e-8)

    # 스케일링과 이동
    return gamma * x_norm + beta
```

### 왜 필요한가?

#### 내부 공변량 이동

네트워크가 훈련될 때, 각 층의 입력 분포는 이전 층의 가중치 변화에 따라 변합니다. 이를 '내부 공변량 이동'이라고 합니다:

```
첫 번째 층 가중치 업데이트 → 첫 번째 층 출력 분포 변경
                    ↓
               두 번째 층 입력 분포 변경 → 두 번째 층이 다시 적응해야 함
                                        ↓
                                   ... (계속 전파됨)
```

배치 정규화는 각 층의 입력이 고정된 분포(평균 0, 표준편차 1)를 갖도록 강제하여 훈련을 안정화합니다.

### AlphaGo에서의 적용

AlphaGo는 각 합성곱 층 뒤, 활성화 함수 전에 배치 정규화를 사용합니다:

```
Conv → BatchNorm → ReLU → Conv → BatchNorm → ReLU → ...
```

장점:
1. **더 빠른 훈련**: 더 큰 학습률 사용 가능
2. **더 안정적**: 초기화에 대한 민감도 감소
3. **정규화 효과**: 약간의 dropout 효과

### 추론 시 처리

훈련 시에는 현재 배치의 통계를 사용합니다. 추론 시에는 전체 훈련 세트의 통계(이동 평균)를 사용합니다:

```python
# 훈련 시
mean = batch_mean
var = batch_var

# 추론 시
mean = running_mean  # 훈련 중 누적된 평균
var = running_var    # 훈련 중 누적된 분산
```

---

## AlphaGo의 구체적 구성

### 전체 아키텍처

```
입력: 19×19×48

제 1층:
  Conv2D(5×5, 192 filters, padding='same')
  BatchNorm
  ReLU
  출력: 19×19×192

제 2-12층 (총 11층):
  Conv2D(3×3, 192 filters, padding='same')
  BatchNorm
  ReLU
  출력: 19×19×192

출력층 (Policy):
  Conv2D(1×1, 1 filter)
  Flatten
  Softmax
  출력: 361차원 확률

출력층 (Value):
  Conv2D(1×1, 1 filter)
  Flatten
  Dense(256)
  ReLU
  Dense(1)
  Tanh
  출력: 단일 값
```

### 파라미터 구성

| 파라미터 | 값 | 설명 |
|------|------|------|
| 입력 채널 | 48 | 특징 평면 수 |
| 필터 수 | 192 | 각 층의 채널 수 |
| 합성곱 커널 크기 | 3×3(첫 번째 층 5×5) | 수용 영역 |
| 층 수 | 13(출력층 포함) | 깊이 |
| 활성화 함수 | ReLU | 비선형성 |
| 정규화 | BatchNorm | 훈련 안정화 |

### PyTorch 구현

```python
import torch
import torch.nn as nn

class AlphaGoCNN(nn.Module):
    def __init__(self, input_channels=48, num_filters=192, num_layers=12):
        super().__init__()

        # 첫 번째 층(5×5 합성곱)
        self.conv1 = nn.Sequential(
            nn.Conv2d(input_channels, num_filters, kernel_size=5, padding=2),
            nn.BatchNorm2d(num_filters),
            nn.ReLU(inplace=True)
        )

        # 중간 층(3×3 합성곱)
        self.conv_layers = nn.Sequential(*[
            nn.Sequential(
                nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),
                nn.BatchNorm2d(num_filters),
                nn.ReLU(inplace=True)
            )
            for _ in range(num_layers - 1)
        ])

        # Policy 출력 헤드
        self.policy_head = nn.Sequential(
            nn.Conv2d(num_filters, 1, kernel_size=1),
            nn.Flatten(),
            nn.Softmax(dim=1)
        )

        # Value 출력 헤드
        self.value_head = nn.Sequential(
            nn.Conv2d(num_filters, 1, kernel_size=1),
            nn.Flatten(),
            nn.Linear(361, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 1),
            nn.Tanh()
        )

    def forward(self, x):
        # 공유 특징 추출
        x = self.conv1(x)
        x = self.conv_layers(x)

        # 분리된 출력
        policy = self.policy_head(x)
        value = self.value_head(x)

        return policy, value
```

---

## 다른 아키텍처와의 비교

### 완전 연결 네트워크

바둑을 완전 연결 네트워크로 처리한다면:

| 특성 | 완전 연결 | CNN |
|------|--------|-----|
| 파라미터 수 | 매우 큼(수억) | 비교적 작음(수백만) |
| 위치 불변성 | 없음 | 있음 |
| 지역 특징 | 학습하기 어려움 | 자연스럽게 포착 |
| 훈련 효율성 | 낮음 | 높음 |

완전 연결 네트워크는 바둑판의 공간 구조를 활용할 수 없어 효율이 매우 낮습니다.

### 순환 신경망(RNN)

RNN은 순서 데이터(대국 기록 등)에 적합하지만:

| 특성 | RNN | CNN |
|------|-----|-----|
| 공간 처리 | 약함 | 강함 |
| 순서 처리 | 강함 | 약함(기록 평면 필요) |
| 병렬화 | 어려움 | 쉬움 |
| 장거리 의존성 | LSTM 필요 | 깊은 층으로 가능 |

AlphaGo는 CNN + RNN이 아닌 CNN + 기록 평면을 선택했습니다.

### 잔차 네트워크(ResNet)

AlphaGo Zero는 ResNet으로 업그레이드되었습니다:

```
일반 CNN:                ResNet:
  x                        x
  ↓                        ↓
 Conv                     Conv
  ↓                        ↓
 ReLU                    ReLU
  ↓                        ↓
 Conv                     Conv
  ↓                        ↓
  y                      y + x  ← 잔차 연결
```

잔차 연결은 기울기가 더 쉽게 흐르게 하여 더 깊은 네트워크(12층 vs 40층)를 훈련할 수 있습니다.

자세한 내용은 [이중 헤드 네트워크와 잔차 네트워크](../dual-head-resnet)를 참조하세요.

---

## 시각적 이해

### 합성곱 과정

```
입력 바둑판 (5×5로 단순화):

   A B C D E
1  . . . . .
2  . ● . . .
3  . . ○ . .
4  . . . ● .
5  . . . . .

어떤 필터 (3×3, '십자 모양' 감지):
┌───────┐
│ 0 1 0 │
│ 1 1 1 │
│ 0 1 0 │
└───────┘

합성곱 출력:
   A B C D E
1  0 0 0 0 0
2  0 0 0 0 0
3  0 0 1 0 0   ← 중심에 강한 반응(십자 모양 일치)
4  0 0 0 0 0
5  0 0 0 0 0
```

### 다층 특징

```
제 1층 출력 (192개 채널 중 4개):

채널 1 (집):      채널 2 (변):      채널 3 (단점):    채널 4 (연결):
┌─────────┐      ┌─────────┐      ┌─────────┐      ┌─────────┐
│ 0 0 0 0 │      │ 0.8 0 0 │      │ 0 0 0 0 │      │ 0 0 0 0 │
│ 0 0.9 0 │      │ 0.8 0 0 │      │ 0 0 0.7 │      │ 0 0.5 0 │
│ 0 0 0 0 │      │ 0.8 0 0 │      │ 0 0 0 0 │      │ 0 0.8 0 │
│ 0 0 0 0 │      │ 0.8 0 0 │      │ 0 0 0 0 │      │ 0 0.5 0 │
└─────────┘      └─────────┘      └─────────┘      └─────────┘

이러한 특징들은 더 깊은 층에서 더 복잡한 개념으로 결합됩니다...
```

---

## 애니메이션 대응

이 글에서 다루는 핵심 개념과 애니메이션 번호:

| 번호 | 개념 | 물리/수학 대응 |
|------|------|--------------|
| D9 | 합성곱 연산 | 필터 응답 |
| D10 | 수용 영역 | 지역→전역 |
| D11 | 배치 정규화 | 분포 안정화 |
| D1 | 다중 채널 입력 | 텐서 연산 |

---

## 추가 자료

- **이전 글**: [입력 특징 설계](../input-features) — 48개 특징 평면 상세 설명
- **다음 글**: [지도 학습 단계](../supervised-learning) — 인간 기보에서 배우는 방법
- **고급 주제**: [이중 헤드 네트워크와 잔차 네트워크](../dual-head-resnet) — AlphaGo Zero의 네트워크 업그레이드

---

## 핵심 요점

1. **CNN은 바둑판에 자연스럽게 적합**: 지역 연결, 가중치 공유, 이동 등변성
2. **합성곱이 지역 특징 추출**: 3×3 영역의 패턴 인식
3. **깊은 네트워크가 전역 시야 획득**: 12층 → 25×25 수용 영역
4. **ReLU가 빠르고 효과적**: 단순한 비선형 활성화
5. **BatchNorm이 훈련 안정화**: 각 층 출력 표준화

CNN은 AlphaGo가 바둑판을 '볼' 수 있게 합니다—마치 인간이 이미지를 눈으로 보는 것처럼 자연스럽게.

---

## 참고 자료

1. LeCun, Y., Bengio, Y., & Hinton, G. (2015). "Deep learning." *Nature*, 521, 436-444.
2. He, K., et al. (2015). "Deep Residual Learning for Image Recognition." *CVPR*.
3. Ioffe, S., & Szegedy, C. (2015). "Batch Normalization: Accelerating Deep Network Training." *ICML*.
4. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). "ImageNet Classification with Deep Convolutional Neural Networks." *NeurIPS*.
