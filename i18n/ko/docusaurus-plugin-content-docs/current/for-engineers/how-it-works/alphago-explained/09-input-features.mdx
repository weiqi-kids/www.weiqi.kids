---
sidebar_position: 10
title: 입력 특성 설계
description: AlphaGo의 48개 평면에서 AlphaGo Zero의 17개 평면까지, 바둑 AI 특성 공학의 진화를 탐구
---

# 입력 특성 설계

신경망은 숫자만 처리할 수 있습니다. 바둑을 이해시키려면 바둑판을 숫자로 '번역'하는 방법이 필요합니다.

이 번역 과정이 바로 **입력 특성 설계**입니다.

AlphaGo는 48개 특성 평면을 사용했고, AlphaGo Zero는 17개로 간소화했으며, KataGo는 22개로 최적화했습니다. 이 글에서는 이러한 설계 선택 뒤의 고려 사항을 상세히 분석합니다.

---

## 특성 평면이란 무엇인가?

### 기본 개념

하나의 **특성 평면**은 19×19 행렬로, 각 요소는 바둑판의 해당 위치의 특정 속성을 나타냅니다.

예를 들어, '흑돌 위치' 특성 평면:

```
바둑판 상태:               특성 평면(흑돌):
  A B C D E               A B C D E
1 . . . . .            1  0 0 0 0 0
2 . ● . . .            2  0 1 0 0 0
3 . . ○ . .    →       3  0 0 0 0 0
4 . . . ● .            4  0 0 0 1 0
5 . . . . .            5  0 0 0 0 0
```

- 흑돌이 있는 위치 = 1
- 흑돌이 없는 위치 = 0

### 여러 특성 평면

신경망은 다양한 정보가 필요하므로, 여러 특성 평면을 쌓습니다:

```
입력 텐서: 19 × 19 × N

    N개 평면
    ↓
┌───────────┐
│ 평면 1    │ ← 흑돌 위치
├───────────┤
│ 평면 2    │ ← 백돌 위치
├───────────┤
│ 평면 3    │ ← 빈 점 위치
├───────────┤
│ ...       │
├───────────┤
│ 평면 N    │ ← 기타 특성
└───────────┘
    19×19
```

이것은 컬러 이미지가 R, G, B 세 채널을 가지는 것과 유사합니다. 바둑 '이미지'는 N개 채널을 가집니다.

---

## AlphaGo의 48개 특성 평면

### 완전한 목록

AlphaGo는 48개 특성 평면을 사용하며, 여러 카테고리로 나뉩니다:

#### 1. 돌 위치 (3개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 1 | 흑돌 | 흑돌 있음 = 1, 아니면 = 0 |
| 2 | 백돌 | 백돌 있음 = 1, 아니면 = 0 |
| 3 | 빈 점 | 빈 점 = 1, 아니면 = 0 |

#### 2. 기록 (16개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 4-11 | 흑돌 기록 | 흑돌이 1-8수 전의 위치 |
| 12-19 | 백돌 기록 | 백돌이 1-8수 전의 위치 |

기록이 왜 필요할까요?
- **패 판단**: 즉시 되잡기가 가능한지 알아야 함
- **착수 의도**: 최근 몇 수가 양측의 계획을 드러냄
- **시간 정보**: CNN 자체는 시간을 처리하지 않으며, 기록 평면이 이를 보완

#### 3. 활로 수 특성 (8개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 20-23 | 1-4 활로 (아군) | 아군 돌 그룹이 1/2/3/4 활로 = 1 |
| 24-27 | 1-4 활로 (상대) | 상대 돌 그룹이 1/2/3/4 활로 = 1 |

활로 수는 바둑에서 가장 중요한 전술 개념입니다:
- **1 활로**: 단수, 곧 잡힐 상태
- **2 활로**: 위험 상태
- **3 활로**: 주의 필요
- **4+ 활로**: 일단 안전

#### 4. 단수 특성 (8개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 28-31 | 단수 위치 (아군) | 여기 두면 상대 1/2/3/4개 돌을 단수로 만듦 |
| 32-35 | 단수 위치 (상대) | 여기 두면 아군 1/2/3/4개 돌을 단수로 만듦 |

단수는 바둑에서 가장 흔한 전술입니다:
- 여러 돌에 단수 = 더 큰 위협
- 다른 규모의 단수는 다른 대응 필요

#### 5. 축머리 특성 (8개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 36-39 | 축머리 관련 (아군) | 아군 축머리와 관련된 위치 |
| 40-43 | 축머리 관련 (상대) | 상대 축머리와 관련된 위치 |

축머리(Ladder)는 바둑에서 유명한 전술입니다:
- 대각선을 따라 상대 돌을 추격
- '축머리 유리' 또는 '축머리 불리' 판단 필요
- 전역적 시야가 필요하며, 전통적 컴퓨터 바둑의 난제

#### 6. 합법성 특성 (1개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 44 | 합법 위치 | 합법적으로 착수 가능 = 1 |

이것은 네트워크가 불법 수를 출력하는 것을 방지합니다:
- 이미 돌이 있는 위치에는 둘 수 없음
- 금지점(자살이면서 따낼 수 없음)에는 둘 수 없음
- 패 즉시 되잡기는 불가

#### 7. 변/귀 특성 (4개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 45 | 변까지 거리 1 | 1선에 있음 = 1 |
| 46 | 변까지 거리 2 | 2선에 있음 = 1 |
| 47 | 변까지 거리 3 | 3선에 있음 = 1 |
| 48 | 변까지 거리 4+ | 4선 이상 안쪽 = 1 |

변과 귀는 바둑에서 특별한 의미가 있습니다:
- **1선**: 사선, 돌이 쉽게 잡힘
- **2선**: 살기 선, 하지만 효율이 낮음
- **3선**: 실리 선, 안정적
- **4선**: 세력 선, 영향력 추구

### 왜 이렇게 많은 특성이 필요한가?

DeepMind의 설계 철학은 **가능한 많은 정보를 제공**하고, 네트워크가 무엇이 유용한지 스스로 결정하게 하는 것입니다:

```
원본 바둑판 → 48개 특성 평면 → 신경망 → 결정

특성 공학자의 일: 바둑 지식을 특성으로 인코딩
신경망의 일: 이러한 특성을 조합하는 법을 학습
```

이것은 "공을 신경망에 넘기는" 전략입니다 — 인간은 특성 설계를 담당하고, 네트워크는 조합 학습을 담당합니다.

---

## AlphaGo Zero의 간소화: 17개 특성 평면

### 혁명적 변화

AlphaGo Zero는 입력 특성을 대폭 간소화했습니다:

| 버전 | 특성 평면 수 | 인간 지식 사용 |
|------|-----------|-------------|
| AlphaGo | 48 | 많음 (활로 수, 축머리 등) |
| AlphaGo Zero | 17 | 거의 없음 |

### 17개 평면의 구성

#### 1. 돌 위치 기록 (16개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 1-8 | 흑돌 T-0에서 T-7 | 흑돌의 현재와 과거 7수의 위치 |
| 9-16 | 백돌 T-0에서 T-7 | 백돌의 현재와 과거 7수의 위치 |

#### 2. 색상 (1개 평면)

| 평면 | 이름 | 설명 |
|------|------|------|
| 17 | 누구 차례 | 흑 차례 = 전부 1, 백 차례 = 전부 0 |

### 왜 이렇게 간소화할 수 있는가?

AlphaGo Zero의 핵심 통찰:

> **충분한 계산 자원과 학습 시간을 주면, 신경망은 이러한 특성을 스스로 학습할 수 있다**

'활로 수', '단수', '축머리' 같은 개념은 인간이 수천 년에 걸쳐 발전시켜 왔습니다. 하지만 AlphaGo Zero는 신경망이 며칠 내에 스스로 학습할 수 있음을 증명했습니다 — 어쩌면 인간보다 더 나은 표현을 학습할 수도 있습니다.

### 효과 비교

놀랍게도, 더 적은 특성을 사용하는 AlphaGo Zero가 오히려 더 강합니다:

| 버전 | 특성 수 | 학습 시간 | 최종 기력 |
|------|--------|---------|---------|
| AlphaGo Master | 48 | 수개월 | 약 5185 Elo |
| AlphaGo Zero | 17 | 40일 | 약 5185 Elo |
| AlphaGo Zero (3일) | 17 | 3일 | 인간 초월 |

더 적은 인간 지식이 오히려 더 강한 성능을 가져왔습니다.

### 왜 인간 지식이 오히려 부담이 되는가?

#### 1. 인간 지식이 틀릴 수 있음

인간이 정리한 바둑 규칙은 경험적이며, 최적이 아닐 수 있습니다. 예를 들어:
- "금각은변초복피" — 하지만 어떤 국면에서는 중앙이 더 중요
- "축머리 불리면 두지 마라" — 하지만 때로는 주동적 버림이 가능

#### 2. 특성 인코딩이 표현을 제한

'활로 수'를 1-4 활로 네 개 평면으로 인코딩하면, '활로 수'가 중요한 분류 방식이라고 암묵적으로 가정하게 됩니다. 하지만 어쩌면 더 좋은 분류 방식이 있을 수 있고, 이 인코딩이 네트워크가 그것을 발견하는 것을 막습니다.

#### 3. 표현 병목

48개 평면은 더 많은 계산 자원을 차지합니다. 일부 특성이 불필요하다면, 이 자원은 낭비됩니다.

---

## KataGo의 최적화: 22개 특성 평면

### 실용주의적 균형

KataGo는 AlphaGo Zero를 기반으로, 소량의 엄선된 인간 지식을 추가했습니다:

| 항목 | AlphaGo Zero | KataGo |
|------|-------------|--------|
| 기록 평면 | 16 | 5 |
| 돌 위치 | 예 | 예 |
| 누구 차례 | 예 | 예 |
| 패 상태 | 아니오 | 예 |
| 규칙 변형 | 아니오 | 예 (덤, 자살 규칙 등) |
| **총계** | 17 | 22 |

### KataGo의 특성 목록

#### 기본 특성 (5개)

| 평면 | 이름 | 설명 |
|------|------|------|
| 1 | 흑돌 | 현재 흑돌 위치 |
| 2 | 백돌 | 현재 백돌 위치 |
| 3 | 빈 점 | 현재 빈 점 위치 |
| 4 | 누구 차례 (1) | 항상 1인 상수 평면 |
| 5 | 누구 차례 (2) | 흑 차례 = 1, 백 차례 = 0 |

#### 기록 특성 (5개)

| 평면 | 이름 | 설명 |
|------|------|------|
| 6 | 직전 수 위치 | 상대가 직전에 둔 위치 |
| 7 | 2수 전 위치 | 내가 직전에 둔 위치 |
| 8 | 3수 전 위치 | 상대가 2수 전에 둔 위치 |
| 9 | 4수 전 위치 | 내가 2수 전에 둔 위치 |
| 10 | 5수 전 위치 | 상대가 3수 전에 둔 위치 |

#### 패 특성 (3개)

| 평면 | 이름 | 설명 |
|------|------|------|
| 11 | 패 금지점 | 현재 둘 수 없는 패 금지점 |
| 12 | 잠재적 패점 (아군) | 아군이 여기 두면 패가 됨 |
| 13 | 잠재적 패점 (상대) | 상대가 여기 두면 패가 됨 |

#### 규칙 특성 (9개)

| 평면 | 이름 | 설명 |
|------|------|------|
| 14-22 | 규칙 인코딩 | 덤, 자살 규칙, 슈퍼 패 등 |

### 왜 이러한 특성을 추가했는가?

KataGo의 저자 lightvector의 설명:

#### 1. 패가 너무 중요함

패는 바둑에서 가장 복잡한 개념 중 하나입니다. 순수하게 원시 바둑판 상태에서 패 규칙을 학습하려면 대량의 샘플이 필요합니다. 패 금지점을 명시적으로 표시하면 학습을 가속할 수 있습니다.

#### 2. 규칙의 다양성

바둑에는 여러 규칙이 있습니다:
- **덤**: 중국 규칙 7.5집, 일본 규칙 6.5집
- **자살 규칙**: 일부 규칙은 자살 허용
- **슈퍼 패**: 긴 순환을 처리하는 다른 방식

입력에 규칙을 명시적으로 인코딩하면, 하나의 네트워크로 모든 변형을 처리할 수 있습니다.

#### 3. 학습 효율

소량의 인간 지식을 추가하면 학습을 크게 가속할 수 있습니다. KataGo는 50 GPU 일로 AlphaGo Zero가 5000+ TPU 일로 도달한 기력에 도달했습니다.

---

## 특성 설계의 철학

### 세 가지 방법

| 방법 | 대표 | 특성 수 | 인간 지식 | 계산 요구 |
|------|------|--------|---------|---------|
| 많은 인간 지식 | AlphaGo | 48 | 많음 | 중간 |
| 최소 인간 지식 | AlphaGo Zero | 17 | 거의 없음 | 매우 높음 |
| 적절한 인간 지식 | KataGo | 22 | 소량 엄선 | 비교적 낮음 |

### 트레이드오프 고려

#### 자원이 제한될 때

계산 자원이 제한되면(대부분 연구자의 상황), 일부 인간 지식을 추가하는 것이 현명합니다:
- 학습 수렴 가속
- 필요한 학습 데이터 감소
- 바퀴를 다시 발명하지 않음

#### 극한을 추구할 때

계산 자원이 충분하면, 인간 지식을 줄이면 더 높은 기력에 도달할 수 있습니다:
- 인간 편향 방지
- 인간이 알지 못하는 전략 발견
- 진정한 '제로에서 시작'

### 시사점

AlphaGo 시리즈의 진화가 알려주는 것:

1. **특성 공학은 여전히 중요** — 하지만 형태가 바뀜
2. **End-to-end 학습이 트렌드** — 네트워크가 스스로 특성을 학습하게 함
3. **유일한 정답은 없음** — 자원과 목표에 따라 다름

---

## 구현 예제

### 특성 추출 (AlphaGo 스타일)

```python
import numpy as np

def extract_features_alphago(board, history, current_player):
    """
    AlphaGo 스타일의 48개 특성 평면 추출

    board: 19×19 바둑판, 0=빈, 1=흑, 2=백
    history: 최근 8수의 기록
    current_player: 1=흑, 2=백
    """
    features = np.zeros((48, 19, 19))

    # 1-3: 돌 위치
    features[0] = (board == 1)  # 흑돌
    features[1] = (board == 2)  # 백돌
    features[2] = (board == 0)  # 빈 점

    # 4-19: 기록 위치
    for i, hist_board in enumerate(history[:8]):
        features[3 + i] = (hist_board == 1)      # 흑돌 기록
        features[11 + i] = (hist_board == 2)     # 백돌 기록

    # 20-27: 활로 수 특성
    liberties = compute_liberties(board)
    for i, lib_count in enumerate([1, 2, 3, 4]):
        my_color = current_player
        opp_color = 3 - current_player
        features[19 + i] = (liberties == lib_count) & (board == my_color)
        features[23 + i] = (liberties == lib_count) & (board == opp_color)

    # 28-35: 단수 특성
    capture_counts = compute_captures(board)
    for i, cap_count in enumerate([1, 2, 3, 4]):
        features[27 + i] = (capture_counts[current_player] == cap_count)
        features[31 + i] = (capture_counts[3-current_player] == cap_count)

    # 36-43: 축머리 특성 (간소화)
    ladder_status = compute_ladder(board)
    # ... 상세 구현 생략 ...

    # 44: 합법 위치
    features[43] = compute_legal_moves(board, current_player)

    # 45-48: 변/귀 거리
    for i in range(19):
        for j in range(19):
            dist = min(i, j, 18-i, 18-j)
            if dist == 0:
                features[44, i, j] = 1
            elif dist == 1:
                features[45, i, j] = 1
            elif dist == 2:
                features[46, i, j] = 1
            else:
                features[47, i, j] = 1

    return features
```

### 특성 추출 (AlphaGo Zero 스타일)

```python
def extract_features_zero(board_history, current_player):
    """
    AlphaGo Zero 스타일의 17개 특성 평면 추출

    board_history: 최근 8수의 바둑판 상태 리스트
    current_player: 1=흑, 2=백
    """
    features = np.zeros((17, 19, 19))

    # 1-8: 흑돌의 T-0에서 T-7 위치
    for i, board in enumerate(board_history[:8]):
        features[i] = (board == 1)

    # 9-16: 백돌의 T-0에서 T-7 위치
    for i, board in enumerate(board_history[:8]):
        features[8 + i] = (board == 2)

    # 17: 누구 차례
    if current_player == 1:  # 흑
        features[16] = np.ones((19, 19))
    else:
        features[16] = np.zeros((19, 19))

    return features
```

### 성능 비교

```python
import time

# 1000회 특성 추출 시뮬레이션
board = np.random.randint(0, 3, (19, 19))
history = [np.random.randint(0, 3, (19, 19)) for _ in range(8)]

# AlphaGo 스타일 (복잡한 계산 포함)
start = time.time()
for _ in range(1000):
    features = extract_features_alphago(board, history, 1)
alphago_time = time.time() - start

# AlphaGo Zero 스타일 (간단)
start = time.time()
for _ in range(1000):
    features = extract_features_zero(history, 1)
zero_time = time.time() - start

print(f"AlphaGo 스타일: {alphago_time:.2f}s")
print(f"AlphaGo Zero 스타일: {zero_time:.2f}s")
# 일반적 결과: AlphaGo 스타일이 5-10배 느림
```

---

## 특성 평면 시각화

### 실제 국면 예제

```
실제 바둑판:
   A B C D E F G H J K L M N O P Q R S T
19 . . . . . . . . . . . . . . . . . . .
18 . . . . . . . . . . . . . . . . . . .
17 . . . ● . . . . . . . . . . . ○ . . .
16 . . . . . . . . . . . . . . . . . . .
15 . . . . . . . . . . . . . . . . . . .
...

특성 평면 1(흑돌):
   A B C D E F G H J K L M N O P Q R S T
19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
17 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
...

특성 평면 2(백돌):
   A B C D E F G H J K L M N O P Q R S T
19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
18 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
...
```

### 특성 평면의 통찰

다른 특성 평면을 관찰하면 모델이 무엇을 '보는지' 이해할 수 있습니다:

| 특성 | 직관적 의미 | 모델이 학습할 수 있는 것 |
|------|---------|---------------|
| 흑돌/백돌 위치 | 누가 어디에 | 돌 모양, 연결성 |
| 기록 | 최근에 무슨 일이 | 착수 의도, 전투 방향 |
| 활로 수 | 누가 위험한가 | 공격/방어 대상 |
| 단수 | 전술 기회 | 국소 전술 |
| 변/귀 거리 | 위치 중요성 | 초반 선점, 변/귀 정석 |

---

## 애니메이션 대응

이 글에서 다루는 핵심 개념과 애니메이션 번호:

| 번호 | 개념 | 물리/수학 대응 |
|------|------|--------------|
| 🎬 A8 | 특성 인코딩 | 텐서 표현 |
| 🎬 A10 | 입력 정규화 | 특성 공학 |
| 🎬 D1 | 컨볼루션 입력 | 다채널 이미지 |
| 🎬 E3 | Zero의 간소화 | 최소 표현 |

---

## 추가 읽기

- **이전 글**: [Value Network 상세 해설](../value-network) — 국면 가치를 어떻게 평가하는가
- **다음 글**: [CNN과 바둑의 결합](../cnn-and-go) — 컨볼루션 신경망이 바둑판을 어떻게 처리하는가
- **관련 주제**: [바둑판 상태 표현](../board-representation) — 더 기초적인 데이터 구조

---

## 핵심 포인트

1. **특성 평면은 바둑판의 수치화된 표현**: 각 평면은 19×19 행렬
2. **AlphaGo는 48개 평면 사용**: 많은 인간 바둑 지식 포함
3. **AlphaGo Zero는 17개로 간소화**: 네트워크가 스스로 특성을 학습할 수 있음을 증명
4. **KataGo는 22개로 최적화**: 효율과 성능의 균형
5. **특성 설계는 트레이드오프**: 인간 지식 vs 계산 자원

입력 특성 설계는 '인간이 이해하는 바둑'과 '기계가 처리할 수 있는 숫자'를 연결하는 다리입니다.

---

## 참고 자료

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." *Nature*, 551, 354-359.
3. Wu, D. (2019). "Accelerating Self-Play Learning in Go." *arXiv:1902.10565*.
4. KataGo Documentation: [https://github.com/lightvector/KataGo](https://github.com/lightvector/KataGo)
