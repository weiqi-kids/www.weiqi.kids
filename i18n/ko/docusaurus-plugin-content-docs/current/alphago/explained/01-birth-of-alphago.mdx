---
sidebar_position: 2
title: AlphaGo의 탄생
description: DeepMind 설립부터 Google 인수까지, AlphaGo가 하나의 무모한 아이디어에서 세상을 바꾼 AI로 거듭나기까지
---

# AlphaGo의 탄생

2016년 3월, AlphaGo가 4:1로 이세돌을 꺾었을 때, 전 세계가 물었습니다: 인공지능 역사를 바꾼 이 프로그램은 대체 어떻게 탄생했을까?

그 답은 한 체스 신동의 꿈에서 시작됩니다.

---

## DeepMind의 설립

### Demis Hassabis: 신동에서 AI 선구자로

**Demis Hassabis**는 DeepMind의 공동 창립자이자 CEO입니다. 그의 인생 경험은 마치 AlphaGo를 만들기 위해 준비된 것처럼 보입니다.

#### 체스 신동

1975년 런던에서 태어난 Hassabis는 4살에 체스를 배웠고, 13살에 체스 마스터 등급(Elo 2300+)에 도달했습니다. 이는 영국 역사상 두 번째로 어린 나이에 이 수준에 도달한 기록입니다.

이 경험은 그에게 깊은 통찰을 주었습니다:
- **보드 게임은 지능의 시금석이다**: 체스는 계획, 직관, 패턴 인식이 필요합니다
- **인간 지능의 본질**: 기사들은 어떻게 방대한 가능성 중에서 좋은 수를 찾을까?
- **컴퓨터의 한계**: 1997년 딥 블루가 카스파로프를 이긴 것은 무차별 검색 덕분이지, 진정한 "이해"가 아니었습니다

#### 게임 디자이너

17살에 Hassabis는 Bullfrog Productions(《파퓰러스》 창작자 Peter Molyneux가 설립한 게임 회사)에 합류하여 명작 게임 《테마 파크》 개발에 참여했습니다. 이 경험은 그에게 다음을 가르쳐 주었습니다:

- **복잡한 시스템 설계 방법**: 게임은 현실 세계를 단순화한 모델입니다
- **플레이어 행동 예측**: AI는 인간의 의사결정 과정을 이해해야 합니다

#### 인지 신경과학자

케임브리지 대학에서 컴퓨터 과학 학위를 받은 후, Hassabis는 UCL(University College London)에서 인지 신경과학 박사 학위를 받았습니다. 그의 연구 주제는: **해마가 어떻게 인간이 상상하고 계획할 수 있게 하는가**였습니다.

이 연구에서 발견한 것:
- 인간의 기억과 상상은 같은 뇌 영역을 사용합니다
- 우리는 "정신적 시간 여행"을 통해 미래를 계획합니다
- 이 능력이 지능의 핵심일 수 있습니다

이러한 통찰은 나중에 AlphaGo 설계에 직접적인 영향을 주었습니다—AI가 미래의 수를 "상상"하고 그로부터 학습할 수 있게 했습니다.

### 공동 창립자

2010년, Hassabis는 두 명의 파트너와 함께 DeepMind를 설립했습니다:

| 창립자 | 배경 | 기여 |
|--------|------|------|
| **Demis Hassabis** | 신경과학, 게임 디자인 | 비전과 전략 |
| **Shane Legg** | 머신러닝 박사 | AGI 이론적 기반 |
| **Mustafa Suleyman** | 사회적 기업가 | 비즈니스와 응용 |

### "지능을 해결하고, 그것으로 모든 것을 해결한다"

DeepMind의 미션 선언문은:

> **"Solve intelligence, and then use that to solve everything else."**
>
> "지능을 해결하고, 그것으로 다른 모든 문제를 해결한다."

이것은 평범한 AI 회사가 아닙니다. 그들의 목표는 제품을 만드는 것이 아니라, **범용 인공지능(AGI)**—인간처럼 생각하고, 배우고, 모든 문제를 해결할 수 있는 AI를 만드는 것입니다.

왜 먼저 "지능을 해결"해야 할까요? AGI가 있으면 기후 변화, 질병, 에너지 등 인류 최대의 과제를 해결하는 데 도움이 될 수 있기 때문입니다.

---

## 초기 돌파구: Atari 게임

바둑에 도전하기 전에, DeepMind는 먼저 자신의 능력을 증명했습니다—AI로 Atari 게임을 플레이했습니다.

### DQN: 게임을 배우는 AI

2013년, DeepMind는 **DQN(Deep Q-Network)** 알고리즘을 발표했습니다. 이 AI는:

1. **화면 픽셀만 보고**—게임 규칙을 알려주지 않습니다
2. **스스로 게임을 배웁니다**—시행착오를 통해
3. **인간 수준에 도달**—일부 게임에서는 인간을 초월합니다

DQN은 《브레이크아웃》에서 인간이 발견하는 데 몇 시간이 걸리는 전략을 배웠습니다: **터널을 파서 공이 블록 뒤로 가게 하여 한 번에 많은 블록을 없애는 것**.

이것은 딥러닝 + 강화학습의 조합이 인간이 생각하지 못한 전략을 발견할 수 있다는 것을 증명했습니다.

### 왜 게임부터 시작했나?

Hassabis가 게임을 연구 플랫폼으로 선택한 이유는:

1. **통제 가능한 환경**: 게임은 명확한 규칙과 목표가 있습니다
2. **진전 측정 가능**: AI 능력을 평가할 객관적인 점수가 있습니다
3. **인간 기준**: 인간 플레이어와 비교할 수 있습니다
4. **다양성**: 다른 게임은 다른 능력을 테스트합니다

이 방법론은 나중에 바둑에도 사용되었습니다.

---

## Google의 인수

### 5억 달러의 베팅

2014년 1월, Google은 약 **5억 달러**에 DeepMind를 인수했습니다. 이것은 당시 AI 분야에서 가장 큰 인수 중 하나였습니다.

왜 Google은 직원 75명에 제품도 없는 회사에 이렇게 많은 돈을 지불했을까요?

답은 **게임 이론**에 있습니다:

- **Facebook도 입찰 중이었습니다**: Facebook이 4억 달러를 제안했다는 소문이 있었습니다
- **AI는 미래의 핵심 기술입니다**: AI를 먼저 장악하는 자가 미래를 장악합니다
- **DeepMind는 최고의 팀입니다**: 그들은 심층 강화학습의 가능성을 증명했습니다

Google CEO Larry Page가 직접 나서서 Hassabis를 설득하여 Facebook 대신 Google을 선택하게 했습니다.

### 인수 조건

Hassabis는 협상에서 몇 가지 핵심 조건을 얻어냈습니다:

1. **독립 운영**: DeepMind는 런던 본사를 유지하며 독립적으로 연구개발
2. **학술적 자유**: 논문 발표 가능, 모든 것을 비밀로 할 필요 없음
3. **윤리 위원회**: AI 윤리 심사 메커니즘 설립
4. **장기 연구**: 단기 상업화 압박 없음

이러한 조건 덕분에 DeepMind는 장기적이고 고위험 연구를 추구할 수 있었습니다—예를 들어 AI로 바둑을 정복하는 것.

### Google의 AI 전략

DeepMind 인수는 Google "AI 우선" 전략의 일부였습니다:

| 시간 | 사건 |
|------|------|
| 2011 | Google Brain 설립 |
| 2013 | DNNresearch(Hinton 팀) 인수 |
| 2014 | DeepMind 인수 |
| 2015 | TensorFlow 오픈소스화 |
| 2016 | TPU 발표 |

Google은 인식했습니다: 검색, 광고, 번역, 음성—모든 핵심 비즈니스가 AI에 의해 재편될 것입니다. 최고의 AI를 가진 자가 승자입니다.

---

## 바둑을 목표로 선택

### 왜 바둑인가?

Google에 인수된 후, DeepMind는 더 많은 리소스를 갖게 되었습니다. Hassabis는 불가능해 보이는 목표에 도전하기로 결정했습니다: **AI로 인간 바둑 챔피언을 이기는 것**.

왜 다른 문제가 아닌 바둑을 선택했을까요?

#### 1. 바둑은 "AI의 성배"

2016년 이전, 전문가들은 AI가 바둑에서 인간을 이기려면 최소 10-20년이 걸릴 것이라고 생각했습니다. 바둑은 "AI의 마지막 보루"라고 불렸습니다.

이유:
- **탐색 공간이 거대**: 10^170가지 가능한 국면(우주의 원자 수는 10^80에 불과)
- **평가가 어려움**: 체스처럼 명확한 기물 가치가 없음
- **직관에 의존**: 정상급 기사들은 종종 "이 수가 맞는 느낌"이라고 말하지만 이유를 설명하지 못함

#### 2. 딥 블루의 교훈

1997년, IBM의 딥 블루(Deep Blue)가 체스 세계 챔피언 카스파로프를 이겼습니다. 하지만 이 승리에는 논쟁이 있었습니다:

- 딥 블루는 **무차별 검색**에 의존(초당 2억 개의 포지션 평가)
- **인간 전문가가 설계한 평가 함수** 사용
- 이것은 진정한 "지능"이 아니라 "계산력"

Hassabis는 증명하고 싶었습니다: AI는 무차별 검색이 아닌 **학습**으로 문제를 해결할 수 있습니다.

#### 3. 측정 가능한 목표

바둑은 국제 랭킹 시스템(Elo rating)과 프로 기사가 있어 객관적인 측정 기준을 제공합니다. AI가 세계 챔피언을 이기면 그것은 논쟁의 여지 없는 성공입니다.

#### 4. 신경과학과의 연결

인간 기사의 직관—바둑판을 한 번 보면 어떤 위치가 중요한지 아는 것—은 정확히 Hassabis가 AI로 복제하고 싶은 능력이었습니다. 바둑은 "기계 직관"을 테스트하기에 완벽한 시나리오입니다.

---

## AlphaGo 팀

### 핵심 인물

AlphaGo의 성공은 다학제 배경을 가진 팀에서 비롯되었습니다:

#### David Silver: 수석 연구원

**David Silver**는 AlphaGo 논문의 제1저자이자 강화학습 분야의 최고 전문가입니다.

- **배경**: 케임브리지 대학 수학과 졸업, 앨버타 대학 RL 박사
- **지도교수**: Richard Sutton(강화학습의 아버지)
- **전문 분야**: 몬테카를로 트리 탐색, 시간차 학습

Silver는 박사 논문에서 이미 컴퓨터 바둑을 연구했지만, 당시 기술은 성숙하지 않았습니다. DeepMind에 합류한 후, 그는 마침내 이 꿈을 실현할 기회를 얻었습니다.

#### Aja Huang: 바둑 전문가

**Aja Huang**(황사걸)은 대만인으로, 아마추어 6단 기사이자 컴퓨터 바둑 분야의 선구자입니다.

- **배경**: 국립대만사범대학 컴퓨터공학 박사
- **전문 분야**: 컴퓨터 바둑 프로그래밍
- **대표작**: Erica(초기 컴퓨터 바둑 프로그램)

Huang은 AlphaGo 팀에서 핵심적인 역할을 했습니다: 그는 바둑뿐만 아니라 AI도 이해했습니다. 이세돌과의 대국에서 그는 실제로 AlphaGo를 조작한 사람입니다.

#### 다른 주요 멤버

| 멤버 | 역할 |
|------|------|
| Chris J. Maddison | 몬테카를로 트리 탐색 전문가 |
| Arthur Guez | 강화학습 연구원 |
| Laurent Sifre | 딥러닝 엔지니어 |
| George van den Driessche | 분산 시스템 엔지니어 |

### 다학제 협력

AlphaGo의 성공은 **다학제 협력**의 힘을 증명했습니다:

- **바둑 전문가**가 도메인 지식 제공
- **머신러닝 연구원**이 알고리즘 설계
- **엔지니어**가 대규모 훈련 시스템 구현
- **신경과학자**가 이론적 영감 제공

이러한 팀 구성은 나중에 DeepMind의 표준 모델이 되었습니다.

---

## Nature 논문 발표

### 비밀의 서프라이즈

2016년 1월 27일, DeepMind는 최고 학술 저널 《Nature》에 논문을 발표했습니다:

> **"Mastering the game of Go with deep neural networks and tree search"**

논문은 AlphaGo가 이미:
1. 다른 모든 바둑 프로그램을 이겼다고 발표
2. **5:0**으로 유럽 챔피언 **판후이**(프로 2단)를 이겼다고 발표

이 뉴스는 세계를 충격에 빠뜨렸습니다. 논문이 발표되기 전까지 아무도 DeepMind가 바둑을 연구하고 있다는 것을 몰랐습니다.

### 논문의 핵심 기여

《Nature》 논문은 AlphaGo의 세 가지 주요 혁신을 설명했습니다:

#### 1. Policy Network(정책 신경망)

딥 컨볼루션 신경망을 사용하여 인간 기사의 다음 수를 예측합니다. 훈련 데이터는 **3천만 국**의 인간 기보에서 가져왔습니다.

```
정확도: 57%(인간 전문가의 다음 수 예측)
```

이것은 이전 최고의 컴퓨터 바둑 프로그램보다 10퍼센트 포인트 이상 높았습니다.

#### 2. Value Network(가치 신경망)

또 다른 신경망을 사용하여 현재 국면의 승률을 평가합니다. 이것은 전통적인 랜덤 시뮬레이션(Monte Carlo rollout)을 대체했습니다.

```
정밀도: 15000번의 랜덤 시뮬레이션과 동등하지만, 계산 속도는 15000배 빠름
```

#### 3. 몬테카를로 트리 탐색 통합

두 신경망을 MCTS 프레임워크에 통합:
- Policy Network가 탐색 방향을 안내
- Value Network가 리프 노드를 평가

이것은 AlphaGo에게 "직관"(신경망)과 "추론"(트리 탐색) 모두를 갖게 했습니다.

### 학계의 반응

논문 발표 후, 학계는 열띤 반응을 보였습니다:

> "이것은 인공지능의 달 착륙 순간입니다."
> — **Stuart Russell**, UC Berkeley 교수, AI 교과서 저자

> "저는 원래 10년은 더 걸릴 것이라고 생각했는데, 이렇게 빠를 줄 몰랐습니다."
> — **Martin Müller**, 컴퓨터 바둑 전문가

하지만 회의적인 시각도 있었습니다:

> "판후이는 프로 2단일 뿐, 진정한 정상급 기사가 아닙니다. AlphaGo가 이세돌과 한판 두면 다시 이야기합시다."

DeepMind는 이 도전을 받아들였습니다.

---

## 이세돌에게 도전

### 왜 이세돌인가?

**이세돌**(Lee Sedol)은 한국 기사로, 당시 지난 10년간 가장 강한 기사 중 한 명으로 여겨졌습니다:

| 지표 | 데이터 |
|------|------|
| 세계 챔피언 타이틀 | 18개 |
| 국제전 우승 | 32개 |
| 최고 세계 랭킹 | 1위 |
| 스타일 | "천재" "신산" |

이세돌을 선택함으로써, DeepMind는 가장 강한 인간 상대에게 도전하는 것이었습니다.

### 100만 달러 상금

Google은 이 대국에 **100만 달러** 상금을 제공했습니다:

- 이세돌이 이기면: 상금은 이세돌에게
- AlphaGo가 이기면: 상금은 UNICEF, STEM 교육 등 자선 단체에 기부

이것은 단순한 기술 시연이 아니라, 전 세계가 주목하는 스포츠 이벤트이기도 했습니다.

### 대국 전 예측

대국 전, 대부분의 프로 기사들은 이세돌이 쉽게 이길 것이라고 예측했습니다:

> "AlphaGo가 한 판 이길 수도 있지만, 5번기에서 저는 5:0으로 이길 것입니다."
> — **이세돌**, 대국 전 인터뷰

> "컴퓨터는 바둑을 딱딱하게 두기 때문에, 정상급 기사가 약점을 찾기 쉽습니다."
> — 어느 프로 9단

하지만 DeepMind 팀은 다른 견해를 가지고 있었습니다. David Silver는 나중에 밝혔습니다:

> "내부 테스트에서 우리는 이미 AlphaGo가 판후이 버전과 500판을 두게 했습니다. 새 버전이 499판을 이겼습니다."

---

## 2016년 3월: 세상을 바꾼 다섯 판의 바둑

### 제1국: 충격의 시작

2016년 3월 9일, 서울 포시즌스 호텔.

이세돌이 흑을 잡고 선공했고, AlphaGo가 백을 잡았습니다. 3시간 28분의 대국 끝에, AlphaGo가 중반 불계승으로 이겼습니다.

이것은 인간 정상급 기사가 처음으로 공식적으로 AI에게 진 것입니다.

### 제2국: 신의 한 수

제2국에서는 "**신의 한 수**"로 불리는 37수가 탄생했습니다—AlphaGo가 5선에 어깨짚기를 두었고, 모든 프로 기사들이 실수라고 생각했지만, 결과적으로 승리의 관건이 되었습니다.

(다음 글 참조: ["신의 한 수" 심층 분석](../move-37))

AlphaGo가 다시 승리했습니다.

### 제3국: 3:0

제3국에서 이세돌은 비전통적인 포석을 시도했지만, AlphaGo는 자연스럽게 대응했습니다. 3:0.

전 세계가 인식하기 시작했습니다: 이것은 우연이 아니라, AI가 정말로 인간을 초월했습니다.

### 제4국: 인간의 반격

제4국에서 이세돌은 "**신의 한 수**"로 불리는 78수를 두었습니다—절묘한 끊기로, AlphaGo를 혼란에 빠뜨렸습니다.

AlphaGo는 이후 몇 수에서 명백한 악수를 두었고, 결국 항복했습니다.

이 승리는 증명했습니다: AI에게도 약점이 있습니다. 이세돌이 그것을 찾았습니다.

### 제5국: 최종 결과

제5국에서 AlphaGo는 정상으로 돌아와 중반 불계승으로 대국을 끝냈습니다.

**최종 결과: AlphaGo 4:1 이세돌**

---

## 영향과 여파

### 전 세계의 관심

이 대국의 영향은 바둑계를 훨씬 넘어섰습니다:

- **전 세계 2억 명**이 생중계를 시청
- 《뉴욕 타임스》, 《이코노미스트》 등 주요 언론이 대대적으로 보도
- Google 주가가 대국 기간 동안 상승
- "인공지능"이 그해 가장 핫한 기술 화제가 됨

### 바둑계에 대한 영향

대국 후, 프로 기사들의 태도는 "경시"에서 "경외"로 바뀌었습니다:

> "우리는 예전에 인간이 바둑을 이해한다고 생각했는데, 지금 보니 우리는 겉핥기만 했습니다."
> — **커제**, 중국 기사, 당시 세계 랭킹 1위

많은 프로 기사들이 AI를 사용하여 훈련하기 시작했고, 바둑의 두는 방식도 이로 인해 변했습니다.

### AI 분야에 대한 영향

AlphaGo는 몇 가지를 증명했습니다:

1. **딥러닝은 전문가 수준의 문제를 해결할 수 있습니다**: 고양이와 개를 인식하는 것뿐 아니라, 바둑도 둘 수 있습니다
2. **강화학습은 인간을 초월할 수 있습니다**: 자가 대국을 통해 AI는 인간이 모르는 전략을 발견할 수 있습니다
3. **신경망 + 탐색은 강력한 조합입니다**: 직관 + 추론 = 더 강한 지능

이러한 통찰은 나중에 다음에 응용되었습니다:
- **AlphaFold**: 단백질 구조 예측(2020 노벨상급 업적)
- **AlphaZero**: 범용 게임 AI
- **MuZero**: 규칙 없이 학습

---

## 애니메이션 대응

본 글에서 다루는 핵심 개념과 애니메이션 번호:

| 번호 | 개념 | 물리/수학 대응 |
|------|------|--------------|
| E7 | 제로부터 시작 | 자기 조직화 |
| E5 | 자가 대국 | 고정점 수렴 |
| F8 | 창발 능력 | 상전이 |
| H4 | 정책 경사법 | 확률적 최적화 |

---

## 추가 읽기

- **다음 글**: [주요 대국 회고](../key-matches) — 판후이, 이세돌, 커제의 완전한 대국 분석
- **기술 세부 사항**: [Policy Network 상세 해설](../policy-network) — AlphaGo가 어떻게 바둑을 배웠는지
- **직접 실습**: [30분 만에 첫 바둑 AI 실행하기](/docs/tech/hands-on/) — 직접 체험

---

## 참고 자료

1. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." *Nature*, 529, 484-489.
2. Mnih, V., et al. (2015). "Human-level control through deep reinforcement learning." *Nature*, 518, 529-533.
3. Hassabis, D. (2017). "Artificial Intelligence: Chess match of the century." *Nature*, 544, 413-414.
4. 《AlphaGo》 다큐멘터리 (2017), 감독 Greg Kohs.
