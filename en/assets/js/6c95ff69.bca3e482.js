"use strict";(self.webpackChunktemp_docusaurus=self.webpackChunktemp_docusaurus||[]).push([[807],{741:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"for-engineers/background-info/katago-paper","title":"KataGo Paper Analysis","description":"KataGo is an open-source Go AI developed by David Wu, with its paper \\"Accelerating Self-Play Learning in Go\\" published in 2019. KataGo achieves playing strength surpassing ELF OpenGo with fewer computational resources, and is currently the most powerful open-source Go AI.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/for-engineers/background-info/katago-paper.md","sourceDirName":"for-engineers/background-info","slug":"/for-engineers/background-info/katago-paper","permalink":"/en/docs/for-engineers/background-info/katago-paper","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/background-info/katago-paper.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"KataGo Paper Analysis"},"sidebar":"tutorialSidebar","previous":{"title":"AlphaGo Paper Analysis","permalink":"/en/docs/for-engineers/background-info/alphago"},"next":{"title":"Other Go AI Introduction","permalink":"/en/docs/for-engineers/background-info/zen"}}');var s=i(3420),t=i(5521);const l={sidebar_position:2,title:"KataGo Paper Analysis"},a="KataGo Paper Analysis",d={},o=[{value:"KataGo&#39;s Innovations",id:"katagos-innovations",level:2},{value:"Core Innovation Overview",id:"core-innovation-overview",level:3},{value:"More Efficient Training Methods",id:"more-efficient-training-methods",level:2},{value:"Auxiliary Training Targets",id:"auxiliary-training-targets",level:3},{value:"Output Head Descriptions",id:"output-head-descriptions",level:4},{value:"Why Auxiliary Targets Are Effective",id:"why-auxiliary-targets-are-effective",level:3},{value:"Playout Cap Randomization",id:"playout-cap-randomization",level:3},{value:"Data Augmentation Improvements",id:"data-augmentation-improvements",level:3},{value:"Multiple Go Rule Support",id:"multiple-go-rule-support",level:2},{value:"Main Rule Differences",id:"main-rule-differences",level:3},{value:"Technical Implementation",id:"technical-implementation",level:3},{value:"Simultaneous Win Rate and Score Prediction",id:"simultaneous-win-rate-and-score-prediction",level:2},{value:"Value vs Score",id:"value-vs-score",level:3},{value:"Practical Application Value",id:"practical-application-value",level:3},{value:"Score Distribution",id:"score-distribution",level:3},{value:"Ownership Map",id:"ownership-map",level:2},{value:"Use Cases",id:"use-cases",level:3},{value:"Comparison with AlphaGo Differences",id:"comparison-with-alphago-differences",level:2},{value:"Training Efficiency Comparison",id:"training-efficiency-comparison",level:3},{value:"Network Architecture Details",id:"network-architecture-details",level:2},{value:"Global Pooling",id:"global-pooling",level:3},{value:"Network Sizes",id:"network-sizes",level:3},{value:"Actual Performance",id:"actual-performance",level:2},{value:"Strength Evaluation",id:"strength-evaluation",level:3},{value:"Analysis Features",id:"analysis-features",level:3},{value:"Further Reading",id:"further-reading",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"katago-paper-analysis",children:"KataGo Paper Analysis"})}),"\n",(0,s.jsx)(n.p,{children:'KataGo is an open-source Go AI developed by David Wu, with its paper "Accelerating Self-Play Learning in Go" published in 2019. KataGo achieves playing strength surpassing ELF OpenGo with fewer computational resources, and is currently the most powerful open-source Go AI.'}),"\n",(0,s.jsx)(n.h2,{id:"katagos-innovations",children:"KataGo's Innovations"}),"\n",(0,s.jsx)(n.p,{children:"KataGo doesn't make revolutionary changes to neural network architecture, but instead systematically optimizes training methods and auxiliary tasks, achieving significant efficiency improvements."}),"\n",(0,s.jsx)(n.h3,{id:"core-innovation-overview",children:"Core Innovation Overview"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Innovation"}),(0,s.jsx)(n.th,{children:"Effect"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Auxiliary training targets"}),(0,s.jsx)(n.td,{children:"Accelerates learning, provides more supervision signals"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Global pooling structure"}),(0,s.jsx)(n.td,{children:"Better captures global information"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Multiple rule support"}),(0,s.jsx)(n.td,{children:"Single model adapts to different tournament rules"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Playout cap randomization"}),(0,s.jsx)(n.td,{children:"Improves training efficiency"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Improved data augmentation"}),(0,s.jsx)(n.td,{children:"Increases training data diversity"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"more-efficient-training-methods",children:"More Efficient Training Methods"}),"\n",(0,s.jsx)(n.h3,{id:"auxiliary-training-targets",children:"Auxiliary Training Targets"}),"\n",(0,s.jsx)(n.p,{children:"Traditional AlphaGo Zero has only two training targets:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Policy: Predict MCTS move probability distribution"}),"\n",(0,s.jsx)(n.li,{children:"Value: Predict game outcome"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"KataGo adds multiple auxiliary training targets, providing richer learning signals:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              KataGo Multi-Head Output Architecture       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502                  ResNet Trunk Network                    \u2502\n\u2502                        \u2502                                \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u25bc       \u25bc       \u25bc       \u25bc       \u25bc       \u25bc          \u2502\n\u2502  Policy  Value   Score  Owner-  Short   Lead         \u2502\n\u2502   Head    Head    Head   ship   term    Head         \u2502\n\u2502                          Head   Value                 \u2502\n\u2502                                  Head                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h4,{id:"output-head-descriptions",children:"Output Head Descriptions"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Output Head"}),(0,s.jsx)(n.th,{children:"Dimension"}),(0,s.jsx)(n.th,{children:"Prediction Target"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Policy"})}),(0,s.jsx)(n.td,{children:"19\xd719+1"}),(0,s.jsx)(n.td,{children:"Move probability for each position (including pass)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Value"})}),(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"Win/Loss/Draw probability"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Score"})}),(0,s.jsx)(n.td,{children:"Continuous"}),(0,s.jsx)(n.td,{children:"Predicted final score difference"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Ownership"})}),(0,s.jsx)(n.td,{children:"19\xd719"}),(0,s.jsx)(n.td,{children:"Final ownership of each point (Black/White territory)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Short-term Value"})}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"Expected win rate in short term"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Lead"})}),(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"Current point lead"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"why-auxiliary-targets-are-effective",children:"Why Auxiliary Targets Are Effective"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Denser supervision signals"}),": Value provides only one number, while Ownership provides 361 supervision points"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Reduces overfitting"}),": Multi-task learning has regularization effect"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accelerates convergence"}),": Auxiliary tasks help network learn useful feature representations faster"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Provides better gradients"}),": Avoids vanishing gradient problems"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"playout-cap-randomization",children:"Playout Cap Randomization"}),"\n",(0,s.jsx)(n.p,{children:"AlphaGo Zero performs a fixed 800 MCTS simulations per move. KataGo introduces randomization:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Traditional approach\nnum_playouts = 800  # Fixed\n\n# KataGo approach\nplayout_cap = random.choice([\n    100, 200, 300, 400, 500, 600, 700, 800\n])\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Training data becomes more diverse"}),"\n",(0,s.jsx)(n.li,{children:"Model learns to make reasonable decisions at different search depths"}),"\n",(0,s.jsx)(n.li,{children:"Performs well in actual play even with less search"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"data-augmentation-improvements",children:"Data Augmentation Improvements"}),"\n",(0,s.jsx)(n.p,{children:"Traditional methods use Go's 8-fold symmetry (4 rotations \xd7 2 reflections) for data augmentation. KataGo improves further:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Random symmetry transforms"}),": Randomly select symmetry transform each sample"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"History state randomization"}),": Randomly select representation of historical positions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Color randomization"}),": Randomly swap Black/White perspectives"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"multiple-go-rule-support",children:"Multiple Go Rule Support"}),"\n",(0,s.jsx)(n.p,{children:"This is one of KataGo's important features. Different Go rules affect strategic decisions:"}),"\n",(0,s.jsx)(n.h3,{id:"main-rule-differences",children:"Main Rule Differences"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Rule System"}),(0,s.jsx)(n.th,{children:"Scoring Method"}),(0,s.jsx)(n.th,{children:"Komi"}),(0,s.jsx)(n.th,{children:"Ko Rule"}),(0,s.jsx)(n.th,{children:"Suicide"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Chinese Rules"}),(0,s.jsx)(n.td,{children:"Area counting"}),(0,s.jsx)(n.td,{children:"7.5"}),(0,s.jsx)(n.td,{children:"Simple ko"}),(0,s.jsx)(n.td,{children:"Forbidden"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Japanese Rules"}),(0,s.jsx)(n.td,{children:"Territory counting"}),(0,s.jsx)(n.td,{children:"6.5"}),(0,s.jsx)(n.td,{children:"Superko"}),(0,s.jsx)(n.td,{children:"Forbidden"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Korean Rules"}),(0,s.jsx)(n.td,{children:"Territory counting"}),(0,s.jsx)(n.td,{children:"6.5"}),(0,s.jsx)(n.td,{children:"Superko"}),(0,s.jsx)(n.td,{children:"Forbidden"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Ing Rules"}),(0,s.jsx)(n.td,{children:"Area counting"}),(0,s.jsx)(n.td,{children:"8 pts"}),(0,s.jsx)(n.td,{children:"Special ko rules"}),(0,s.jsx)(n.td,{children:"Forbidden"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Tromp-Taylor"}),(0,s.jsx)(n.td,{children:"Area counting"}),(0,s.jsx)(n.td,{children:"Adjustable"}),(0,s.jsx)(n.td,{children:"Superko"}),(0,s.jsx)(n.td,{children:"Allowed"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"AGA Rules"}),(0,s.jsx)(n.td,{children:"Area/Territory"}),(0,s.jsx)(n.td,{children:"7.5"}),(0,s.jsx)(n.td,{children:"Superko"}),(0,s.jsx)(n.td,{children:"Forbidden"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"New Zealand Rules"}),(0,s.jsx)(n.td,{children:"Area counting"}),(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"Simple ko"}),(0,s.jsx)(n.td,{children:"Allowed"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"technical-implementation",children:"Technical Implementation"}),"\n",(0,s.jsx)(n.p,{children:"KataGo encodes rule information as input features:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Rule-related input feature example\nrule_features = {\n    'komi': 7.5,           # Komi value\n    'scoring_rule': 'area', # Area/territory counting\n    'ko_rule': 'simple',    # Ko rule\n    'suicide_allowed': False,\n    'tax_rule': 'none',     # Whether there's \"eye\" tax\n    # ...\n}\n"})}),"\n",(0,s.jsx)(n.p,{children:"The network learns to adjust strategy based on different rules. For example:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Territory counting focuses more on territory control"}),"\n",(0,s.jsx)(n.li,{children:"When suicide is allowed, can be used for special tactics"}),"\n",(0,s.jsx)(n.li,{children:"Different komi affects opening choices"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"simultaneous-win-rate-and-score-prediction",children:"Simultaneous Win Rate and Score Prediction"}),"\n",(0,s.jsx)(n.p,{children:"This is one of KataGo's most practical features, extremely valuable for Go teaching and analysis."}),"\n",(0,s.jsx)(n.h3,{id:"value-vs-score",children:"Value vs Score"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                Position Evaluation Comparison            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                         \u2502\n\u2502  Traditional AlphaGo:                                   \u2502\n\u2502  "This position Black has 73% win rate"                 \u2502\n\u2502                                                         \u2502\n\u2502  KataGo:                                               \u2502\n\u2502  "This position Black has 73% win rate, leading ~4.5pts"\u2502\n\u2502  "With optimal play, expected Black wins by 3.2 pts"    \u2502\n\u2502                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,s.jsx)(n.h3,{id:"practical-application-value",children:"Practical Application Value"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"More precise position evaluation"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"80% win rate but only 1 point lead \u2192 Still uncertain"}),"\n",(0,s.jsx)(n.li,{children:"80% win rate with 20 point lead \u2192 Game is decided"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Teaching assistance"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Help students understand "how many points a move lost"'}),"\n",(0,s.jsx)(n.li,{children:"Compare point differences of different choices"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Handicap game analysis"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Accurately evaluate if handicap is appropriate"}),"\n",(0,s.jsx)(n.li,{children:"Judge whether to attack or defend"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"score-distribution",children:"Score Distribution"}),"\n",(0,s.jsx)(n.p,{children:"KataGo predicts not just a single score, but the complete score distribution:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Score distribution example:\n\u251c\u2500 Black wins by 10+ pts: 15%\n\u251c\u2500 Black wins by 5-10 pts: 25%\n\u251c\u2500 Black wins by 0-5 pts: 20%\n\u251c\u2500 White wins by 0-5 pts: 18%\n\u251c\u2500 White wins by 5-10 pts: 15%\n\u2514\u2500 White wins by 10+ pts: 7%\n\nExpected value: Black +3.2 pts\nStandard deviation: \xb18.5 pts\n"})}),"\n",(0,s.jsx)(n.p,{children:"This distribution information better reflects the complexity and uncertainty of the position."}),"\n",(0,s.jsx)(n.h2,{id:"ownership-map",children:"Ownership Map"}),"\n",(0,s.jsx)(n.p,{children:"Ownership predicts whether each point will belong to Black or White at game end:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"                  Ownership Map\n    A B C D E F G H J K L M N O P Q R S T\n19  \u25cb \u25cb \u25cb \u25cb \u25cb \u25cb \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\n18  \u25cb \u25cb \u25cb \u25cb \u25cb \u25cb \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \u25cf \u25cf \u25cf \u25cf \u25cf \u25cf\n17  \u25cb \u25cb \u25cb \u25cb \u25cb \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \xb7 \u25cf \u25cf \u25cf \u25cf \u25cf\n16  \u25cb \u25cb \u25cb \u254b \xb7 \xb7 \xb7 \xb7 \xb7 \u254b \xb7 \xb7 \xb7 \xb7 \xb7 \u254b \u25cf \u25cf \u25cf\n...\n\nLegend: \u25cb = White territory  \u25cf = Black territory  \xb7 = Undetermined\n"})}),"\n",(0,s.jsx)(n.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Position analysis"}),": See both sides' spheres of influence at a glance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Life and death judgment"}),": Determine if a group can still be saved"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Endgame calculation"}),": Evaluate value of endgame moves in different areas"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Teaching demonstration"}),": Visualize territory concepts"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"comparison-with-alphago-differences",children:"Comparison with AlphaGo Differences"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Aspect"}),(0,s.jsx)(n.th,{children:"AlphaGo Zero"}),(0,s.jsx)(n.th,{children:"KataGo"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Training targets"})}),(0,s.jsx)(n.td,{children:"Policy + Value"}),(0,s.jsx)(n.td,{children:"Multiple auxiliary targets"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Output information"})}),(0,s.jsx)(n.td,{children:"Win rate"}),(0,s.jsx)(n.td,{children:"Win rate + Score + Territory"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Rule support"})}),(0,s.jsx)(n.td,{children:"Single rule"}),(0,s.jsx)(n.td,{children:"Multiple rules"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Network structure"})}),(0,s.jsx)(n.td,{children:"Pure convolutional ResNet"}),(0,s.jsx)(n.td,{children:"Added global pooling"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Search amount"})}),(0,s.jsx)(n.td,{children:"Fixed"}),(0,s.jsx)(n.td,{children:"Randomized"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Training efficiency"})}),(0,s.jsx)(n.td,{children:"Baseline"}),(0,s.jsx)(n.td,{children:"~50x efficiency improvement"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Open source level"})}),(0,s.jsx)(n.td,{children:"Paper description"}),(0,s.jsx)(n.td,{children:"Fully open source"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"training-efficiency-comparison",children:"Training Efficiency Comparison"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Resources needed to reach ELF OpenGo level:\n\nELF OpenGo:\n- 2000 GPUs\n- 2 weeks training\n\nKataGo:\n- 1 GPU (or tens of GPUs to accelerate)\n- Days to weeks\n\nEfficiency improvement: ~50-100x\n"})}),"\n",(0,s.jsx)(n.h2,{id:"network-architecture-details",children:"Network Architecture Details"}),"\n",(0,s.jsx)(n.h3,{id:"global-pooling",children:"Global Pooling"}),"\n",(0,s.jsx)(n.p,{children:"Traditional CNNs can only see local information. KataGo adds global pooling layers to capture global features:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class GlobalPoolingBlock(nn.Module):\n    def forward(self, x):\n        # x: [batch, channels, 19, 19]\n\n        # Global average pooling\n        global_avg = x.mean(dim=[2, 3])  # [batch, channels]\n\n        # Global max pooling\n        global_max = x.max(dim=2)[0].max(dim=1)[0]  # [batch, channels]\n\n        # Combine global features\n        global_features = torch.cat([global_avg, global_max], dim=1)\n\n        # Process global features\n        global_features = dense_layer(global_features)  # [batch, C]\n\n        # Broadcast back to spatial dimensions and combine with regular path\n        global_features = global_features.view(batch, -1, 1, 1)\n        global_features = global_features.expand(-1, -1, 19, 19)\n\n        return torch.cat([x, global_features], dim=1)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Benefits"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Can sense global situation (like who is ahead)"}),"\n",(0,s.jsx)(n.li,{children:"Better handles positions requiring global judgment"}),"\n",(0,s.jsx)(n.li,{children:"Especially helpful for score prediction"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"network-sizes",children:"Network Sizes"}),"\n",(0,s.jsx)(n.p,{children:"KataGo provides models of different sizes:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Res Blocks"}),(0,s.jsx)(n.th,{children:"Channels"}),(0,s.jsx)(n.th,{children:"Parameters"}),(0,s.jsx)(n.th,{children:"Use Case"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"b10c128"}),(0,s.jsx)(n.td,{children:"10"}),(0,s.jsx)(n.td,{children:"128"}),(0,s.jsx)(n.td,{children:"~5M"}),(0,s.jsx)(n.td,{children:"CPU running"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"b15c192"}),(0,s.jsx)(n.td,{children:"15"}),(0,s.jsx)(n.td,{children:"192"}),(0,s.jsx)(n.td,{children:"~15M"}),(0,s.jsx)(n.td,{children:"General GPU"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"b20c256"}),(0,s.jsx)(n.td,{children:"20"}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"~35M"}),(0,s.jsx)(n.td,{children:"Mid-range GPU"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"b40c256"}),(0,s.jsx)(n.td,{children:"40"}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"~70M"}),(0,s.jsx)(n.td,{children:"High-end GPU"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"b60c320"}),(0,s.jsx)(n.td,{children:"60"}),(0,s.jsx)(n.td,{children:"320"}),(0,s.jsx)(n.td,{children:"~150M"}),(0,s.jsx)(n.td,{children:"Top-tier GPU"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"actual-performance",children:"Actual Performance"}),"\n",(0,s.jsx)(n.h3,{id:"strength-evaluation",children:"Strength Evaluation"}),"\n",(0,s.jsx)(n.p,{children:"KataGo's performance in various tests:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Surpasses all Leela Zero networks"}),"\n",(0,s.jsx)(n.li,{children:"Maintains high win rate against professional 9-dan players"}),"\n",(0,s.jsx)(n.li,{children:"Ranks #1 on CGOS (Computer Go Server)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"analysis-features",children:"Analysis Features"}),"\n",(0,s.jsx)(n.p,{children:"KataGo's analysis mode provides:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "moveInfos": [\n    {\n      "move": "Q16",\n      "visits": 3420,\n      "winrate": 0.573,\n      "scoreLead": 2.8,\n      "pv": ["Q16", "D4", "Q4", "D16"],\n      "ownership": [...]\n    }\n  ],\n  "rootInfo": {\n    "winrate": 0.48,\n    "scoreLead": -0.5,\n    "visits": 10000\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1902.10565",children:"KataGo paper: Accelerating Self-Play Learning in Go"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/lightvector/KataGo",children:"KataGo GitHub project"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://katagotraining.org/",children:"KataGo training logs and analysis"})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["After understanding KataGo's technical features, let's look at ",(0,s.jsx)(n.a,{href:"/en/docs/for-engineers/background-info/zen",children:"other Go AI developments"})," for a more complete picture of the industry."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},5521:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var r=i(6672);const s={},t=r.createContext(s);function l(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);