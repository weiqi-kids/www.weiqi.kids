"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[931],{69692(e,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"for-engineers/deep-dive/evaluation","title":"Evaluation & Benchmarking","description":"Go AI Elo rating system, match testing, and performance benchmarking methods","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/for-engineers/deep-dive/evaluation.md","sourceDirName":"for-engineers/deep-dive","slug":"/for-engineers/deep-dive/evaluation","permalink":"/en/docs/for-engineers/deep-dive/evaluation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/deep-dive/evaluation.md","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"title":"Evaluation & Benchmarking","description":"Go AI Elo rating system, match testing, and performance benchmarking methods"},"sidebar":"tutorialSidebar","previous":{"title":"Model Quantization & Deployment","permalink":"/en/docs/for-engineers/deep-dive/quantization-deploy"},"next":{"title":"Custom Rules & Variants","permalink":"/en/docs/for-engineers/deep-dive/custom-rules"}}');var s=t(62615),r=t(30416);const a={sidebar_position:9,title:"Evaluation & Benchmarking",description:"Go AI Elo rating system, match testing, and performance benchmarking methods"},l="Evaluation & Benchmarking",c={},d=[{value:"Elo Rating System",id:"elo-rating-system",level:2},{value:"Basic Concept",id:"basic-concept",level:3},{value:"Elo Difference vs Win Rate",id:"elo-difference-vs-win-rate",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Match Testing",id:"match-testing",level:2},{value:"Testing Framework",id:"testing-framework",level:3},{value:"Statistical Significance",id:"statistical-significance",level:3},{value:"Recommended Game Counts",id:"recommended-game-counts",level:3},{value:"SPRT (Sequential Probability Ratio Test)",id:"sprt-sequential-probability-ratio-test",level:2},{value:"Concept",id:"concept",level:3},{value:"KataGo Benchmarking",id:"katago-benchmarking",level:2},{value:"Run Benchmark",id:"run-benchmark",level:3},{value:"Output Interpretation",id:"output-interpretation",level:3},{value:"Key Metrics",id:"key-metrics",level:3},{value:"Strength Evaluation",id:"strength-evaluation",level:2},{value:"Human Strength Reference",id:"human-strength-reference",level:3},{value:"Major AI Elo Ratings",id:"major-ai-elo-ratings",level:3},{value:"Test Comparison",id:"test-comparison",level:3},{value:"Performance Monitoring",id:"performance-monitoring",level:2},{value:"Continuous Monitoring",id:"continuous-monitoring",level:3},{value:"Performance Bottleneck Diagnosis",id:"performance-bottleneck-diagnosis",level:3},{value:"Automated Testing",id:"automated-testing",level:2},{value:"CI/CD Integration",id:"cicd-integration",level:3},{value:"Regression Testing",id:"regression-testing",level:3},{value:"Further Reading",id:"further-reading",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"evaluation--benchmarking",children:"Evaluation & Benchmarking"})}),"\n",(0,s.jsx)(n.p,{children:"This article introduces how to evaluate Go AI strength and performance, including the Elo rating system, match testing methods, and standard benchmarks."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"elo-rating-system",children:"Elo Rating System"}),"\n",(0,s.jsx)(n.h3,{id:"basic-concept",children:"Basic Concept"}),"\n",(0,s.jsx)(n.p,{children:"Elo rating is the standard method for measuring relative playing strength:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Expected win rate E_A = 1 / (1 + 10^((R_B - R_A) / 400))\n\nNew Elo = Old Elo + K \xd7 (Actual result - Expected result)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"elo-difference-vs-win-rate",children:"Elo Difference vs Win Rate"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Elo Difference"}),(0,s.jsx)(n.th,{children:"Stronger Player Win Rate"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"50%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"100"}),(0,s.jsx)(n.td,{children:"64%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"200"}),(0,s.jsx)(n.td,{children:"76%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"400"}),(0,s.jsx)(n.td,{children:"91%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"800"}),(0,s.jsx)(n.td,{children:"99%"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"implementation",children:"Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def expected_score(rating_a, rating_b):\n    """Calculate A\'s expected score against B"""\n    return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n\ndef update_elo(rating, expected, actual, k=32):\n    """Update Elo rating"""\n    return rating + k * (actual - expected)\n\ndef calculate_elo_diff(wins, losses, draws):\n    """Calculate Elo difference from match results"""\n    total = wins + losses + draws\n    win_rate = (wins + 0.5 * draws) / total\n\n    if win_rate <= 0 or win_rate >= 1:\n        return float(\'inf\') if win_rate >= 1 else float(\'-inf\')\n\n    return 400 * math.log10(win_rate / (1 - win_rate))\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"match-testing",children:"Match Testing"}),"\n",(0,s.jsx)(n.h3,{id:"testing-framework",children:"Testing Framework"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"class MatchTester:\n    def __init__(self, engine_a, engine_b):\n        self.engine_a = engine_a\n        self.engine_b = engine_b\n        self.results = {'a_wins': 0, 'b_wins': 0, 'draws': 0}\n\n    def run_match(self, num_games=400):\n        \"\"\"Run match test\"\"\"\n        for i in range(num_games):\n            # Alternate colors\n            if i % 2 == 0:\n                black, white = self.engine_a, self.engine_b\n                a_is_black = True\n            else:\n                black, white = self.engine_b, self.engine_a\n                a_is_black = False\n\n            # Play game\n            result = self.play_game(black, white)\n\n            # Record result\n            if result == 'black':\n                if a_is_black:\n                    self.results['a_wins'] += 1\n                else:\n                    self.results['b_wins'] += 1\n            elif result == 'white':\n                if a_is_black:\n                    self.results['b_wins'] += 1\n                else:\n                    self.results['a_wins'] += 1\n            else:\n                self.results['draws'] += 1\n\n        return self.results\n\n    def play_game(self, black_engine, white_engine):\n        \"\"\"Play one game\"\"\"\n        game = Game()\n\n        while not game.is_terminal():\n            if game.current_player == 'black':\n                move = black_engine.get_move(game.state)\n            else:\n                move = white_engine.get_move(game.state)\n\n            game.play(move)\n\n        return game.get_winner()\n"})}),"\n",(0,s.jsx)(n.h3,{id:"statistical-significance",children:"Statistical Significance"}),"\n",(0,s.jsx)(n.p,{children:"Ensure test results are statistically meaningful:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from scipy import stats\n\ndef calculate_confidence_interval(wins, total, confidence=0.95):\n    """Calculate confidence interval for win rate"""\n    p = wins / total\n    z = stats.norm.ppf((1 + confidence) / 2)\n    margin = z * math.sqrt(p * (1 - p) / total)\n\n    return (p - margin, p + margin)\n\n# Example\nwins, total = 220, 400\nci_low, ci_high = calculate_confidence_interval(wins, total)\nprint(f"Win rate: {wins/total:.1%}, 95% CI: [{ci_low:.1%}, {ci_high:.1%}]")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"recommended-game-counts",children:"Recommended Game Counts"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Expected Elo Diff"}),(0,s.jsx)(n.th,{children:"Recommended Games"}),(0,s.jsx)(n.th,{children:"Confidence"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:">100"}),(0,s.jsx)(n.td,{children:"100"}),(0,s.jsx)(n.td,{children:"95%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"50-100"}),(0,s.jsx)(n.td,{children:"200"}),(0,s.jsx)(n.td,{children:"95%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"20-50"}),(0,s.jsx)(n.td,{children:"400"}),(0,s.jsx)(n.td,{children:"95%"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"<20"}),(0,s.jsx)(n.td,{children:"1000+"}),(0,s.jsx)(n.td,{children:"95%"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"sprt-sequential-probability-ratio-test",children:"SPRT (Sequential Probability Ratio Test)"}),"\n",(0,s.jsx)(n.h3,{id:"concept",children:"Concept"}),"\n",(0,s.jsx)(n.p,{children:"No fixed game count needed; dynamically decide whether to stop based on accumulated results:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def sprt(wins, losses, elo0=0, elo1=10, alpha=0.05, beta=0.05):\n    \"\"\"\n    Sequential Probability Ratio Test\n\n    elo0: Null hypothesis Elo difference (usually 0)\n    elo1: Alternative hypothesis Elo difference (usually 5-20)\n    alpha: False positive rate\n    beta: False negative rate\n    \"\"\"\n    if wins + losses == 0:\n        return 'continue'\n\n    # Calculate log likelihood ratio\n    p0 = expected_score(elo1, 0)  # Expected win rate under H1\n    p1 = expected_score(elo0, 0)  # Expected win rate under H0\n\n    llr = (\n        wins * math.log(p0 / p1) +\n        losses * math.log((1 - p0) / (1 - p1))\n    )\n\n    # Decision boundaries\n    lower = math.log(beta / (1 - alpha))\n    upper = math.log((1 - beta) / alpha)\n\n    if llr <= lower:\n        return 'reject'  # H0 rejected, new model is worse\n    elif llr >= upper:\n        return 'accept'  # H0 accepted, new model is better\n    else:\n        return 'continue'  # Continue testing\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"katago-benchmarking",children:"KataGo Benchmarking"}),"\n",(0,s.jsx)(n.h3,{id:"run-benchmark",children:"Run Benchmark"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Basic test\nkatago benchmark -model model.bin.gz\n\n# Specify visit count\nkatago benchmark -model model.bin.gz -v 1000\n\n# Detailed output\nkatago benchmark -model model.bin.gz -v 1000 -t 8\n"})}),"\n",(0,s.jsx)(n.h3,{id:"output-interpretation",children:"Output Interpretation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"KataGo Benchmark Results\n========================\n\nConfiguration:\n  Model: kata-b18c384.bin.gz\n  Backend: CUDA\n  Threads: 8\n  Visits: 1000\n\nPerformance:\n  NN evals/second: 2847.3\n  Playouts/second: 4521.8\n  Avg time per move: 0.221 seconds\n\nMemory:\n  GPU memory usage: 2.1 GB\n  System memory: 1.3 GB\n\nQuality metrics:\n  Policy accuracy: 0.612\n  Value accuracy: 0.891\n"})}),"\n",(0,s.jsx)(n.h3,{id:"key-metrics",children:"Key Metrics"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Good Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"NN evals/sec"}),(0,s.jsx)(n.td,{children:"Neural network evaluation speed"}),(0,s.jsx)(n.td,{children:">1000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Playouts/sec"}),(0,s.jsx)(n.td,{children:"MCTS simulation speed"}),(0,s.jsx)(n.td,{children:">2000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"GPU utilization"}),(0,s.jsx)(n.td,{children:"GPU usage efficiency"}),(0,s.jsx)(n.td,{children:">80%"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"strength-evaluation",children:"Strength Evaluation"}),"\n",(0,s.jsx)(n.h3,{id:"human-strength-reference",children:"Human Strength Reference"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"AI Elo"}),(0,s.jsx)(n.th,{children:"Human Strength"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~1500"}),(0,s.jsx)(n.td,{children:"Amateur 1 dan"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~2000"}),(0,s.jsx)(n.td,{children:"Amateur 5 dan"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~2500"}),(0,s.jsx)(n.td,{children:"Professional 1 dan"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~3000"}),(0,s.jsx)(n.td,{children:"Professional 5 dan"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~3500"}),(0,s.jsx)(n.td,{children:"World champion level"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"~4000+"}),(0,s.jsx)(n.td,{children:"Beyond human"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"major-ai-elo-ratings",children:"Major AI Elo Ratings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"AI"}),(0,s.jsx)(n.th,{children:"Elo (estimated)"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"KataGo (latest)"}),(0,s.jsx)(n.td,{children:"~5000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"AlphaGo Zero"}),(0,s.jsx)(n.td,{children:"~5000"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Leela Zero"}),(0,s.jsx)(n.td,{children:"~4500"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Fine Art"}),(0,s.jsx)(n.td,{children:"~4800"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"test-comparison",children:"Test Comparison"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def estimate_human_rank(ai_model, test_positions):\n    """Estimate AI\'s equivalent human rank"""\n    # Use standard test problems\n    correct = 0\n    for pos in test_positions:\n        ai_move = ai_model.get_best_move(pos[\'state\'])\n        if ai_move == pos[\'best_move\']:\n            correct += 1\n\n    accuracy = correct / len(test_positions)\n\n    # Accuracy reference table\n    if accuracy > 0.9:\n        return "Professional level"\n    elif accuracy > 0.7:\n        return "Amateur 5 dan+"\n    elif accuracy > 0.5:\n        return "Amateur 1-5 dan"\n    else:\n        return "Below amateur level"\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"performance-monitoring",children:"Performance Monitoring"}),"\n",(0,s.jsx)(n.h3,{id:"continuous-monitoring",children:"Continuous Monitoring"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import time\nimport psutil\nimport GPUtil\n\nclass PerformanceMonitor:\n    def __init__(self):\n        self.metrics = []\n\n    def sample(self):\n        """Sample current performance metrics"""\n        gpus = GPUtil.getGPUs()\n\n        self.metrics.append({\n            \'timestamp\': time.time(),\n            \'cpu_percent\': psutil.cpu_percent(),\n            \'memory_percent\': psutil.virtual_memory().percent,\n            \'gpu_util\': gpus[0].load * 100 if gpus else 0,\n            \'gpu_memory\': gpus[0].memoryUsed if gpus else 0,\n        })\n\n    def report(self):\n        """Generate report"""\n        if not self.metrics:\n            return\n\n        avg_cpu = sum(m[\'cpu_percent\'] for m in self.metrics) / len(self.metrics)\n        avg_gpu = sum(m[\'gpu_util\'] for m in self.metrics) / len(self.metrics)\n\n        print(f"Average CPU usage: {avg_cpu:.1f}%")\n        print(f"Average GPU usage: {avg_gpu:.1f}%")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"performance-bottleneck-diagnosis",children:"Performance Bottleneck Diagnosis"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Symptom"}),(0,s.jsx)(n.th,{children:"Possible Cause"}),(0,s.jsx)(n.th,{children:"Solution"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"CPU 100%, GPU low"}),(0,s.jsx)(n.td,{children:"Insufficient search threads"}),(0,s.jsx)(n.td,{children:"Increase numSearchThreads"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"GPU 100%, slow output"}),(0,s.jsx)(n.td,{children:"Batch too small"}),(0,s.jsx)(n.td,{children:"Increase nnMaxBatchSize"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Out of memory"}),(0,s.jsx)(n.td,{children:"Model too large"}),(0,s.jsx)(n.td,{children:"Use smaller model"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Unstable speed"}),(0,s.jsx)(n.td,{children:"Overheating"}),(0,s.jsx)(n.td,{children:"Improve cooling"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"automated-testing",children:"Automated Testing"}),"\n",(0,s.jsx)(n.h3,{id:"cicd-integration",children:"CI/CD Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# .github/workflows/benchmark.yml\nname: Benchmark\n\non:\n  push:\n    branches: [main]\n\njobs:\n  benchmark:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run benchmark\n        run: |\n          ./katago benchmark -model model.bin.gz -v 500 > results.txt\n\n      - name: Check performance\n        run: |\n          playouts=$(grep "Playouts/second" results.txt | awk \'{print $2}\')\n          if (( $(echo "$playouts < 1000" | bc -l) )); then\n            echo "Performance regression detected!"\n            exit 1\n          fi\n'})}),"\n",(0,s.jsx)(n.h3,{id:"regression-testing",children:"Regression Testing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def regression_test(new_model, baseline_model, threshold=0.95):\n    """Check if new model has performance regression"""\n    # Test accuracy\n    new_accuracy = test_accuracy(new_model)\n    baseline_accuracy = test_accuracy(baseline_model)\n\n    if new_accuracy < baseline_accuracy * threshold:\n        raise Exception(f"Accuracy regression: {new_accuracy:.3f} < {baseline_accuracy:.3f}")\n\n    # Test speed\n    new_speed = benchmark_speed(new_model)\n    baseline_speed = benchmark_speed(baseline_model)\n\n    if new_speed < baseline_speed * threshold:\n        raise Exception(f"Speed regression: {new_speed:.1f} < {baseline_speed:.1f}")\n\n    print("Regression test passed")\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../training",children:"KataGo Training Mechanism"})," \u2014 How models are trained"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../distributed-training",children:"Distributed Training Architecture"})," \u2014 Large-scale evaluation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"../gpu-optimization",children:"GPU Backend & Optimization"})," \u2014 Performance tuning"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},30416(e,n,t){t.d(n,{R:()=>a,x:()=>l});var i=t(59471);const s={},r=i.createContext(s);function a(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);