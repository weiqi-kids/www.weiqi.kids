"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[7444],{3156(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"for-engineers/deep-dive/distributed-training","title":"Distributed Training Architecture","description":"KataGo distributed training system architecture, Self-play Worker, and model release process","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/for-engineers/deep-dive/distributed-training.md","sourceDirName":"for-engineers/deep-dive","slug":"/for-engineers/deep-dive/distributed-training","permalink":"/en/docs/for-engineers/deep-dive/distributed-training","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/deep-dive/distributed-training.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Distributed Training Architecture","description":"KataGo distributed training system architecture, Self-play Worker, and model release process"},"sidebar":"tutorialSidebar","previous":{"title":"GPU Backend & Optimization","permalink":"/en/docs/for-engineers/deep-dive/gpu-optimization"},"next":{"title":"Model Quantization & Deployment","permalink":"/en/docs/for-engineers/deep-dive/quantization-deploy"}}');var t=i(62615),s=i(30416);const a={sidebar_position:7,title:"Distributed Training Architecture",description:"KataGo distributed training system architecture, Self-play Worker, and model release process"},l="Distributed Training Architecture",o={},d=[{value:"System Architecture Overview",id:"system-architecture-overview",level:2},{value:"Self-play Worker",id:"self-play-worker",level:2},{value:"Workflow",id:"workflow",level:3},{value:"Game Generation",id:"game-generation",level:3},{value:"Data Format",id:"data-format",level:3},{value:"Data Collection Server",id:"data-collection-server",level:2},{value:"Functions",id:"functions",level:3},{value:"Data Validation",id:"data-validation",level:3},{value:"Data Storage Structure",id:"data-storage-structure",level:3},{value:"Training Process",id:"training-process",level:2},{value:"Training Loop",id:"training-loop",level:3},{value:"Loss Functions",id:"loss-functions",level:3},{value:"Model Evaluation &amp; Release",id:"model-evaluation--release",level:2},{value:"Elo Evaluation",id:"elo-evaluation",level:3},{value:"Release Conditions",id:"release-conditions",level:3},{value:"Model Version Naming",id:"model-version-naming",level:3},{value:"KataGo Training Participation Guide",id:"katago-training-participation-guide",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Install Worker",id:"install-worker",level:3},{value:"Configuration File",id:"configuration-file",level:3},{value:"Monitor Contributions",id:"monitor-contributions",level:3},{value:"Training Statistics",id:"training-statistics",level:2},{value:"KataGo Training Milestones",id:"katago-training-milestones",level:3},{value:"Community Contributors",id:"community-contributors",level:3},{value:"Advanced Topics",id:"advanced-topics",level:2},{value:"Curriculum Learning",id:"curriculum-learning",level:3},{value:"Data Augmentation",id:"data-augmentation",level:3},{value:"Further Reading",id:"further-reading",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"distributed-training-architecture",children:"Distributed Training Architecture"})}),"\n",(0,t.jsx)(n.p,{children:"This article introduces KataGo's distributed training system architecture, explaining how the global community's computing power continuously improves the model."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"system-architecture-overview",children:"System Architecture Overview"}),"\n",(0,t.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Workers["Self-play Workers"]\n        W1["Worker 1<br/>(Self-play)"]\n        W2["Worker 2<br/>(Self-play)"]\n        WN["Worker N<br/>(Self-play)"]\n    end\n\n    Server["Training Server<br/>(Data Collection)"]\n    Train["Training Process<br/>(Model Training)"]\n    Release["New Model Release<br/>(Model Release)"]\n\n    W1 --\x3e Server\n    W2 --\x3e Server\n    WN --\x3e Server\n    Server --\x3e Train --\x3e Release'}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"self-play-worker",children:"Self-play Worker"}),"\n",(0,t.jsx)(n.h3,{id:"workflow",children:"Workflow"}),"\n",(0,t.jsx)(n.p,{children:"Each Worker executes the following loop:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def self_play_worker():\n    while True:\n        # 1. Download latest model\n        model = download_latest_model()\n\n        # 2. Execute self-play\n        games = []\n        for _ in range(batch_size):\n            game = play_game(model)\n            games.append(game)\n\n        # 3. Upload game data\n        upload_games(games)\n\n        # 4. Check for new model\n        if new_model_available():\n            model = download_latest_model()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"game-generation",children:"Game Generation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def play_game(model):\n    \"\"\"Execute one self-play game\"\"\"\n    game = Game()\n    positions = []\n\n    while not game.is_terminal():\n        # MCTS search\n        mcts = MCTS(model, num_simulations=800)\n        policy = mcts.get_policy(game.state)\n\n        # Add Dirichlet noise (increase exploration)\n        if game.move_count < 30:\n            policy = add_dirichlet_noise(policy)\n\n        # Select action based on policy\n        if game.move_count < 30:\n            # First 30 moves use temperature sampling\n            action = sample_with_temperature(policy, temp=1.0)\n        else:\n            # Later moves greedy selection\n            action = np.argmax(policy)\n\n        # Record training data\n        positions.append({\n            'state': game.state.copy(),\n            'policy': policy,\n            'player': game.current_player\n        })\n\n        game.play(action)\n\n    # Mark winner\n    winner = game.get_winner()\n    for pos in positions:\n        pos['value'] = 1.0 if pos['player'] == winner else -1.0\n\n    return positions\n"})}),"\n",(0,t.jsx)(n.h3,{id:"data-format",children:"Data Format"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "version": 1,\n  "rules": "chinese",\n  "komi": 7.5,\n  "board_size": 19,\n  "positions": [\n    {\n      "move_number": 0,\n      "board": "...",\n      "policy": [0.01, 0.02, ...],\n      "value": 1.0,\n      "score": 2.5\n    }\n  ]\n}\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"data-collection-server",children:"Data Collection Server"}),"\n",(0,t.jsx)(n.h3,{id:"functions",children:"Functions"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Receive game data"}),": Collect games from Workers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data validation"}),": Check format, filter anomalies"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data storage"}),": Write to training dataset"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Statistics monitoring"}),": Track game counts, Worker status"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"data-validation",children:"Data Validation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def validate_game(game_data):\n    \"\"\"Validate game data\"\"\"\n    checks = [\n        len(game_data['positions']) > 10,  # Minimum moves\n        len(game_data['positions']) < 500,  # Maximum moves\n        all(is_valid_policy(p['policy']) for p in game_data['positions']),\n        game_data['rules'] in SUPPORTED_RULES,\n    ]\n    return all(checks)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"data-storage-structure",children:"Data Storage Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"training_data/\n\u251c\u2500\u2500 run_001/\n\u2502   \u251c\u2500\u2500 games_00001.npz\n\u2502   \u251c\u2500\u2500 games_00002.npz\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 run_002/\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 current/\n    \u2514\u2500\u2500 latest_games.npz\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"training-process",children:"Training Process"}),"\n",(0,t.jsx)(n.h3,{id:"training-loop",children:"Training Loop"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def training_loop():\n    model = load_model()\n    optimizer = Adam(model.parameters(), lr=1e-4)\n\n    for epoch in range(num_epochs):\n        # Load latest game data\n        dataset = load_recent_games(num_games=100000)\n        dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n\n        for batch in dataloader:\n            states = batch['states']\n            target_policies = batch['policies']\n            target_values = batch['values']\n\n            # Forward pass\n            pred_policies, pred_values = model(states)\n\n            # Compute loss\n            policy_loss = cross_entropy(pred_policies, target_policies)\n            value_loss = mse_loss(pred_values, target_values)\n            loss = policy_loss + value_loss\n\n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        # Periodic evaluation\n        if epoch % 100 == 0:\n            evaluate_model(model)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"loss-functions",children:"Loss Functions"}),"\n",(0,t.jsx)(n.p,{children:"KataGo uses multiple loss terms:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def compute_loss(predictions, targets):\n    # Policy loss (cross-entropy)\n    policy_loss = F.cross_entropy(\n        predictions['policy'],\n        targets['policy']\n    )\n\n    # Value loss (MSE)\n    value_loss = F.mse_loss(\n        predictions['value'],\n        targets['value']\n    )\n\n    # Score loss (MSE)\n    score_loss = F.mse_loss(\n        predictions['score'],\n        targets['score']\n    )\n\n    # Ownership loss (MSE)\n    ownership_loss = F.mse_loss(\n        predictions['ownership'],\n        targets['ownership']\n    )\n\n    # Weighted sum\n    total_loss = (\n        1.0 * policy_loss +\n        1.0 * value_loss +\n        0.5 * score_loss +\n        0.5 * ownership_loss\n    )\n\n    return total_loss\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"model-evaluation--release",children:"Model Evaluation & Release"}),"\n",(0,t.jsx)(n.h3,{id:"elo-evaluation",children:"Elo Evaluation"}),"\n",(0,t.jsx)(n.p,{children:"New models need to play against old models to evaluate strength:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def evaluate_new_model(new_model, baseline_model, num_games=400):\n    \"\"\"Evaluate new model's Elo\"\"\"\n    wins = 0\n    losses = 0\n    draws = 0\n\n    for _ in range(num_games // 2):\n        # New model plays Black\n        result = play_game(new_model, baseline_model)\n        if result == 'black_wins':\n            wins += 1\n        elif result == 'white_wins':\n            losses += 1\n        else:\n            draws += 1\n\n        # New model plays White\n        result = play_game(baseline_model, new_model)\n        if result == 'white_wins':\n            wins += 1\n        elif result == 'black_wins':\n            losses += 1\n        else:\n            draws += 1\n\n    # Calculate Elo difference\n    win_rate = (wins + 0.5 * draws) / num_games\n    elo_diff = 400 * math.log10(win_rate / (1 - win_rate))\n\n    return elo_diff\n"})}),"\n",(0,t.jsx)(n.h3,{id:"release-conditions",children:"Release Conditions"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def should_release_model(new_model, current_best):\n    """Decide whether to release new model"""\n    elo_diff = evaluate_new_model(new_model, current_best)\n\n    # Condition: Elo improvement exceeds threshold\n    if elo_diff > 20:\n        return True\n\n    # Or: Reached certain training steps\n    if training_steps % 10000 == 0:\n        return True\n\n    return False\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-version-naming",children:"Model Version Naming"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"kata1-b18c384nbt-s{steps}-d{data}.bin.gz\n\nExample:\nkata1-b18c384nbt-s9996604416-d4316597426.bin.gz\n\u251c\u2500\u2500 kata1: Training run\n\u251c\u2500\u2500 b18c384nbt: Architecture (18 residual blocks, 384 channels)\n\u251c\u2500\u2500 s9996604416: Training steps\n\u2514\u2500\u2500 d4316597426: Training data volume\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"katago-training-participation-guide",children:"KataGo Training Participation Guide"}),"\n",(0,t.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Item"}),(0,t.jsx)(n.th,{children:"Minimum"}),(0,t.jsx)(n.th,{children:"Recommended"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"GPU"}),(0,t.jsx)(n.td,{children:"GTX 1060"}),(0,t.jsx)(n.td,{children:"RTX 3060+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"VRAM"}),(0,t.jsx)(n.td,{children:"4 GB"}),(0,t.jsx)(n.td,{children:"8 GB+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Network"}),(0,t.jsx)(n.td,{children:"10 Mbps"}),(0,t.jsx)(n.td,{children:"50 Mbps+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Runtime"}),(0,t.jsx)(n.td,{children:"Continuous"}),(0,t.jsx)(n.td,{children:"24/7"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"install-worker",children:"Install Worker"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Download Worker\nwget https://katagotraining.org/download/worker\n\n# Configure\n./katago contribute -config contribute.cfg\n\n# Start contributing\n./katago contribute\n"})}),"\n",(0,t.jsx)(n.h3,{id:"configuration-file",children:"Configuration File"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ini",children:"# contribute.cfg\n\n# Server settings\nserverUrl = https://katagotraining.org/\n\n# Username (for statistics)\nusername = your_username\n\n# GPU settings\nnumNNServerThreadsPerModel = 1\nnnMaxBatchSize = 16\n\n# Game settings\ngamesPerBatch = 25\n"})}),"\n",(0,t.jsx)(n.h3,{id:"monitor-contributions",children:"Monitor Contributions"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# View statistics\nhttps://katagotraining.org/contributions/\n\n# Local logs\ntail -f katago_contribute.log\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"training-statistics",children:"Training Statistics"}),"\n",(0,t.jsx)(n.h3,{id:"katago-training-milestones",children:"KataGo Training Milestones"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Time"}),(0,t.jsx)(n.th,{children:"Games"}),(0,t.jsx)(n.th,{children:"Elo"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2019.06"}),(0,t.jsx)(n.td,{children:"10M"}),(0,t.jsx)(n.td,{children:"Initial"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2020.01"}),(0,t.jsx)(n.td,{children:"100M"}),(0,t.jsx)(n.td,{children:"+500"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2021.01"}),(0,t.jsx)(n.td,{children:"500M"}),(0,t.jsx)(n.td,{children:"+800"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2022.01"}),(0,t.jsx)(n.td,{children:"1B"}),(0,t.jsx)(n.td,{children:"+1000"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2024.01"}),(0,t.jsx)(n.td,{children:"5B+"}),(0,t.jsx)(n.td,{children:"+1200"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"community-contributors",children:"Community Contributors"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Hundreds of global contributors"}),"\n",(0,t.jsx)(n.li,{children:"Thousands of GPU-years of compute accumulated"}),"\n",(0,t.jsx)(n.li,{children:"Running 24/7 continuously"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"advanced-topics",children:"Advanced Topics"}),"\n",(0,t.jsx)(n.h3,{id:"curriculum-learning",children:"Curriculum Learning"}),"\n",(0,t.jsx)(n.p,{children:"Gradually increase training difficulty:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"def get_training_config(training_step):\n    if training_step < 100000:\n        return {'board_size': 9, 'visits': 200}\n    elif training_step < 500000:\n        return {'board_size': 13, 'visits': 400}\n    else:\n        return {'board_size': 19, 'visits': 800}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"data-augmentation",children:"Data Augmentation"}),"\n",(0,t.jsx)(n.p,{children:"Leverage board symmetry to increase data volume:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def augment_position(state, policy):\n    """8 symmetry transformations"""\n    augmented = []\n\n    for rotation in [0, 90, 180, 270]:\n        for flip in [False, True]:\n            aug_state = transform(state, rotation, flip)\n            aug_policy = transform_policy(policy, rotation, flip)\n            augmented.append((aug_state, aug_policy))\n\n    return augmented\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"../training",children:"KataGo Training Mechanism"})," \u2014 Training process details"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"../contributing",children:"Contributing to Open Source"})," \u2014 How to contribute code"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"../evaluation",children:"Evaluation & Benchmarking"})," \u2014 Model evaluation methods"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},30416(e,n,i){i.d(n,{R:()=>a,x:()=>l});var r=i(59471);const t={},s=r.createContext(t);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);