"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[4402],{58808(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>o,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"for-engineers/how-it-works/alphago-explained/distributed-systems","title":"Distributed Systems and TPU","description":"Deep dive into AlphaGo\'s distributed training architecture, TPU acceleration, and large-scale parallel MCTS","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/for-engineers/how-it-works/alphago-explained/19-distributed-systems.mdx","sourceDirName":"for-engineers/how-it-works/alphago-explained","slug":"/for-engineers/how-it-works/alphago-explained/distributed-systems","permalink":"/en/docs/for-engineers/how-it-works/alphago-explained/distributed-systems","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/19-distributed-systems.mdx","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20,"title":"Distributed Systems and TPU","description":"Deep dive into AlphaGo\'s distributed training architecture, TPU acceleration, and large-scale parallel MCTS","keywords":["distributed systems","TPU","parallel computing","MCTS","virtual loss","deep learning","hardware acceleration"]},"sidebar":"tutorialSidebar","previous":{"title":"Training from Scratch","permalink":"/en/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch"},"next":{"title":"AlphaGo\'s Legacy","permalink":"/en/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact"}}');var i=r(62615),l=r(30416);const t={sidebar_position:20,title:"Distributed Systems and TPU",description:"Deep dive into AlphaGo's distributed training architecture, TPU acceleration, and large-scale parallel MCTS",keywords:["distributed systems","TPU","parallel computing","MCTS","virtual loss","deep learning","hardware acceleration"]},a="Distributed Systems and TPU",d={},c=[{value:"Training Architecture Overview",id:"training-architecture-overview",level:2},{value:"Original AlphaGo Training Architecture",id:"original-alphago-training-architecture",level:3},{value:"AlphaGo Zero Training Architecture",id:"alphago-zero-training-architecture",level:3},{value:"Self-play Workers",id:"self-play-workers",level:2},{value:"Task Assignment",id:"task-assignment",level:3},{value:"Workflow",id:"workflow",level:3},{value:"Load Balancing",id:"load-balancing",level:3},{value:"Training Workers",id:"training-workers",level:2},{value:"Task Assignment",id:"task-assignment-1",level:3},{value:"Distributed Training",id:"distributed-training",level:3},{value:"Synchronous vs. Asynchronous Updates",id:"synchronous-vs-asynchronous-updates",level:3},{value:"The Role of TPU",id:"the-role-of-tpu",level:2},{value:"What is TPU?",id:"what-is-tpu",level:3},{value:"TPU Architecture",id:"tpu-architecture",level:3},{value:"Why Does AlphaGo Need TPU?",id:"why-does-alphago-need-tpu",level:3},{value:"Evolution of TPU Usage",id:"evolution-of-tpu-usage",level:3},{value:"Parallel MCTS and Virtual Loss",id:"parallel-mcts-and-virtual-loss",level:2},{value:"Parallelization Challenge",id:"parallelization-challenge",level:3},{value:"Leaf Parallelization",id:"leaf-parallelization",level:3},{value:"Virtual Loss",id:"virtual-loss",level:3},{value:"Basic Concept",id:"basic-concept",level:4},{value:"Operation Flow",id:"operation-flow",level:4},{value:"Effects of Virtual Loss",id:"effects-of-virtual-loss",level:4},{value:"Batch Neural Network Evaluation",id:"batch-neural-network-evaluation",level:3},{value:"Inference Architecture",id:"inference-architecture",level:2},{value:"Competition Configuration",id:"competition-configuration",level:3},{value:"Distributed Inference Flow",id:"distributed-inference-flow",level:3},{value:"Time Management",id:"time-management",level:3},{value:"Communication and Synchronization",id:"communication-and-synchronization",level:2},{value:"Data Format",id:"data-format",level:3},{value:"Network Bandwidth Requirements",id:"network-bandwidth-requirements",level:3},{value:"Fault Handling",id:"fault-handling",level:3},{value:"Cost Analysis",id:"cost-analysis",level:2},{value:"Hardware Cost Estimate",id:"hardware-cost-estimate",level:3},{value:"Comparison with Human Training",id:"comparison-with-human-training",level:3},{value:"Inference Cost",id:"inference-cost",level:3},{value:"Technology Evolution",id:"technology-evolution",level:2},{value:"From AlphaGo to AlphaZero",id:"from-alphago-to-alphazero",level:3},{value:"Impact on Open Source Community",id:"impact-on-open-source-community",level:3},{value:"Animation Reference",id:"animation-reference",level:2},{value:"Further Reading",id:"further-reading",level:2},{value:"References",id:"references",level:2}];function h(e){const n={a:"a",annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"distributed-systems-and-tpu",children:"Distributed Systems and TPU"})}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo's success was not just an algorithmic victory but also an engineering triumph. Training a Go AI that surpasses humans in reasonable time required carefully designed distributed systems and specialized hardware support."}),"\n",(0,i.jsx)(n.p,{children:"This article will deeply analyze the system architecture behind AlphaGo, including the training process, inference architecture, parallel MCTS, and the crucial role of TPUs."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"training-architecture-overview",children:"Training Architecture Overview"}),"\n",(0,i.jsx)(n.h3,{id:"original-alphago-training-architecture",children:"Original AlphaGo Training Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The original AlphaGo (the version that defeated Lee Sedol) had training divided into multiple stages, each using different resource configurations:"}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Phase1["Phase 1: Supervised Learning"]\n        HG["Human games<br/>(30M games)"] --\x3e GPU1["GPU cluster<br/>(50 GPUs)"] --\x3e PN1["Policy Net<br/>(SL ver.)"]\n    end\n\n    subgraph Phase2["Phase 2: Reinforcement Learning"]\n        SP["Self-play<br/>(millions)"] --\x3e GPU2["GPU cluster<br/>(50 GPUs)"] --\x3e PN2["Policy Net<br/>(RL ver.)"]\n    end\n\n    subgraph Phase3["Phase 3: Value Network Training"]\n        RD["RL game data<br/>(30M)"] --\x3e GPU3["GPU cluster<br/>(50 GPUs)"] --\x3e VN["Value Net"]\n    end\n\n    Phase1 --\x3e Phase2 --\x3e Phase3'}),"\n",(0,i.jsx)(n.h3,{id:"alphago-zero-training-architecture",children:"AlphaGo Zero Training Architecture"}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo Zero greatly simplified the training process, using a single end-to-end training loop:"}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Loop["AlphaGo Zero Training Loop"]\n        SP["Self-play Workers<br/>(TPU x N)"]\n        RB["Replay Buffer<br/>(Most recent 500K games)<br/>(RAM/SSD)"]\n        TW["Training Workers<br/>(TPU x M)"]\n        NC["Network Checkpoint"]\n\n        SP --\x3e|"Game data"| RB\n        RB --\x3e TW\n        TW --\x3e NC\n        NC --\x3e|"Update network for Self-play"| SP\n    end'}),"\n",(0,i.jsx)(n.p,{children:"Advantages of this architecture:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Continuous learning"}),": Self-play and Training run simultaneously, no waiting needed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Resource efficiency"}),": All resources are doing useful work"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fast iteration"}),": Network updates are immediately used to generate new data"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"self-play-workers",children:"Self-play Workers"}),"\n",(0,i.jsx)(n.h3,{id:"task-assignment",children:"Task Assignment"}),"\n",(0,i.jsx)(n.p,{children:"Self-play Workers are responsible for playing self-play games using the current strongest network, generating training data."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{children:"AlphaGo Zero"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Number of Workers"}),(0,i.jsx)(n.td,{children:"Dozens"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Per Worker"}),(0,i.jsx)(n.td,{children:"1-4 TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MCTS per game"}),(0,i.jsx)(n.td,{children:"1600 simulations"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Daily production"}),(0,i.jsx)(n.td,{children:"~100,000 games"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"workflow",children:"Workflow"}),"\n",(0,i.jsx)(n.p,{children:"Each Self-play Worker's workflow:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"while True:\n    # 1. Download latest network weights\n    network = download_latest_checkpoint()\n\n    # 2. Play multiple self-play games\n    for game in range(batch_size):\n        positions = []\n        board = EmptyBoard()\n\n        while not board.is_terminal():\n            # Execute MCTS\n            mcts = MCTS(network, board)\n            policy = mcts.search(num_simulations=1600)\n\n            # Select move\n            action = sample(policy)\n\n            # Record\n            positions.append((board.state, policy))\n\n            # Play move\n            board = board.play(action)\n\n        # 3. Get game result\n        result = board.get_result()\n\n        # 4. Upload data\n        upload_to_replay_buffer(positions, result)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"load-balancing",children:"Load Balancing"}),"\n",(0,i.jsx)(n.p,{children:"Multiple Workers need load balancing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Network synchronization"}),": All Workers use the same network version"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data balancing"}),": Ensure data from different Workers is all used"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fault tolerance"}),": Single Worker failure doesn't affect overall training"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"training-workers",children:"Training Workers"}),"\n",(0,i.jsx)(n.h3,{id:"task-assignment-1",children:"Task Assignment"}),"\n",(0,i.jsx)(n.p,{children:"Training Workers are responsible for sampling data from the Replay Buffer and training the neural network."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{children:"AlphaGo Zero"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Number of Workers"}),(0,i.jsx)(n.td,{children:"1-4"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Per Worker"}),(0,i.jsx)(n.td,{children:"4 TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Batch Size"}),(0,i.jsx)(n.td,{children:"2048 (512 per TPU)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Training steps"}),(0,i.jsx)(n.td,{children:"Tens of thousands per day"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"distributed-training",children:"Distributed Training"}),"\n",(0,i.jsxs)(n.p,{children:["Large-scale training uses ",(0,i.jsx)(n.strong,{children:"Data Parallelism"}),":"]}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    PS["Parameter Server"]\n    TPU0["TPU 0<br/>Batch 0"]\n    TPU1["TPU 1<br/>Batch 1"]\n    TPU2["TPU 2<br/>Batch 2"]\n    GA["Gradient Aggregation"]\n\n    PS --\x3e TPU0\n    PS --\x3e TPU1\n    PS --\x3e TPU2\n    TPU0 --\x3e GA\n    TPU1 --\x3e GA\n    TPU2 --\x3e GA\n    GA --\x3e PS'}),"\n",(0,i.jsx)(n.p,{children:"Each TPU processes a different mini-batch, computes local gradients, then aggregates to update global parameters."}),"\n",(0,i.jsx)(n.h3,{id:"synchronous-vs-asynchronous-updates",children:"Synchronous vs. Asynchronous Updates"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Update Method"}),(0,i.jsx)(n.th,{children:"Pros"}),(0,i.jsx)(n.th,{children:"Cons"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Synchronous"}),(0,i.jsx)(n.td,{children:"Stable, reproducible"}),(0,i.jsx)(n.td,{children:"Workers wait for slowest one"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Asynchronous"}),(0,i.jsx)(n.td,{children:"High throughput"}),(0,i.jsx)(n.td,{children:"Gradients may be stale"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["AlphaGo Zero uses ",(0,i.jsx)(n.strong,{children:"synchronous updates"})," to ensure training stability."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"the-role-of-tpu",children:"The Role of TPU"}),"\n",(0,i.jsx)(n.h3,{id:"what-is-tpu",children:"What is TPU?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TPU (Tensor Processing Unit)"})," is an accelerator Google designed specifically for deep learning:"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"TPU"}),(0,i.jsx)(n.th,{children:"GPU"}),(0,i.jsx)(n.th,{children:"CPU"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Design goal"}),(0,i.jsx)(n.td,{children:"Matrix operations"}),(0,i.jsx)(n.td,{children:"General parallel"}),(0,i.jsx)(n.td,{children:"General computing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Precision"}),(0,i.jsx)(n.td,{children:"FP16/BF16 optimized"}),(0,i.jsx)(n.td,{children:"FP32/FP16"}),(0,i.jsx)(n.td,{children:"FP64/FP32"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Power consumption"}),(0,i.jsx)(n.td,{children:"Relatively low"}),(0,i.jsx)(n.td,{children:"Higher"}),(0,i.jsx)(n.td,{children:"Highest"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Latency"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"High"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"tpu-architecture",children:"TPU Architecture"}),"\n",(0,i.jsxs)(n.p,{children:["TPU's core is the ",(0,i.jsx)(n.strong,{children:"MXU (Matrix Multiply Unit)"}),":"]}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph TPU["TPU v2/v3"]\n        MXU["MXU (128x128)<br/>Matrix Multiply Unit<br/>(128x128 = 16K MACs/cycle)"]\n        VU["Vector Unit"]\n        HBM["HBM<br/>(16-32 GB)"]\n    end'}),"\n",(0,i.jsx)(n.p,{children:"MXU can execute 16K multiply-accumulate operations per cycle, which is crucial for neural network matrix multiplication."}),"\n",(0,i.jsx)(n.h3,{id:"why-does-alphago-need-tpu",children:"Why Does AlphaGo Need TPU?"}),"\n",(0,i.jsxs)(n.p,{children:["Go AI's computational bottleneck is ",(0,i.jsx)(n.strong,{children:"neural network inference"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Operation"}),(0,i.jsx)(n.th,{children:"Proportion"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Neural network forward pass"}),(0,i.jsx)(n.td,{children:"~95%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MCTS tree operations"}),(0,i.jsx)(n.td,{children:"~4%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Other"}),(0,i.jsx)(n.td,{children:"~1%"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Each MCTS step requires 1600 neural network inferences. TPU's high throughput makes this possible."}),"\n",(0,i.jsx)(n.h3,{id:"evolution-of-tpu-usage",children:"Evolution of TPU Usage"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Version"}),(0,i.jsx)(n.th,{children:"Training TPU"}),(0,i.jsx)(n.th,{children:"Inference TPU"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Lee"}),(0,i.jsx)(n.td,{children:"50 GPU"}),(0,i.jsx)(n.td,{children:"48 TPU (v1)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Master"}),(0,i.jsx)(n.td,{children:"4 TPU (v2)"}),(0,i.jsx)(n.td,{children:"4 TPU (v2)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Zero"}),(0,i.jsx)(n.td,{children:"4 TPU (v2)"}),(0,i.jsx)(n.td,{children:"4 TPU (v2) (scalable)"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo Zero uses significantly fewer TPUs, thanks to more efficient architecture and newer TPU versions."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"parallel-mcts-and-virtual-loss",children:"Parallel MCTS and Virtual Loss"}),"\n",(0,i.jsx)(n.h3,{id:"parallelization-challenge",children:"Parallelization Challenge"}),"\n",(0,i.jsxs)(n.p,{children:["Standard MCTS implementation is ",(0,i.jsx)(n.strong,{children:"serial"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"for i in range(num_simulations):\n    1. Selection: Select downward from root\n    2. Expansion: Expand leaf node\n    3. Evaluation: Neural network evaluation\n    4. Backup: Propagate back updates\n"})}),"\n",(0,i.jsxs)(n.p,{children:["But neural network evaluation is GPU/TPU-friendly ",(0,i.jsx)(n.strong,{children:"batch operation"}),". How to run multiple simulations simultaneously?"]}),"\n",(0,i.jsx)(n.h3,{id:"leaf-parallelization",children:"Leaf Parallelization"}),"\n",(0,i.jsx)(n.p,{children:"The simplest parallel approach: run multiple complete simulations simultaneously, merge results at the end."}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    Root["Root"]\n    S1["Sim 1<br/>(indep.)"]\n    S2["Sim 2<br/>(indep.)"]\n    S3["Sim 3<br/>(indep.)"]\n    S4["Sim 4<br/>(indep.)"]\n    Merge["Merge Trees"]\n\n    Root --\x3e S1\n    Root --\x3e S2\n    Root --\x3e S3\n    Root --\x3e S4\n    S1 --\x3e Merge\n    S2 --\x3e Merge\n    S3 --\x3e Merge\n    S4 --\x3e Merge'}),"\n",(0,i.jsx)(n.p,{children:"Problem: Each simulation starts from root, exploring the same paths repeatedly."}),"\n",(0,i.jsx)(n.h3,{id:"virtual-loss",children:"Virtual Loss"}),"\n",(0,i.jsxs)(n.p,{children:["DeepMind adopted ",(0,i.jsx)(n.strong,{children:"Virtual Loss"})," technique to implement Tree Parallelization."]}),"\n",(0,i.jsx)(n.h4,{id:"basic-concept",children:"Basic Concept"}),"\n",(0,i.jsx)(n.p,{children:"When one thread is exploring a node, temporarily reduce that node's value so other threads choose other paths."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Normal UCB: Q(s,a) + c * P(s,a) * sqrt(N(s)) / (1 + N(s,a))\n\nWith virtual loss:\n(Q(s,a) * N(s,a) - v * n_virtual) / (N(s,a) + n_virtual) + c * P(s,a) * sqrt(N(s)) / (1 + N(s,a) + n_virtual)\n"})}),"\n",(0,i.jsx)(n.p,{children:"where:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"n_virtual"})," is the number of threads currently exploring that node"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"v"})," is the virtual loss value (usually 1 or corresponding to win rate)"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"operation-flow",children:"Operation Flow"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'Time T1:\n  Thread 1 selects path A \u2192 B \u2192 C\n  Node C gets virtual loss -1\n\nTime T2:\n  Thread 2 selects path A \u2192 B \u2192 D (because C is "penalized")\n  Node D gets virtual loss -1\n\nTime T3:\n  Thread 1 completes evaluation, updates C\'s actual value, removes virtual loss\n  Thread 3 might now select C (if actual value is good enough)\n'})}),"\n",(0,i.jsx)(n.h4,{id:"effects-of-virtual-loss",children:"Effects of Virtual Loss"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Effect"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Exploration diversity"}),(0,i.jsx)(n.td,{children:"Forces exploration of different paths"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Batch efficiency"}),(0,i.jsx)(n.td,{children:"Can evaluate multiple leaf nodes simultaneously"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Convergence"}),(0,i.jsx)(n.td,{children:"Virtual loss eventually overwritten by real values, doesn't affect convergence"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"batch-neural-network-evaluation",children:"Batch Neural Network Evaluation"}),"\n",(0,i.jsxs)(n.p,{children:["Through virtual loss, multiple leaf nodes awaiting evaluation can be collected for ",(0,i.jsx)(n.strong,{children:"batch inference"}),":"]}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart LR\n    subgraph MCTS["Parallel MCTS"]\n        T1["Thread 1 -> Leaf L1"]\n        T2["Thread 2 -> Leaf L2"]\n        T3["Thread 3 -> Leaf L3"]\n        T4["Thread 4 -> Leaf L4"]\n    end\n\n    Batch["Batch"]\n    TPU["TPU"]\n    Results["(P1,V1), (P2,V2),<br/>(P3,V3), (P4,V4)"]\n\n    T1 --\x3e Batch\n    T2 --\x3e Batch\n    T3 --\x3e Batch\n    T4 --\x3e Batch\n    Batch --\x3e TPU --\x3e Results'}),"\n",(0,i.jsx)(n.p,{children:"TPU batch inference efficiency is much higher than individual inference, making parallel MCTS possible."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"inference-architecture",children:"Inference Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"competition-configuration",children:"Competition Configuration"}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo's inference architecture during official matches:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Version"}),(0,i.jsx)(n.th,{children:"Hardware Configuration"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Fan"}),(0,i.jsx)(n.td,{children:"176 GPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Lee"}),(0,i.jsx)(n.td,{children:"48 TPU + multiple servers"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Master"}),(0,i.jsx)(n.td,{children:"4 TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"AlphaGo Zero"}),(0,i.jsx)(n.td,{children:"4 TPU (scalable)"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"distributed-inference-flow",children:"Distributed Inference Flow"}),"\n",(0,i.jsx)(n.p,{children:"Match inference flow (using AlphaGo Lee as example):"}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TB\n    subgraph Arch["Distributed Inference Architecture"]\n        Main["Main node<br/>(Receive opponent move, send AlphaGo move)"]\n        MCTS["MCTS Controller<br/>(Manage search tree, assign tasks, collect results)"]\n\n        subgraph Cluster["TPU Cluster (48 TPUs)"]\n            TPU1["TPU 1"]\n            TPU2["TPU 2"]\n            TPU3["TPU 3"]\n            TPU4["TPU 4"]\n            TPU5["TPU 5"]\n            TPU48["... TPU 48"]\n        end\n\n        Main --\x3e MCTS --\x3e Cluster\n    end'}),"\n",(0,i.jsx)(n.h3,{id:"time-management",children:"Time Management"}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo's time management strategy:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Position"}),(0,i.jsx)(n.th,{children:"Think Time"}),(0,i.jsx)(n.th,{children:"MCTS Count"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Opening (has joseki)"}),(0,i.jsx)(n.td,{children:"Shorter"}),(0,i.jsx)(n.td,{children:"~10,000"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Middle game (complex)"}),(0,i.jsx)(n.td,{children:"Longer"}),(0,i.jsx)(n.td,{children:"~100,000"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Clear position"}),(0,i.jsx)(n.td,{children:"Shorter"}),(0,i.jsx)(n.td,{children:"~5,000"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Byo-yomi"}),(0,i.jsx)(n.td,{children:"Fixed"}),(0,i.jsx)(n.td,{children:"~1,600"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"More MCTS simulations generally mean better move quality."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"communication-and-synchronization",children:"Communication and Synchronization"}),"\n",(0,i.jsx)(n.h3,{id:"data-format",children:"Data Format"}),"\n",(0,i.jsx)(n.p,{children:"Training data transmission format:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-protobuf",children:"message TrainingExample {\n    // Board state (17 \xd7 19 \xd7 19)\n    repeated float board_planes = 1;\n\n    // MCTS search result (362)\n    repeated float mcts_policy = 2;\n\n    // Game result (1 = current side wins, -1 = current side loses)\n    float game_result = 3;\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"network-bandwidth-requirements",children:"Network Bandwidth Requirements"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Data Flow"}),(0,i.jsx)(n.th,{children:"Size"}),(0,i.jsx)(n.th,{children:"Frequency"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Training samples"}),(0,i.jsx)(n.td,{children:"~10 KB/sample"}),(0,i.jsx)(n.td,{children:"Thousands per second"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Network weights"}),(0,i.jsx)(n.td,{children:"~200 MB"}),(0,i.jsx)(n.td,{children:"Several times per hour"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Control messages"}),(0,i.jsx)(n.td,{children:"< 1 KB"}),(0,i.jsx)(n.td,{children:"Continuous"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Total bandwidth requirement: ~100 Mbps (internal network sufficient)"}),"\n",(0,i.jsx)(n.h3,{id:"fault-handling",children:"Fault Handling"}),"\n",(0,i.jsx)(n.p,{children:"Distributed system fault handling:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Fault Type"}),(0,i.jsx)(n.th,{children:"Handling Method"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Worker crashes"}),(0,i.jsx)(n.td,{children:"Restart, continue from latest checkpoint"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Network disconnect"}),(0,i.jsx)(n.td,{children:"Buffer data, resume transmission after reconnect"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TPU failure"}),(0,i.jsx)(n.td,{children:"Auto-switch to backup TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Data corruption"}),(0,i.jsx)(n.td,{children:"Discard after verification, regenerate"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"cost-analysis",children:"Cost Analysis"}),"\n",(0,i.jsx)(n.h3,{id:"hardware-cost-estimate",children:"Hardware Cost Estimate"}),"\n",(0,i.jsx)(n.p,{children:"Estimating AlphaGo Zero training cost using Google Cloud TPU pricing:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Resource"}),(0,i.jsx)(n.th,{children:"Quantity"}),(0,i.jsx)(n.th,{children:"Price/Hour"}),(0,i.jsx)(n.th,{children:"Total/Day"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TPU v2 Pod"}),(0,i.jsx)(n.td,{children:"4"}),(0,i.jsx)(n.td,{children:"~$32"}),(0,i.jsx)(n.td,{children:"~$3,000"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"High-memory VM"}),(0,i.jsx)(n.td,{children:"Several"}),(0,i.jsx)(n.td,{children:"~$5"}),(0,i.jsx)(n.td,{children:"~$500"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Storage"}),(0,i.jsx)(n.td,{children:"10 TB"}),(0,i.jsx)(n.td,{children:"~$0.02/GB"}),(0,i.jsx)(n.td,{children:"~$200"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Network"}),(0,i.jsx)(n.td,{children:"-"}),(0,i.jsx)(n.td,{children:"Included"}),(0,i.jsx)(n.td,{children:"-"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsxs)(n.strong,{children:["About ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"3"}),(0,i.jsx)(n.mo,{separator:"true",children:","}),(0,i.jsx)(n.mn,{children:"700"}),(0,i.jsx)(n.mi,{mathvariant:"normal",children:"/"}),(0,i.jsx)(n.mi,{children:"d"}),(0,i.jsx)(n.mi,{children:"a"}),(0,i.jsx)(n.mi,{children:"y"}),(0,i.jsx)(n.mo,{children:"\u2217"}),(0,i.jsx)(n.mo,{children:"\u2217"}),(0,i.jsx)(n.mo,{separator:"true",children:","}),(0,i.jsx)(n.mi,{children:"c"}),(0,i.jsx)(n.mi,{children:"o"}),(0,i.jsx)(n.mi,{children:"m"}),(0,i.jsx)(n.mi,{children:"p"}),(0,i.jsx)(n.mi,{children:"l"}),(0,i.jsx)(n.mi,{children:"e"}),(0,i.jsx)(n.mi,{children:"t"}),(0,i.jsx)(n.mi,{children:"e"}),(0,i.jsx)(n.mi,{children:"t"}),(0,i.jsx)(n.mi,{children:"r"}),(0,i.jsx)(n.mi,{children:"a"}),(0,i.jsx)(n.mi,{children:"i"}),(0,i.jsx)(n.mi,{children:"n"}),(0,i.jsx)(n.mi,{children:"i"}),(0,i.jsx)(n.mi,{children:"n"}),(0,i.jsx)(n.mi,{children:"g"}),(0,i.jsx)(n.mo,{stretchy:"false",children:"("}),(0,i.jsx)(n.mn,{children:"40"}),(0,i.jsx)(n.mi,{children:"d"}),(0,i.jsx)(n.mi,{children:"a"}),(0,i.jsx)(n.mi,{children:"y"}),(0,i.jsx)(n.mi,{children:"s"}),(0,i.jsx)(n.mo,{stretchy:"false",children:")"}),(0,i.jsx)(n.mi,{children:"a"}),(0,i.jsx)(n.mi,{children:"b"}),(0,i.jsx)(n.mi,{children:"o"}),(0,i.jsx)(n.mi,{children:"u"}),(0,i.jsx)(n.mi,{children:"t"}),(0,i.jsx)(n.mo,{children:"\u2217"}),(0,i.jsx)(n.mo,{children:"\u2217"})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"3,700/day**, complete training (40 days) about **"})]})})}),(0,i.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(n.span,{className:"mord",children:"3"}),(0,i.jsx)(n.span,{className:"mpunct",children:","}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(n.span,{className:"mord",children:"700/"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(n.span,{className:"mbin",children:"\u2217"}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\u2217"}),(0,i.jsx)(n.span,{className:"mpunct",children:","}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"co"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"m"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"pl"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"e"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"r"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"ainin"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"g"}),(0,i.jsx)(n.span,{className:"mopen",children:"("}),(0,i.jsx)(n.span,{className:"mord",children:"40"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"d"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"a"}),(0,i.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"s"}),(0,i.jsx)(n.span,{className:"mclose",children:")"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"ab"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"o"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"u"}),(0,i.jsx)(n.span,{className:"mord mathnormal",children:"t"}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,i.jsx)(n.span,{className:"mbin",children:"\u2217"}),(0,i.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.4653em"}}),(0,i.jsx)(n.span,{className:"mord",children:"\u2217"})]})]})]}),"150,000"]}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Note: This is a 2017 estimate; DeepMind as a Google subsidiary may have internal discounts."}),"\n",(0,i.jsx)(n.h3,{id:"comparison-with-human-training",children:"Comparison with Human Training"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"AlphaGo Zero"}),(0,i.jsx)(n.th,{children:"Human Professional"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Reach professional level"}),(0,i.jsx)(n.td,{children:"2 days"}),(0,i.jsx)(n.td,{children:"10-15 years"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Training cost"}),(0,i.jsx)(n.td,{children:"~$7,500"}),(0,i.jsx)(n.td,{children:"Millions (tuition, living, opportunity cost)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Ongoing cost"}),(0,i.jsx)(n.td,{children:"Electricity"}),(0,i.jsx)(n.td,{children:"Living expenses"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Reproducibility"}),(0,i.jsx)(n.td,{children:"Perfect reproduction"}),(0,i.jsx)(n.td,{children:"Cannot reproduce"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Of course, this comparison isn't entirely fair - humans learn more than just Go while studying the game."}),"\n",(0,i.jsx)(n.h3,{id:"inference-cost",children:"Inference Cost"}),"\n",(0,i.jsx)(n.p,{children:"Official match inference cost:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Configuration"}),(0,i.jsx)(n.th,{children:"Cost per Game"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"48 TPU (AlphaGo Lee)"}),(0,i.jsx)(n.td,{children:"~$500"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4 TPU (AlphaGo Zero)"}),(0,i.jsx)(n.td,{children:"~$50"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Single GPU (KataGo)"}),(0,i.jsx)(n.td,{children:"~$1"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Inference cost has decreased dramatically with technological progress."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"technology-evolution",children:"Technology Evolution"}),"\n",(0,i.jsx)(n.h3,{id:"from-alphago-to-alphazero",children:"From AlphaGo to AlphaZero"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"AlphaGo Lee"}),(0,i.jsx)(n.th,{children:"AlphaGo Zero"}),(0,i.jsx)(n.th,{children:"AlphaZero"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Training TPU"}),(0,i.jsx)(n.td,{children:"50+ GPU \u2192 TPU"}),(0,i.jsx)(n.td,{children:"4 TPU"}),(0,i.jsx)(n.td,{children:"4 TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Inference TPU"}),(0,i.jsx)(n.td,{children:"48 TPU"}),(0,i.jsx)(n.td,{children:"4 TPU"}),(0,i.jsx)(n.td,{children:"4 TPU"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MCTS/move"}),(0,i.jsx)(n.td,{children:"~100,000"}),(0,i.jsx)(n.td,{children:"~1,600"}),(0,i.jsx)(n.td,{children:"~800"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Training time"}),(0,i.jsx)(n.td,{children:"Months"}),(0,i.jsx)(n.td,{children:"40 days"}),(0,i.jsx)(n.td,{children:"Hours to days"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Approximately 100\xd7 efficiency improvement."}),"\n",(0,i.jsx)(n.h3,{id:"impact-on-open-source-community",children:"Impact on Open Source Community"}),"\n",(0,i.jsx)(n.p,{children:"AlphaGo's architecture inspired multiple open source projects:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Project"}),(0,i.jsx)(n.th,{children:"Features"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Leela Zero"}),(0,i.jsx)(n.td,{children:"Community distributed training, replicating AlphaGo Zero"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"KataGo"}),(0,i.jsx)(n.td,{children:"Single GPU efficient training, surpasses AlphaGo Zero"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"ELF OpenGo"}),(0,i.jsx)(n.td,{children:"Facebook open source, uses PyTorch"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Minigo"}),(0,i.jsx)(n.td,{children:"Google open source, uses TensorFlow"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"These projects let ordinary researchers train powerful Go AI too."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"animation-reference",children:"Animation Reference"}),"\n",(0,i.jsx)(n.p,{children:"Core concepts covered in this article with animation numbers:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Number"}),(0,i.jsx)(n.th,{children:"Concept"}),(0,i.jsx)(n.th,{children:"Physics/Math Correspondence"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Animation C9"}),(0,i.jsx)(n.td,{children:"Parallel MCTS"}),(0,i.jsx)(n.td,{children:"Many-body problem"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Animation E9"}),(0,i.jsx)(n.td,{children:"Distributed training"}),(0,i.jsx)(n.td,{children:"Distributed computing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Animation C5"}),(0,i.jsx)(n.td,{children:"Virtual loss"}),(0,i.jsx)(n.td,{children:"Repulsive potential"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Animation D15"}),(0,i.jsx)(n.td,{children:"Batch inference"}),(0,i.jsx)(n.td,{children:"Vectorized computation"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Previous"}),": ",(0,i.jsx)(n.a,{href:"../training-from-scratch",children:"Training from Scratch"})," - Detailed analysis of training curve"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Next"}),": ",(0,i.jsx)(n.a,{href:"../legacy-and-impact",children:"AlphaGo's Legacy"})," - AlphaGo's profound impact on AI field"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Related Article"}),": ",(0,i.jsx)(n.a,{href:"../mcts-neural-combo",children:"MCTS and Neural Network Integration"})," - MCTS fundamentals"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:['Silver, D., et al. (2017). "Mastering the game of Go without human knowledge." ',(0,i.jsx)(n.em,{children:"Nature"}),", 550, 354-359."]}),"\n",(0,i.jsxs)(n.li,{children:['Jouppi, N., et al. (2017). "In-Datacenter Performance Analysis of a Tensor Processing Unit." ',(0,i.jsx)(n.em,{children:"ISCA 2017"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:['Dean, J., et al. (2012). "Large Scale Distributed Deep Networks." ',(0,i.jsx)(n.em,{children:"NeurIPS 2012"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:['Chaslot, G., et al. (2008). "Parallel Monte-Carlo Tree Search." ',(0,i.jsx)(n.em,{children:"CIG 2008"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:['Segal, R. (2010). "On the Scalability of Parallel UCT." ',(0,i.jsx)(n.em,{children:"CIG 2010"}),"."]}),"\n"]})]})}function o(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},30416(e,n,r){r.d(n,{R:()=>t,x:()=>a});var s=r(59471);const i={},l=s.createContext(i);function t(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);