<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/birth-of-alphago" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">The Birth of AlphaGo | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/en/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/en/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" property="og:locale:alternate" content="ar"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="圍棋, Go, 好棋寶寶, AI, KataGo, AlphaGo, 圍棋教學, 圍棋入門"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="The Birth of AlphaGo | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="From the founding of DeepMind to the Google acquisition, how AlphaGo evolved from a crazy idea to world-changing AI"><meta data-rh="true" property="og:description" content="From the founding of DeepMind to the Google acquisition, how AlphaGo evolved from a crazy idea to world-changing AI"><link data-rh="true" rel="icon" href="/en/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/en/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/en/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"The Birth of AlphaGo","item":"https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/styles.f23bf74b.css">
<script src="/en/assets/js/runtime~main.51eae05f.js" defer="defer"></script>
<script src="/en/assets/js/main.74a0125b.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/en/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/logo.svg" alt="Good Go Baby Association Logo" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/en/img/logo.svg" alt="Good Go Baby Association Logo" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">Weiqi.Kids</b></a><a class="navbar__item navbar__link" href="/en/docs/for-players/">For Go Players</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/en/docs/for-engineers/">For Engineers</a><a class="navbar__item navbar__link" href="/en/docs/about/">About Us</a><a class="navbar__item navbar__link" href="/en/docs/activities/">Activities</a><a class="navbar__item navbar__link" href="/en/docs/references/">References</a><a class="navbar__item navbar__link" href="/en/docs/sop/">Standard Procedures</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/intro/"><span title="User Guide" class="linkLabel_REp1">User Guide</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/en/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="Expand sidebar category &#x27;關於協會&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/en/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="Expand sidebar category &#x27;活動實績&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/en/docs/for-players/"><span title="For Go Players" class="categoryLinkLabel_ezQx">For Go Players</span></a><button aria-label="Expand sidebar category &#x27;For Go Players&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/en/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="Expand sidebar category &#x27;參考資料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/en/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="Expand sidebar category &#x27;標準作業流程&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/en/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="Collapse sidebar category &#x27;給工程師的圍棋 AI 指南&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/en/docs/for-engineers/deep-dive/"><span title="For Deep Learners" class="categoryLinkLabel_ezQx">For Deep Learners</span></a><button aria-label="Expand sidebar category &#x27;For Deep Learners&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/en/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="Expand sidebar category &#x27;30 分鐘跑起第一個圍棋 AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/en/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="Collapse sidebar category &#x27;一篇文章搞懂圍棋 AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="Collapse sidebar category &#x27;AlphaGo 完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="The Birth of AlphaGo" class="linkLabel_REp1">The Birth of AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="Key Matches Review" class="linkLabel_REp1">Key Matches Review</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="Deep Analysis of &quot;The Divine Move&quot;" class="linkLabel_REp1">Deep Analysis of &quot;The Divine Move&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="Why Is Go Hard?" class="linkLabel_REp1">Why Is Go Hard?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="Limits of Traditional Methods" class="linkLabel_REp1">Limits of Traditional Methods</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="Board State Representation" class="linkLabel_REp1">Board State Representation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="Policy Network Deep Dive" class="linkLabel_REp1">Policy Network Deep Dive</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="Value Network Explained" class="linkLabel_REp1">Value Network Explained</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="Input Feature Design" class="linkLabel_REp1">Input Feature Design</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="CNN and Go" class="linkLabel_REp1">CNN and Go</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="Supervised Learning Phase" class="linkLabel_REp1">Supervised Learning Phase</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="Introduction to Reinforcement Learning" class="linkLabel_REp1">Introduction to Reinforcement Learning</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="Self-Play" class="linkLabel_REp1">Self-Play</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="MCTS and Neural Network Integration" class="linkLabel_REp1">MCTS and Neural Network Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="PUCT Formula Explained" class="linkLabel_REp1">PUCT Formula Explained</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="AlphaGo Zero Overview" class="linkLabel_REp1">AlphaGo Zero Overview</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="Dual-Head Network and Residual Network" class="linkLabel_REp1">Dual-Head Network and Residual Network</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="Training from Scratch" class="linkLabel_REp1">Training from Scratch</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="Distributed Systems and TPU" class="linkLabel_REp1">Distributed Systems and TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="AlphaGo&#x27;s Legacy" class="linkLabel_REp1">AlphaGo&#x27;s Legacy</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/en/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="Expand sidebar category &#x27;圍棋 AI 產業現況&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/en/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="Expand sidebar category &#x27;圍棋 AI 能做什麼？&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/en/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/en/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/en/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">The Birth of AlphaGo</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>The Birth of AlphaGo</h1></header>
<p>In March 2016, when AlphaGo defeated Lee Sedol 4:1, the whole world was asking: how exactly was this program that changed the history of artificial intelligence born?</p>
<p>The answer begins with the dream of a chess prodigy.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="the-founding-of-deepmind">The Founding of DeepMind<a href="#the-founding-of-deepmind" class="hash-link" aria-label="Direct link to The Founding of DeepMind" title="Direct link to The Founding of DeepMind" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="demis-hassabis-from-prodigy-to-ai-pioneer">Demis Hassabis: From Prodigy to AI Pioneer<a href="#demis-hassabis-from-prodigy-to-ai-pioneer" class="hash-link" aria-label="Direct link to Demis Hassabis: From Prodigy to AI Pioneer" title="Direct link to Demis Hassabis: From Prodigy to AI Pioneer" translate="no">​</a></h3>
<p><strong>Demis Hassabis</strong> is the co-founder and CEO of DeepMind. His life experience seems almost tailor-made for creating AlphaGo.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="chess-prodigy">Chess Prodigy<a href="#chess-prodigy" class="hash-link" aria-label="Direct link to Chess Prodigy" title="Direct link to Chess Prodigy" translate="no">​</a></h4>
<p>Born in London in 1975, Hassabis learned chess at age 4 and reached chess master level (Elo 2300+) by age 13, making him the second youngest person in British history to achieve this level.</p>
<p>This experience gave him deep insights into:</p>
<ul>
<li class=""><strong>Board games as a test of intelligence</strong>: Chess requires planning, intuition, and pattern recognition</li>
<li class=""><strong>The nature of human intelligence</strong>: How do chess players find good moves among vast possibilities?</li>
<li class=""><strong>Computer limitations</strong>: Deep Blue&#x27;s 1997 victory over Kasparov relied on brute-force search, not true &quot;understanding&quot;</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="game-designer">Game Designer<a href="#game-designer" class="hash-link" aria-label="Direct link to Game Designer" title="Direct link to Game Designer" translate="no">​</a></h4>
<p>At 17, Hassabis joined Bullfrog Productions (the game company founded by Peter Molyneux, creator of <em>Populous</em>) and participated in developing the classic game <em>Theme Park</em>. This experience taught him:</p>
<ul>
<li class=""><strong>How to design complex systems</strong>: Games are simplified models simulating the real world</li>
<li class=""><strong>Player behavior prediction</strong>: AI needs to understand human decision-making processes</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="cognitive-neuroscientist">Cognitive Neuroscientist<a href="#cognitive-neuroscientist" class="hash-link" aria-label="Direct link to Cognitive Neuroscientist" title="Direct link to Cognitive Neuroscientist" translate="no">​</a></h4>
<p>After obtaining a computer science degree from Cambridge University, Hassabis earned a PhD in cognitive neuroscience from University College London (UCL). His research focused on: <strong>how the hippocampus enables humans to imagine and plan</strong>.</p>
<p>This research discovered:</p>
<ul>
<li class="">Human memory and imagination use the same brain regions</li>
<li class="">We plan the future through &quot;mental time travel&quot;</li>
<li class="">This ability may be the core of intelligence</li>
</ul>
<p>These insights directly influenced AlphaGo&#x27;s later design—enabling AI to &quot;imagine&quot; future moves and learn from them.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="co-founders">Co-founders<a href="#co-founders" class="hash-link" aria-label="Direct link to Co-founders" title="Direct link to Co-founders" translate="no">​</a></h3>
<p>In 2010, Hassabis co-founded DeepMind with two partners:</p>
<table><thead><tr><th>Founder</th><th>Background</th><th>Contribution</th></tr></thead><tbody><tr><td><strong>Demis Hassabis</strong></td><td>Neuroscience, game design</td><td>Vision and strategy</td></tr><tr><td><strong>Shane Legg</strong></td><td>Machine learning PhD</td><td>AGI theoretical foundation</td></tr><tr><td><strong>Mustafa Suleyman</strong></td><td>Social entrepreneur</td><td>Business and applications</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="solve-intelligence-then-use-it-to-solve-everything-else">&quot;Solve Intelligence, Then Use It to Solve Everything Else&quot;<a href="#solve-intelligence-then-use-it-to-solve-everything-else" class="hash-link" aria-label="Direct link to &quot;Solve Intelligence, Then Use It to Solve Everything Else&quot;" title="Direct link to &quot;Solve Intelligence, Then Use It to Solve Everything Else&quot;" translate="no">​</a></h3>
<p>DeepMind&#x27;s mission statement is:</p>
<blockquote>
<p><strong>&quot;Solve intelligence, and then use that to solve everything else.&quot;</strong></p>
</blockquote>
<p>This is not an ordinary AI company. Their goal is not to make products, but to create <strong>Artificial General Intelligence (AGI)</strong>—an AI that can think, learn, and solve any problem like humans.</p>
<p>Why &quot;solve intelligence&quot; first? Because once we have AGI, it can help us solve humanity&#x27;s greatest challenges: climate change, disease, energy, and more.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="early-breakthrough-atari-games">Early Breakthrough: Atari Games<a href="#early-breakthrough-atari-games" class="hash-link" aria-label="Direct link to Early Breakthrough: Atari Games" title="Direct link to Early Breakthrough: Atari Games" translate="no">​</a></h2>
<p>Before challenging Go, DeepMind first proved its capabilities—using AI to play Atari games.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="dqn-ai-that-learned-to-play-games">DQN: AI That Learned to Play Games<a href="#dqn-ai-that-learned-to-play-games" class="hash-link" aria-label="Direct link to DQN: AI That Learned to Play Games" title="Direct link to DQN: AI That Learned to Play Games" translate="no">​</a></h3>
<p>In 2013, DeepMind published the <strong>DQN (Deep Q-Network)</strong> algorithm. This AI could:</p>
<ol>
<li class=""><strong>Only see screen pixels</strong>—no game rules provided</li>
<li class=""><strong>Learn to play games on its own</strong>—through trial and error</li>
<li class=""><strong>Reach human level</strong>—and even surpass humans in some games</li>
</ol>
<p>In <em>Breakout</em>, DQN learned a strategy that humans would take hours to discover: <strong>dig a tunnel to let the ball get behind the bricks, clearing large sections at once</strong>.</p>
<p>This proved that the combination of deep learning + reinforcement learning could discover strategies humans had never thought of.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="why-start-with-games">Why Start with Games?<a href="#why-start-with-games" class="hash-link" aria-label="Direct link to Why Start with Games?" title="Direct link to Why Start with Games?" translate="no">​</a></h3>
<p>Hassabis chose games as a research platform for several reasons:</p>
<ol>
<li class=""><strong>Controlled environment</strong>: Games have clear rules and objectives</li>
<li class=""><strong>Measurable progress</strong>: Objective scores to evaluate AI capability</li>
<li class=""><strong>Human baseline</strong>: Can be compared with human players</li>
<li class=""><strong>Diversity</strong>: Different games test different abilities</li>
</ol>
<p>This methodology was later applied to Go.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="googles-acquisition">Google&#x27;s Acquisition<a href="#googles-acquisition" class="hash-link" aria-label="Direct link to Google&#x27;s Acquisition" title="Direct link to Google&#x27;s Acquisition" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-500-million-bet">A $500 Million Bet<a href="#a-500-million-bet" class="hash-link" aria-label="Direct link to A $500 Million Bet" title="Direct link to A $500 Million Bet" translate="no">​</a></h3>
<p>In January 2014, Google acquired DeepMind for approximately <strong>$500 million</strong>. This was one of the largest acquisitions in the AI field at the time.</p>
<p>Why was Google willing to pay so much for a company with only 75 people and no products?</p>
<p>The answer lies in <strong>game theory</strong>:</p>
<ul>
<li class=""><strong>Facebook was also bidding</strong>: Rumor had it that Facebook offered $400 million</li>
<li class=""><strong>AI is the key technology of the future</strong>: Whoever masters AI first controls the future</li>
<li class=""><strong>DeepMind was the best team</strong>: They had proven the feasibility of deep reinforcement learning</li>
</ul>
<p>Google CEO Larry Page personally intervened to convince Hassabis to choose Google over Facebook.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="acquisition-conditions">Acquisition Conditions<a href="#acquisition-conditions" class="hash-link" aria-label="Direct link to Acquisition Conditions" title="Direct link to Acquisition Conditions" translate="no">​</a></h3>
<p>Hassabis negotiated several key conditions:</p>
<ol>
<li class=""><strong>Independent operation</strong>: DeepMind maintains London headquarters, independent R&amp;D</li>
<li class=""><strong>Academic freedom</strong>: Can publish papers, not keep everything secret</li>
<li class=""><strong>Ethics committee</strong>: Establish AI ethics review mechanism</li>
<li class=""><strong>Long-term research</strong>: No short-term commercialization pressure</li>
</ol>
<p>These conditions allowed DeepMind to pursue long-term, high-risk research—like conquering Go with AI.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="googles-ai-strategy">Google&#x27;s AI Strategy<a href="#googles-ai-strategy" class="hash-link" aria-label="Direct link to Google&#x27;s AI Strategy" title="Direct link to Google&#x27;s AI Strategy" translate="no">​</a></h3>
<p>The DeepMind acquisition was part of Google&#x27;s &quot;AI first&quot; strategy:</p>
<table><thead><tr><th>Year</th><th>Event</th></tr></thead><tbody><tr><td>2011</td><td>Founded Google Brain</td></tr><tr><td>2013</td><td>Acquired DNNresearch (Hinton&#x27;s team)</td></tr><tr><td>2014</td><td>Acquired DeepMind</td></tr><tr><td>2015</td><td>TensorFlow open-sourced</td></tr><tr><td>2016</td><td>TPU announced</td></tr></tbody></table>
<p>Google realized: search, advertising, translation, voice—all core businesses would be reshaped by AI. Whoever has the best AI wins.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="choosing-go-as-the-target">Choosing Go as the Target<a href="#choosing-go-as-the-target" class="hash-link" aria-label="Direct link to Choosing Go as the Target" title="Direct link to Choosing Go as the Target" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="why-go">Why Go?<a href="#why-go" class="hash-link" aria-label="Direct link to Why Go?" title="Direct link to Why Go?" translate="no">​</a></h3>
<p>After being acquired by Google, DeepMind had more resources. Hassabis decided to tackle a seemingly impossible goal: <strong>use AI to defeat the human Go champion</strong>.</p>
<p>Why choose Go, not other problems?</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-go-is-the-holy-grail-of-ai">1. Go Is the &quot;Holy Grail of AI&quot;<a href="#1-go-is-the-holy-grail-of-ai" class="hash-link" aria-label="Direct link to 1. Go Is the &quot;Holy Grail of AI&quot;" title="Direct link to 1. Go Is the &quot;Holy Grail of AI&quot;" translate="no">​</a></h4>
<p>Before 2016, experts generally believed AI would need at least 10-20 years to defeat humans at Go. Go was called &quot;AI&#x27;s last bastion.&quot;</p>
<p>Reasons:</p>
<ul>
<li class=""><strong>Enormous search space</strong>: 10^170 possible board positions (the number of atoms in the universe is only 10^80)</li>
<li class=""><strong>Difficult evaluation</strong>: Unlike chess, there are no clear piece values</li>
<li class=""><strong>Intuition dependence</strong>: Top players often say &quot;this move feels right&quot; without being able to explain why</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-the-deep-blue-revelation">2. The Deep Blue Revelation<a href="#2-the-deep-blue-revelation" class="hash-link" aria-label="Direct link to 2. The Deep Blue Revelation" title="Direct link to 2. The Deep Blue Revelation" translate="no">​</a></h4>
<p>In 1997, IBM&#x27;s Deep Blue defeated world chess champion Kasparov. But this victory was controversial:</p>
<ul>
<li class="">Deep Blue relied on <strong>brute-force search</strong> (evaluating 200 million positions per second)</li>
<li class="">Used <strong>evaluation functions designed by human experts</strong></li>
<li class="">This was not true &quot;intelligence,&quot; but &quot;computational power&quot;</li>
</ul>
<p>Hassabis wanted to prove: AI can solve problems through <strong>learning</strong> rather than brute-force search.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-measurable-objective">3. Measurable Objective<a href="#3-measurable-objective" class="hash-link" aria-label="Direct link to 3. Measurable Objective" title="Direct link to 3. Measurable Objective" translate="no">​</a></h4>
<p>Go has an international ranking system (Elo rating) and professional players, providing objective measurement standards. If AI can defeat the world champion, it&#x27;s an indisputable success.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="4-connection-to-neuroscience">4. Connection to Neuroscience<a href="#4-connection-to-neuroscience" class="hash-link" aria-label="Direct link to 4. Connection to Neuroscience" title="Direct link to 4. Connection to Neuroscience" translate="no">​</a></h4>
<p>Human players&#x27; intuition—knowing which positions are important at a glance—is exactly the ability Hassabis wanted AI to replicate. Go is the perfect scenario for testing &quot;machine intuition.&quot;</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="the-alphago-team">The AlphaGo Team<a href="#the-alphago-team" class="hash-link" aria-label="Direct link to The AlphaGo Team" title="Direct link to The AlphaGo Team" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="key-figures">Key Figures<a href="#key-figures" class="hash-link" aria-label="Direct link to Key Figures" title="Direct link to Key Figures" translate="no">​</a></h3>
<p>AlphaGo&#x27;s success came from a multidisciplinary team:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="david-silver-lead-researcher">David Silver: Lead Researcher<a href="#david-silver-lead-researcher" class="hash-link" aria-label="Direct link to David Silver: Lead Researcher" title="Direct link to David Silver: Lead Researcher" translate="no">​</a></h4>
<p><strong>David Silver</strong> is the first author of the AlphaGo paper and a top expert in reinforcement learning.</p>
<ul>
<li class=""><strong>Background</strong>: Cambridge mathematics graduate, Alberta RL PhD</li>
<li class=""><strong>Advisor</strong>: Richard Sutton (father of reinforcement learning)</li>
<li class=""><strong>Expertise</strong>: Monte Carlo Tree Search, temporal difference learning</li>
</ul>
<p>Silver had researched computer Go in his doctoral thesis, but the technology was far from mature at the time. After joining DeepMind, he finally had the opportunity to realize this dream.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="aja-huang-go-expert">Aja Huang: Go Expert<a href="#aja-huang-go-expert" class="hash-link" aria-label="Direct link to Aja Huang: Go Expert" title="Direct link to Aja Huang: Go Expert" translate="no">​</a></h4>
<p><strong>Aja Huang</strong> is from Taiwan, an amateur 6-dan player, and a pioneer in computer Go.</p>
<ul>
<li class=""><strong>Background</strong>: PhD in Computer Science from National Taiwan Normal University</li>
<li class=""><strong>Expertise</strong>: Computer Go programming</li>
<li class=""><strong>Notable work</strong>: Erica (early computer Go program)</li>
</ul>
<p>Huang played a key role in the AlphaGo team: he understood both Go and AI. In the matches against Lee Sedol, he was the person actually operating AlphaGo.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="other-key-members">Other Key Members<a href="#other-key-members" class="hash-link" aria-label="Direct link to Other Key Members" title="Direct link to Other Key Members" translate="no">​</a></h4>
<table><thead><tr><th>Member</th><th>Role</th></tr></thead><tbody><tr><td>Chris J. Maddison</td><td>Monte Carlo Tree Search expert</td></tr><tr><td>Arthur Guez</td><td>Reinforcement learning researcher</td></tr><tr><td>Laurent Sifre</td><td>Deep learning engineer</td></tr><tr><td>George van den Driessche</td><td>Distributed systems engineer</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="cross-disciplinary-collaboration">Cross-disciplinary Collaboration<a href="#cross-disciplinary-collaboration" class="hash-link" aria-label="Direct link to Cross-disciplinary Collaboration" title="Direct link to Cross-disciplinary Collaboration" translate="no">​</a></h3>
<p>AlphaGo&#x27;s success proved the power of <strong>cross-disciplinary collaboration</strong>:</p>
<ul>
<li class=""><strong>Go experts</strong> provided domain knowledge</li>
<li class=""><strong>Machine learning researchers</strong> designed algorithms</li>
<li class=""><strong>Engineers</strong> implemented large-scale training systems</li>
<li class=""><strong>Neuroscientists</strong> provided theoretical inspiration</li>
</ul>
<p>This team composition later became DeepMind&#x27;s standard model.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="nature-paper-publication">Nature Paper Publication<a href="#nature-paper-publication" class="hash-link" aria-label="Direct link to Nature Paper Publication" title="Direct link to Nature Paper Publication" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="a-secret-surprise">A Secret Surprise<a href="#a-secret-surprise" class="hash-link" aria-label="Direct link to A Secret Surprise" title="Direct link to A Secret Surprise" translate="no">​</a></h3>
<p>On January 27, 2016, DeepMind published a paper in the top academic journal <em>Nature</em>:</p>
<blockquote>
<p><strong>&quot;Mastering the game of Go with deep neural networks and tree search&quot;</strong></p>
</blockquote>
<p>The paper announced that AlphaGo had:</p>
<ol>
<li class="">Defeated all other Go programs</li>
<li class="">Defeated European champion <strong>Fan Hui</strong> (professional 2-dan) <strong>5:0</strong></li>
</ol>
<p>This news stunned the world. Before the paper&#x27;s publication, no one knew DeepMind was researching Go.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="core-contributions-of-the-paper">Core Contributions of the Paper<a href="#core-contributions-of-the-paper" class="hash-link" aria-label="Direct link to Core Contributions of the Paper" title="Direct link to Core Contributions of the Paper" translate="no">​</a></h3>
<p>The <em>Nature</em> paper described AlphaGo&#x27;s three major innovations:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-policy-network">1. Policy Network<a href="#1-policy-network" class="hash-link" aria-label="Direct link to 1. Policy Network" title="Direct link to 1. Policy Network" translate="no">​</a></h4>
<p>A deep convolutional neural network to predict human players&#x27; next moves. Training data came from <strong>30 million games</strong> of human game records.</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Accuracy: 57% (predicting human expert&#x27;s next move)</span><br></span></code></pre></div></div>
<p>This was more than 10 percentage points higher than the best previous computer Go programs.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-value-network">2. Value Network<a href="#2-value-network" class="hash-link" aria-label="Direct link to 2. Value Network" title="Direct link to 2. Value Network" translate="no">​</a></h4>
<p>Another neural network to evaluate the win probability of the current position. This replaced traditional random simulations (Monte Carlo rollout).</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Precision: Equivalent to 15,000 random simulations, but 15,000 times faster</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-monte-carlo-tree-search-integration">3. Monte Carlo Tree Search Integration<a href="#3-monte-carlo-tree-search-integration" class="hash-link" aria-label="Direct link to 3. Monte Carlo Tree Search Integration" title="Direct link to 3. Monte Carlo Tree Search Integration" translate="no">​</a></h4>
<p>Integrating both neural networks into the MCTS framework:</p>
<ul>
<li class="">Policy Network guides search direction</li>
<li class="">Value Network evaluates leaf nodes</li>
</ul>
<p>This gave AlphaGo both &quot;intuition&quot; (neural networks) and &quot;reasoning&quot; (tree search).</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="academic-response">Academic Response<a href="#academic-response" class="hash-link" aria-label="Direct link to Academic Response" title="Direct link to Academic Response" translate="no">​</a></h3>
<p>After the paper&#x27;s publication, the academic community responded enthusiastically:</p>
<blockquote>
<p>&quot;This is AI&#x27;s moonshot moment.&quot;
— <strong>Stuart Russell</strong>, UC Berkeley professor, AI textbook author</p>
</blockquote>
<blockquote>
<p>&quot;I originally thought it would take another 10 years, didn&#x27;t expect it so soon.&quot;
— <strong>Martin Muller</strong>, computer Go expert</p>
</blockquote>
<p>But some were skeptical:</p>
<blockquote>
<p>&quot;Fan Hui is only professional 2-dan, not a true top player. Let AlphaGo play Lee Sedol and we&#x27;ll see.&quot;</p>
</blockquote>
<p>DeepMind accepted this challenge.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="challenging-lee-sedol">Challenging Lee Sedol<a href="#challenging-lee-sedol" class="hash-link" aria-label="Direct link to Challenging Lee Sedol" title="Direct link to Challenging Lee Sedol" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="why-lee-sedol">Why Lee Sedol?<a href="#why-lee-sedol" class="hash-link" aria-label="Direct link to Why Lee Sedol?" title="Direct link to Why Lee Sedol?" translate="no">​</a></h3>
<p><strong>Lee Sedol</strong> is a Korean player, considered one of the strongest players of the past decade:</p>
<table><thead><tr><th>Metric</th><th>Data</th></tr></thead><tbody><tr><td>World championship titles</td><td>18</td></tr><tr><td>International tournament wins</td><td>32</td></tr><tr><td>Highest world ranking</td><td>#1</td></tr><tr><td>Style</td><td>&quot;Genius&quot; &quot;Divine calculator&quot;</td></tr></tbody></table>
<p>By choosing Lee Sedol, DeepMind was challenging the strongest human opponent.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="1-million-prize">$1 Million Prize<a href="#1-million-prize" class="hash-link" aria-label="Direct link to $1 Million Prize" title="Direct link to $1 Million Prize" translate="no">​</a></h3>
<p>Google provided a <strong>$1 million</strong> prize for this match:</p>
<ul>
<li class="">If Lee Sedol wins: Prize goes to Lee Sedol</li>
<li class="">If AlphaGo wins: Prize donated to UNICEF, STEM education, and other charities</li>
</ul>
<p>This was not just a technology demonstration, but a globally watched sporting event.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="pre-match-predictions">Pre-match Predictions<a href="#pre-match-predictions" class="hash-link" aria-label="Direct link to Pre-match Predictions" title="Direct link to Pre-match Predictions" translate="no">​</a></h3>
<p>Before the match, most professional players predicted Lee Sedol would win easily:</p>
<blockquote>
<p>&quot;AlphaGo might win one game, but in a 5-game match I&#x27;ll win 5:0.&quot;
— <strong>Lee Sedol</strong>, pre-match interview</p>
</blockquote>
<blockquote>
<p>&quot;Computers play rigidly, top players can easily find weaknesses.&quot;
— A professional 9-dan</p>
</blockquote>
<p>But the DeepMind team had a different view. David Silver later revealed:</p>
<blockquote>
<p>&quot;In internal testing, we had the new AlphaGo play 500 games against the version that played Fan Hui. The new version won 499 games.&quot;</p>
</blockquote>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="march-2016-five-games-that-changed-the-world">March 2016: Five Games That Changed the World<a href="#march-2016-five-games-that-changed-the-world" class="hash-link" aria-label="Direct link to March 2016: Five Games That Changed the World" title="Direct link to March 2016: Five Games That Changed the World" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="game-1-the-shock-begins">Game 1: The Shock Begins<a href="#game-1-the-shock-begins" class="hash-link" aria-label="Direct link to Game 1: The Shock Begins" title="Direct link to Game 1: The Shock Begins" translate="no">​</a></h3>
<p>March 9, 2016, Four Seasons Hotel, Seoul.</p>
<p>Lee Sedol played black (first move), AlphaGo played white. After 3 hours and 28 minutes of play, AlphaGo won by resignation.</p>
<p>This was the first time a top human player officially lost to AI.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="game-2-the-divine-move">Game 2: The Divine Move<a href="#game-2-the-divine-move" class="hash-link" aria-label="Direct link to Game 2: The Divine Move" title="Direct link to Game 2: The Divine Move" translate="no">​</a></h3>
<p>Game 2 produced what became known as &quot;<strong>Move 37</strong>&quot;—AlphaGo played a shoulder hit on the fifth line that all professional players thought was a mistake, but proved to be the key to victory.</p>
<p>(See next article: <a class="" href="/en/docs/for-engineers/how-it-works/alphago-explained/move-37/">In-Depth Analysis of &quot;Move 37&quot;</a>)</p>
<p>AlphaGo won again.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="game-3-3-0">Game 3: 3-0<a href="#game-3-3-0" class="hash-link" aria-label="Direct link to Game 3: 3-0" title="Direct link to Game 3: 3-0" translate="no">​</a></h3>
<p>In Game 3, Lee Sedol tried an unconventional opening, but AlphaGo responded calmly. 3:0.</p>
<p>The world began to realize: this was not a fluke, AI had truly surpassed humans.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="game-4-humanity-strikes-back">Game 4: Humanity Strikes Back<a href="#game-4-humanity-strikes-back" class="hash-link" aria-label="Direct link to Game 4: Humanity Strikes Back" title="Direct link to Game 4: Humanity Strikes Back" translate="no">​</a></h3>
<p>In Game 4, Lee Sedol played what became known as his &quot;<strong>Divine Move</strong>&quot;—Move 78, a brilliant wedge that caused AlphaGo to malfunction.</p>
<p>AlphaGo played several obviously bad moves in the following sequence and eventually resigned.</p>
<p>This victory proved: AI also has weaknesses. Lee Sedol found it.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="game-5-final-score">Game 5: Final Score<a href="#game-5-final-score" class="hash-link" aria-label="Direct link to Game 5: Final Score" title="Direct link to Game 5: Final Score" translate="no">​</a></h3>
<p>In Game 5, AlphaGo recovered and ended the match with a resignation victory.</p>
<p><strong>Final score: AlphaGo 4:1 Lee Sedol</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="impact-and-aftermath">Impact and Aftermath<a href="#impact-and-aftermath" class="hash-link" aria-label="Direct link to Impact and Aftermath" title="Direct link to Impact and Aftermath" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="global-attention">Global Attention<a href="#global-attention" class="hash-link" aria-label="Direct link to Global Attention" title="Direct link to Global Attention" translate="no">​</a></h3>
<p>The impact of this match extended far beyond the Go community:</p>
<ul>
<li class=""><strong>200 million people worldwide</strong> watched the live broadcast</li>
<li class=""><em>The New York Times</em>, <em>The Economist</em>, and other mainstream media provided extensive coverage</li>
<li class="">Google&#x27;s stock price rose during the match</li>
<li class="">&quot;Artificial intelligence&quot; became the hottest tech topic of the year</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="impact-on-the-go-community">Impact on the Go Community<a href="#impact-on-the-go-community" class="hash-link" aria-label="Direct link to Impact on the Go Community" title="Direct link to Impact on the Go Community" translate="no">​</a></h3>
<p>After the match, professional players&#x27; attitudes shifted from &quot;dismissive&quot; to &quot;reverent&quot;:</p>
<blockquote>
<p>&quot;We used to think humans understood Go, now we realize we only know a little.&quot;
— <strong>Ke Jie</strong>, Chinese player, world #1 at the time</p>
</blockquote>
<p>Many professional players began using AI to train, and Go playing styles changed as a result.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="impact-on-the-ai-field">Impact on the AI Field<a href="#impact-on-the-ai-field" class="hash-link" aria-label="Direct link to Impact on the AI Field" title="Direct link to Impact on the AI Field" translate="no">​</a></h3>
<p>AlphaGo proved several things:</p>
<ol>
<li class=""><strong>Deep learning can solve expert-level problems</strong>: Not just recognizing cats and dogs, but playing Go</li>
<li class=""><strong>Reinforcement learning can surpass humans</strong>: Through self-play, AI can discover strategies unknown to humans</li>
<li class=""><strong>Neural networks + search is a powerful combination</strong>: Intuition + reasoning = stronger intelligence</li>
</ol>
<p>These insights were later applied to:</p>
<ul>
<li class=""><strong>AlphaFold</strong>: Protein structure prediction (Nobel Prize-level achievement in 2020)</li>
<li class=""><strong>AlphaZero</strong>: General game AI</li>
<li class=""><strong>MuZero</strong>: Learning without rules</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="animation-references">Animation References<a href="#animation-references" class="hash-link" aria-label="Direct link to Animation References" title="Direct link to Animation References" translate="no">​</a></h2>
<p>Core concepts covered in this article and their animation numbers:</p>
<table><thead><tr><th>Number</th><th>Concept</th><th>Physics/Math Correspondence</th></tr></thead><tbody><tr><td>E7</td><td>From Scratch</td><td>Self-organization</td></tr><tr><td>E5</td><td>Self-Play</td><td>Fixed-point convergence</td></tr><tr><td>F8</td><td>Emergent Abilities</td><td>Phase transition</td></tr><tr><td>H4</td><td>Policy Gradient</td><td>Stochastic optimization</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="further-reading">Further Reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">​</a></h2>
<ul>
<li class=""><strong>Next Article</strong>: <a class="" href="/en/docs/for-engineers/how-it-works/alphago-explained/key-matches/">Key Matches Review</a> — Complete analysis of matches with Fan Hui, Lee Sedol, Ke Jie</li>
<li class=""><strong>Technical Details</strong>: <a class="" href="/en/docs/for-engineers/how-it-works/alphago-explained/policy-network/">Policy Network Explained</a> — How AlphaGo learned to play Go</li>
<li class=""><strong>Hands-on Practice</strong>: <a class="" href="/en/docs/for-engineers/hands-on/">Run Your First Go AI in 30 Minutes</a> — Experience it yourself</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2016). &quot;Mastering the game of Go with deep neural networks and tree search.&quot; <em>Nature</em>, 529, 484-489.</li>
<li class="">Mnih, V., et al. (2015). &quot;Human-level control through deep reinforcement learning.&quot; <em>Nature</em>, 518, 529-533.</li>
<li class="">Hassabis, D. (2017). &quot;Artificial Intelligence: Chess match of the century.&quot; <em>Nature</em>, 544, 413-414.</li>
<li class=""><em>AlphaGo</em> documentary (2017), directed by Greg Kohs.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/01-birth-of-alphago.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/docs/for-engineers/how-it-works/alphago-explained/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">AlphaGo In-Depth</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Key Matches Review</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-founding-of-deepmind" class="table-of-contents__link toc-highlight">The Founding of DeepMind</a><ul><li><a href="#demis-hassabis-from-prodigy-to-ai-pioneer" class="table-of-contents__link toc-highlight">Demis Hassabis: From Prodigy to AI Pioneer</a></li><li><a href="#co-founders" class="table-of-contents__link toc-highlight">Co-founders</a></li><li><a href="#solve-intelligence-then-use-it-to-solve-everything-else" class="table-of-contents__link toc-highlight">&quot;Solve Intelligence, Then Use It to Solve Everything Else&quot;</a></li></ul></li><li><a href="#early-breakthrough-atari-games" class="table-of-contents__link toc-highlight">Early Breakthrough: Atari Games</a><ul><li><a href="#dqn-ai-that-learned-to-play-games" class="table-of-contents__link toc-highlight">DQN: AI That Learned to Play Games</a></li><li><a href="#why-start-with-games" class="table-of-contents__link toc-highlight">Why Start with Games?</a></li></ul></li><li><a href="#googles-acquisition" class="table-of-contents__link toc-highlight">Google&#39;s Acquisition</a><ul><li><a href="#a-500-million-bet" class="table-of-contents__link toc-highlight">A $500 Million Bet</a></li><li><a href="#acquisition-conditions" class="table-of-contents__link toc-highlight">Acquisition Conditions</a></li><li><a href="#googles-ai-strategy" class="table-of-contents__link toc-highlight">Google&#39;s AI Strategy</a></li></ul></li><li><a href="#choosing-go-as-the-target" class="table-of-contents__link toc-highlight">Choosing Go as the Target</a><ul><li><a href="#why-go" class="table-of-contents__link toc-highlight">Why Go?</a></li></ul></li><li><a href="#the-alphago-team" class="table-of-contents__link toc-highlight">The AlphaGo Team</a><ul><li><a href="#key-figures" class="table-of-contents__link toc-highlight">Key Figures</a></li><li><a href="#cross-disciplinary-collaboration" class="table-of-contents__link toc-highlight">Cross-disciplinary Collaboration</a></li></ul></li><li><a href="#nature-paper-publication" class="table-of-contents__link toc-highlight">Nature Paper Publication</a><ul><li><a href="#a-secret-surprise" class="table-of-contents__link toc-highlight">A Secret Surprise</a></li><li><a href="#core-contributions-of-the-paper" class="table-of-contents__link toc-highlight">Core Contributions of the Paper</a></li><li><a href="#academic-response" class="table-of-contents__link toc-highlight">Academic Response</a></li></ul></li><li><a href="#challenging-lee-sedol" class="table-of-contents__link toc-highlight">Challenging Lee Sedol</a><ul><li><a href="#why-lee-sedol" class="table-of-contents__link toc-highlight">Why Lee Sedol?</a></li><li><a href="#1-million-prize" class="table-of-contents__link toc-highlight">$1 Million Prize</a></li><li><a href="#pre-match-predictions" class="table-of-contents__link toc-highlight">Pre-match Predictions</a></li></ul></li><li><a href="#march-2016-five-games-that-changed-the-world" class="table-of-contents__link toc-highlight">March 2016: Five Games That Changed the World</a><ul><li><a href="#game-1-the-shock-begins" class="table-of-contents__link toc-highlight">Game 1: The Shock Begins</a></li><li><a href="#game-2-the-divine-move" class="table-of-contents__link toc-highlight">Game 2: The Divine Move</a></li><li><a href="#game-3-3-0" class="table-of-contents__link toc-highlight">Game 3: 3-0</a></li><li><a href="#game-4-humanity-strikes-back" class="table-of-contents__link toc-highlight">Game 4: Humanity Strikes Back</a></li><li><a href="#game-5-final-score" class="table-of-contents__link toc-highlight">Game 5: Final Score</a></li></ul></li><li><a href="#impact-and-aftermath" class="table-of-contents__link toc-highlight">Impact and Aftermath</a><ul><li><a href="#global-attention" class="table-of-contents__link toc-highlight">Global Attention</a></li><li><a href="#impact-on-the-go-community" class="table-of-contents__link toc-highlight">Impact on the Go Community</a></li><li><a href="#impact-on-the-ai-field" class="table-of-contents__link toc-highlight">Impact on the AI Field</a></li></ul></li><li><a href="#animation-references" class="table-of-contents__link toc-highlight">Animation References</a></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further Reading</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>