<!doctype html>
<html lang="ar" dir="rtl" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-for-engineers/how-it-works/alphago-explained/alphago-zero" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">نظرة عامة على AlphaGo Zero | 好棋寶寶協會 | Weiqi.Kids</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.weiqi.kids/ar/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://www.weiqi.kids/ar/img/social-card.png"><meta data-rh="true" property="og:url" content="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><meta data-rh="true" property="og:locale" content="ar"><meta data-rh="true" property="og:locale:alternate" content="zh_tw"><meta data-rh="true" property="og:locale:alternate" content="zh_cn"><meta data-rh="true" property="og:locale:alternate" content="zh_hk"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" property="og:locale:alternate" content="ja"><meta data-rh="true" property="og:locale:alternate" content="ko"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" property="og:locale:alternate" content="pt"><meta data-rh="true" property="og:locale:alternate" content="hi"><meta data-rh="true" property="og:locale:alternate" content="id"><meta data-rh="true" name="docusaurus_locale" content="ar"><meta data-rh="true" name="docsearch:language" content="ar"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="نظرة عامة على AlphaGo Zero | 好棋寶寶協會 | Weiqi.Kids"><meta data-rh="true" name="description" content="البداية من الصفر، التعلم الذاتي الكامل - كيف تجاوز AlphaGo Zero جميع الإصدارات السابقة بدون سجلات بشرية"><meta data-rh="true" property="og:description" content="البداية من الصفر، التعلم الذاتي الكامل - كيف تجاوز AlphaGo Zero جميع الإصدارات السابقة بدون سجلات بشرية"><meta data-rh="true" name="keywords" content="AlphaGo Zero,اللعب الذاتي,التعلم المعزز,التعلم العميق,ذكاء الغو الاصطناعي,التعلم غير الإشرافي"><link data-rh="true" rel="icon" href="/ar/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="zh-tw"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-cn/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/zh-hk/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="zh-hk"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/en/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ja/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="ja"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="ko"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/es/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="es"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/pt/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="pt"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/hi/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="hi"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/id/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="id"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="ar"><link data-rh="true" rel="alternate" href="https://www.weiqi.kids/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.weiqi.kids#organization","name":"台灣好棋寶寶協會","alternateName":"Taiwan Good Go Baby Association","url":"https://www.weiqi.kids","logo":{"@type":"ImageObject","url":"https://www.weiqi.kids/img/logo.svg","width":200,"height":200},"sameAs":["https://mastodon.weiqi.kids/","https://peertube.weiqi.kids/"],"contactPoint":{"@type":"ContactPoint","contactType":"customer service","url":"https://www.weiqi.kids/docs/aboutus"},"description":"推動圍棋文化與 AI 研究的台灣非營利組織"},{"@type":"WebSite","@id":"https://www.weiqi.kids#website","name":"好棋寶寶協會官網","url":"https://www.weiqi.kids","publisher":{"@id":"https://www.weiqi.kids#organization"},"inLanguage":["zh-TW","zh-CN","zh-HK","en","ja","ko","es","pt","hi","id","ar"],"potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.weiqi.kids/search?q={search_term_string}"},"query-input":"required name=search_term_string"}}]}</script><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"給工程師的圍棋 AI 指南","item":"https://www.weiqi.kids/ar/docs/for-engineers/"},{"@type":"ListItem","position":2,"name":"一篇文章搞懂圍棋 AI","item":"https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/"},{"@type":"ListItem","position":3,"name":"AlphaGo 完整解析","item":"https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/"},{"@type":"ListItem","position":4,"name":"نظرة عامة على AlphaGo Zero","item":"https://www.weiqi.kids/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero"}]}</script><meta property="og:type" content="website">
<meta property="og:site_name" content="好棋寶寶協會">
<meta name="twitter:card" content="summary_large_image">
<meta name="robots" content="index, follow">
<meta name="author" content="台灣好棋寶寶協會">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/ar/assets/css/styles.fac9ec51.css">
<script src="/ar/assets/js/runtime~main.18fbb87e.js" defer="defer"></script>
<script src="/ar/assets/js/main.aa5269b2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>document.documentElement.setAttribute("data-theme","light"),document.documentElement.setAttribute("data-theme-choice","light"),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ar/img/logo.svg"><div role="region" aria-label="انتقل إلى المحتوى الرئيسي"><a class="skipToContent_WWLT" href="#__docusaurus_skipToContent_fallback">انتقل إلى المحتوى الرئيسي</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ar/"><div class="navbar__logo"><img src="/ar/img/logo.svg" alt="شعار جمعية ويكي كيدز" class="themedComponent_rBb5 themedComponent--light_t3c2"><img src="/ar/img/logo.svg" alt="شعار جمعية ويكي كيدز" class="themedComponent_rBb5 themedComponent--dark_Z76H"></div><b class="navbar__title text--truncate">ويكي كيدز</b></a><a class="navbar__item navbar__link" href="/ar/docs/for-players/">للاعبين</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ar/docs/for-engineers/">للمهندسين</a><a class="navbar__item navbar__link" href="/ar/docs/about/">من نحن</a><a class="navbar__item navbar__link" href="/ar/docs/activities/">الأنشطة</a><a class="navbar__item navbar__link" href="/ar/docs/references/">المراجع</a><a class="navbar__item navbar__link" href="/ar/docs/sop/">الإجراءات القياسية</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link navbar__item--compact"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_LXmZ"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>العربية</a><ul class="dropdown__menu"><li><a href="/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-tw">繁體中文</a></li><li><a href="/zh-cn/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-cn">简体中文</a></li><li><a href="/zh-hk/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-hk">粵語（香港）</a></li><li><a href="/en/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/ja/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ja">日本語</a></li><li><a href="/ko/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ko">한국어</a></li><li><a href="/es/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="es">Español</a></li><li><a href="/pt/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="pt">Português</a></li><li><a href="/hi/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="hi">हिन्दी</a></li><li><a href="/id/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="id">Bahasa Indonesia</a></li><li><a href="/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ar">العربية</a></li></ul></div><a href="https://github.com/weiqi-kids/www.weiqi.kids" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link navbar__item--compact" aria-label="GitHub"></a><div class="navbarSearchContainer_MDM0"><div class="navbar__search searchBarContainer_Qpyg" dir="ltr"><input placeholder="بحث..." aria-label="Search" class="navbar__search-input searchInput_KBva" value=""><div class="loadingRing_riNO searchBarLoadingRing_XquT"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_SQvo"><div class="docsWrapper_HjTU"><button aria-label="أنتقل للأعلى" class="clean-btn theme-back-to-top-button backToTopButton_91RE" type="button"></button><div class="docRoot_SzOB"><aside class="theme-doc-sidebar-container docSidebarContainer_Q0cb"><div class="sidebarViewport_TEb6"><div class="sidebar_LiQ3"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_iDgU"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ar/docs/intro/"><span title="دليل الاستخدام" class="linkLabel_REp1">دليل الاستخدام</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ar/docs/about/"><span title="關於協會" class="categoryLinkLabel_ezQx">關於協會</span></a><button aria-label="Expand sidebar category &#x27;關於協會&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ar/docs/activities/"><span title="活動實績" class="categoryLinkLabel_ezQx">活動實績</span></a><button aria-label="Expand sidebar category &#x27;活動實績&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ar/docs/for-players/"><span title="للاعبي Go" class="categoryLinkLabel_ezQx">للاعبي Go</span></a><button aria-label="Expand sidebar category &#x27;للاعبي Go&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ar/docs/references/"><span title="參考資料" class="categoryLinkLabel_ezQx">參考資料</span></a><button aria-label="Expand sidebar category &#x27;參考資料&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" href="/ar/docs/sop/"><span title="標準作業流程" class="categoryLinkLabel_ezQx">標準作業流程</span></a><button aria-label="Expand sidebar category &#x27;標準作業流程&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" href="/ar/docs/for-engineers/"><span title="給工程師的圍棋 AI 指南" class="categoryLinkLabel_ezQx">給工程師的圍棋 AI 指南</span></a><button aria-label="Collapse sidebar category &#x27;給工程師的圍棋 AI 指南&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ar/docs/for-engineers/deep-dive/"><span title="للباحثين المتعمقين" class="categoryLinkLabel_ezQx">للباحثين المتعمقين</span></a><button aria-label="Expand sidebar category &#x27;للباحثين المتعمقين&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ar/docs/for-engineers/hands-on/"><span title="30 分鐘跑起第一個圍棋 AI" class="categoryLinkLabel_ezQx">30 分鐘跑起第一個圍棋 AI</span></a><button aria-label="Expand sidebar category &#x27;30 分鐘跑起第一個圍棋 AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ar/docs/for-engineers/how-it-works/"><span title="一篇文章搞懂圍棋 AI" class="categoryLinkLabel_ezQx">一篇文章搞懂圍棋 AI</span></a><button aria-label="Collapse sidebar category &#x27;一篇文章搞懂圍棋 AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/"><span title="AlphaGo 完整解析" class="categoryLinkLabel_ezQx">AlphaGo 完整解析</span></a><button aria-label="Collapse sidebar category &#x27;AlphaGo 完整解析&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/birth-of-alphago/"><span title="ولادة AlphaGo" class="linkLabel_REp1">ولادة AlphaGo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/key-matches/"><span title="استعراض المباريات الرئيسية" class="linkLabel_REp1">استعراض المباريات الرئيسية</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/move-37/"><span title="تحليل معمّق لـ &quot;الحركة الإلهية&quot;" class="linkLabel_REp1">تحليل معمّق لـ &quot;الحركة الإلهية&quot;</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/why-go-is-hard/"><span title="لماذا الغو صعب؟" class="linkLabel_REp1">لماذا الغو صعب؟</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/traditional-limits/"><span title="حدود الأساليب التقليدية" class="linkLabel_REp1">حدود الأساليب التقليدية</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/board-representation/"><span title="تمثيل حالة اللوحة" class="linkLabel_REp1">تمثيل حالة اللوحة</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/policy-network/"><span title="شرح مفصل لشبكة Policy" class="linkLabel_REp1">شرح مفصل لشبكة Policy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/value-network/"><span title="شرح مفصل لشبكة Value" class="linkLabel_REp1">شرح مفصل لشبكة Value</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/input-features/"><span title="تصميم ميزات المدخلات" class="linkLabel_REp1">تصميم ميزات المدخلات</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/cnn-and-go/"><span title="الشبكات العصبية الالتفافية ولعبة الجو" class="linkLabel_REp1">الشبكات العصبية الالتفافية ولعبة الجو</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/supervised-learning/"><span title="مرحلة التعلم الخاضع للإشراف" class="linkLabel_REp1">مرحلة التعلم الخاضع للإشراف</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/reinforcement-intro/"><span title="مقدمة في التعلم المعزز" class="linkLabel_REp1">مقدمة في التعلم المعزز</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/self-play/"><span title="اللعب الذاتي" class="linkLabel_REp1">اللعب الذاتي</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/mcts-neural-combo/"><span title="دمج MCTS مع الشبكات العصبية" class="linkLabel_REp1">دمج MCTS مع الشبكات العصبية</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><span title="شرح تفصيلي لمعادلة PUCT" class="linkLabel_REp1">شرح تفصيلي لمعادلة PUCT</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/alphago-zero/"><span title="نظرة عامة على AlphaGo Zero" class="linkLabel_REp1">نظرة عامة على AlphaGo Zero</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><span title="الشبكة مزدوجة الرأس وشبكة الباقي" class="linkLabel_REp1">الشبكة مزدوجة الرأس وشبكة الباقي</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/"><span title="عملية التدريب من الصفر" class="linkLabel_REp1">عملية التدريب من الصفر</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/distributed-systems/"><span title="الأنظمة الموزعة و TPU" class="linkLabel_REp1">الأنظمة الموزعة و TPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/alphago-explained/legacy-and-impact/"><span title="إرث AlphaGo" class="linkLabel_REp1">إرث AlphaGo</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/katago-innovations/"><span title="KataGo 的關鍵創新" class="linkLabel_REp1">KataGo 的關鍵創新</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ar/docs/for-engineers/how-it-works/concepts/"><span title="概念速查表" class="linkLabel_REp1">概念速查表</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ar/docs/for-engineers/industry/"><span title="圍棋 AI 產業現況" class="categoryLinkLabel_ezQx">圍棋 AI 產業現況</span></a><button aria-label="Expand sidebar category &#x27;圍棋 AI 產業現況&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_nItb menu__link menu__link--sublist" tabindex="0" href="/ar/docs/for-engineers/overview/"><span title="圍棋 AI 能做什麼？" class="categoryLinkLabel_ezQx">圍棋 AI 能做什麼？</span></a><button aria-label="Expand sidebar category &#x27;圍棋 AI 能做什麼？&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_C0wL"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_txwF"><div class="docItemContainer_FUEM"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_DlgT" aria-label="التنقل التفصيلي"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="الرئيسية" class="breadcrumbs__link" href="/ar/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_BMIH"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ar/docs/for-engineers/"><span>給工程師的圍棋 AI 指南</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ar/docs/for-engineers/how-it-works/"><span>一篇文章搞懂圍棋 AI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ar/docs/for-engineers/how-it-works/alphago-explained/"><span>AlphaGo 完整解析</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">نظرة عامة على AlphaGo Zero</span></li></ul></nav><div class="tocCollapsible_LBsY theme-doc-toc-mobile tocMobile_eMWB"><button type="button" class="clean-btn tocCollapsibleButton_fVBn">محتويات هذه الصفحة</button></div><div class="theme-doc-markdown markdown"><header><h1>نظرة عامة على AlphaGo Zero</h1></header>
<p>في أكتوبر 2017، نشرت DeepMind نتيجة أذهلت عالم الذكاء الاصطناعي: <strong>AlphaGo Zero</strong> بدأ التدريب من حالة عشوائية تماماً دون استخدام أي سجلات بشرية، وفي ثلاثة أيام فقط تجاوز AlphaGo الأصلي الذي هزم لي سيدول، وفاز بنتيجة <strong>100:0</strong>.</p>
<p>هذا ليس مجرد تقدم في الأرقام. إنه يمثل نموذجاً جديداً تماماً: <strong>الذكاء الاصطناعي لا يحتاج المعرفة البشرية، يمكنه اكتشاف كل شيء من الصفر</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="لماذا-لا-يحتاج-سجلات-بشرية">لماذا لا يحتاج سجلات بشرية؟<a href="#لماذا-لا-يحتاج-سجلات-بشرية" class="hash-link" aria-label="ارتباط مباشر بالعنوان لماذا لا يحتاج سجلات بشرية؟" title="ارتباط مباشر بالعنوان لماذا لا يحتاج سجلات بشرية؟" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="قيود-السجلات-البشرية">قيود السجلات البشرية<a href="#قيود-السجلات-البشرية" class="hash-link" aria-label="ارتباط مباشر بالعنوان قيود السجلات البشرية" title="ارتباط مباشر بالعنوان قيود السجلات البشرية" translate="no">​</a></h3>
<p>عملية تدريب AlphaGo الأصلي كانت على مرحلتين:</p>
<ol>
<li class=""><strong>التعلم الإشرافي</strong>: تدريب Policy Network باستخدام 30 مليون مباراة بشرية</li>
<li class=""><strong>التعلم المعزز</strong>: التحسين الإضافي من خلال اللعب الذاتي</li>
</ol>
<p>هذه الطريقة لها عدة مشاكل جوهرية:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-السجلات-البشرية-لها-سقف">1. السجلات البشرية لها سقف<a href="#1-السجلات-البشرية-لها-سقف" class="hash-link" aria-label="ارتباط مباشر بالعنوان 1. السجلات البشرية لها سقف" title="ارتباط مباشر بالعنوان 1. السجلات البشرية لها سقف" translate="no">​</a></h4>
<p>قوة لعب اللاعبين البشريين لها حدود، السجلات تحتوي على فهم البشر، وأيضاً أخطاء البشر وتحيزاتهم. عندما يتعلم الذكاء الاصطناعي من السجلات البشرية، فإنه يتعلم:</p>
<ul>
<li class="">الحركات التي يعتقد البشر أنها جيدة (لكنها ليست بالضرورة الأمثل)</li>
<li class="">أنماط تفكير البشر (لكنها قد تحد من الابتكار)</li>
<li class="">أخطاء البشر (يتم تعلمها كعينات صحيحة)</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-عنق-الزجاجة-في-التعلم-الإشرافي">2. عنق الزجاجة في التعلم الإشرافي<a href="#2-عنق-الزجاجة-في-التعلم-الإشرافي" class="hash-link" aria-label="ارتباط مباشر بالعنوان 2. عنق الزجاجة في التعلم الإشرافي" title="ارتباط مباشر بالعنوان 2. عنق الزجاجة في التعلم الإشرافي" translate="no">​</a></h4>
<p>هدف التعلم الإشرافي هو &quot;تقليد البشر&quot; — التنبؤ بالحركة التي سيلعبها اللاعب البشري. هذا يعني أن سقف قدرة الذكاء الاصطناعي محدود بقدرة اللاعبين البشريين.</p>
<p>تماماً كمتدرب يمكنه فقط تقليد أستاذه، ولا يستطيع أبداً تجاوز أستاذه.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-تكلفة-جمع-البيانات">3. تكلفة جمع البيانات<a href="#3-تكلفة-جمع-البيانات" class="hash-link" aria-label="ارتباط مباشر بالعنوان 3. تكلفة جمع البيانات" title="ارتباط مباشر بالعنوان 3. تكلفة جمع البيانات" translate="no">​</a></h4>
<p>السجلات البشرية عالية الجودة تحتاج سنوات عديدة للتراكم، وهي موجودة فقط في ألعاب ذات تاريخ طويل مثل الغو. إذا أردنا تطبيق الذكاء الاصطناعي على مجالات جديدة (مثل التنبؤ ببنية البروتينات)، فلا توجد &quot;سجلات خبراء بشريين&quot; للاستخدام.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="اختراق-zero">اختراق Zero<a href="#اختراق-zero" class="hash-link" aria-label="ارتباط مباشر بالعنوان اختراق Zero" title="ارتباط مباشر بالعنوان اختراق Zero" translate="no">​</a></h3>
<p>AlphaGo Zero تخطى مرحلة التعلم الإشرافي تماماً، وبدأ اللعب الذاتي مباشرة من <strong>تهيئة عشوائية</strong>. هذا حل جميع المشاكل المذكورة:</p>
<table><thead><tr><th>المشكلة</th><th>AlphaGo الأصلي</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>سقف المعرفة البشرية</td><td>محدود بجودة السجلات</td><td>لا يوجد هذا القيد</td></tr><tr><td>هدف التعلم</td><td>تقليد البشر</td><td>تعظيم نسبة الفوز</td></tr><tr><td>متطلبات البيانات</td><td>30 مليون سجل</td><td>0</td></tr><tr><td>قابلية التعميم</td><td>الغو فقط</td><td>قابل للتعميم على مجالات أخرى</td></tr></tbody></table>
<p>هذا تحول جذري في النموذج: من &quot;تعلم المعرفة البشرية&quot; إلى &quot;اكتشاف المعرفة من المبادئ الأولى&quot;.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="المقارنة-مع-alphago-الأصلي-1000">المقارنة مع AlphaGo الأصلي: 100:0<a href="#المقارنة-مع-alphago-الأصلي-1000" class="hash-link" aria-label="ارتباط مباشر بالعنوان المقارنة مع AlphaGo الأصلي: 100:0" title="ارتباط مباشر بالعنوان المقارنة مع AlphaGo الأصلي: 100:0" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="الفوز-الساحق">الفوز الساحق<a href="#الفوز-الساحق" class="hash-link" aria-label="ارتباط مباشر بالعنوان الفوز الساحق" title="ارتباط مباشر بالعنوان الفوز الساحق" translate="no">​</a></h3>
<p>جعلت DeepMind AlphaGo Zero المدرب يلعب ضد إصدارات مختلفة من AlphaGo:</p>
<table><thead><tr><th>الخصم</th><th>نتيجة AlphaGo Zero</th></tr></thead><tbody><tr><td>AlphaGo Fan (الإصدار الذي هزم فان هوي)</td><td>100:0</td></tr><tr><td>AlphaGo Lee (الإصدار الذي هزم لي سيدول)</td><td>100:0</td></tr><tr><td>AlphaGo Master (إصدار 60 انتصاراً متتالياً)</td><td>89:11</td></tr></tbody></table>
<p><strong>100:0</strong> — هذا يعني أنه في 100 مباراة، لم يستطع AlphaGo الأصلي الفوز ولو مباراة واحدة.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="موارد-أقل-قوة-أكبر">موارد أقل، قوة أكبر<a href="#موارد-أقل-قوة-أكبر" class="hash-link" aria-label="ارتباط مباشر بالعنوان موارد أقل، قوة أكبر" title="ارتباط مباشر بالعنوان موارد أقل، قوة أكبر" translate="no">​</a></h3>
<p>ليس فقط الفوز، AlphaGo Zero حقق قوة أكبر بموارد أقل:</p>
<table><thead><tr><th>المؤشر</th><th>AlphaGo Lee</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>وقت التدريب</td><td>عدة أشهر</td><td>40 يوماً (3 أيام لتجاوز AlphaGo Lee)</td></tr><tr><td>عدد المباريات التدريبية</td><td>30 مليون سجل بشري + لعب ذاتي</td><td>4.9 مليون لعب ذاتي</td></tr><tr><td>عدد TPUs (التدريب)</td><td>50+</td><td>4</td></tr><tr><td>عدد TPUs (الاستنتاج)</td><td>48</td><td>4</td></tr><tr><td>ميزات الإدخال</td><td>48 مستوى</td><td>17 مستوى</td></tr><tr><td>الشبكة العصبية</td><td>شبكتا SL + RL</td><td>شبكة مزدوجة الرأس واحدة</td></tr></tbody></table>
<p>هذا تحسين مذهل في الكفاءة: <strong>الموارد أقل بأكثر من 10 مرات، لكن قوة اللعب أعلى بكثير</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="لماذا-zero-أقوى">لماذا Zero أقوى؟<a href="#لماذا-zero-أقوى" class="hash-link" aria-label="ارتباط مباشر بالعنوان لماذا Zero أقوى؟" title="ارتباط مباشر بالعنوان لماذا Zero أقوى؟" translate="no">​</a></h3>
<p>يمكن فهم قوة AlphaGo Zero الأكبر من عدة زوايا:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-التعلم-بدون-تحيز">1. التعلم بدون تحيز<a href="#1-التعلم-بدون-تحيز" class="hash-link" aria-label="ارتباط مباشر بالعنوان 1. التعلم بدون تحيز" title="ارتباط مباشر بالعنوان 1. التعلم بدون تحيز" translate="no">​</a></h4>
<p>AlphaGo الأصلي تعلم من السجلات البشرية، وورث تحيزات البشر. على سبيل المثال، اللاعبون البشريون قد يبالغون في أهمية بعض الجوسيكي، أو يقيّمون بعض الأوضاع بشكل خاطئ.</p>
<p>AlphaGo Zero ليس لديه هذه الأعباء. بدأ من صفحة بيضاء، يتعلم فقط من خلال نتائج الفوز والخسارة ما هي الحركات الجيدة. هذا سمح له باكتشاف حركات لم يفكر فيها البشر أبداً.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-هدف-تعلم-متسق">2. هدف تعلم متسق<a href="#2-هدف-تعلم-متسق" class="hash-link" aria-label="ارتباط مباشر بالعنوان 2. هدف تعلم متسق" title="ارتباط مباشر بالعنوان 2. هدف تعلم متسق" translate="no">​</a></h4>
<p>تدريب AlphaGo الأصلي كان له هدفان مختلفان:</p>
<ul>
<li class="">التعلم الإشرافي: تعظيم دقة التنبؤ بحركات البشر</li>
<li class="">التعلم المعزز: تعظيم نسبة الفوز</li>
</ul>
<p>هذان الهدفان قد يتعارضان. AlphaGo Zero له هدف واحد فقط: <strong>تعظيم نسبة الفوز</strong>. هذا يجعل عملية التعلم أكثر اتساقاً وفعالية.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-بنية-أبسط">3. بنية أبسط<a href="#3-بنية-أبسط" class="hash-link" aria-label="ارتباط مباشر بالعنوان 3. بنية أبسط" title="ارتباط مباشر بالعنوان 3. بنية أبسط" translate="no">​</a></h4>
<p>AlphaGo الأصلي استخدم Policy Network و Value Network منفصلين. AlphaGo Zero يستخدم شبكة مزدوجة الرأس واحدة (انظر المقال التالي للتفاصيل)، مما يسمح بمشاركة تمثيل الميزات، ويحسن كفاءة التعلم.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="ميزات-الإدخال-المبسطة-من-48-إلى-17">ميزات الإدخال المبسطة: من 48 إلى 17<a href="#ميزات-الإدخال-المبسطة-من-48-إلى-17" class="hash-link" aria-label="ارتباط مباشر بالعنوان ميزات الإدخال المبسطة: من 48 إلى 17" title="ارتباط مباشر بالعنوان ميزات الإدخال المبسطة: من 48 إلى 17" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="48-مستوى-ميزات-في-alphago-الأصلي">48 مستوى ميزات في AlphaGo الأصلي<a href="#48-مستوى-ميزات-في-alphago-الأصلي" class="hash-link" aria-label="ارتباط مباشر بالعنوان 48 مستوى ميزات في AlphaGo الأصلي" title="ارتباط مباشر بالعنوان 48 مستوى ميزات في AlphaGo الأصلي" translate="no">​</a></h3>
<p>إدخال الشبكة العصبية في AlphaGo الأصلي كان يتضمن 48 مستوى ميزات 19x19، تشفر كمية كبيرة من الميزات المصممة بشرياً:</p>
<table><thead><tr><th>الفئة</th><th>عدد الميزات</th><th>المحتوى</th></tr></thead><tbody><tr><td>موقع الأحجار</td><td>3</td><td>أحجار سوداء، أحجار بيضاء، نقاط فارغة</td></tr><tr><td>الحريات</td><td>8</td><td>سلاسل بـ 1-8 حريات</td></tr><tr><td>الأسر</td><td>8</td><td>يمكن أسر 1-8 حجر</td></tr><tr><td>الكو</td><td>1</td><td>موقع الكو</td></tr><tr><td>المسافة من الحافة</td><td>4</td><td>من الخط الأول إلى الرابع</td></tr><tr><td>قانونية الحركة</td><td>1</td><td>أين يمكن اللعب</td></tr><tr><td>الحالة التاريخية</td><td>8</td><td>مواقع آخر 8 حركات</td></tr><tr><td>الدور</td><td>1</td><td>الأسود أو الأبيض</td></tr><tr><td>أخرى</td><td>14</td><td>المطاردة، العيون، إلخ</td></tr></tbody></table>
<p>هذه الـ 48 ميزة صممها خبراء الغو بعناية، تحتوي على كمية كبيرة من المعرفة المجالية.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="17-مستوى-ميزات-في-alphago-zero">17 مستوى ميزات في AlphaGo Zero<a href="#17-مستوى-ميزات-في-alphago-zero" class="hash-link" aria-label="ارتباط مباشر بالعنوان 17 مستوى ميزات في AlphaGo Zero" title="ارتباط مباشر بالعنوان 17 مستوى ميزات في AlphaGo Zero" translate="no">​</a></h3>
<p>AlphaGo Zero بسّط الإدخال بشكل كبير، يستخدم 17 مستوى ميزات فقط:</p>
<table><thead><tr><th>رقم المستوى</th><th>المحتوى</th><th>العدد</th></tr></thead><tbody><tr><td>1-8</td><td>موقع الأحجار السوداء (آخر 8 حركات)</td><td>8</td></tr><tr><td>9-16</td><td>موقع الأحجار البيضاء (آخر 8 حركات)</td><td>8</td></tr><tr><td>17</td><td>الدور الحالي (كلها 1 أو كلها 0)</td><td>1</td></tr></tbody></table>
<p>هذه الـ 17 ميزة تتضمن فقط:</p>
<ul>
<li class=""><strong>حالة اللوحة الحالية</strong>: كل موقع به حجر أسود، أبيض، أو فارغ</li>
<li class=""><strong>معلومات تاريخية</strong>: حالة اللوحة في آخر 8 حركات</li>
<li class=""><strong>معلومات الدور</strong>: دور من الآن</li>
</ul>
<p>لا حريات، لا حكم مطاردة، لا مسافة من الحافة — كل هذه &quot;المعرفة بالغو&quot; تُترك للشبكة العصبية لتتعلمها بنفسها.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="لماذا-التبسيط-جيد">لماذا التبسيط جيد؟<a href="#لماذا-التبسيط-جيد" class="hash-link" aria-label="ارتباط مباشر بالعنوان لماذا التبسيط جيد؟" title="ارتباط مباشر بالعنوان لماذا التبسيط جيد؟" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-ترك-الشبكة-تكتشف-الميزات-بنفسها">1. ترك الشبكة تكتشف الميزات بنفسها<a href="#1-ترك-الشبكة-تكتشف-الميزات-بنفسها" class="hash-link" aria-label="ارتباط مباشر بالعنوان 1. ترك الشبكة تكتشف الميزات بنفسها" title="ارتباط مباشر بالعنوان 1. ترك الشبكة تكتشف الميزات بنفسها" translate="no">​</a></h4>
<p>الميزات اليدوية المعقدة قد تفوّت معلومات مهمة، أو تشفّر افتراضات خاطئة. ترك الشبكة العصبية تتعلم من البيانات الخام، قد تكتشف تمثيلات ميزات أفضل.</p>
<p>في الواقع، AlphaGo Zero تعلم جميع الميزات التي صممها البشر (الحريات، المطاردة، إلخ)، وتعلم أيضاً بعض الأنماط التي لم يكن البشر واعين بها صراحة.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-قابلية-تعميم-أفضل">2. قابلية تعميم أفضل<a href="#2-قابلية-تعميم-أفضل" class="hash-link" aria-label="ارتباط مباشر بالعنوان 2. قابلية تعميم أفضل" title="ارتباط مباشر بالعنوان 2. قابلية تعميم أفضل" translate="no">​</a></h4>
<p>كثير من الـ 48 ميزة خاصة بالغو (مثل المطاردة، مسافة الحافة). الـ 17 ميزة المبسطة عامة — أي لعبة لوحة يمكن تشفيرها بطريقة مماثلة.</p>
<p>هذا وضع الأساس لـ <strong>AlphaZero</strong> اللاحق (ذكاء ألعاب عام).</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-تقليل-الأخطاء-البشرية">3. تقليل الأخطاء البشرية<a href="#3-تقليل-الأخطاء-البشرية" class="hash-link" aria-label="ارتباط مباشر بالعنوان 3. تقليل الأخطاء البشرية" title="ارتباط مباشر بالعنوان 3. تقليل الأخطاء البشرية" translate="no">​</a></h4>
<p>الميزات المصممة يدوياً قد تحتوي على تعريفات خاطئة أو غير كاملة. تبسيط الإدخال يزيل إمكانية هذه المشاكل.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="بنية-الشبكة-الواحدة">بنية الشبكة الواحدة<a href="#بنية-الشبكة-الواحدة" class="hash-link" aria-label="ارتباط مباشر بالعنوان بنية الشبكة الواحدة" title="ارتباط مباشر بالعنوان بنية الشبكة الواحدة" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="تصميم-الشبكتين-في-النسخة-الأصلية">تصميم الشبكتين في النسخة الأصلية<a href="#تصميم-الشبكتين-في-النسخة-الأصلية" class="hash-link" aria-label="ارتباط مباشر بالعنوان تصميم الشبكتين في النسخة الأصلية" title="ارتباط مباشر بالعنوان تصميم الشبكتين في النسخة الأصلية" translate="no">​</a></h3>
<p>AlphaGo الأصلي استخدم شبكتين عصبيتين مستقلتين:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">Policy Network:  الإدخال → CNN → احتمالية 19x19 للحركة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Value Network:   الإدخال → CNN → تقدير نسبة الفوز (-1 إلى 1)</span><br></span></code></pre></div></div>
<p>هاتان الشبكتان:</p>
<ul>
<li class="">لهما بنيات مختلفة (عدد الطبقات، عدد القنوات يختلف قليلاً)</li>
<li class="">تُدربان بشكل مستقل (Policy أولاً، ثم Value)</li>
<li class="">لا تشتركان في أي معاملات</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="شبكة-مزدوجة-الرأس-في-zero">شبكة مزدوجة الرأس في Zero<a href="#شبكة-مزدوجة-الرأس-في-zero" class="hash-link" aria-label="ارتباط مباشر بالعنوان شبكة مزدوجة الرأس في Zero" title="ارتباط مباشر بالعنوان شبكة مزدوجة الرأس في Zero" translate="no">​</a></h3>
<p>AlphaGo Zero يستخدم شبكة واحدة، لكن برأسين إخراج (heads):</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">الإدخال → عمود ResNet المشترك → Policy Head → احتمالية 19x19 للحركة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                             → Value Head  → تقدير نسبة الفوز</span><br></span></code></pre></div></div>
<p>الرأسان يشتركان في نفس عمود ResNet (انظر <a class="" href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/">المقال التالي: الشبكة مزدوجة الرأس وشبكة الباقي</a> للتفاصيل)، وهذا يجلب عدة فوائد:</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-كفاءة-المعاملات">1. كفاءة المعاملات<a href="#1-كفاءة-المعاملات" class="hash-link" aria-label="ارتباط مباشر بالعنوان 1. كفاءة المعاملات" title="ارتباط مباشر بالعنوان 1. كفاءة المعاملات" translate="no">​</a></h4>
<p>العمود المشترك يعني أن معظم المعاملات تُستخدم من قبل المهمتين. هذا يقلل إجمالي عدد المعاملات، ويقلل خطر الإفراط في التكيف.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-مشاركة-الميزات">2. مشاركة الميزات<a href="#2-مشاركة-الميزات" class="hash-link" aria-label="ارتباط مباشر بالعنوان 2. مشاركة الميزات" title="ارتباط مباشر بالعنوان 2. مشاركة الميزات" translate="no">​</a></h4>
<p>&quot;أين يجب اللعب&quot; (Policy) و&quot;من سيفوز&quot; (Value) يحتاجان فهم أنماط لوحة مشابهة. العمود المشترك يسمح بتعلم واستخدام هذه الميزات من قبل المهمتين في نفس الوقت.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-استقرار-التدريب">3. استقرار التدريب<a href="#3-استقرار-التدريب" class="hash-link" aria-label="ارتباط مباشر بالعنوان 3. استقرار التدريب" title="ارتباط مباشر بالعنوان 3. استقرار التدريب" translate="no">​</a></h4>
<p>التدريب المشترك يجعل إشارات التدرج تأتي من مصدرين، مما يوفر إشراف أغنى، ويجعل التدريب أكثر استقراراً.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="قوة-شبكة-الباقي">قوة شبكة الباقي<a href="#قوة-شبكة-الباقي" class="hash-link" aria-label="ارتباط مباشر بالعنوان قوة شبكة الباقي" title="ارتباط مباشر بالعنوان قوة شبكة الباقي" translate="no">​</a></h3>
<p>عمود AlphaGo Zero يستخدم <strong>شبكة باقي بـ 40 طبقة (ResNet)</strong>، أعمق بكثير من CNN بـ 13 طبقة في AlphaGo الأصلي.</p>
<p>اتصالات الباقي (skip connections) تسمح للشبكات العميقة بالتدريب بفعالية، وتتجنب مشكلة تلاشي التدرج. هذه تقنية اختراقية من مسابقة ImageNet 2015، طُبقت بنجاح في AlphaGo Zero على مجال الغو.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="تحسين-كفاءة-التدريب">تحسين كفاءة التدريب<a href="#تحسين-كفاءة-التدريب" class="hash-link" aria-label="ارتباط مباشر بالعنوان تحسين كفاءة التدريب" title="ارتباط مباشر بالعنوان تحسين كفاءة التدريب" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="النمو-الأسي-للعب-الذاتي">النمو الأسي للعب الذاتي<a href="#النمو-الأسي-للعب-الذاتي" class="hash-link" aria-label="ارتباط مباشر بالعنوان النمو الأسي للعب الذاتي" title="ارتباط مباشر بالعنوان النمو الأسي للعب الذاتي" translate="no">​</a></h3>
<p>عملية تدريب AlphaGo Zero أظهرت كفاءة مذهلة:</p>
<table><thead><tr><th>وقت التدريب</th><th>تقييم ELO</th><th>يعادل</th></tr></thead><tbody><tr><td>0 ساعة</td><td>0</td><td>لعب عشوائي</td></tr><tr><td>3 ساعات</td><td>~1000</td><td>اكتشاف القواعد الأساسية</td></tr><tr><td>12 ساعة</td><td>~3000</td><td>اكتشاف الجوسيكي</td></tr><tr><td>36 ساعة</td><td>~4500</td><td>تجاوز إصدار فان هوي</td></tr><tr><td>60 ساعة</td><td>~5200</td><td>تجاوز إصدار لي سيدول</td></tr><tr><td>72 ساعة</td><td>~5400</td><td>تجاوز AlphaGo الأصلي</td></tr><tr><td>40 يوماً</td><td>~5600</td><td>الإصدار الأقوى</td></tr></tbody></table>
<p><strong>تجاوز البشر في ثلاثة أيام، تجاوز الذكاء الاصطناعي الذي استغرق أشهراً في التدريب في ثلاثة أيام</strong> — هذا تحسين أسي في الكفاءة.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="لماذا-بهذه-السرعة">لماذا بهذه السرعة؟<a href="#لماذا-بهذه-السرعة" class="hash-link" aria-label="ارتباط مباشر بالعنوان لماذا بهذه السرعة؟" title="ارتباط مباشر بالعنوان لماذا بهذه السرعة؟" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="1-إرشاد-بحث-أقوى">1. إرشاد بحث أقوى<a href="#1-إرشاد-بحث-أقوى" class="hash-link" aria-label="ارتباط مباشر بالعنوان 1. إرشاد بحث أقوى" title="ارتباط مباشر بالعنوان 1. إرشاد بحث أقوى" translate="no">​</a></h4>
<p>MCTS في AlphaGo Zero موجه بالكامل بالشبكة العصبية، لم يعد يستخدم استراتيجية اللعب السريع (rollout). هذا يجعل البحث أكثر كفاءة ودقة.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="2-لعب-ذاتي-أسرع">2. لعب ذاتي أسرع<a href="#2-لعب-ذاتي-أسرع" class="hash-link" aria-label="ارتباط مباشر بالعنوان 2. لعب ذاتي أسرع" title="ارتباط مباشر بالعنوان 2. لعب ذاتي أسرع" translate="no">​</a></h4>
<p>بما أنه يحتاج شبكة واحدة فقط (بدلاً من اثنتين)، تكلفة حساب كل مباراة لعب ذاتي أقل. هذا يعني إمكانية توليد بيانات تدريب أكثر في نفس الوقت.</p>
<h4 class="anchor anchorTargetStickyNavbar_l_sM" id="3-تعلم-أكثر-فعالية">3. تعلم أكثر فعالية<a href="#3-تعلم-أكثر-فعالية" class="hash-link" aria-label="ارتباط مباشر بالعنوان 3. تعلم أكثر فعالية" title="ارتباط مباشر بالعنوان 3. تعلم أكثر فعالية" translate="no">​</a></h4>
<p>التدريب المشترك للشبكة مزدوجة الرأس يجعل معلومات كل مباراة تُستخدم بشكل أكثر فعالية. تدرجات Policy و Value تقوي بعضها البعض، وتسرع التقارب.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="المقارنة-مع-التعلم-البشري">المقارنة مع التعلم البشري<a href="#المقارنة-مع-التعلم-البشري" class="hash-link" aria-label="ارتباط مباشر بالعنوان المقارنة مع التعلم البشري" title="ارتباط مباشر بالعنوان المقارنة مع التعلم البشري" translate="no">​</a></h3>
<p>كم يحتاج اللاعب البشري من الوقت للوصول إلى مستويات مختلفة؟</p>
<table><thead><tr><th>المستوى</th><th>الوقت البشري</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td>المبتدئ</td><td>عدة أسابيع</td><td>دقائق</td></tr><tr><td>دان هاوٍ</td><td>سنوات</td><td>ساعات</td></tr><tr><td>مستوى احترافي</td><td>10-20 سنة</td><td>1-2 يوم</td></tr><tr><td>بطل العالم</td><td>20+ سنة تفرغ كامل</td><td>3 أيام</td></tr><tr><td>تجاوز البشر</td><td>مستحيل</td><td>3 أيام</td></tr></tbody></table>
<p>هذه المقارنة ليست للتقليل من اللاعبين البشريين — هم يستخدمون خلايا عصبية بيولوجية، بينما AlphaGo Zero يستخدم TPUs مصممة خصيصاً وعدة آلاف واط من الطاقة. لكنها تُظهر مدى كفاءة طريقة التعلم الصحيحة.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="العمومية-الشطرنج-الشوغي">العمومية: الشطرنج، الشوغي<a href="#العمومية-الشطرنج-الشوغي" class="hash-link" aria-label="ارتباط مباشر بالعنوان العمومية: الشطرنج، الشوغي" title="ارتباط مباشر بالعنوان العمومية: الشطرنج، الشوغي" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ولادة-alphazero">ولادة AlphaZero<a href="#ولادة-alphazero" class="hash-link" aria-label="ارتباط مباشر بالعنوان ولادة AlphaZero" title="ارتباط مباشر بالعنوان ولادة AlphaZero" translate="no">​</a></h3>
<p>في ديسمبر 2017، نشرت DeepMind <strong>AlphaZero</strong> — النسخة العامة من AlphaGo Zero. نفس الخوارزمية، بتعديل قواعد اللعبة فقط، تستطيع الوصول إلى مستوى عالمي في ثلاث ألعاب:</p>
<table><thead><tr><th>اللعبة</th><th>وقت التدريب</th><th>الخصم</th><th>النتيجة</th></tr></thead><tbody><tr><td>الغو</td><td>8 ساعات</td><td>AlphaGo Zero</td><td>60:40</td></tr><tr><td>الشطرنج</td><td>4 ساعات</td><td>Stockfish 8</td><td>28 فوز 72 تعادل 0 خسارة</td></tr><tr><td>الشوغي</td><td>ساعتان</td><td>Elmo</td><td>90:8:2</td></tr></tbody></table>
<p>لاحظ الخصوم هنا:</p>
<ul>
<li class=""><strong>Stockfish</strong> كان أقوى محرك شطرنج في ذلك الوقت، يستخدم عقوداً من المعرفة البشرية والتحسينات</li>
<li class=""><strong>Elmo</strong> كان أقوى ذكاء شوغي اصطناعي في ذلك الوقت</li>
</ul>
<p>AlphaZero بساعات قليلة من التدريب، تجاوز هذه الأنظمة المتخصصة التي استغرقت سنوات في التطوير.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="أهمية-العمومية">أهمية العمومية<a href="#أهمية-العمومية" class="hash-link" aria-label="ارتباط مباشر بالعنوان أهمية العمومية" title="ارتباط مباشر بالعنوان أهمية العمومية" translate="no">​</a></h3>
<p>AlphaGo Zero / AlphaZero أثبتا شيئاً مهماً:</p>
<blockquote>
<p><strong>نفس خوارزمية التعلم، يمكنها الوصول إلى مستوى فوق بشري في مجالات مختلفة.</strong></p>
</blockquote>
<p>هذا ليس ثلاثة ذكاءات اصطناعية مختلفة، بل إطار تعلم عام واحد:</p>
<ol>
<li class=""><strong>اللعب الذاتي</strong> يولّد الخبرة</li>
<li class=""><strong>بحث شجرة مونت كارلو</strong> يستكشف الاحتمالات</li>
<li class=""><strong>الشبكة العصبية</strong> تتعلم دالة السياسة والقيمة</li>
<li class=""><strong>التعلم المعزز</strong> يحسّن دالة الهدف</li>
</ol>
<p>هذا الإطار لا يعتمد على معرفة مجال محدد، وهذا خطوة مهمة نحو تعميم الذكاء الاصطناعي.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="التأثير-على-الذكاء-الاصطناعي-التقليدي">التأثير على الذكاء الاصطناعي التقليدي<a href="#التأثير-على-الذكاء-الاصطناعي-التقليدي" class="hash-link" aria-label="ارتباط مباشر بالعنوان التأثير على الذكاء الاصطناعي التقليدي" title="ارتباط مباشر بالعنوان التأثير على الذكاء الاصطناعي التقليدي" translate="no">​</a></h3>
<p>قبل AlphaZero، أقوى ذكاء اصطناعي في الشطرنج والشوغي كان من نمط &quot;النظام الخبير&quot;:</p>
<ul>
<li class=""><strong>معرفة بشرية كثيرة</strong>: مكتبات افتتاحية، مكتبات نهاية، دوال تقييم</li>
<li class=""><strong>عقود من التحسين</strong>: جهود لاعبين ومهندسين لا تُحصى</li>
<li class=""><strong>تخصص شديد</strong>: Stockfish لا يستطيع لعب الغو، Elmo لا يستطيع لعب الشطرنج</li>
</ul>
<p>AlphaZero بخوارزمية عامة واحدة تجاوز كل هذا في ساعات. هذا جعل كثيراً من باحثي الذكاء الاصطناعي يعيدون التفكير:</p>
<blockquote>
<p>هل يجب أن نستثمر جهداً أكثر في &quot;خوارزميات التعلم العامة&quot; أم &quot;تشفير المعرفة الخبيرة&quot;؟</p>
</blockquote>
<p>الجواب يبدو أوضح وأوضح: ترك الآلة تتعلم بنفسها أكثر فعالية من تعليمها المعرفة.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="أسلوب-لعب-alphago-zero">أسلوب لعب AlphaGo Zero<a href="#أسلوب-لعب-alphago-zero" class="hash-link" aria-label="ارتباط مباشر بالعنوان أسلوب لعب AlphaGo Zero" title="ارتباط مباشر بالعنوان أسلوب لعب AlphaGo Zero" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="جماليات-تتجاوز-البشر">جماليات تتجاوز البشر<a href="#جماليات-تتجاوز-البشر" class="hash-link" aria-label="ارتباط مباشر بالعنوان جماليات تتجاوز البشر" title="ارتباط مباشر بالعنوان جماليات تتجاوز البشر" translate="no">​</a></h3>
<p>مجتمع الغو لديه تقييم عام لحركات AlphaGo Zero: <strong>أكثر جمالاً</strong>.</p>
<p>حركات AlphaGo Lee كانت تبدو أحياناً &quot;غريبة&quot; — مثل الحركة 37، البشر احتاجوا تحليلاً لاحقاً لفهم روعتها. لكن حركات AlphaGo Zero غالباً ما تُقيَّم لاحقاً بأنها &quot;واضحة أنها جيدة من النظرة الأولى&quot;.</p>
<p>قد يكون هذا بسبب:</p>
<ol>
<li class=""><strong>قوة لعب أكبر</strong>: Zero يرى أعمق، يلعب بأريحية أكبر</li>
<li class=""><strong>بدون تحيز بشري</strong>: غير مقيد بالجوسيكي التقليدي</li>
<li class=""><strong>هدف متسق</strong>: يسعى فقط لنسبة الفوز، لا يقلد البشر</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="إعادة-اكتشاف-نظرية-الغو-البشرية">إعادة اكتشاف نظرية الغو البشرية<a href="#إعادة-اكتشاف-نظرية-الغو-البشرية" class="hash-link" aria-label="ارتباط مباشر بالعنوان إعادة اكتشاف نظرية الغو البشرية" title="ارتباط مباشر بالعنوان إعادة اكتشاف نظرية الغو البشرية" translate="no">​</a></h3>
<p>المثير للاهتمام، AlphaGo Zero خلال التدريب &quot;أعاد اكتشاف&quot; معرفة الغو التي راكمها البشر آلاف السنين:</p>
<ul>
<li class=""><strong>الجوسيكي</strong>: Zero اكتشف بنفسه كثيراً من الجوسيكي الشائعة، لأنها فعلاً الحل الأمثل للطرفين</li>
<li class=""><strong>مبادئ الفوسيكي (الافتتاح)</strong>: ترتيب أهمية الزاوية، الحافة، الوسط</li>
<li class=""><strong>معرفة شكل الأحجار</strong>: الفرق بين الشكل السيء والجيد</li>
</ul>
<p>هذا يؤكد معقولية نظرية الغو البشرية — هذه المعرفة ليست صدفة، بل انعكاس لجوهر الغو.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="ابتكار-يتجاوز-البشر">ابتكار يتجاوز البشر<a href="#ابتكار-يتجاوز-البشر" class="hash-link" aria-label="ارتباط مباشر بالعنوان ابتكار يتجاوز البشر" title="ارتباط مباشر بالعنوان ابتكار يتجاوز البشر" translate="no">​</a></h3>
<p>لكن Zero اكتشف أيضاً حركات لم يفكر فيها البشر أبداً:</p>
<ul>
<li class=""><strong>افتتاحيات غير تقليدية</strong>: تنويعات على الافتتاحيات التقليدية</li>
<li class=""><strong>تضحية عدوانية</strong>: أكثر استعداداً من البشر للتخلي عن المحلي مقابل ميزة شاملة</li>
<li class=""><strong>أشكال معاكسة للحدس</strong>: ما يبدو &quot;شكلاً سيئاً&quot; هو في الواقع الحل الأمثل</li>
</ul>
<p>هذه الابتكارات تغيّر فهم البشر للغو. كثير من اللاعبين المحترفين أفادوا أن دراسة سجلات AlphaGo Zero أعطتهم فهماً جديداً تماماً للغو.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="ملخص-التفاصيل-التقنية">ملخص التفاصيل التقنية<a href="#ملخص-التفاصيل-التقنية" class="hash-link" aria-label="ارتباط مباشر بالعنوان ملخص التفاصيل التقنية" title="ارتباط مباشر بالعنوان ملخص التفاصيل التقنية" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="المقارنة-الكاملة-مع-alphago-الأصلي">المقارنة الكاملة مع AlphaGo الأصلي<a href="#المقارنة-الكاملة-مع-alphago-الأصلي" class="hash-link" aria-label="ارتباط مباشر بالعنوان المقارنة الكاملة مع AlphaGo الأصلي" title="ارتباط مباشر بالعنوان المقارنة الكاملة مع AlphaGo الأصلي" translate="no">​</a></h3>
<table><thead><tr><th>الجانب</th><th>AlphaGo (الأصلي)</th><th>AlphaGo Zero</th></tr></thead><tbody><tr><td><strong>بيانات التدريب</strong></td><td>سجلات بشرية + لعب ذاتي</td><td>لعب ذاتي نقي</td></tr><tr><td><strong>طريقة التعلم</strong></td><td>تعلم إشرافي + تعلم معزز</td><td>تعلم معزز نقي</td></tr><tr><td><strong>ميزات الإدخال</strong></td><td>48 مستوى</td><td>17 مستوى</td></tr><tr><td><strong>بنية الشبكة</strong></td><td>Policy/Value منفصلة</td><td>ResNet مزدوجة الرأس</td></tr><tr><td><strong>عمق الشبكة</strong></td><td>13 طبقة</td><td>40 طبقة (أو أكثر)</td></tr><tr><td><strong>تقييم MCTS</strong></td><td>شبكة عصبية + Rollout</td><td>شبكة عصبية نقية</td></tr><tr><td><strong>عدد البحث</strong></td><td>~100,000 لكل حركة</td><td>~1,600 لكل حركة</td></tr><tr><td><strong>TPUs للتدريب</strong></td><td>50+</td><td>4</td></tr><tr><td><strong>TPUs للاستنتاج</strong></td><td>48</td><td>4 (قابل للتوسع)</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="الخوارزمية-الأساسية">الخوارزمية الأساسية<a href="#الخوارزمية-الأساسية" class="hash-link" aria-label="ارتباط مباشر بالعنوان الخوارزمية الأساسية" title="ارتباط مباشر بالعنوان الخوارزمية الأساسية" translate="no">​</a></h3>
<p>دورة تدريب AlphaGo Zero بسيطة جداً:</p>
<div class="language-text codeBlockContainer_huE5 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_oko_"><pre tabindex="0" class="prism-code language-text codeBlock_BBgU thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_t9f9"><span class="token-line" style="color:#393A34"><span class="token plain">1. اللعب الذاتي</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - استخدام الشبكة الحالية لـ MCTS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - اختيار الحركة حسب احتمالية بحث MCTS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - تسجيل (الوضع، احتمالية MCTS، نتيجة الفوز/الخسارة) لكل حركة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. تدريب الشبكة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - أخذ عينات من مجمع الخبرة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Policy Head: تقليل الإنتروبيا المتقاطعة مع احتمالية MCTS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Value Head: تقليل الخطأ التربيعي المتوسط مع الفوز/الخسارة الفعلي</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - تحسين الهدفين معاً</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. تحديث الشبكة</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - استبدال الشبكة القديمة بالجديدة (التحقق بالمباراة أن الشبكة الجديدة أقوى)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - العودة للخطوة 1</span><br></span></code></pre></div></div>
<p>هذه الدورة تستمر، والشبكة تصبح أقوى باستمرار. بدون بيانات بشرية، بدون معرفة بشرية، فقط قواعد اللعبة وهدف الفوز/الخسارة.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="دروس-لأبحاث-الذكاء-الاصطناعي">دروس لأبحاث الذكاء الاصطناعي<a href="#دروس-لأبحاث-الذكاء-الاصطناعي" class="hash-link" aria-label="ارتباط مباشر بالعنوان دروس لأبحاث الذكاء الاصطناعي" title="ارتباط مباشر بالعنوان دروس لأبحاث الذكاء الاصطناعي" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="التعلم-من-المبادئ-الأولى">التعلم من المبادئ الأولى<a href="#التعلم-من-المبادئ-الأولى" class="hash-link" aria-label="ارتباط مباشر بالعنوان التعلم من المبادئ الأولى" title="ارتباط مباشر بالعنوان التعلم من المبادئ الأولى" translate="no">​</a></h3>
<p>AlphaGo Zero أظهر طريقة تعلم &quot;المبادئ الأولى&quot;:</p>
<blockquote>
<p>لا تخبر الذكاء الاصطناعي كيف يفعل، فقط أخبره ما هو الهدف، ودعه يكتشف الطريقة بنفسه.</p>
</blockquote>
<p>هذا يتناقض بشكل صارخ مع طريقة النظام الخبير التقليدي. النظام الخبير يحاول تشفير المعرفة البشرية في الذكاء الاصطناعي، بينما AlphaGo Zero يدع الذكاء الاصطناعي يكتشف المعرفة بنفسه.</p>
<p>النتيجة هي: المعرفة التي يكتشفها الذكاء الاصطناعي قد تكون أكثر اكتمالاً ودقة من المعرفة البشرية.</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="قوة-اللعب-الذاتي">قوة اللعب الذاتي<a href="#قوة-اللعب-الذاتي" class="hash-link" aria-label="ارتباط مباشر بالعنوان قوة اللعب الذاتي" title="ارتباط مباشر بالعنوان قوة اللعب الذاتي" translate="no">​</a></h3>
<p>AlphaGo Zero أثبت أن اللعب الذاتي يمكنه توليد بيانات تدريب لا نهائية، وجودة هذه البيانات تتحسن مع تحسن الشبكة.</p>
<p>هذه &quot;دورة إيجابية&quot;:</p>
<ul>
<li class="">شبكة أقوى → بيانات لعب ذاتي أفضل</li>
<li class="">بيانات أفضل → شبكة أقوى</li>
</ul>
<p>هذه الدورة يمكن أن تستمر حتى الوصول إلى الحد النظري للعبة (إن وجد).</p>
<h3 class="anchor anchorTargetStickyNavbar_l_sM" id="أهمية-التبسيط">أهمية التبسيط<a href="#أهمية-التبسيط" class="hash-link" aria-label="ارتباط مباشر بالعنوان أهمية التبسيط" title="ارتباط مباشر بالعنوان أهمية التبسيط" translate="no">​</a></h3>
<p>نجاح AlphaGo Zero أثبت أهمية &quot;التبسيط&quot;:</p>
<ul>
<li class="">تبسيط الإدخال (48 → 17)</li>
<li class="">تبسيط البنية (شبكتان → شبكة واحدة)</li>
<li class="">تبسيط التدريب (إشرافي + معزز → معزز نقي)</li>
</ul>
<p>كل تبسيط جعل النظام أقوى. هذا يعلمنا: المعقد لا يساوي الجيد، أبسط الحلول غالباً أفضلها.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="تطابق-الرسوم-المتحركة">تطابق الرسوم المتحركة<a href="#تطابق-الرسوم-المتحركة" class="hash-link" aria-label="ارتباط مباشر بالعنوان تطابق الرسوم المتحركة" title="ارتباط مباشر بالعنوان تطابق الرسوم المتحركة" translate="no">​</a></h2>
<p>المفاهيم الأساسية في هذه المقالة ورقم الرسوم المتحركة المقابل:</p>
<table><thead><tr><th>الرقم</th><th>المفهوم</th><th>التطابق الفيزيائي/الرياضي</th></tr></thead><tbody><tr><td>🎬 E7</td><td>التدريب من الصفر</td><td>ظاهرة التنظيم الذاتي</td></tr><tr><td>🎬 E5</td><td>اللعب الذاتي</td><td>تقارب النقطة الثابتة</td></tr><tr><td>🎬 E12</td><td>منحنى نمو قوة اللعب</td><td>نمو S-شكل</td></tr><tr><td>🎬 D12</td><td>شبكة الباقي</td><td>طريق التدرج السريع</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="قراءة-موسعة">قراءة موسعة<a href="#قراءة-موسعة" class="hash-link" aria-label="ارتباط مباشر بالعنوان قراءة موسعة" title="ارتباط مباشر بالعنوان قراءة موسعة" translate="no">​</a></h2>
<ul>
<li class=""><strong>المقال التالي</strong>: <a class="" href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/">الشبكة مزدوجة الرأس وشبكة الباقي</a> — شرح تفصيلي لبنية الشبكة العصبية في AlphaGo Zero</li>
<li class=""><strong>مقال ذو صلة</strong>: <a class="" href="/ar/docs/for-engineers/how-it-works/alphago-explained/self-play/">اللعب الذاتي</a> — لماذا يستطيع اللعب الذاتي إنتاج مستوى فوق بشري</li>
<li class=""><strong>تعمق تقني</strong>: <a class="" href="/ar/docs/for-engineers/how-it-works/alphago-explained/training-from-scratch/">عملية التدريب من الصفر</a> — التطور التفصيلي من اليوم 0 إلى 3</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_l_sM" id="المراجع">المراجع<a href="#المراجع" class="hash-link" aria-label="ارتباط مباشر بالعنوان المراجع" title="ارتباط مباشر بالعنوان المراجع" translate="no">​</a></h2>
<ol>
<li class="">Silver, D., et al. (2017). &quot;Mastering the game of Go without human knowledge.&quot; <em>Nature</em>, 550, 354-359.</li>
<li class="">Silver, D., et al. (2018). &quot;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.&quot; <em>Science</em>, 362(6419), 1140-1144.</li>
<li class="">DeepMind. (2017). &quot;AlphaGo Zero: Starting from scratch.&quot; <em>DeepMind Blog</em>.</li>
<li class="">Schrittwieser, J., et al. (2020). &quot;Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.&quot; <em>Nature</em>, 588, 604-609.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_YM8j"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/for-engineers/how-it-works/alphago-explained/16-alphago-zero.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_hRvp" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>تعديل هذه الصفحة</a></div><div class="col lastUpdated_LNbR"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="صفحة التوثيق"><a class="pagination-nav__link pagination-nav__link--prev" href="/ar/docs/for-engineers/how-it-works/alphago-explained/puct-formula/"><div class="pagination-nav__sublabel">السابق</div><div class="pagination-nav__label">شرح تفصيلي لمعادلة PUCT</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ar/docs/for-engineers/how-it-works/alphago-explained/dual-head-resnet/"><div class="pagination-nav__sublabel">التالي</div><div class="pagination-nav__label">الشبكة مزدوجة الرأس وشبكة الباقي</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_VU0O thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#لماذا-لا-يحتاج-سجلات-بشرية" class="table-of-contents__link toc-highlight">لماذا لا يحتاج سجلات بشرية؟</a><ul><li><a href="#قيود-السجلات-البشرية" class="table-of-contents__link toc-highlight">قيود السجلات البشرية</a></li><li><a href="#اختراق-zero" class="table-of-contents__link toc-highlight">اختراق Zero</a></li></ul></li><li><a href="#المقارنة-مع-alphago-الأصلي-1000" class="table-of-contents__link toc-highlight">المقارنة مع AlphaGo الأصلي: 100:0</a><ul><li><a href="#الفوز-الساحق" class="table-of-contents__link toc-highlight">الفوز الساحق</a></li><li><a href="#موارد-أقل-قوة-أكبر" class="table-of-contents__link toc-highlight">موارد أقل، قوة أكبر</a></li><li><a href="#لماذا-zero-أقوى" class="table-of-contents__link toc-highlight">لماذا Zero أقوى؟</a></li></ul></li><li><a href="#ميزات-الإدخال-المبسطة-من-48-إلى-17" class="table-of-contents__link toc-highlight">ميزات الإدخال المبسطة: من 48 إلى 17</a><ul><li><a href="#48-مستوى-ميزات-في-alphago-الأصلي" class="table-of-contents__link toc-highlight">48 مستوى ميزات في AlphaGo الأصلي</a></li><li><a href="#17-مستوى-ميزات-في-alphago-zero" class="table-of-contents__link toc-highlight">17 مستوى ميزات في AlphaGo Zero</a></li><li><a href="#لماذا-التبسيط-جيد" class="table-of-contents__link toc-highlight">لماذا التبسيط جيد؟</a></li></ul></li><li><a href="#بنية-الشبكة-الواحدة" class="table-of-contents__link toc-highlight">بنية الشبكة الواحدة</a><ul><li><a href="#تصميم-الشبكتين-في-النسخة-الأصلية" class="table-of-contents__link toc-highlight">تصميم الشبكتين في النسخة الأصلية</a></li><li><a href="#شبكة-مزدوجة-الرأس-في-zero" class="table-of-contents__link toc-highlight">شبكة مزدوجة الرأس في Zero</a></li><li><a href="#قوة-شبكة-الباقي" class="table-of-contents__link toc-highlight">قوة شبكة الباقي</a></li></ul></li><li><a href="#تحسين-كفاءة-التدريب" class="table-of-contents__link toc-highlight">تحسين كفاءة التدريب</a><ul><li><a href="#النمو-الأسي-للعب-الذاتي" class="table-of-contents__link toc-highlight">النمو الأسي للعب الذاتي</a></li><li><a href="#لماذا-بهذه-السرعة" class="table-of-contents__link toc-highlight">لماذا بهذه السرعة؟</a></li><li><a href="#المقارنة-مع-التعلم-البشري" class="table-of-contents__link toc-highlight">المقارنة مع التعلم البشري</a></li></ul></li><li><a href="#العمومية-الشطرنج-الشوغي" class="table-of-contents__link toc-highlight">العمومية: الشطرنج، الشوغي</a><ul><li><a href="#ولادة-alphazero" class="table-of-contents__link toc-highlight">ولادة AlphaZero</a></li><li><a href="#أهمية-العمومية" class="table-of-contents__link toc-highlight">أهمية العمومية</a></li><li><a href="#التأثير-على-الذكاء-الاصطناعي-التقليدي" class="table-of-contents__link toc-highlight">التأثير على الذكاء الاصطناعي التقليدي</a></li></ul></li><li><a href="#أسلوب-لعب-alphago-zero" class="table-of-contents__link toc-highlight">أسلوب لعب AlphaGo Zero</a><ul><li><a href="#جماليات-تتجاوز-البشر" class="table-of-contents__link toc-highlight">جماليات تتجاوز البشر</a></li><li><a href="#إعادة-اكتشاف-نظرية-الغو-البشرية" class="table-of-contents__link toc-highlight">إعادة اكتشاف نظرية الغو البشرية</a></li><li><a href="#ابتكار-يتجاوز-البشر" class="table-of-contents__link toc-highlight">ابتكار يتجاوز البشر</a></li></ul></li><li><a href="#ملخص-التفاصيل-التقنية" class="table-of-contents__link toc-highlight">ملخص التفاصيل التقنية</a><ul><li><a href="#المقارنة-الكاملة-مع-alphago-الأصلي" class="table-of-contents__link toc-highlight">المقارنة الكاملة مع AlphaGo الأصلي</a></li><li><a href="#الخوارزمية-الأساسية" class="table-of-contents__link toc-highlight">الخوارزمية الأساسية</a></li></ul></li><li><a href="#دروس-لأبحاث-الذكاء-الاصطناعي" class="table-of-contents__link toc-highlight">دروس لأبحاث الذكاء الاصطناعي</a><ul><li><a href="#التعلم-من-المبادئ-الأولى" class="table-of-contents__link toc-highlight">التعلم من المبادئ الأولى</a></li><li><a href="#قوة-اللعب-الذاتي" class="table-of-contents__link toc-highlight">قوة اللعب الذاتي</a></li><li><a href="#أهمية-التبسيط" class="table-of-contents__link toc-highlight">أهمية التبسيط</a></li></ul></li><li><a href="#تطابق-الرسوم-المتحركة" class="table-of-contents__link toc-highlight">تطابق الرسوم المتحركة</a></li><li><a href="#قراءة-موسعة" class="table-of-contents__link toc-highlight">قراءة موسعة</a></li><li><a href="#المراجع" class="table-of-contents__link toc-highlight">المراجع</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Weiqi.Kids. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>