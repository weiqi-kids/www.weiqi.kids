"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[9525],{57416(n,e,r){r.r(e),r.d(e,{assets:()=>a,contentTitle:()=>t,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"tech/deep-dive/build-from-scratch","title":"\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631","description":"\u062f\u0644\u064a\u0644 \u062e\u0637\u0648\u0629 \u0628\u062e\u0637\u0648\u0629 \u0644\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0639\u0644\u0649 \u0637\u0631\u0627\u0632 AlphaGo Zero \u0627\u0644\u0645\u0628\u0633\u0637","source":"@site/i18n/ar/docusaurus-plugin-content-docs/current/tech/deep-dive/build-from-scratch.md","sourceDirName":"tech/deep-dive","slug":"/tech/deep-dive/build-from-scratch","permalink":"/ar/docs/tech/deep-dive/build-from-scratch","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tech/deep-dive/build-from-scratch.md","tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"title":"\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631","description":"\u062f\u0644\u064a\u0644 \u062e\u0637\u0648\u0629 \u0628\u062e\u0637\u0648\u0629 \u0644\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0639\u0644\u0649 \u0637\u0631\u0627\u0632 AlphaGo Zero \u0627\u0644\u0645\u0628\u0633\u0637"},"sidebar":"tutorialSidebar","previous":{"title":"\u062f\u0644\u064a\u0644 \u0642\u0631\u0627\u0621\u0629 \u0627\u0644\u0623\u0648\u0631\u0627\u0642 \u0627\u0644\u0628\u062d\u062b\u064a\u0629 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629","permalink":"/ar/docs/tech/deep-dive/papers"},"next":{"title":"30 \u5206\u9418\u8dd1\u8d77\u7b2c\u4e00\u500b\u570d\u68cb AI","permalink":"/ar/docs/tech/hands-on/"}}');var l=r(62615),o=r(30416);const i={sidebar_position:12,title:"\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631",description:"\u062f\u0644\u064a\u0644 \u062e\u0637\u0648\u0629 \u0628\u062e\u0637\u0648\u0629 \u0644\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0639\u0644\u0649 \u0637\u0631\u0627\u0632 AlphaGo Zero \u0627\u0644\u0645\u0628\u0633\u0637"},t="\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631",a={},d=[{value:"\u0647\u064a\u0643\u0644 \u0627\u0644\u0645\u0634\u0631\u0648\u0639",id:"\u0647\u064a\u0643\u0644-\u0627\u0644\u0645\u0634\u0631\u0648\u0639",level:2},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0623\u0648\u0644\u0649: \u0627\u0644\u0644\u0648\u062d\u0629 \u0648\u0627\u0644\u0642\u0648\u0627\u0639\u062f",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0623\u0648\u0644\u0649-\u0627\u0644\u0644\u0648\u062d\u0629-\u0648\u0627\u0644\u0642\u0648\u0627\u0639\u062f",level:2},{value:"\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0644\u0648\u062d\u0629",id:"\u062a\u0646\u0641\u064a\u0630-\u0627\u0644\u0644\u0648\u062d\u0629",level:3},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062b\u0627\u0646\u064a\u0629: \u062a\u0631\u0645\u064a\u0632 \u0627\u0644\u0645\u064a\u0632\u0627\u062a",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062b\u0627\u0646\u064a\u0629-\u062a\u0631\u0645\u064a\u0632-\u0627\u0644\u0645\u064a\u0632\u0627\u062a",level:2},{value:"\u0645\u064a\u0632\u0627\u062a \u0627\u0644\u0625\u062f\u062e\u0627\u0644",id:"\u0645\u064a\u0632\u0627\u062a-\u0627\u0644\u0625\u062f\u062e\u0627\u0644",level:3},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062b\u0627\u0644\u062b\u0629: \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062b\u0627\u0644\u062b\u0629-\u0627\u0644\u0634\u0628\u0643\u0629-\u0627\u0644\u0639\u0635\u0628\u064a\u0629",level:2},{value:"\u0628\u0646\u064a\u0629 \u0627\u0644\u0634\u0628\u0643\u0629 \u0628\u0631\u0623\u0633\u064a\u0646",id:"\u0628\u0646\u064a\u0629-\u0627\u0644\u0634\u0628\u0643\u0629-\u0628\u0631\u0623\u0633\u064a\u0646",level:3},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0631\u0627\u0628\u0639\u0629: \u062a\u0646\u0641\u064a\u0630 MCTS",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0631\u0627\u0628\u0639\u0629-\u062a\u0646\u0641\u064a\u0630-mcts",level:2},{value:"\u0641\u0626\u0629 \u0627\u0644\u0639\u0642\u062f\u0629",id:"\u0641\u0626\u0629-\u0627\u0644\u0639\u0642\u062f\u0629",level:3},{value:"\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0628\u062d\u062b",id:"\u062a\u0646\u0641\u064a\u0630-\u0627\u0644\u0628\u062d\u062b",level:3},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062e\u0627\u0645\u0633\u0629: \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062e\u0627\u0645\u0633\u0629-\u0627\u0644\u0644\u0639\u0628-\u0627\u0644\u0630\u0627\u062a\u064a",level:2},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0633\u0627\u062f\u0633\u0629: \u0627\u0644\u0645\u062f\u0631\u0628",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0633\u0627\u062f\u0633\u0629-\u0627\u0644\u0645\u062f\u0631\u0628",level:2},{value:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0633\u0627\u0628\u0639\u0629: \u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c \u0627\u0644\u0631\u0626\u064a\u0633\u064a",id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0633\u0627\u0628\u0639\u0629-\u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c-\u0627\u0644\u0631\u0626\u064a\u0633\u064a",level:2},{value:"\u0627\u0644\u062a\u0634\u063a\u064a\u0644 \u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631",id:"\u0627\u0644\u062a\u0634\u063a\u064a\u0644-\u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631",level:2},{value:"\u062a\u062b\u0628\u064a\u062a \u0627\u0644\u062a\u0628\u0639\u064a\u0627\u062a",id:"\u062a\u062b\u0628\u064a\u062a-\u0627\u0644\u062a\u0628\u0639\u064a\u0627\u062a",level:3},{value:"\u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u062a\u062f\u0631\u064a\u0628",id:"\u062a\u0634\u063a\u064a\u0644-\u0627\u0644\u062a\u062f\u0631\u064a\u0628",level:3},{value:"\u0627\u0644\u0645\u062e\u0631\u062c\u0627\u062a \u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629",id:"\u0627\u0644\u0645\u062e\u0631\u062c\u0627\u062a-\u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629",level:3},{value:"\u0627\u0642\u062a\u0631\u0627\u062d\u0627\u062a \u0627\u0644\u062a\u062d\u0633\u064a\u0646",id:"\u0627\u0642\u062a\u0631\u0627\u062d\u0627\u062a-\u0627\u0644\u062a\u062d\u0633\u064a\u0646",level:2},{value:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a \u0642\u0635\u064a\u0631\u0629 \u0627\u0644\u0645\u062f\u0649",id:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a-\u0642\u0635\u064a\u0631\u0629-\u0627\u0644\u0645\u062f\u0649",level:3},{value:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a \u0637\u0648\u064a\u0644\u0629 \u0627\u0644\u0645\u062f\u0649",id:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a-\u0637\u0648\u064a\u0644\u0629-\u0627\u0644\u0645\u062f\u0649",level:3},{value:"\u0642\u0631\u0627\u0621\u0627\u062a \u0625\u0636\u0627\u0641\u064a\u0629",id:"\u0642\u0631\u0627\u0621\u0627\u062a-\u0625\u0636\u0627\u0641\u064a\u0629",level:2}];function c(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...n.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.header,{children:(0,l.jsx)(e.h1,{id:"\u0628\u0646\u0627\u0621-\u0630\u0643\u0627\u0621-\u0627\u0635\u0637\u0646\u0627\u0639\u064a-\u0644\u0644\u063a\u0648-\u0645\u0646-\u0627\u0644\u0635\u0641\u0631",children:"\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0645\u0646 \u0627\u0644\u0635\u0641\u0631"})}),"\n",(0,l.jsx)(e.p,{children:"\u064a\u0631\u0634\u062f\u0643 \u0647\u0630\u0627 \u0627\u0644\u0645\u0642\u0627\u0644 \u062e\u0637\u0648\u0629 \u0628\u062e\u0637\u0648\u0629 \u0644\u0628\u0646\u0627\u0621 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0639\u0644\u0649 \u0637\u0631\u0627\u0632 AlphaGo Zero \u0627\u0644\u0645\u0628\u0633\u0637\u060c \u064a\u0634\u0645\u0644 \u0645\u0646\u0637\u0642 \u0627\u0644\u0644\u0639\u0628\u0629 \u0648\u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629 \u0648MCTS \u0648\u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u062a\u062f\u0631\u064a\u0628."}),"\n",(0,l.jsxs)(e.admonition,{title:"\u0623\u0647\u062f\u0627\u0641 \u0627\u0644\u062a\u0639\u0644\u0645",type:"info",children:[(0,l.jsx)(e.p,{children:"\u0628\u0639\u062f \u0625\u0643\u0645\u0627\u0644 \u0647\u0630\u0627 \u0627\u0644\u062f\u0644\u064a\u0644\u060c \u0633\u064a\u0643\u0648\u0646 \u0644\u062f\u064a\u0643 \u0630\u0643\u0627\u0621 \u0627\u0635\u0637\u0646\u0627\u0639\u064a \u0644\u0644\u063a\u0648 \u0642\u0627\u062f\u0631 \u0639\u0644\u0649:"}),(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"\u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a \u0639\u0644\u0649 \u0644\u0648\u062d\u0629 9\xd79"}),"\n",(0,l.jsx)(e.li,{children:"\u0627\u0644\u062a\u062d\u0633\u0646 \u0627\u0644\u0645\u0633\u062a\u0645\u0631 \u0645\u0646 \u062e\u0644\u0627\u0644 \u0627\u0644\u062a\u0639\u0644\u0645 \u0627\u0644\u0645\u0639\u0632\u0632"}),"\n",(0,l.jsx)(e.li,{children:"\u0627\u0644\u0648\u0635\u0648\u0644 \u0644\u0645\u0633\u062a\u0648\u0649 \u0647\u0627\u0648\u064d \u0645\u0628\u062a\u062f\u0626"}),"\n"]})]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0647\u064a\u0643\u0644-\u0627\u0644\u0645\u0634\u0631\u0648\u0639",children:"\u0647\u064a\u0643\u0644 \u0627\u0644\u0645\u0634\u0631\u0648\u0639"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{children:"mini-alphago/\n\u251c\u2500\u2500 game/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 board.py          # \u0645\u0646\u0637\u0642 \u0627\u0644\u0644\u0648\u062d\u0629\n\u2502   \u251c\u2500\u2500 rules.py          # \u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0642\u0648\u0627\u0639\u062f\n\u2502   \u2514\u2500\u2500 state.py          # \u062d\u0627\u0644\u0629 \u0627\u0644\u0644\u0639\u0628\u0629\n\u251c\u2500\u2500 model/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 network.py        # \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\u2502   \u2514\u2500\u2500 features.py       # \u062a\u0631\u0645\u064a\u0632 \u0627\u0644\u0645\u064a\u0632\u0627\u062a\n\u251c\u2500\u2500 mcts/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 node.py           # \u0639\u0642\u062f\u0629 MCTS\n\u2502   \u2514\u2500\u2500 search.py         # \u0628\u062d\u062b MCTS\n\u251c\u2500\u2500 training/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 self_play.py      # \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a\n\u2502   \u2514\u2500\u2500 trainer.py        # \u0627\u0644\u0645\u062f\u0631\u0628\n\u251c\u2500\u2500 main.py               # \u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c \u0627\u0644\u0631\u0626\u064a\u0633\u064a\n\u2514\u2500\u2500 requirements.txt\n"})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0623\u0648\u0644\u0649-\u0627\u0644\u0644\u0648\u062d\u0629-\u0648\u0627\u0644\u0642\u0648\u0627\u0639\u062f",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0623\u0648\u0644\u0649: \u0627\u0644\u0644\u0648\u062d\u0629 \u0648\u0627\u0644\u0642\u0648\u0627\u0639\u062f"}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u0646\u0641\u064a\u0630-\u0627\u0644\u0644\u0648\u062d\u0629",children:"\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0644\u0648\u062d\u0629"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# game/board.py\nimport numpy as np\n\nclass Board:\n    """\u0644\u0648\u062d\u0629 \u0627\u0644\u063a\u0648"""\n\n    EMPTY = 0\n    BLACK = 1\n    WHITE = 2\n\n    def __init__(self, size=9):\n        self.size = size\n        self.board = np.zeros((size, size), dtype=np.int8)\n        self.current_player = self.BLACK\n        self.ko_point = None\n        self.history = []\n\n    def copy(self):\n        """\u0646\u0633\u062e \u0627\u0644\u0644\u0648\u062d\u0629"""\n        new_board = Board(self.size)\n        new_board.board = self.board.copy()\n        new_board.current_player = self.current_player\n        new_board.ko_point = self.ko_point\n        new_board.history = self.history.copy()\n        return new_board\n\n    def get_opponent(self, player):\n        """\u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u062e\u0635\u0645"""\n        return self.WHITE if player == self.BLACK else self.BLACK\n\n    def is_on_board(self, x, y):\n        """\u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0623\u0646\u0647 \u0639\u0644\u0649 \u0627\u0644\u0644\u0648\u062d\u0629"""\n        return 0 <= x < self.size and 0 <= y < self.size\n\n    def get_neighbors(self, x, y):\n        """\u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0646\u0642\u0627\u0637 \u0627\u0644\u0645\u062c\u0627\u0648\u0631\u0629"""\n        neighbors = []\n        for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n            nx, ny = x + dx, y + dy\n            if self.is_on_board(nx, ny):\n                neighbors.append((nx, ny))\n        return neighbors\n\n    def get_group(self, x, y):\n        """\u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0633\u0644\u0633\u0644\u0629 (\u0627\u0644\u0623\u062d\u062c\u0627\u0631 \u0627\u0644\u0645\u062a\u0635\u0644\u0629 \u0645\u0646 \u0646\u0641\u0633 \u0627\u0644\u0644\u0648\u0646)"""\n        color = self.board[x, y]\n        if color == self.EMPTY:\n            return set(), set()\n\n        group = set()\n        liberties = set()\n        stack = [(x, y)]\n\n        while stack:\n            cx, cy = stack.pop()\n            if (cx, cy) in group:\n                continue\n            group.add((cx, cy))\n\n            for nx, ny in self.get_neighbors(cx, cy):\n                if self.board[nx, ny] == self.EMPTY:\n                    liberties.add((nx, ny))\n                elif self.board[nx, ny] == color and (nx, ny) not in group:\n                    stack.append((nx, ny))\n\n        return group, liberties\n\n    def count_liberties(self, x, y):\n        """\u062d\u0633\u0627\u0628 \u0639\u062f\u062f \u0627\u0644\u062d\u0631\u064a\u0627\u062a"""\n        _, liberties = self.get_group(x, y)\n        return len(liberties)\n\n    def remove_group(self, group):\n        """\u0625\u0632\u0627\u0644\u0629 \u0627\u0644\u0633\u0644\u0633\u0644\u0629"""\n        for x, y in group:\n            self.board[x, y] = self.EMPTY\n\n    def is_legal(self, x, y, player=None):\n        """\u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0623\u0646\u0647\u0627 \u062d\u0631\u0643\u0629 \u0642\u0627\u0646\u0648\u0646\u064a\u0629"""\n        if player is None:\n            player = self.current_player\n\n        # \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0623\u0646\u0647\u0627 \u0646\u0642\u0637\u0629 \u0641\u0627\u0631\u063a\u0629\n        if self.board[x, y] != self.EMPTY:\n            return False\n\n        # \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u0643\u0648\n        if self.ko_point == (x, y):\n            return False\n\n        # \u0645\u062d\u0627\u0643\u0627\u0629 \u0627\u0644\u062d\u0631\u0643\u0629\n        test_board = self.copy()\n        test_board.board[x, y] = player\n\n        # \u0627\u0644\u062a\u062d\u0642\u0642 \u0623\u0648\u0644\u0627\u064b \u0645\u0646 \u0625\u0645\u0643\u0627\u0646\u064a\u0629 \u0627\u0644\u0623\u0633\u0631\n        opponent = self.get_opponent(player)\n        captured = []\n        for nx, ny in self.get_neighbors(x, y):\n            if test_board.board[nx, ny] == opponent:\n                group, liberties = test_board.get_group(nx, ny)\n                if len(liberties) == 0:\n                    captured.extend(group)\n\n        if captured:\n            return True\n\n        # \u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0644\u0627\u0646\u062a\u062d\u0627\u0631\n        _, liberties = test_board.get_group(x, y)\n        if len(liberties) == 0:\n            return False\n\n        return True\n\n    def play(self, x, y):\n        """\u0648\u0636\u0639 \u062d\u062c\u0631"""\n        if not self.is_legal(x, y):\n            return False\n\n        player = self.current_player\n        opponent = self.get_opponent(player)\n\n        # \u0648\u0636\u0639 \u0627\u0644\u062d\u062c\u0631\n        self.board[x, y] = player\n\n        # \u0627\u0644\u0623\u0633\u0631\n        captured = []\n        for nx, ny in self.get_neighbors(x, y):\n            if self.board[nx, ny] == opponent:\n                group, liberties = self.get_group(nx, ny)\n                if len(liberties) == 0:\n                    captured.extend(group)\n                    self.remove_group(group)\n\n        # \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0643\u0648\n        if len(captured) == 1:\n            cx, cy = list(captured)[0]\n            _, my_liberties = self.get_group(x, y)\n            if len(my_liberties) == 1:\n                self.ko_point = (cx, cy)\n            else:\n                self.ko_point = None\n        else:\n            self.ko_point = None\n\n        # \u062a\u0633\u062c\u064a\u0644 \u0627\u0644\u062a\u0627\u0631\u064a\u062e\n        self.history.append((x, y, player))\n\n        # \u062a\u0628\u062f\u064a\u0644 \u0627\u0644\u0644\u0627\u0639\u0628\n        self.current_player = opponent\n\n        return True\n\n    def pass_move(self):\n        """\u0627\u0644\u062a\u0645\u0631\u064a\u0631 (pass)"""\n        self.history.append((-1, -1, self.current_player))\n        self.current_player = self.get_opponent(self.current_player)\n        self.ko_point = None\n\n    def is_game_over(self):\n        """\u0627\u0644\u062a\u062d\u0642\u0642 \u0645\u0646 \u0627\u0646\u062a\u0647\u0627\u0621 \u0627\u0644\u0644\u0639\u0628\u0629"""\n        if len(self.history) < 2:\n            return False\n        # \u0643\u0644\u0627 \u0627\u0644\u0637\u0631\u0641\u064a\u0646 \u064a\u0645\u0631\u0631\u0627\u0646 \u0645\u062a\u062a\u0627\u0644\u064a\u064a\u0646\n        return (self.history[-1][0] == -1 and\n                self.history[-2][0] == -1)\n\n    def get_legal_moves(self):\n        """\u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u062c\u0645\u064a\u0639 \u0627\u0644\u062d\u0631\u0643\u0627\u062a \u0627\u0644\u0642\u0627\u0646\u0648\u0646\u064a\u0629"""\n        moves = []\n        for x in range(self.size):\n            for y in range(self.size):\n                if self.is_legal(x, y):\n                    moves.append((x, y))\n        moves.append((-1, -1))  # pass\n        return moves\n\n    def score(self):\n        """\u062d\u0633\u0627\u0628 \u0627\u0644\u0646\u062a\u064a\u062c\u0629 (\u0639\u062f \u0627\u0644\u0623\u062d\u062c\u0627\u0631 \u0627\u0644\u0645\u0628\u0633\u0637)"""\n        black_score = np.sum(self.board == self.BLACK)\n        white_score = np.sum(self.board == self.WHITE)\n\n        # \u062d\u0633\u0627\u0628 \u0627\u0644\u0645\u0646\u0637\u0642\u0629 \u0627\u0644\u0645\u0628\u0633\u0637\n        for x in range(self.size):\n            for y in range(self.size):\n                if self.board[x, y] == self.EMPTY:\n                    neighbors = self.get_neighbors(x, y)\n                    colors = set(self.board[nx, ny] for nx, ny in neighbors)\n                    colors.discard(self.EMPTY)\n                    if len(colors) == 1:\n                        if self.BLACK in colors:\n                            black_score += 1\n                        else:\n                            white_score += 1\n\n        komi = 5.5 if self.size == 9 else 7.5\n        return black_score - white_score - komi\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062b\u0627\u0646\u064a\u0629-\u062a\u0631\u0645\u064a\u0632-\u0627\u0644\u0645\u064a\u0632\u0627\u062a",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062b\u0627\u0646\u064a\u0629: \u062a\u0631\u0645\u064a\u0632 \u0627\u0644\u0645\u064a\u0632\u0627\u062a"}),"\n",(0,l.jsx)(e.h3,{id:"\u0645\u064a\u0632\u0627\u062a-\u0627\u0644\u0625\u062f\u062e\u0627\u0644",children:"\u0645\u064a\u0632\u0627\u062a \u0627\u0644\u0625\u062f\u062e\u0627\u0644"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# model/features.py\nimport numpy as np\n\ndef encode_board(board):\n    """\n    \u062a\u0631\u0645\u064a\u0632 \u0627\u0644\u0644\u0648\u062d\u0629 \u0643\u0645\u062f\u062e\u0644 \u0644\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629\n\n    \u0645\u0633\u062a\u0648\u064a\u0627\u062a \u0627\u0644\u0645\u064a\u0632\u0627\u062a:\n    0: \u0623\u062d\u062c\u0627\u0631\u0646\u0627\n    1: \u0623\u062d\u062c\u0627\u0631 \u0627\u0644\u062e\u0635\u0645\n    2: \u0627\u0644\u0646\u0642\u0627\u0637 \u0627\u0644\u0641\u0627\u0631\u063a\u0629\n    3: \u0645\u0648\u0642\u0639 \u0627\u0644\u062d\u0631\u0643\u0629 \u0627\u0644\u0623\u062e\u064a\u0631\u0629\n    4: \u0645\u0648\u0642\u0639 \u0627\u0644\u062d\u0631\u0643\u0629 \u0642\u0628\u0644 \u0627\u0644\u0623\u062e\u064a\u0631\u0629\n    5: \u0645\u0648\u0627\u0642\u0639 \u0627\u0644\u062d\u0631\u0643\u0627\u062a \u0627\u0644\u0642\u0627\u0646\u0648\u0646\u064a\u0629\n    6: \u062f\u0648\u0631 \u0627\u0644\u0623\u0633\u0648\u062f (\u0643\u0644\u0647\u0627 1 \u0623\u0648 \u0643\u0644\u0647\u0627 0)\n    """\n    size = board.size\n    features = np.zeros((7, size, size), dtype=np.float32)\n\n    current = board.current_player\n    opponent = board.get_opponent(current)\n\n    # \u0645\u0648\u0627\u0642\u0639 \u0627\u0644\u0623\u062d\u062c\u0627\u0631 \u0627\u0644\u0623\u0633\u0627\u0633\u064a\u0629\n    features[0] = (board.board == current).astype(np.float32)\n    features[1] = (board.board == opponent).astype(np.float32)\n    features[2] = (board.board == board.EMPTY).astype(np.float32)\n\n    # \u0623\u062d\u062f\u062b \u0627\u0644\u062d\u0631\u0643\u0627\u062a\n    if len(board.history) >= 1:\n        x, y, _ = board.history[-1]\n        if x >= 0:\n            features[3, x, y] = 1.0\n\n    if len(board.history) >= 2:\n        x, y, _ = board.history[-2]\n        if x >= 0:\n            features[4, x, y] = 1.0\n\n    # \u0627\u0644\u062d\u0631\u0643\u0627\u062a \u0627\u0644\u0642\u0627\u0646\u0648\u0646\u064a\u0629\n    for x in range(size):\n        for y in range(size):\n            if board.is_legal(x, y):\n                features[5, x, y] = 1.0\n\n    # \u0645\u0646 \u064a\u0644\u0639\u0628\n    if current == board.BLACK:\n        features[6] = np.ones((size, size), dtype=np.float32)\n\n    return features\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062b\u0627\u0644\u062b\u0629-\u0627\u0644\u0634\u0628\u0643\u0629-\u0627\u0644\u0639\u0635\u0628\u064a\u0629",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062b\u0627\u0644\u062b\u0629: \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629"}),"\n",(0,l.jsx)(e.h3,{id:"\u0628\u0646\u064a\u0629-\u0627\u0644\u0634\u0628\u0643\u0629-\u0628\u0631\u0623\u0633\u064a\u0646",children:"\u0628\u0646\u064a\u0629 \u0627\u0644\u0634\u0628\u0643\u0629 \u0628\u0631\u0623\u0633\u064a\u0646"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# model/network.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResidualBlock(nn.Module):\n    """\u0643\u062a\u0644\u0629 \u0645\u062a\u0628\u0642\u064a\u0629"""\n\n    def __init__(self, channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(channels)\n        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(channels)\n\n    def forward(self, x):\n        residual = x\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        x = F.relu(x + residual)\n        return x\n\n\nclass PolicyValueNetwork(nn.Module):\n    """\u0634\u0628\u0643\u0629 \u0627\u0644\u0633\u064a\u0627\u0633\u0629-\u0627\u0644\u0642\u064a\u0645\u0629 \u0628\u0631\u0623\u0633\u064a\u0646"""\n\n    def __init__(self, board_size=9, input_channels=7, num_filters=64, num_blocks=4):\n        super().__init__()\n        self.board_size = board_size\n\n        # \u0627\u0644\u0627\u0644\u062a\u0641\u0627\u0641 \u0627\u0644\u0623\u0648\u0644\u064a\n        self.conv_input = nn.Conv2d(input_channels, num_filters, 3, padding=1)\n        self.bn_input = nn.BatchNorm2d(num_filters)\n\n        # \u0627\u0644\u0643\u062a\u0644 \u0627\u0644\u0645\u062a\u0628\u0642\u064a\u0629\n        self.residual_blocks = nn.ModuleList([\n            ResidualBlock(num_filters) for _ in range(num_blocks)\n        ])\n\n        # \u0631\u0623\u0633 \u0627\u0644\u0633\u064a\u0627\u0633\u0629\n        self.policy_conv = nn.Conv2d(num_filters, 2, 1)\n        self.policy_bn = nn.BatchNorm2d(2)\n        self.policy_fc = nn.Linear(2 * board_size * board_size, board_size * board_size + 1)\n\n        # \u0631\u0623\u0633 \u0627\u0644\u0642\u064a\u0645\u0629\n        self.value_conv = nn.Conv2d(num_filters, 1, 1)\n        self.value_bn = nn.BatchNorm2d(1)\n        self.value_fc1 = nn.Linear(board_size * board_size, 64)\n        self.value_fc2 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        # \u0627\u0644\u062c\u0630\u0639 \u0627\u0644\u0645\u0634\u062a\u0631\u0643\n        x = F.relu(self.bn_input(self.conv_input(x)))\n        for block in self.residual_blocks:\n            x = block(x)\n\n        # \u0631\u0623\u0633 \u0627\u0644\u0633\u064a\u0627\u0633\u0629\n        policy = F.relu(self.policy_bn(self.policy_conv(x)))\n        policy = policy.view(policy.size(0), -1)\n        policy = self.policy_fc(policy)\n        policy = F.log_softmax(policy, dim=1)\n\n        # \u0631\u0623\u0633 \u0627\u0644\u0642\u064a\u0645\u0629\n        value = F.relu(self.value_bn(self.value_conv(x)))\n        value = value.view(value.size(0), -1)\n        value = F.relu(self.value_fc1(value))\n        value = torch.tanh(self.value_fc2(value))\n\n        return policy, value\n\n\ndef create_network(board_size=9):\n    """\u0625\u0646\u0634\u0627\u0621 \u0627\u0644\u0634\u0628\u0643\u0629"""\n    return PolicyValueNetwork(\n        board_size=board_size,\n        input_channels=7,\n        num_filters=64,\n        num_blocks=4\n    )\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0631\u0627\u0628\u0639\u0629-\u062a\u0646\u0641\u064a\u0630-mcts",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0631\u0627\u0628\u0639\u0629: \u062a\u0646\u0641\u064a\u0630 MCTS"}),"\n",(0,l.jsx)(e.h3,{id:"\u0641\u0626\u0629-\u0627\u0644\u0639\u0642\u062f\u0629",children:"\u0641\u0626\u0629 \u0627\u0644\u0639\u0642\u062f\u0629"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# mcts/node.py\nimport numpy as np\n\nclass MCTSNode:\n    """\u0639\u0642\u062f\u0629 MCTS"""\n\n    def __init__(self, prior=0.0):\n        self.visit_count = 0\n        self.value_sum = 0.0\n        self.prior = prior\n        self.children = {}\n\n    @property\n    def value(self):\n        if self.visit_count == 0:\n            return 0.0\n        return self.value_sum / self.visit_count\n\n    def expand(self, policy, legal_moves):\n        """\u062a\u0648\u0633\u064a\u0639 \u0627\u0644\u0639\u0642\u062f\u0629"""\n        for move in legal_moves:\n            if move not in self.children:\n                idx = move[0] * 9 + move[1] if move[0] >= 0 else 81\n                self.children[move] = MCTSNode(prior=np.exp(policy[idx]))\n\n    def select_child(self, c_puct=1.5):\n        """\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u0639\u0642\u062f\u0629 \u0627\u0644\u0641\u0631\u0639\u064a\u0629 \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 PUCT"""\n        best_score = -float(\'inf\')\n        best_move = None\n        best_child = None\n\n        sqrt_total = np.sqrt(max(1, self.visit_count))\n\n        for move, child in self.children.items():\n            if child.visit_count > 0:\n                q_value = child.value\n            else:\n                q_value = 0.0\n\n            u_value = c_puct * child.prior * sqrt_total / (1 + child.visit_count)\n            score = q_value + u_value\n\n            if score > best_score:\n                best_score = score\n                best_move = move\n                best_child = child\n\n        return best_move, best_child\n'})}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u0646\u0641\u064a\u0630-\u0627\u0644\u0628\u062d\u062b",children:"\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0628\u062d\u062b"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# mcts/search.py\nimport numpy as np\nimport torch\nfrom .node import MCTSNode\n\nclass MCTS:\n    """\u0628\u062d\u062b \u0634\u062c\u0631\u0629 \u0645\u0648\u0646\u062a \u0643\u0627\u0631\u0644\u0648"""\n\n    def __init__(self, network, board_size=9, num_simulations=100, c_puct=1.5):\n        self.network = network\n        self.board_size = board_size\n        self.num_simulations = num_simulations\n        self.c_puct = c_puct\n\n    def search(self, board, add_noise=False):\n        """\u062a\u0646\u0641\u064a\u0630 \u0628\u062d\u062b MCTS"""\n        root = MCTSNode()\n\n        # \u062a\u0642\u064a\u064a\u0645 \u0639\u0642\u062f\u0629 \u0627\u0644\u062c\u0630\u0631\n        policy, value = self.evaluate(board)\n        legal_moves = board.get_legal_moves()\n        root.expand(policy, legal_moves)\n\n        # \u0625\u0636\u0627\u0641\u0629 \u0636\u0648\u0636\u0627\u0621 Dirichlet (\u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062f\u0631\u064a\u0628)\n        if add_noise:\n            self.add_dirichlet_noise(root)\n\n        # \u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0645\u062d\u0627\u0643\u0627\u0629\n        for _ in range(self.num_simulations):\n            node = root\n            scratch_board = board.copy()\n            path = [node]\n\n            # Selection\n            while node.children and scratch_board.get_legal_moves():\n                move, node = node.select_child(self.c_puct)\n                if move[0] >= 0:\n                    scratch_board.play(move[0], move[1])\n                else:\n                    scratch_board.pass_move()\n                path.append(node)\n\n                if scratch_board.is_game_over():\n                    break\n\n            # Expansion + Evaluation\n            if not scratch_board.is_game_over():\n                policy, value = self.evaluate(scratch_board)\n                legal_moves = scratch_board.get_legal_moves()\n                if legal_moves:\n                    node.expand(policy, legal_moves)\n\n            # \u062d\u0633\u0627\u0628 \u0627\u0644\u0642\u064a\u0645\u0629 \u0645\u0646 \u0645\u0646\u0638\u0648\u0631 \u0646\u0642\u0637\u0629 \u0628\u062f\u0627\u064a\u0629 \u0627\u0644\u0628\u062d\u062b\n            if scratch_board.is_game_over():\n                score = scratch_board.score()\n                value = 1.0 if score > 0 else (-1.0 if score < 0 else 0.0)\n                if board.current_player != scratch_board.BLACK:\n                    value = -value\n\n            # Backpropagation\n            for node in reversed(path):\n                node.visit_count += 1\n                node.value_sum += value\n                value = -value\n\n        return root\n\n    def evaluate(self, board):\n        """\u0627\u0644\u062a\u0642\u064a\u064a\u0645 \u0628\u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629"""\n        from model.features import encode_board\n\n        features = encode_board(board)\n        features = torch.tensor(features).unsqueeze(0)\n\n        self.network.eval()\n        with torch.no_grad():\n            policy, value = self.network(features)\n\n        return policy[0].numpy(), value[0].item()\n\n    def add_dirichlet_noise(self, root, alpha=0.3, epsilon=0.25):\n        """\u0625\u0636\u0627\u0641\u0629 \u0636\u0648\u0636\u0627\u0621 \u0627\u0633\u062a\u0643\u0634\u0627\u0641"""\n        noise = np.random.dirichlet([alpha] * len(root.children))\n        for i, child in enumerate(root.children.values()):\n            child.prior = (1 - epsilon) * child.prior + epsilon * noise[i]\n\n    def get_policy(self, root, temperature=1.0):\n        """\u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0633\u064a\u0627\u0633\u0629 \u0645\u0646 \u0646\u062a\u0627\u0626\u062c \u0627\u0644\u0628\u062d\u062b"""\n        visits = np.zeros(self.board_size ** 2 + 1)\n\n        for move, child in root.children.items():\n            idx = move[0] * self.board_size + move[1] if move[0] >= 0 else self.board_size ** 2\n            visits[idx] = child.visit_count\n\n        if temperature == 0:\n            policy = np.zeros_like(visits)\n            policy[np.argmax(visits)] = 1.0\n        else:\n            visits = visits ** (1 / temperature)\n            policy = visits / visits.sum()\n\n        return policy\n\n    def select_move(self, root, temperature=1.0):\n        """\u0627\u062e\u062a\u064a\u0627\u0631 \u0627\u0644\u062d\u0631\u0643\u0629"""\n        policy = self.get_policy(root, temperature)\n        idx = np.random.choice(len(policy), p=policy)\n\n        if idx == self.board_size ** 2:\n            return (-1, -1)\n        else:\n            return (idx // self.board_size, idx % self.board_size)\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u062e\u0627\u0645\u0633\u0629-\u0627\u0644\u0644\u0639\u0628-\u0627\u0644\u0630\u0627\u062a\u064a",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u062e\u0627\u0645\u0633\u0629: \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:"# training/self_play.py\nimport numpy as np\nfrom game.board import Board\nfrom model.features import encode_board\n\ndef self_play_game(mcts, temperature=1.0, temp_threshold=30):\n    \"\"\"\u062a\u0646\u0641\u064a\u0630 \u0645\u0628\u0627\u0631\u0627\u0629 \u0644\u0639\u0628 \u0630\u0627\u062a\u064a\"\"\"\n    board = Board(size=9)\n    game_history = []\n\n    move_count = 0\n    while not board.is_game_over() and move_count < 200:\n        # \u0628\u062d\u062b MCTS\n        root = mcts.search(board, add_noise=True)\n\n        # \u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0633\u064a\u0627\u0633\u0629\n        temp = temperature if move_count < temp_threshold else 0.0\n        policy = mcts.get_policy(root, temp)\n\n        # \u062a\u0633\u062c\u064a\u0644 \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n        features = encode_board(board)\n        game_history.append({\n            'features': features,\n            'policy': policy,\n            'player': board.current_player\n        })\n\n        # \u0627\u062e\u062a\u064a\u0627\u0631 \u0648\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u062d\u0631\u0643\u0629\n        move = mcts.select_move(root, temp)\n        if move[0] >= 0:\n            board.play(move[0], move[1])\n        else:\n            board.pass_move()\n\n        move_count += 1\n\n    # \u062d\u0633\u0627\u0628 \u0627\u0644\u0641\u0627\u0626\u0632\n    score = board.score()\n    winner = Board.BLACK if score > 0 else (Board.WHITE if score < 0 else 0)\n\n    # \u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0642\u064a\u0645\n    for data in game_history:\n        if winner == 0:\n            data['value'] = 0.0\n        elif data['player'] == winner:\n            data['value'] = 1.0\n        else:\n            data['value'] = -1.0\n\n    return game_history\n\n\ndef generate_training_data(mcts, num_games=100):\n    \"\"\"\u062a\u0648\u0644\u064a\u062f \u0628\u064a\u0627\u0646\u0627\u062a \u0627\u0644\u062a\u062f\u0631\u064a\u0628\"\"\"\n    all_data = []\n\n    for i in range(num_games):\n        print(f\"\u0645\u0628\u0627\u0631\u0627\u0629 \u0644\u0639\u0628 \u0630\u0627\u062a\u064a {i+1}/{num_games}\")\n        game_data = self_play_game(mcts)\n        all_data.extend(game_data)\n\n    return all_data\n"})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0633\u0627\u062f\u0633\u0629-\u0627\u0644\u0645\u062f\u0631\u0628",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0633\u0627\u062f\u0633\u0629: \u0627\u0644\u0645\u062f\u0631\u0628"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# training/trainer.py\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\n\nclass Trainer:\n    """\u0627\u0644\u0645\u062f\u0631\u0628"""\n\n    def __init__(self, network, learning_rate=0.001):\n        self.network = network\n        self.optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n\n    def train_step(self, batch):\n        """\u062e\u0637\u0648\u0629 \u062a\u062f\u0631\u064a\u0628 \u0648\u0627\u062d\u062f\u0629"""\n        features, target_policy, target_value = batch\n\n        self.network.train()\n        self.optimizer.zero_grad()\n\n        # \u0627\u0644\u062a\u0645\u0631\u064a\u0631 \u0627\u0644\u0623\u0645\u0627\u0645\u064a\n        pred_policy, pred_value = self.network(features)\n\n        # \u062d\u0633\u0627\u0628 \u0627\u0644\u062e\u0633\u0627\u0631\u0629\n        policy_loss = F.kl_div(pred_policy, target_policy, reduction=\'batchmean\')\n        value_loss = F.mse_loss(pred_value.squeeze(), target_value)\n        total_loss = policy_loss + value_loss\n\n        # \u0627\u0644\u062a\u0645\u0631\u064a\u0631 \u0627\u0644\u0639\u0643\u0633\u064a\n        total_loss.backward()\n        self.optimizer.step()\n\n        return {\n            \'total_loss\': total_loss.item(),\n            \'policy_loss\': policy_loss.item(),\n            \'value_loss\': value_loss.item()\n        }\n\n    def train_epoch(self, data, batch_size=32):\n        """\u062a\u062f\u0631\u064a\u0628 epoch \u0648\u0627\u062d\u062f"""\n        # \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0628\u064a\u0627\u0646\u0627\u062a\n        features = np.array([d[\'features\'] for d in data])\n        policies = np.array([d[\'policy\'] for d in data])\n        values = np.array([d[\'value\'] for d in data])\n\n        features = torch.tensor(features, dtype=torch.float32)\n        policies = torch.tensor(policies, dtype=torch.float32)\n        values = torch.tensor(values, dtype=torch.float32)\n\n        dataset = TensorDataset(features, policies, values)\n        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n        total_losses = []\n        for batch in loader:\n            losses = self.train_step(batch)\n            total_losses.append(losses[\'total_loss\'])\n\n        return np.mean(total_losses)\n\n    def save(self, path):\n        """\u062d\u0641\u0638 \u0627\u0644\u0646\u0645\u0648\u0630\u062c"""\n        torch.save(self.network.state_dict(), path)\n\n    def load(self, path):\n        """\u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c"""\n        self.network.load_state_dict(torch.load(path))\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062e\u0637\u0648\u0629-\u0627\u0644\u0633\u0627\u0628\u0639\u0629-\u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c-\u0627\u0644\u0631\u0626\u064a\u0633\u064a",children:"\u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0633\u0627\u0628\u0639\u0629: \u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c \u0627\u0644\u0631\u0626\u064a\u0633\u064a"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-python",children:'# main.py\nfrom model.network import create_network\nfrom mcts.search import MCTS\nfrom training.self_play import generate_training_data\nfrom training.trainer import Trainer\n\ndef main():\n    # \u0625\u0646\u0634\u0627\u0621 \u0627\u0644\u0634\u0628\u0643\u0629\n    network = create_network(board_size=9)\n    mcts = MCTS(network, board_size=9, num_simulations=100)\n    trainer = Trainer(network)\n\n    # \u062f\u0648\u0631\u0629 \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n    num_iterations = 100\n    games_per_iteration = 50\n    epochs_per_iteration = 10\n\n    for iteration in range(num_iterations):\n        print(f"\\n=== \u0627\u0644\u062a\u0643\u0631\u0627\u0631 {iteration + 1}/{num_iterations} ===")\n\n        # \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a\n        print("\u062a\u0648\u0644\u064a\u062f \u0645\u0628\u0627\u0631\u064a\u0627\u062a \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a...")\n        training_data = generate_training_data(mcts, num_games=games_per_iteration)\n\n        # \u0627\u0644\u062a\u062f\u0631\u064a\u0628\n        print("\u0627\u0644\u062a\u062f\u0631\u064a\u0628...")\n        for epoch in range(epochs_per_iteration):\n            loss = trainer.train_epoch(training_data)\n            print(f"  Epoch {epoch + 1}: loss = {loss:.4f}")\n\n        # \u0627\u0644\u062d\u0641\u0638\n        trainer.save(f"model_iter_{iteration + 1}.pt")\n\n    print("\\n\u0627\u0643\u062a\u0645\u0644 \u0627\u0644\u062a\u062f\u0631\u064a\u0628!")\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0644\u062a\u0634\u063a\u064a\u0644-\u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631",children:"\u0627\u0644\u062a\u0634\u063a\u064a\u0644 \u0648\u0627\u0644\u0627\u062e\u062a\u0628\u0627\u0631"}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u062b\u0628\u064a\u062a-\u0627\u0644\u062a\u0628\u0639\u064a\u0627\u062a",children:"\u062a\u062b\u0628\u064a\u062a \u0627\u0644\u062a\u0628\u0639\u064a\u0627\u062a"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-bash",children:"pip install torch numpy\n"})}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u0634\u063a\u064a\u0644-\u0627\u0644\u062a\u062f\u0631\u064a\u0628",children:"\u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u062a\u062f\u0631\u064a\u0628"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{className:"language-bash",children:"python main.py\n"})}),"\n",(0,l.jsx)(e.h3,{id:"\u0627\u0644\u0645\u062e\u0631\u062c\u0627\u062a-\u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629",children:"\u0627\u0644\u0645\u062e\u0631\u062c\u0627\u062a \u0627\u0644\u0645\u062a\u0648\u0642\u0639\u0629"}),"\n",(0,l.jsx)(e.pre,{children:(0,l.jsx)(e.code,{children:"=== \u0627\u0644\u062a\u0643\u0631\u0627\u0631 1/100 ===\n\u062a\u0648\u0644\u064a\u062f \u0645\u0628\u0627\u0631\u064a\u0627\u062a \u0627\u0644\u0644\u0639\u0628 \u0627\u0644\u0630\u0627\u062a\u064a...\n\u0645\u0628\u0627\u0631\u0627\u0629 \u0644\u0639\u0628 \u0630\u0627\u062a\u064a 1/50\n\u0645\u0628\u0627\u0631\u0627\u0629 \u0644\u0639\u0628 \u0630\u0627\u062a\u064a 2/50\n...\n\u0627\u0644\u062a\u062f\u0631\u064a\u0628...\n  Epoch 1: loss = 2.3456\n  Epoch 2: loss = 1.8765\n  ...\n"})}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0627\u0642\u062a\u0631\u0627\u062d\u0627\u062a-\u0627\u0644\u062a\u062d\u0633\u064a\u0646",children:"\u0627\u0642\u062a\u0631\u0627\u062d\u0627\u062a \u0627\u0644\u062a\u062d\u0633\u064a\u0646"}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a-\u0642\u0635\u064a\u0631\u0629-\u0627\u0644\u0645\u062f\u0649",children:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a \u0642\u0635\u064a\u0631\u0629 \u0627\u0644\u0645\u062f\u0649"}),"\n",(0,l.jsxs)(e.table,{children:[(0,l.jsx)(e.thead,{children:(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.th,{children:"\u0639\u0646\u0635\u0631 \u0627\u0644\u062a\u062d\u0633\u064a\u0646"}),(0,l.jsx)(e.th,{children:"\u0627\u0644\u0648\u0635\u0641"})]})}),(0,l.jsxs)(e.tbody,{children:[(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u0632\u064a\u0627\u062f\u0629 \u0627\u0644\u0643\u062a\u0644 \u0627\u0644\u0645\u062a\u0628\u0642\u064a\u0629"}),(0,l.jsx)(e.td,{children:"4 \u2192 8 \u2192 16 \u0643\u062a\u0644\u0629"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u0632\u064a\u0627\u062f\u0629 \u0639\u062f\u062f \u0627\u0644\u0642\u0646\u0648\u0627\u062a"}),(0,l.jsx)(e.td,{children:"64 \u2192 128 \u2192 256"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u0632\u064a\u0627\u062f\u0629 \u0639\u062f\u062f \u0627\u0644\u0645\u062d\u0627\u0643\u0627\u0629"}),(0,l.jsx)(e.td,{children:"100 \u2192 400 \u2192 800"})]}),(0,l.jsxs)(e.tr,{children:[(0,l.jsx)(e.td,{children:"\u0645\u062c\u0645\u0648\u0639\u0629 \u062a\u062f\u0631\u064a\u0628 \u0623\u0643\u0628\u0631"}),(0,l.jsx)(e.td,{children:"50 \u2192 200 \u2192 1000 \u0645\u0628\u0627\u0631\u0627\u0629/\u062a\u0643\u0631\u0627\u0631"})]})]})]}),"\n",(0,l.jsx)(e.h3,{id:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a-\u0637\u0648\u064a\u0644\u0629-\u0627\u0644\u0645\u062f\u0649",children:"\u062a\u062d\u0633\u064a\u0646\u0627\u062a \u0637\u0648\u064a\u0644\u0629 \u0627\u0644\u0645\u062f\u0649"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsx)(e.li,{children:"\u062f\u0639\u0645 \u0644\u0648\u062d\u0629 19\xd719"}),"\n",(0,l.jsx)(e.li,{children:"\u0625\u0636\u0627\u0641\u0629 \u0623\u0647\u062f\u0627\u0641 \u062a\u062f\u0631\u064a\u0628 \u0645\u0633\u0627\u0639\u062f\u0629 (\u062a\u0648\u0642\u0639 \u0627\u0644\u0645\u0646\u0637\u0642\u0629)"}),"\n",(0,l.jsx)(e.li,{children:"\u062a\u0646\u0641\u064a\u0630 \u0644\u0639\u0628 \u0630\u0627\u062a\u064a \u0645\u062a\u0648\u0627\u0632\u064a"}),"\n",(0,l.jsx)(e.li,{children:"\u0625\u0636\u0627\u0641\u0629 \u062a\u0633\u0631\u064a\u0639 GPU"}),"\n"]}),"\n",(0,l.jsx)(e.hr,{}),"\n",(0,l.jsx)(e.h2,{id:"\u0642\u0631\u0627\u0621\u0627\u062a-\u0625\u0636\u0627\u0641\u064a\u0629",children:"\u0642\u0631\u0627\u0621\u0627\u062a \u0625\u0636\u0627\u0641\u064a\u0629"}),"\n",(0,l.jsxs)(e.ul,{children:["\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.a,{href:"../neural-network",children:"\u0634\u0631\u062d \u0628\u0646\u064a\u0629 \u0627\u0644\u0634\u0628\u0643\u0629 \u0627\u0644\u0639\u0635\u0628\u064a\u0629"})," \u2014 \u062a\u0635\u0645\u064a\u0645 \u0634\u0628\u0643\u0629 \u0623\u0639\u0645\u0642"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.a,{href:"../mcts-implementation",children:"\u062a\u0641\u0627\u0635\u064a\u0644 \u062a\u0646\u0641\u064a\u0630 MCTS"})," \u2014 \u062a\u0642\u0646\u064a\u0627\u062a \u0628\u062d\u062b \u0645\u062a\u0642\u062f\u0645\u0629"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.a,{href:"../training",children:"\u062a\u062d\u0644\u064a\u0644 \u0622\u0644\u064a\u0629 \u062a\u062f\u0631\u064a\u0628 KataGo"})," \u2014 \u0646\u0638\u0627\u0645 \u062a\u062f\u0631\u064a\u0628 \u0628\u0645\u0633\u062a\u0648\u0649 \u0625\u0646\u062a\u0627\u062c\u064a"]}),"\n",(0,l.jsxs)(e.li,{children:[(0,l.jsx)(e.a,{href:"../papers",children:"\u062f\u0644\u064a\u0644 \u0642\u0631\u0627\u0621\u0629 \u0627\u0644\u0623\u0648\u0631\u0627\u0642 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629"})," \u2014 \u0627\u0644\u0623\u0633\u0627\u0633 \u0627\u0644\u0646\u0638\u0631\u064a"]}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,l.jsx)(e,{...n,children:(0,l.jsx)(c,{...n})}):c(n)}},30416(n,e,r){r.d(e,{R:()=>i,x:()=>t});var s=r(59471);const l={},o=s.createContext(l);function i(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(l):n.components||l:i(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);